<rss version="2.0">
  <channel>
    <title>GitHub Python Weekly Trending</title>
    <description>Weekly Trending of Python in GitHub</description>
    <pubDate>Wed, 14 Jan 2026 01:48:42 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>VectifyAI/PageIndex</title>
      <link>https://github.com/VectifyAI/PageIndex</link>
      <description>&lt;p&gt;üìë PageIndex: Document Index for Reasoning-based RAG&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a href="https://vectify.ai/pageindex" target="_blank"&gt; &lt;img src="https://github.com/user-attachments/assets/46201e72-675b-43bc-bfbd-081cc6b65a1d" alt="PageIndex Banner" /&gt; &lt;/a&gt; 
 &lt;br /&gt; 
 &lt;br /&gt; 
 &lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/14736" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/14736" alt="VectifyAI%2FPageIndex | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;p align="center"&gt;&lt;b&gt;Reasoning-based RAG&amp;nbsp; ‚ó¶ &amp;nbsp;No Vector DB&amp;nbsp; ‚ó¶ &amp;nbsp;No Chunking&amp;nbsp; ‚ó¶ &amp;nbsp;Human-like Retrieval&lt;/b&gt;&lt;/p&gt; 
 &lt;h4 align="center"&gt; &lt;a href="https://vectify.ai"&gt;üè† Homepage&lt;/a&gt;&amp;nbsp; ‚Ä¢ &amp;nbsp; &lt;a href="https://chat.pageindex.ai"&gt;üñ•Ô∏è Chat Platform&lt;/a&gt;&amp;nbsp; ‚Ä¢ &amp;nbsp; &lt;a href="https://pageindex.ai/mcp"&gt;üîå MCP&lt;/a&gt;&amp;nbsp; ‚Ä¢ &amp;nbsp; &lt;a href="https://docs.pageindex.ai"&gt;üìö Docs&lt;/a&gt;&amp;nbsp; ‚Ä¢ &amp;nbsp; &lt;a href="https://discord.com/invite/VuXuf29EUj"&gt;üí¨ Discord&lt;/a&gt;&amp;nbsp; ‚Ä¢ &amp;nbsp; &lt;a href="https://ii2abc2jejf.typeform.com/to/tK3AXl8T"&gt;‚úâÔ∏è Contact&lt;/a&gt;&amp;nbsp; &lt;/h4&gt; 
&lt;/div&gt; 
&lt;details open&gt; 
 &lt;summary&gt;&lt;h2&gt;üì¢ Latest Updates&lt;/h2&gt;&lt;/summary&gt; 
 &lt;p&gt;&lt;strong&gt;üî• Releases:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://chat.pageindex.ai"&gt;&lt;strong&gt;PageIndex Chat&lt;/strong&gt;&lt;/a&gt;: The first human-like document-analysis agent &lt;a href="https://chat.pageindex.ai"&gt;platform&lt;/a&gt; built for professional long documents. Can also be integrated via &lt;a href="https://pageindex.ai/mcp"&gt;MCP&lt;/a&gt; or &lt;a href="https://docs.pageindex.ai/quickstart"&gt;API&lt;/a&gt; (beta).&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;!-- - [**PageIndex Chat API**](https://docs.pageindex.ai/quickstart): An API that brings PageIndex's advanced long-document intelligence directly into your applications and workflows. --&gt; 
 &lt;!-- - [PageIndex MCP](https://pageindex.ai/mcp): Bring PageIndex into Claude, Cursor, or any MCP-enabled agent. Chat with long PDFs in a reasoning-based, human-like way. --&gt; 
 &lt;p&gt;&lt;strong&gt;üìù Articles:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://pageindex.ai/blog/pageindex-intro"&gt;&lt;strong&gt;PageIndex Framework&lt;/strong&gt;&lt;/a&gt;: Introduces the PageIndex framework ‚Äî an &lt;em&gt;agentic, in-context&lt;/em&gt; &lt;em&gt;tree index&lt;/em&gt; that enables LLMs to perform &lt;em&gt;reasoning-based&lt;/em&gt;, &lt;em&gt;human-like retrieval&lt;/em&gt; over long documents, without vector DB or chunking.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;!-- - [Do We Still Need OCR?](https://pageindex.ai/blog/do-we-need-ocr): Explores how vision-based, reasoning-native RAG challenges the traditional OCR pipeline, and why the future of document AI might be *vectorless* and *vision-based*. --&gt; 
 &lt;p&gt;&lt;strong&gt;üß™ Cookbooks:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://docs.pageindex.ai/cookbook/vectorless-rag-pageindex"&gt;Vectorless RAG&lt;/a&gt;: A minimal, hands-on example of reasoning-based RAG using PageIndex. No vectors, no chunking, and human-like retrieval.&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://docs.pageindex.ai/cookbook/vision-rag-pageindex"&gt;Vision-based Vectorless RAG&lt;/a&gt;: OCR-free, vision-only RAG with PageIndex's reasoning-native retrieval workflow that works directly over PDF page images.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;h1&gt;üìë Introduction to PageIndex&lt;/h1&gt; 
&lt;p&gt;Are you frustrated with vector database retrieval accuracy for long professional documents? Traditional vector-based RAG relies on semantic &lt;em&gt;similarity&lt;/em&gt; rather than true &lt;em&gt;relevance&lt;/em&gt;. But &lt;strong&gt;similarity ‚â† relevance&lt;/strong&gt; ‚Äî what we truly need in retrieval is &lt;strong&gt;relevance&lt;/strong&gt;, and that requires &lt;strong&gt;reasoning&lt;/strong&gt;. When working with professional documents that demand domain expertise and multi-step reasoning, similarity search often falls short.&lt;/p&gt; 
&lt;p&gt;Inspired by AlphaGo, we propose &lt;strong&gt;&lt;a href="https://vectify.ai/pageindex"&gt;PageIndex&lt;/a&gt;&lt;/strong&gt; ‚Äî a &lt;strong&gt;vectorless&lt;/strong&gt;, &lt;strong&gt;reasoning-based RAG&lt;/strong&gt; system that builds a &lt;strong&gt;hierarchical tree index&lt;/strong&gt; from long documents and uses LLMs to &lt;strong&gt;reason&lt;/strong&gt; &lt;em&gt;over that index&lt;/em&gt; for &lt;strong&gt;agentic, context-aware retrieval&lt;/strong&gt;. It simulates how &lt;em&gt;human experts&lt;/em&gt; navigate and extract knowledge from complex documents through &lt;em&gt;tree search&lt;/em&gt;, enabling LLMs to &lt;em&gt;think&lt;/em&gt; and &lt;em&gt;reason&lt;/em&gt; their way to the most relevant document sections. PageIndex performs retrieval in two steps:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Generate a ‚ÄúTable-of-Contents‚Äù &lt;strong&gt;tree structure index&lt;/strong&gt; of documents&lt;/li&gt; 
 &lt;li&gt;Perform reasoning-based retrieval through &lt;strong&gt;tree search&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://pageindex.ai/blog/pageindex-intro" target="_blank" title="The PageIndex Framework"&gt; &lt;img src="https://docs.pageindex.ai/images/cookbook/vectorless-rag.png" width="70%" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h3&gt;üéØ Features&lt;/h3&gt; 
&lt;p&gt;Compared to traditional vector-based RAG, &lt;strong&gt;PageIndex&lt;/strong&gt; features:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;No Vector DB&lt;/strong&gt;: Uses document structure and LLM reasoning for retrieval, instead of vector similarity search.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;No Chunking&lt;/strong&gt;: Documents are organized into natural sections, not artificial chunks.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Human-like Retrieval&lt;/strong&gt;: Simulates how human experts navigate and extract knowledge from complex documents.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Better Explainability and Traceability&lt;/strong&gt;: Retrieval is based on reasoning ‚Äî traceable and interpretable, with page and section references. No more opaque, approximate vector search (‚Äúvibe retrieval‚Äù).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;PageIndex powers a reasoning-based RAG system that achieved &lt;strong&gt;state-of-the-art&lt;/strong&gt; &lt;a href="https://github.com/VectifyAI/Mafin2.5-FinanceBench"&gt;98.7% accuracy&lt;/a&gt; on FinanceBench, demonstrating superior performance over vector-based RAG solutions in professional document analysis (see our &lt;a href="https://vectify.ai/blog/Mafin2.5"&gt;blog post&lt;/a&gt; for details).&lt;/p&gt; 
&lt;h3&gt;üìç Explore PageIndex&lt;/h3&gt; 
&lt;p&gt;To learn more, please see a detailed introduction of the &lt;a href="https://pageindex.ai/blog/pageindex-intro"&gt;PageIndex framework&lt;/a&gt;. Check out this GitHub repo for open-source code, and the &lt;a href="https://docs.pageindex.ai/cookbook"&gt;cookbooks&lt;/a&gt;, &lt;a href="https://docs.pageindex.ai/tutorials"&gt;tutorials&lt;/a&gt;, and &lt;a href="https://pageindex.ai/blog"&gt;blog&lt;/a&gt; for additional usage guides and examples.&lt;/p&gt; 
&lt;p&gt;The PageIndex service is available as a ChatGPT-style &lt;a href="https://chat.pageindex.ai"&gt;chat platform&lt;/a&gt;, or can be integrated via &lt;a href="https://pageindex.ai/mcp"&gt;MCP&lt;/a&gt; or &lt;a href="https://docs.pageindex.ai/quickstart"&gt;API&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;üõ†Ô∏è Deployment Options&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Self-host ‚Äî run locally with this open-source repo.&lt;/li&gt; 
 &lt;li&gt;Cloud Service ‚Äî try instantly with our &lt;a href="https://chat.pageindex.ai/"&gt;Chat Platform&lt;/a&gt;, or integrate with &lt;a href="https://pageindex.ai/mcp"&gt;MCP&lt;/a&gt; or &lt;a href="https://docs.pageindex.ai/quickstart"&gt;API&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;Enterprise&lt;/em&gt; ‚Äî private or on-prem deployment. &lt;a href="https://ii2abc2jejf.typeform.com/to/tK3AXl8T"&gt;Contact us&lt;/a&gt; or &lt;a href="https://calendly.com/pageindex/meet"&gt;book a demo&lt;/a&gt; for more details.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üß™ Quick Hands-on&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Try the &lt;a href="https://github.com/VectifyAI/PageIndex/raw/main/cookbook/pageindex_RAG_simple.ipynb"&gt;&lt;strong&gt;Vectorless RAG&lt;/strong&gt;&lt;/a&gt; notebook ‚Äî a &lt;em&gt;minimal&lt;/em&gt;, hands-on example of reasoning-based RAG using PageIndex.&lt;/li&gt; 
 &lt;li&gt;Experiment with &lt;a href="https://github.com/VectifyAI/PageIndex/raw/main/cookbook/vision_RAG_pageindex.ipynb"&gt;&lt;em&gt;Vision-based Vectorless RAG&lt;/em&gt;&lt;/a&gt; ‚Äî no OCR; a minimal, reasoning-native RAG pipeline that works directly over page images.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://colab.research.google.com/github/VectifyAI/PageIndex/blob/main/cookbook/pageindex_RAG_simple.ipynb" target="_blank" rel="noopener"&gt; &lt;img src="https://img.shields.io/badge/Open_In_Colab-Vectorless_RAG-orange?style=for-the-badge&amp;amp;logo=googlecolab" alt="Open in Colab: Vectorless RAG" /&gt; &lt;/a&gt; &amp;nbsp;&amp;nbsp; 
 &lt;a href="https://colab.research.google.com/github/VectifyAI/PageIndex/blob/main/cookbook/vision_RAG_pageindex.ipynb" target="_blank" rel="noopener"&gt; &lt;img src="https://img.shields.io/badge/Open_In_Colab-Vision_RAG-orange?style=for-the-badge&amp;amp;logo=googlecolab" alt="Open in Colab: Vision RAG" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h1&gt;üå≤ PageIndex Tree Structure&lt;/h1&gt; 
&lt;p&gt;PageIndex can transform lengthy PDF documents into a semantic &lt;strong&gt;tree structure&lt;/strong&gt;, similar to a &lt;em&gt;"table of contents"&lt;/em&gt; but optimized for use with Large Language Models (LLMs). It's ideal for: financial reports, regulatory filings, academic textbooks, legal or technical manuals, and any document that exceeds LLM context limits.&lt;/p&gt; 
&lt;p&gt;Below is an example PageIndex tree structure. Also see more example &lt;a href="https://github.com/VectifyAI/PageIndex/tree/main/tests/pdfs"&gt;documents&lt;/a&gt; and generated &lt;a href="https://github.com/VectifyAI/PageIndex/tree/main/tests/results"&gt;tree structures&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-jsonc"&gt;...
{
  "title": "Financial Stability",
  "node_id": "0006",
  "start_index": 21,
  "end_index": 22,
  "summary": "The Federal Reserve ...",
  "nodes": [
    {
      "title": "Monitoring Financial Vulnerabilities",
      "node_id": "0007",
      "start_index": 22,
      "end_index": 28,
      "summary": "The Federal Reserve's monitoring ..."
    },
    {
      "title": "Domestic and International Cooperation and Coordination",
      "node_id": "0008",
      "start_index": 28,
      "end_index": 31,
      "summary": "In 2023, the Federal Reserve collaborated ..."
    }
  ]
}
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can generate the PageIndex tree structure with this open-source repo, or use our &lt;a href="https://docs.pageindex.ai/quickstart"&gt;API&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h1&gt;‚öôÔ∏è Package Usage&lt;/h1&gt; 
&lt;p&gt;You can follow these steps to generate a PageIndex tree from a PDF document.&lt;/p&gt; 
&lt;h3&gt;1. Install dependencies&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip3 install --upgrade -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. Set your OpenAI API key&lt;/h3&gt; 
&lt;p&gt;Create a &lt;code&gt;.env&lt;/code&gt; file in the root directory and add your API key:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;CHATGPT_API_KEY=your_openai_key_here
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;3. Run PageIndex on your PDF&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python3 run_pageindex.py --pdf_path /path/to/your/document.pdf
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Optional parameters&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; You can customize the processing with additional optional arguments: 
 &lt;pre&gt;&lt;code&gt;--model                 OpenAI model to use (default: gpt-4o-2024-11-20)
--toc-check-pages       Pages to check for table of contents (default: 20)
--max-pages-per-node    Max pages per node (default: 10)
--max-tokens-per-node   Max tokens per node (default: 20000)
--if-add-node-id        Add node ID (yes/no, default: yes)
--if-add-node-summary   Add node summary (yes/no, default: yes)
--if-add-doc-description Add doc description (yes/no, default: yes)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Markdown support&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; We also provide markdown support for PageIndex. You can use the `-md_path` flag to generate a tree structure for a markdown file. 
 &lt;pre&gt;&lt;code class="language-bash"&gt;python3 run_pageindex.py --md_path /path/to/your/document.md
&lt;/code&gt;&lt;/pre&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;Note: in this function, we use "#" to determine node heading and their levels. For example, "##" is level 2, "###" is level 3, etc. Make sure your markdown file is formatted correctly. If your Markdown file was converted from a PDF or HTML, we don't recommend using this function, since most existing conversion tools cannot preserve the original hierarchy. Instead, use our &lt;a href="https://pageindex.ai/blog/ocr"&gt;PageIndex OCR&lt;/a&gt;, which is designed to preserve the original hierarchy, to convert the PDF to a markdown file and then use this function.&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/details&gt; 
&lt;!-- 
# ‚òÅÔ∏è Improved Tree Generation with PageIndex OCR

This repo is designed for generating PageIndex tree structure for simple PDFs, but many real-world use cases involve complex PDFs that are hard to parse by classic Python tools. However, extracting high-quality text from PDF documents remains a non-trivial challenge. Most OCR tools only extract page-level content, losing the broader document context and hierarchy.

To address this, we introduced PageIndex OCR ‚Äî the first long-context OCR model designed to preserve the global structure of documents. PageIndex OCR significantly outperforms other leading OCR tools, such as those from Mistral and Contextual AI, in recognizing true hierarchy and semantic relationships across document pages.

- Experience next-level OCR quality with PageIndex OCR at our [Dashboard](https://dash.pageindex.ai/).
- Integrate PageIndex OCR seamlessly into your stack via our [API](https://docs.pageindex.ai/quickstart).

&lt;p align="center"&gt;
  &lt;img src="https://github.com/user-attachments/assets/eb35d8ae-865c-4e60-a33b-ebbd00c41732" width="80%"&gt;
&lt;/p&gt;
--&gt; 
&lt;hr /&gt; 
&lt;h1&gt;üìà Case Study: PageIndex Leads Finance QA Benchmark&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://vectify.ai/mafin"&gt;Mafin 2.5&lt;/a&gt; is a reasoning-based RAG system for financial document analysis, powered by &lt;strong&gt;PageIndex&lt;/strong&gt;. It achieved a state-of-the-art &lt;a href="https://vectify.ai/blog/Mafin2.5"&gt;&lt;strong&gt;98.7% accuracy&lt;/strong&gt;&lt;/a&gt; on the &lt;a href="https://arxiv.org/abs/2311.11944"&gt;FinanceBench&lt;/a&gt; benchmark, significantly outperforming traditional vector-based RAG systems.&lt;/p&gt; 
&lt;p&gt;PageIndex's hierarchical indexing and reasoning-driven retrieval enable precise navigation and extraction of relevant context from complex financial reports, such as SEC filings and earnings disclosures.&lt;/p&gt; 
&lt;p&gt;Explore the full &lt;a href="https://github.com/VectifyAI/Mafin2.5-FinanceBench"&gt;benchmark results&lt;/a&gt; and our &lt;a href="https://vectify.ai/blog/Mafin2.5"&gt;blog post&lt;/a&gt; for detailed comparisons and performance metrics.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/VectifyAI/Mafin2.5-FinanceBench"&gt; &lt;img src="https://github.com/user-attachments/assets/571aa074-d803-43c7-80c4-a04254b782a3" width="70%" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h1&gt;üß≠ Resources&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;üß™ &lt;a href="https://docs.pageindex.ai/cookbook/vectorless-rag-pageindex"&gt;Cookbooks&lt;/a&gt;: hands-on, runnable examples and advanced use cases.&lt;/li&gt; 
 &lt;li&gt;üìñ &lt;a href="https://docs.pageindex.ai/doc-search"&gt;Tutorials&lt;/a&gt;: practical guides and strategies, including &lt;em&gt;Document Search&lt;/em&gt; and &lt;em&gt;Tree Search&lt;/em&gt;.&lt;/li&gt; 
 &lt;li&gt;üìù &lt;a href="https://pageindex.ai/blog"&gt;Blog&lt;/a&gt;: technical articles, research insights, and product updates.&lt;/li&gt; 
 &lt;li&gt;üîå &lt;a href="https://pageindex.ai/mcp#quick-setup"&gt;MCP setup&lt;/a&gt; &amp;amp; &lt;a href="https://docs.pageindex.ai/quickstart"&gt;API docs&lt;/a&gt;: integration details and configuration options.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h1&gt;‚≠ê Support Us&lt;/h1&gt; 
&lt;p&gt;Leave us a star üåü if you like our project. Thank you!&lt;/p&gt; 
&lt;p&gt; &lt;img src="https://github.com/user-attachments/assets/eae4ff38-48ae-4a7c-b19f-eab81201d794" width="80%" /&gt; &lt;/p&gt; 
&lt;h3&gt;Connect with Us&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://x.com/VectifyAI"&gt;&lt;img src="https://img.shields.io/badge/Twitter-000000?style=for-the-badge&amp;amp;logo=x&amp;amp;logoColor=white" alt="Twitter" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://www.linkedin.com/company/vectify-ai/"&gt;&lt;img src="https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&amp;amp;logo=linkedin&amp;amp;logoColor=white" alt="LinkedIn" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://discord.com/invite/VuXuf29EUj"&gt;&lt;img src="https://img.shields.io/badge/Discord-5865F2?style=for-the-badge&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://ii2abc2jejf.typeform.com/to/tK3AXl8T"&gt;&lt;img src="https://img.shields.io/badge/Contact_Us-3B82F6?style=for-the-badge&amp;amp;logo=envelope&amp;amp;logoColor=white" alt="Contact Us" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;¬© 2025 &lt;a href="https://vectify.ai"&gt;Vectify AI&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>icloud-photos-downloader/icloud_photos_downloader</title>
      <link>https://github.com/icloud-photos-downloader/icloud_photos_downloader</link>
      <description>&lt;p&gt;A command-line tool to download photos from iCloud&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;!!!! &lt;a href="https://github.com/icloud-photos-downloader/icloud_photos_downloader/issues/1305"&gt;Looking for MAINTAINER for this project&lt;/a&gt; !!!!&lt;/h1&gt; 
&lt;h1&gt;iCloud Photos Downloader &lt;a href="https://github.com/icloud-photos-downloader/icloud_photos_downloader/actions/workflows/quality-checks.yml"&gt;&lt;img src="https://github.com/icloud-photos-downloader/icloud_photos_downloader/workflows/Quality%20Checks/badge.svg?sanitize=true" alt="Quality Checks" /&gt;&lt;/a&gt; &lt;a href="https://github.com/icloud-photos-downloader/icloud_photos_downloader/actions/workflows/produce-artifacts.yml"&gt;&lt;img src="https://github.com/icloud-photos-downloader/icloud_photos_downloader/workflows/Produce%20Artifacts/badge.svg?sanitize=true" alt="Build and Package" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/icloud-photos-downloader/icloud_photos_downloader/master/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-MIT-blue.svg?sanitize=true" alt="MIT License" /&gt;&lt;/a&gt;&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;A command-line tool to download all your iCloud photos.&lt;/li&gt; 
 &lt;li&gt;Works on Linux, Windows, and macOS; laptop, desktop, and NAS&lt;/li&gt; 
 &lt;li&gt;Available as an executable for direct downloading and through package managers/ecosystems (&lt;a href="https://icloud-photos-downloader.github.io/icloud_photos_downloader/install.html#docker"&gt;Docker&lt;/a&gt;, &lt;a href="https://icloud-photos-downloader.github.io/icloud_photos_downloader/install.html#pypi"&gt;PyPI&lt;/a&gt;, &lt;a href="https://icloud-photos-downloader.github.io/icloud_photos_downloader/install.html#aur"&gt;AUR&lt;/a&gt;, &lt;a href="https://icloud-photos-downloader.github.io/icloud_photos_downloader/install.html#npm"&gt;npm&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;Developed and maintained by volunteers (we are always looking for &lt;a href="https://raw.githubusercontent.com/icloud-photos-downloader/icloud_photos_downloader/master/CONTRIBUTING.md"&gt;help&lt;/a&gt;).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See &lt;a href="https://icloud-photos-downloader.github.io/icloud_photos_downloader/"&gt;Documentation&lt;/a&gt; for more details. Also, check &lt;a href="https://github.com/icloud-photos-downloader/icloud_photos_downloader/issues"&gt;Issues&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;We aim to release new versions once a week (Friday), if there is something worth delivering.&lt;/p&gt; 
&lt;h2&gt;iCloud Prerequisites&lt;/h2&gt; 
&lt;p&gt;To make iCloud Photo Downloader work, ensure the iCloud account is configured with the following settings, otherwise Apple Servers will return an ACCESS_DENIED error:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Enable Access iCloud Data on the Web:&lt;/strong&gt; On your iPhone / iPad, enable &lt;code&gt;Settings &amp;gt; Apple ID &amp;gt; iCloud &amp;gt; Access iCloud Data on the Web&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Disable Advanced Data Protection:&lt;/strong&gt; On your iPhone /iPad disable &lt;code&gt;Settings &amp;gt; Apple ID &amp;gt; iCloud &amp;gt; Advanced Data Protection&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Install and Run&lt;/h2&gt; 
&lt;p&gt;There are three ways to run &lt;code&gt;icloudpd&lt;/code&gt;:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Download executable for your platform from the GitHub &lt;a href="https://github.com/icloud-photos-downloader/icloud_photos_downloader/releases/tag/v1.32.2"&gt;Release&lt;/a&gt; and run it&lt;/li&gt; 
 &lt;li&gt;Use package manager to install, update, and, in some cases, run (&lt;a href="https://icloud-photos-downloader.github.io/icloud_photos_downloader/install.html#docker"&gt;Docker&lt;/a&gt;, &lt;a href="https://icloud-photos-downloader.github.io/icloud_photos_downloader/install.html#pypi"&gt;PyPI&lt;/a&gt;, &lt;a href="https://icloud-photos-downloader.github.io/icloud_photos_downloader/install.html#aur"&gt;AUR&lt;/a&gt;, &lt;a href="https://icloud-photos-downloader.github.io/icloud_photos_downloader/install.html#npm"&gt;npm&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;Build and run from the source&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;See &lt;a href="https://icloud-photos-downloader.github.io/icloud_photos_downloader/install.html"&gt;Documentation&lt;/a&gt; for more details&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;!-- start features --&gt; 
&lt;ul&gt; 
 &lt;li&gt;Three modes of operation: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Copy&lt;/strong&gt; - download new photos from iCloud (default mode)&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Sync&lt;/strong&gt; - download new photos from iCloud and delete local files that were removed in iCloud (&lt;code&gt;--auto-delete&lt;/code&gt; option)&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Move&lt;/strong&gt; - download new photos from iCloud and delete photos in iCloud (&lt;code&gt;--keep-icloud-recent-days&lt;/code&gt; option)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Support for Live Photos (image and video as separate files) and RAW images (including RAW+JPEG)&lt;/li&gt; 
 &lt;li&gt;Automatic de-duplication of photos with the same name&lt;/li&gt; 
 &lt;li&gt;One time download and an option to monitor for iCloud changes continuously (&lt;code&gt;--watch-with-interval&lt;/code&gt; option)&lt;/li&gt; 
 &lt;li&gt;Optimizations for incremental runs (&lt;code&gt;--until-found&lt;/code&gt; and &lt;code&gt;--recent&lt;/code&gt; options)&lt;/li&gt; 
 &lt;li&gt;Photo metadata (EXIF) updates (&lt;code&gt;--set-exif-datetime&lt;/code&gt; option)&lt;/li&gt; 
 &lt;li&gt;... and many more (use &lt;code&gt;--help&lt;/code&gt; option to get full list)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- end features --&gt; 
&lt;h2&gt;Experimental Mode&lt;/h2&gt; 
&lt;p&gt;Some changes are added to the experimental mode before they graduate into the main package. &lt;a href="https://raw.githubusercontent.com/icloud-photos-downloader/icloud_photos_downloader/master/EXPERIMENTAL.md"&gt;Details&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;To keep your iCloud photo collection synchronized to your local system:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;icloudpd --directory /data --username my@email.address --watch-with-interval 3600
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] It is &lt;code&gt;icloudpd&lt;/code&gt;, not &lt;code&gt;icloud&lt;/code&gt; executable&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] Synchronization logic can be adjusted with command-line parameters. Run &lt;code&gt;icloudpd --help&lt;/code&gt; to get full list.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;To independently create and authorize a session (and complete 2SA/2FA validation if needed) on your local system:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;icloudpd --username my@email.address --password my_password --auth-only
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] This feature can also be used to check and verify that the session is still authenticated.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Want to contribute to iCloud Photos Downloader? Awesome! Check out the &lt;a href="https://raw.githubusercontent.com/icloud-photos-downloader/icloud_photos_downloader/master/CONTRIBUTING.md"&gt;contributing guidelines&lt;/a&gt; to get involved.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Free-TV/IPTV</title>
      <link>https://github.com/Free-TV/IPTV</link>
      <description>&lt;p&gt;M3U Playlist for free TV channels&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Free TV&lt;/h1&gt; 
&lt;p&gt;This is an M3U playlist for free TV channels around the World.&lt;/p&gt; 
&lt;p&gt;Either free locally (over the air):&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/usa.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/us.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/canada.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/ca.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/uk.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/gb.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/ireland.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/ie.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/australia.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/au.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/india.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/in.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/japan.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/jp.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/china.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/cn.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/hong_kong.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/hk.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/macau.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/mo.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/taiwan.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/tw.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/north_korea.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/kp.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/korea.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/kr.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/denmark.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/dk.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/faroe_islands.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/fo.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/greenland.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/gl.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/finland.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/fi.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/iceland.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/is.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/norway.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/no.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/sweden.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/se.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/estonia.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/ee.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/latvia.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/lv.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/lithuania.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/lt.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/belgium.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/be.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/netherlands.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/nl.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/luxembourg.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/lu.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/germany.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/de.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/austria.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/at.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/switzerland.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/ch.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/poland.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/pl.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/czech_republic.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/cz.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/slovakia.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/sk.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/hungary.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/hu.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/romania.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/ro.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/moldova.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/md.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/bulgaria.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/bg.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/france.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/fr.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/italy.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/it.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/portugal.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/pt.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/spain.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/es.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/russia.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/ru.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/belarus.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/by.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/ukraine.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/ua.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/armenia.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/am.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/azerbaijan.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/az.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/georgia.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/ge.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/bosnia_and_herzegovina.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/ba.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/croatia.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/hr.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/montenegro.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/me.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/north_macedonia.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/mk.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/serbia.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/rs.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/slovenia.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/si.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/albania.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/al.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/kosovo.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/xk.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/greece.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/gr.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/cyprus.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/cy.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/andorra.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/ad.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/malta.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/mt.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/monaco.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/mc.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/san_marino.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/sm.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/iran.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/ir.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/iraq.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/iq.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/israel.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/il.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/qatar.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/qa.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/turkey.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/tr.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/united_arab_emirates.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/ae.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/argentina.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/ar.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/costa_rica.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/cr.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/dominican_republic.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/do.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/mexico.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/mx.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/paraguay.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/py.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/peru.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/pe.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/venezuela.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/ve.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/brazil.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/br.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/trinidad.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/tt.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/chad.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/td.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/somalia.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/so.svg?sanitize=true" width="24" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/lists/indonesia.md"&gt;&lt;img src="https://hatscripts.github.io/circle-flags/flags/id.svg?sanitize=true" width="24" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Or free on the Internet:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Plex TV&lt;/li&gt; 
 &lt;li&gt;Pluto TV (English, Spanish, French, Italian)&lt;/li&gt; 
 &lt;li&gt;Redbox Live TV&lt;/li&gt; 
 &lt;li&gt;Roku TV&lt;/li&gt; 
 &lt;li&gt;Samsung TV Plus&lt;/li&gt; 
 &lt;li&gt;Youtube live channels&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To use it point your IPTV player to &lt;a href="https://raw.githubusercontent.com/Free-TV/IPTV/master/playlist.m3u8"&gt;https://raw.githubusercontent.com/Free-TV/IPTV/master/playlist.m3u8&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Philosophy&lt;/h1&gt; 
&lt;p&gt;The main goals for this playlist are listed below.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Quality over quantity&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;The less channels we support the better.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;All channels should work well.&lt;/li&gt; 
 &lt;li&gt;As much as possible channels should be in HD, not SD.&lt;/li&gt; 
 &lt;li&gt;Only one URL per channel (no +1, no alternate feeds, no regional declinations)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Only free channels&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;If a channel is normally only available via commercial subscriptions it has nothing to do in this playlist. If on the other hand it is provided for free to everybody in a particular country, then it should be in this playlist.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;No paid channels&lt;/li&gt; 
 &lt;li&gt;Only channels which are officially provided for free (via DVB-S, DVB-T, analog, etc..)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Only mainstream channels&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;This is a playlist for everybody.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;No adult channels&lt;/li&gt; 
 &lt;li&gt;No channels dedicated to any particular religion&lt;/li&gt; 
 &lt;li&gt;No channels dedicated to any particular political party&lt;/li&gt; 
 &lt;li&gt;No channels made for a country and funded by a different country&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Feed sources&lt;/h1&gt; 
&lt;p&gt;It can be quite hard to find up to date URLs, here's a list of sources:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/iptv-org/iptv/tree/master/streams"&gt;https://github.com/iptv-org/iptv/tree/master/streams&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Youtube: As long as the channel is live and its URL doesn't change (check the age of the stream, the number of viewers..)&lt;/li&gt; 
 &lt;li&gt;Dailymotion: Same criteria as for youtube&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Format&lt;/h1&gt; 
&lt;p&gt;The m3u8 playlist is generated by &lt;code&gt;make_playlist.py&lt;/code&gt;, using the &lt;code&gt;.md&lt;/code&gt; files located in &lt;code&gt;lists&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Each .md file represesnts a group. The &lt;code&gt;&amp;lt;h1&amp;gt;&lt;/code&gt; line is used as the group title.&lt;/p&gt; 
&lt;p&gt;Only channels which URL column starts with &lt;code&gt;[&amp;gt;]&lt;/code&gt; are included in the playlist.&lt;/p&gt; 
&lt;p&gt;Channels which are not in HD are marked with an &lt;code&gt;‚ìà&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Channels which use GeoIP blocking are marked with a &lt;code&gt;‚íº&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Channels which are live Youtube channels are marked with a &lt;code&gt;‚ìé&lt;/code&gt;.&lt;/p&gt; 
&lt;h1&gt;Issues&lt;/h1&gt; 
&lt;p&gt;Only create issues for bugs and feature requests.&lt;/p&gt; 
&lt;p&gt;Do not create issues to add/edit or to remove channels. If you want to add/edit/remove channels, create a pull request directly.&lt;/p&gt; 
&lt;h1&gt;Pull Requests&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;Only modify .md files&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;If your Pull Request modifies channels, only modify .md files. Do not modify m3u8 files in your pull request.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Adding a new Channel&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;To add a new channel, make a Pull Request.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;In your Pull Request you need to provide information to show that the channel is free.&lt;/li&gt; 
 &lt;li&gt;Use imgur.com to host the channel logo and point to it.&lt;/li&gt; 
 &lt;li&gt;If you have a valid stream, add it and put &lt;code&gt;[&amp;gt;]&lt;/code&gt; in front of it.&lt;/li&gt; 
 &lt;li&gt;If you don't have an stream for the channel, add &lt;code&gt;[x]()&lt;/code&gt; in the url column and place your channel in the Invalid category.&lt;/li&gt; 
 &lt;li&gt;If you have a stream but it doesn't work well, put the channel in the Invalid category and put &lt;code&gt;[x]&lt;/code&gt; in front of the url.&lt;/li&gt; 
 &lt;li&gt;If you're adding geoblocked URLs specify it in your PR and specify which country they're working in. The PR will only be merged if these URLs can be tested.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Removing a Channel&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;To remove a channel, make a Pull Request.&lt;/p&gt; 
&lt;p&gt;In your Pull Request you need to provide information to show that the channel is only available via a private paid subscription.&lt;/p&gt; 
&lt;p&gt;Note: Public taxes (whether national or regional, whether called TV License or not) do not constitute a private paid subscription.&lt;/p&gt; 
&lt;p&gt;If a stream is broken, simply move the channel to the invalid category and replace &lt;code&gt;[&amp;gt;]&lt;/code&gt; with &lt;code&gt;[x]&lt;/code&gt; in the url column.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>OpenBB-finance/OpenBB</title>
      <link>https://github.com/OpenBB-finance/OpenBB</link>
      <description>&lt;p&gt;Financial data platform for analysts, quants and AI agents.&lt;/p&gt;&lt;hr&gt;&lt;br /&gt; 
&lt;img src="https://github.com/OpenBB-finance/OpenBB/raw/develop/images/odp-light.svg?raw=true#gh-light-mode-only" alt="Open Data Platform by OpenBB logo" width="600" /&gt; 
&lt;img src="https://github.com/OpenBB-finance/OpenBB/raw/develop/images/odp-dark.svg?raw=true#gh-dark-mode-only" alt="Open Data Platform by OpenBB logo" width="600" /&gt; 
&lt;br /&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;a href="https://x.com/openbb_finance"&gt;&lt;img src="https://img.shields.io/twitter/url/https/twitter.com/openbb_finance.svg?style=social&amp;amp;label=Follow%20%40openbb_finance" alt="Twitter" /&gt;&lt;/a&gt; &lt;a href="https://discord.com/invite/xPHTuHCmuV"&gt;&lt;img src="https://img.shields.io/discord/831165782750789672" alt="Discord Shield" /&gt;&lt;/a&gt; &lt;a href="https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/OpenBB-finance/OpenBB"&gt;&lt;img src="https://img.shields.io/static/v1?label=Dev%20Containers&amp;amp;message=Open&amp;amp;color=blue&amp;amp;logo=visualstudiocode" alt="Open in Dev Containers" /&gt;&lt;/a&gt; &lt;a href="https://codespaces.new/OpenBB-finance/OpenBB"&gt; &lt;img src="https://github.com/codespaces/badge.svg?sanitize=true" height="20" /&gt; &lt;/a&gt; &lt;a target="_blank" href="https://colab.research.google.com/github/OpenBB-finance/OpenBB/blob/develop/examples/googleColab.ipynb"&gt; &lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open In Colab" /&gt; &lt;/a&gt; &lt;a href="https://pypi.org/project/openbb/"&gt;&lt;img src="https://img.shields.io/pypi/v/openbb?color=blue&amp;amp;label=PyPI%20Package" alt="PyPI" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Open Data Platform by OpenBB (ODP) is the open-source toolset that helps data engineers integrate proprietary, licensed, and public data sources into downstream applications like AI copilots and research dashboards.&lt;/p&gt; 
&lt;p&gt;ODP operates as the "connect once, consume everywhere" infrastructure layer that consolidates and exposes data to multiple surfaces at once: Python environments for quants, OpenBB Workspace and Excel for analysts, MCP servers for AI agents, and REST APIs for other applications.&lt;/p&gt; 
&lt;a href="https://pro.openbb.co"&gt; 
 &lt;div align="center"&gt; 
  &lt;img src="https://openbb-cms.directus.app/assets/70b971ef-7a7e-486e-b5ae-1cc602f2162c.png" alt="Logo" width="1000" /&gt; 
 &lt;/div&gt; &lt;/a&gt; 
&lt;p&gt;Get started with: &lt;code&gt;pip install openbb&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from openbb import obb
output = obb.equity.price.historical("AAPL")
df = output.to_dataframe()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Data integrations available can be found here: &lt;a href="https://docs.openbb.co/python/reference"&gt;https://docs.openbb.co/python/reference&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;OpenBB Workspace&lt;/h2&gt; 
&lt;p&gt;While the Open Data Platform provides the open-source data integration foundation, &lt;strong&gt;OpenBB Workspace&lt;/strong&gt; offers the enterprise UI for analysts to visualize datasets and leverage AI agents. The platform's "connect once, consume everywhere" architecture enables seamless integration between the two.&lt;/p&gt; 
&lt;p&gt;You can find OpenBB Workspace at &lt;a href="https://pro.openbb.co"&gt;https://pro.openbb.co&lt;/a&gt;. &lt;a href="https://pro.openbb.co"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;a href="https://pro.openbb.co"&gt; 
 &lt;div align="center"&gt; 
  &lt;img src="https://openbb-cms.directus.app/assets/f69b6aaf-0821-4bc8-a43c-715e03a924ef.png" alt="Logo" width="1000" /&gt; 
 &lt;/div&gt; &lt;/a&gt; 
&lt;p&gt;Data integration:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You can learn more about adding data to the OpenBB workspace from the &lt;a href="https://docs.openbb.co/workspace"&gt;docs&lt;/a&gt; or &lt;a href="https://github.com/OpenBB-finance/backends-for-openbb"&gt;this open source repository&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;AI Agents integration:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You can learn more about adding AI agents to the OpenBB workspace from &lt;a href="https://github.com/OpenBB-finance/agents-for-openbb"&gt;this open source repository&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Integrating Open Data Platform to the OpenBB Workspace&lt;/h3&gt; 
&lt;p&gt;Connect this library to the OpenBB Workspace with a few simple commands, in a Python (3.9.21 - 3.12) environment.&lt;/p&gt; 
&lt;h4&gt;Run an ODP backend&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install the packages.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;pip install "openbb[all]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Start the API server over localhost.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;openbb-api
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will launch a FastAPI server, via Uvicorn, at &lt;code&gt;127.0.0.1:6900&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;You can check that it works by going to &lt;a href="http://127.0.0.1:6900"&gt;http://127.0.0.1:6900&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Integrate the ODP Backend to OpenBB Workspace&lt;/h4&gt; 
&lt;p&gt;Sign-in to the &lt;a href="https://pro.openbb.co/"&gt;OpenBB Workspace&lt;/a&gt;, and follow the following steps:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/75cffb4a-5e95-470a-b9d0-6ffd4067e069" alt="CleanShot 2025-05-17 at 09 51 56@2x" /&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Go to the "Apps" tab&lt;/li&gt; 
 &lt;li&gt;Click on "Connect backend"&lt;/li&gt; 
 &lt;li&gt;Fill in the form with: Name: Open Data Platform URL: &lt;a href="http://127.0.0.1:6900"&gt;http://127.0.0.1:6900&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Click on "Test". You should get a "Test successful" with the number of apps found.&lt;/li&gt; 
 &lt;li&gt;Click on "Add".&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;That's it.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;!-- TABLE OF CONTENTS --&gt; 
&lt;details closed="closed"&gt; 
 &lt;summary&gt;&lt;h2 style="display: inline-block"&gt;Table of Contents&lt;/h2&gt;&lt;/summary&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#1-installation"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#2-contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#3-license"&gt;License&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#4-disclaimer"&gt;Disclaimer&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#5-contacts"&gt;Contacts&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#6-star-history"&gt;Star History&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#7-contributors"&gt;Contributors&lt;/a&gt;&lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;h2&gt;1. Installation&lt;/h2&gt; 
&lt;p&gt;The ODP Python Package can be installed from &lt;a href="https://pypi.org/project/openbb/"&gt;PyPI package&lt;/a&gt; by running &lt;code&gt;pip install openbb&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;or by cloning the repository directly with &lt;code&gt;git clone https://github.com/OpenBB-finance/OpenBB.git&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Please find more about the installation process, in the &lt;a href="https://docs.openbb.co/python/installation"&gt;OpenBB Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;ODP CLI installation&lt;/h3&gt; 
&lt;p&gt;The ODP CLI is a command-line interface that allows you to access the ODP directly from your command line.&lt;/p&gt; 
&lt;p&gt;It can be installed by running &lt;code&gt;pip install openbb-cli&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;or by cloning the repository directly with &lt;code&gt;git clone https://github.com/OpenBB-finance/OpenBB.git&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Please find more about the installation process in the &lt;a href="https://docs.openbb.co/cli/installation"&gt;OpenBB Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;2. Contributing&lt;/h2&gt; 
&lt;p&gt;There are three main ways of contributing to this project. (Hopefully you have starred the project by now ‚≠êÔ∏è)&lt;/p&gt; 
&lt;h3&gt;Become a Contributor&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;More information on our &lt;a href="https://docs.openbb.co/python/developer"&gt;Developer Documentation&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Create a GitHub ticket&lt;/h3&gt; 
&lt;p&gt;Before creating a ticket make sure the one you are creating doesn't exist already &lt;a href="https://github.com/OpenBB-finance/OpenBB/issues"&gt;among the existing issues&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;amp;labels=bug&amp;amp;template=bug_report.md&amp;amp;title=%5BBug%5D"&gt;Report bug&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;amp;labels=enhancement&amp;amp;template=enhancement.md&amp;amp;title=%5BIMPROVE%5D"&gt;Suggest improvement&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;amp;labels=new+feature&amp;amp;template=feature_request.md&amp;amp;title=%5BFR%5D"&gt;Request a feature&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Provide feedback&lt;/h3&gt; 
&lt;p&gt;We are most active on &lt;a href="https://openbb.co/discord"&gt;our Discord&lt;/a&gt;, but feel free to reach out to us in any of &lt;a href="https://openbb.co/links"&gt;our social media&lt;/a&gt; for feedback.&lt;/p&gt; 
&lt;h2&gt;3. License&lt;/h2&gt; 
&lt;p&gt;Distributed under the AGPLv3 License. See &lt;a href="https://github.com/OpenBB-finance/OpenBB/raw/main/LICENSE"&gt;LICENSE&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;4. Disclaimer&lt;/h2&gt; 
&lt;p&gt;Trading in financial instruments involves high risks including the risk of losing some, or all, of your investment amount, and may not be suitable for all investors.&lt;/p&gt; 
&lt;p&gt;Before deciding to trade in a financial instrument you should be fully informed of the risks and costs associated with trading the financial markets, carefully consider your investment objectives, level of experience, and risk appetite, and seek professional advice where needed.&lt;/p&gt; 
&lt;p&gt;The data contained in the Open Data Platform is not necessarily accurate.&lt;/p&gt; 
&lt;p&gt;OpenBB and any provider of the data contained in this website will not accept liability for any loss or damage as a result of your trading, or your reliance on the information displayed.&lt;/p&gt; 
&lt;p&gt;All names, logos, and brands of third parties that may be referenced in our sites, products or documentation are trademarks of their respective owners. Unless otherwise specified, OpenBB and its products and services are not endorsed by, sponsored by, or affiliated with these third parties.&lt;/p&gt; 
&lt;p&gt;Our use of these names, logos, and brands is for identification purposes only, and does not imply any such endorsement, sponsorship, or affiliation.&lt;/p&gt; 
&lt;h2&gt;5. Contacts&lt;/h2&gt; 
&lt;p&gt;If you have any questions about the platform or anything OpenBB, feel free to email us at &lt;code&gt;support@openbb.co&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;If you want to say hi, or are interested in partnering with us, feel free to reach us at &lt;code&gt;hello@openbb.co&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Any of our social media platforms: &lt;a href="https://openbb.co/links"&gt;openbb.co/links&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;6. Star History&lt;/h2&gt; 
&lt;p&gt;This is a proxy of our growth and that we are just getting started.&lt;/p&gt; 
&lt;p&gt;But for more metrics important to us check &lt;a href="https://openbb.co/open"&gt;openbb.co/open&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://api.star-history.com/svg?repos=openbb-finance/OpenBB&amp;amp;type=Date&amp;amp;theme=dark"&gt;&lt;img src="https://api.star-history.com/svg?repos=openbb-finance/OpenBB&amp;amp;type=Date&amp;amp;theme=dark" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;7. Contributors&lt;/h2&gt; 
&lt;p&gt;OpenBB wouldn't be OpenBB without you. If we are going to disrupt financial industry, every contribution counts. Thank you for being part of this journey.&lt;/p&gt; 
&lt;a href="https://github.com/OpenBB-finance/OpenBB/graphs/contributors"&gt; &lt;img src="https://contributors-img.web.app/image?repo=OpenBB-finance/OpenBB" width="800" /&gt; &lt;/a&gt; 
&lt;!-- MARKDOWN LINKS &amp; IMAGES --&gt; 
&lt;!-- https://www.markdownguide.org/basic-syntax/#reference-style-links --&gt;</description>
    </item>
    
    <item>
      <title>ThanhNguyxn/SheerID-Verification-Tool</title>
      <link>https://github.com/ThanhNguyxn/SheerID-Verification-Tool</link>
      <description>&lt;p&gt;A lightweight tool for integrating and testing SheerID verification workflows. It simplifies API requests, handles responses, and supports eligibility checks for programs like student.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;üîê SheerID Verification Tool&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/ThanhNguyxn/SheerID-Verification-Tool/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/ThanhNguyxn/SheerID-Verification-Tool?style=social" alt="GitHub Stars" /&gt;&lt;/a&gt; &lt;a href="https://opensource.org/licenses/MIT"&gt;&lt;img src="https://img.shields.io/badge/License-MIT-yellow.svg?sanitize=true" alt="License: MIT" /&gt;&lt;/a&gt; &lt;a href="https://www.python.org/"&gt;&lt;img src="https://img.shields.io/badge/Python-3.8+-blue.svg?sanitize=true" alt="Python 3.8+" /&gt;&lt;/a&gt; &lt;a href="https://thanhnguyxn.github.io/SheerID-Verification-Tool/"&gt;&lt;img src="https://img.shields.io/badge/Docs-Website-2ea44f?style=flat&amp;amp;logo=github&amp;amp;logoColor=white" alt="Documentation" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;A comprehensive collection of tools for automating SheerID verification workflows for various services (Spotify, YouTube, Google One, etc.).&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üõ†Ô∏è Available Tools&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Tool&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Target&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ThanhNguyxn/SheerID-Verification-Tool/master/spotify-verify-tool/"&gt;spotify-verify-tool&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;üéµ Student&lt;/td&gt; 
   &lt;td&gt;Spotify Premium&lt;/td&gt; 
   &lt;td&gt;University student verification&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ThanhNguyxn/SheerID-Verification-Tool/master/youtube-verify-tool/"&gt;youtube-verify-tool&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;üé¨ Student&lt;/td&gt; 
   &lt;td&gt;YouTube Premium&lt;/td&gt; 
   &lt;td&gt;University student verification&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ThanhNguyxn/SheerID-Verification-Tool/master/one-verify-tool/"&gt;one-verify-tool&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;ü§ñ Student&lt;/td&gt; 
   &lt;td&gt;Gemini Advanced&lt;/td&gt; 
   &lt;td&gt;Google One AI Premium verification&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ThanhNguyxn/SheerID-Verification-Tool/master/boltnew-verify-tool/"&gt;boltnew-verify-tool&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;üë®‚Äçüè´ Teacher&lt;/td&gt; 
   &lt;td&gt;Bolt.new&lt;/td&gt; 
   &lt;td&gt;Teacher verification (University)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ThanhNguyxn/SheerID-Verification-Tool/master/canva-teacher-tool/"&gt;canva-teacher-tool&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;üá¨üáß Teacher&lt;/td&gt; 
   &lt;td&gt;Canva Education&lt;/td&gt; 
   &lt;td&gt;UK Teacher verification (K-12)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ThanhNguyxn/SheerID-Verification-Tool/master/k12-verify-tool/"&gt;k12-verify-tool&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;üè´ K12&lt;/td&gt; 
   &lt;td&gt;ChatGPT Plus&lt;/td&gt; 
   &lt;td&gt;K12 Teacher verification (High School)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ThanhNguyxn/SheerID-Verification-Tool/master/veterans-verify-tool/"&gt;veterans-verify-tool&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;üéñÔ∏è Military&lt;/td&gt; 
   &lt;td&gt;General&lt;/td&gt; 
   &lt;td&gt;Military status verification&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ThanhNguyxn/SheerID-Verification-Tool/master/veterans-extension/"&gt;veterans-extension&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;üß© Chrome&lt;/td&gt; 
   &lt;td&gt;Browser&lt;/td&gt; 
   &lt;td&gt;Chrome extension for military verification&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;üîó External Tools&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Tool&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://roxybrowser.com?code=01045PFA"&gt;RoxyBrowser&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;ü¶ä Browser&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Anti-detect browser&lt;/strong&gt; ‚Äî Safely manage multiple verified accounts without getting banned&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://ip123.in/sheerid/?code=01045PFA"&gt;SheerID Auto Verify&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;üîê Web&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Auto verification tool&lt;/strong&gt; ‚Äî Fast automated SheerID verification&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://t.me/SheerID_Verification_bot?start=ref_LdPKPES3Ej"&gt;SheerID Verification Bot&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;ü§ñ Bot&lt;/td&gt; 
   &lt;td&gt;Automated Telegram verification bot&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://t.me/vgptplusbot?start=ref_7762497789"&gt;GPT Bot&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;ü§ñ Bot&lt;/td&gt; 
   &lt;td&gt;Automated verification bot&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://thanhnguyxn.github.io/student-card-generator/"&gt;Student Card Generator&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;üéì Tool&lt;/td&gt; 
   &lt;td&gt;Create student cards for manual verification&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://thanhnguyxn.github.io/payslip-generator/"&gt;Payslip Generator&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;üí∞ Tool&lt;/td&gt; 
   &lt;td&gt;Generate payslips for teacher verification&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üß† Core Architecture &amp;amp; Logic&lt;/h2&gt; 
&lt;p&gt;All Python tools in this repository share a common, optimized architecture designed for high success rates.&lt;/p&gt; 
&lt;h3&gt;1. The Verification Flow&lt;/h3&gt; 
&lt;p&gt;The tools follow a standardized "Waterfall" process:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Data Generation&lt;/strong&gt;: Creates a realistic identity (Name, DOB, Email) matching the target demographic.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Submission (&lt;code&gt;collectStudentPersonalInfo&lt;/code&gt;)&lt;/strong&gt;: Submits data to SheerID API.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;SSO Skip (&lt;code&gt;DELETE /step/sso&lt;/code&gt;)&lt;/strong&gt;: Crucial step. Bypasses the requirement to log in to a school portal.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Document Upload (&lt;code&gt;docUpload&lt;/code&gt;)&lt;/strong&gt;: Uploads a generated proof document (Student ID, Transcript, or Teacher Badge).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Completion (&lt;code&gt;completeDocUpload&lt;/code&gt;)&lt;/strong&gt;: Signals to SheerID that upload is finished.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;2. Intelligent Strategies&lt;/h3&gt; 
&lt;h4&gt;üéì University Strategy (Spotify, YouTube, Gemini)&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Weighted Selection&lt;/strong&gt;: Uses a curated list of &lt;strong&gt;45+ Universities&lt;/strong&gt; (US, VN, JP, KR, etc.).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Success Tracking&lt;/strong&gt;: Universities with higher success rates are selected more often.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Document Gen&lt;/strong&gt;: Generates realistic-looking Student ID cards with dynamic names and dates.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;üë®‚Äçüè´ Teacher Strategy (Bolt.new)&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Age Targeting&lt;/strong&gt;: Generates older identities (25-55 years old) to match teacher demographics.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Document Gen&lt;/strong&gt;: Creates "Employment Certificates" instead of Student IDs.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Endpoint&lt;/strong&gt;: Targets &lt;code&gt;collectTeacherPersonalInfo&lt;/code&gt; instead of student endpoints.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;üè´ K12 Strategy (ChatGPT Plus)&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;School Type Targeting&lt;/strong&gt;: Specifically targets schools with &lt;code&gt;type: "K12"&lt;/code&gt; (not &lt;code&gt;HIGH_SCHOOL&lt;/code&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Auto-Pass Logic&lt;/strong&gt;: K12 verification often &lt;strong&gt;auto-approves&lt;/strong&gt; without document upload if the school and teacher info match.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Fallback&lt;/strong&gt;: If upload is required, it generates a Teacher Badge.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;üéñÔ∏è Veterans Strategy (ChatGPT Plus)&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Strict Eligibility&lt;/strong&gt;: Targets Active Duty or Veterans separated within the &lt;strong&gt;last 12 months&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Authoritative Check&lt;/strong&gt;: SheerID verifies against DoD/DEERS database.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Logic&lt;/strong&gt;: Defaults to recent discharge dates to maximize auto-approval chances.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;üõ°Ô∏è Anti-Detection Module&lt;/h4&gt; 
&lt;p&gt;All tools now include &lt;code&gt;anti_detect.py&lt;/code&gt; which provides:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Random User-Agents&lt;/strong&gt;: 10+ real browser UA strings (Chrome, Firefox, Edge, Safari)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Browser-like Headers&lt;/strong&gt;: Proper &lt;code&gt;sec-ch-ua&lt;/code&gt;, &lt;code&gt;Accept-Language&lt;/code&gt;, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;TLS Fingerprint Spoofing&lt;/strong&gt;: Uses &lt;code&gt;curl_cffi&lt;/code&gt; to impersonate Chrome's JA3/JA4 fingerprint&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Random Delays&lt;/strong&gt;: Avoids rate limiting with randomized request timing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Smart Session&lt;/strong&gt;: Auto-selects best available HTTP library (curl_cffi &amp;gt; cloudscraper &amp;gt; httpx &amp;gt; requests)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;NewRelic Headers&lt;/strong&gt;: Required tracking headers for SheerID API calls&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] &lt;strong&gt;API-Based Tools Have Inherent Limitations&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;SheerID uses advanced detection including:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;TLS Fingerprinting&lt;/strong&gt;: Python &lt;code&gt;requests&lt;/code&gt;/&lt;code&gt;httpx&lt;/code&gt; have detectable signatures&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Signal Intelligence&lt;/strong&gt;: IP address, device attributes, email age analysis&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;AI Document Review&lt;/strong&gt;: Detects forged/template documents&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;For best results: Use &lt;strong&gt;residential proxies&lt;/strong&gt; + install &lt;code&gt;curl_cffi&lt;/code&gt; for TLS spoofing. Browser extensions generally have higher success rates than API tools.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìã Quick Start&lt;/h2&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Python 3.8+&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;pip&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Clone the repository:&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/ThanhNguyxn/SheerID-Verification-Tool.git
cd SheerID-Verification-Tool
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Install dependencies:&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pip install httpx Pillow
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;[Optional] Enhanced Anti-Detection:&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pip install curl_cffi cloudscraper
&lt;/code&gt;&lt;/pre&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;curl_cffi&lt;/code&gt;: Spoofs TLS fingerprint (JA3/JA4) to look like real Chrome&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;cloudscraper&lt;/code&gt;: Bypasses Cloudflare protection&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Run a tool (e.g., Spotify):&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;cd spotify-verify-tool
python main.py "YOUR_SHEERID_URL"
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ü¶ä Official Partner: RoxyBrowser&lt;/h2&gt; 
&lt;p&gt;üõ° &lt;strong&gt;Anti-Detect Protection&lt;/strong&gt; ‚Äî Unique fingerprint for each account, looks like different real devices.&lt;/p&gt; 
&lt;p&gt;üìâ &lt;strong&gt;Prevent Linkage&lt;/strong&gt; ‚Äî Stops SheerID and platforms from linking your accounts.&lt;/p&gt; 
&lt;p&gt;üöÄ &lt;strong&gt;Ideal for Bulk Users&lt;/strong&gt; ‚Äî Safely manage hundreds of verified accounts.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://roxybrowser.com?code=01045PFA"&gt;&lt;img src="https://img.shields.io/badge/Try%20for%20free-RoxyBrowser-ff6b35?style=for-the-badge&amp;amp;logo=googlechrome&amp;amp;logoColor=white" alt="Try for free" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;‚ö†Ô∏è Disclaimer&lt;/h2&gt; 
&lt;p&gt;This project is for &lt;strong&gt;educational purposes only&lt;/strong&gt;. The tools demonstrate how verification systems work and how they can be tested.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Do not use this for fraudulent purposes.&lt;/li&gt; 
 &lt;li&gt;The authors are not responsible for any misuse.&lt;/li&gt; 
 &lt;li&gt;Respect the Terms of Service of all platforms.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; 
&lt;p&gt;Contributions are welcome! Please feel free to submit a Pull Request.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;‚ù§Ô∏è Support&lt;/h2&gt; 
&lt;p&gt;If you find this project helpful, consider supporting me:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/sponsors/ThanhNguyxn"&gt;&lt;img src="https://img.shields.io/badge/Sponsor-GitHub-ea4aaa?style=for-the-badge&amp;amp;logo=github" alt="GitHub Sponsors" /&gt;&lt;/a&gt; &lt;a href="https://buymeacoffee.com/thanhnguyxn"&gt;&lt;img src="https://img.shields.io/badge/Buy%20Me%20a%20Coffee-FFDD00?style=for-the-badge&amp;amp;logo=buy-me-a-coffee&amp;amp;logoColor=black" alt="Buy Me a Coffee" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üåê Translations&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;üá∫üá∏ &lt;a href="https://raw.githubusercontent.com/ThanhNguyxn/SheerID-Verification-Tool/master/README.md"&gt;English&lt;/a&gt;&lt;/th&gt; 
   &lt;th align="center"&gt;üáªüá≥ &lt;a href="https://raw.githubusercontent.com/ThanhNguyxn/SheerID-Verification-Tool/master/docs/README.vi.md"&gt;Ti·∫øng Vi·ªát&lt;/a&gt;&lt;/th&gt; 
   &lt;th align="center"&gt;üá®üá≥ &lt;a href="https://raw.githubusercontent.com/ThanhNguyxn/SheerID-Verification-Tool/master/docs/README.zh.md"&gt;‰∏≠Êñá&lt;/a&gt;&lt;/th&gt; 
   &lt;th align="center"&gt;üáØüáµ &lt;a href="https://raw.githubusercontent.com/ThanhNguyxn/SheerID-Verification-Tool/master/docs/README.ja.md"&gt;Êó•Êú¨Ë™û&lt;/a&gt;&lt;/th&gt; 
   &lt;th align="center"&gt;üá∞üá∑ &lt;a href="https://raw.githubusercontent.com/ThanhNguyxn/SheerID-Verification-Tool/master/docs/README.ko.md"&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;üá™üá∏ &lt;a href="https://raw.githubusercontent.com/ThanhNguyxn/SheerID-Verification-Tool/master/docs/README.es.md"&gt;Espa√±ol&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;üá´üá∑ &lt;a href="https://raw.githubusercontent.com/ThanhNguyxn/SheerID-Verification-Tool/master/docs/README.fr.md"&gt;Fran√ßais&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;üá©üá™ &lt;a href="https://raw.githubusercontent.com/ThanhNguyxn/SheerID-Verification-Tool/master/docs/README.de.md"&gt;Deutsch&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;üáßüá∑ &lt;a href="https://raw.githubusercontent.com/ThanhNguyxn/SheerID-Verification-Tool/master/docs/README.pt-BR.md"&gt;Portugu√™s&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;üá∑üá∫ &lt;a href="https://raw.githubusercontent.com/ThanhNguyxn/SheerID-Verification-Tool/master/docs/README.ru.md"&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;üá∏üá¶ &lt;a href="https://raw.githubusercontent.com/ThanhNguyxn/SheerID-Verification-Tool/master/docs/README.ar.md"&gt;ÿßŸÑÿπÿ±ÿ®Ÿäÿ©&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;üáÆüá≥ &lt;a href="https://raw.githubusercontent.com/ThanhNguyxn/SheerID-Verification-Tool/master/docs/README.hi.md"&gt;‡§π‡§ø‡§®‡•ç‡§¶‡•Ä&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;üáπüá≠ &lt;a href="https://raw.githubusercontent.com/ThanhNguyxn/SheerID-Verification-Tool/master/docs/README.th.md"&gt;‡πÑ‡∏ó‡∏¢&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;üáπüá∑ &lt;a href="https://raw.githubusercontent.com/ThanhNguyxn/SheerID-Verification-Tool/master/docs/README.tr.md"&gt;T√ºrk√ße&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;üáµüá± &lt;a href="https://raw.githubusercontent.com/ThanhNguyxn/SheerID-Verification-Tool/master/docs/README.pl.md"&gt;Polski&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;üáÆüáπ &lt;a href="https://raw.githubusercontent.com/ThanhNguyxn/SheerID-Verification-Tool/master/docs/README.it.md"&gt;Italiano&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;üáÆüá© &lt;a href="https://raw.githubusercontent.com/ThanhNguyxn/SheerID-Verification-Tool/master/docs/README.id.md"&gt;Bahasa Indonesia&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt;</description>
    </item>
    
    <item>
      <title>EveryInc/compound-engineering-plugin</title>
      <link>https://github.com/EveryInc/compound-engineering-plugin</link>
      <description>&lt;p&gt;Official Claude Code compound engineering plugin&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Compound Engineering Plugin&lt;/h1&gt; 
&lt;p&gt;A Claude Code plugin that makes each unit of engineering work easier than the last.&lt;/p&gt; 
&lt;h2&gt;Install&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;/plugin marketplace add https://github.com/EveryInc/compound-engineering-plugin
/plugin install compound-engineering
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Workflow&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;Plan ‚Üí Work ‚Üí Review ‚Üí Compound ‚Üí Repeat
&lt;/code&gt;&lt;/pre&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Command&lt;/th&gt; 
   &lt;th&gt;Purpose&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;/workflows:plan&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Turn feature ideas into detailed implementation plans&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;/workflows:work&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Execute plans with worktrees and task tracking&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;/workflows:review&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Multi-agent code review before merging&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;/workflows:compound&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Document learnings to make future work easier&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Each cycle compounds: plans inform future plans, reviews catch more issues, patterns get documented.&lt;/p&gt; 
&lt;h2&gt;Philosophy&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Each unit of engineering work should make subsequent units easier‚Äînot harder.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Traditional development accumulates technical debt. Every feature adds complexity. The codebase becomes harder to work with over time.&lt;/p&gt; 
&lt;p&gt;Compound engineering inverts this. 80% is in planning and review, 20% is in execution:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Plan thoroughly before writing code&lt;/li&gt; 
 &lt;li&gt;Review to catch issues and capture learnings&lt;/li&gt; 
 &lt;li&gt;Codify knowledge so it's reusable&lt;/li&gt; 
 &lt;li&gt;Keep quality high so future changes are easy&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Learn More&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EveryInc/compound-engineering-plugin/main/plugins/compound-engineering/README.md"&gt;Full component reference&lt;/a&gt; - all agents, commands, skills&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://every.to/chain-of-thought/compound-engineering-how-every-codes-with-agents"&gt;Compound engineering: how Every codes with agents&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://every.to/source-code/my-ai-had-already-fixed-the-code-before-i-saw-it"&gt;The story behind compounding engineering&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>hacksider/Deep-Live-Cam</title>
      <link>https://github.com/hacksider/Deep-Live-Cam</link>
      <description>&lt;p&gt;real time face swap and one-click video deepfake with only a single image&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt;Deep-Live-Cam 2.0.1c&lt;/h1&gt; 
&lt;p align="center"&gt; Real-time face swap and video deepfake with a single click and only a single image. &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/11395" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/11395" alt="hacksider%2FDeep-Live-Cam | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/demo.gif" alt="Demo GIF" width="800" /&gt; &lt;/p&gt; 
&lt;h2&gt;Disclaimer&lt;/h2&gt; 
&lt;p&gt;This deepfake software is designed to be a productive tool for the AI-generated media industry. It can assist artists in animating custom characters, creating engaging content, and even using models for clothing design.&lt;/p&gt; 
&lt;p&gt;We are aware of the potential for unethical applications and are committed to preventative measures. A built-in check prevents the program from processing inappropriate media (nudity, graphic content, sensitive material like war footage, etc.). We will continue to develop this project responsibly, adhering to the law and ethics. We may shut down the project or add watermarks if legally required.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Ethical Use: Users are expected to use this software responsibly and legally. If using a real person's face, obtain their consent and clearly label any output as a deepfake when sharing online.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Content Restrictions: The software includes built-in checks to prevent processing inappropriate media, such as nudity, graphic content, or sensitive material.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Legal Compliance: We adhere to all relevant laws and ethical guidelines. If legally required, we may shut down the project or add watermarks to the output.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;User Responsibility: We are not responsible for end-user actions. Users must ensure their use of the software aligns with ethical standards and legal requirements.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;By using this software, you agree to these terms and commit to using it in a manner that respects the rights and dignity of others.&lt;/p&gt; 
&lt;p&gt;Users are expected to use this software responsibly and legally. If using a real person's face, obtain their consent and clearly label any output as a deepfake when sharing online. We are not responsible for end-user actions.&lt;/p&gt; 
&lt;h2&gt;Exclusive v2.4 Quick Start - Pre-built (Windows/Mac Silicon)&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://deeplivecam.net/index.php/quickstart"&gt; &lt;img src="https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/Download.png" width="285" height="77" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;a href="https://deeplivecam.net/index.php/quickstart"&gt; &lt;h5&gt;This is the fastest build you can get if you have a discrete NVIDIA or AMD GPU or Mac Silicon, And you'll receive special priority support.&lt;/h5&gt; &lt;h6&gt;These Pre-builts are perfect for non-technical users or those who don't have time to, or can't manually install all the requirements. Just a heads-up: this is an open-source project, so you can also install it manually.&lt;/h6&gt; &lt;h2&gt;TLDR; Live Deepfake in just 3 Clicks&lt;/h2&gt; &lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/af825228-852c-411b-b787-ffd9aac72fc6" alt="easysteps" /&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Select a face&lt;/li&gt; 
  &lt;li&gt;Select which camera to use&lt;/li&gt; 
  &lt;li&gt;Press live!&lt;/li&gt; 
 &lt;/ol&gt; &lt;h2&gt;Features &amp;amp; Uses - Everything is in real-time&lt;/h2&gt; &lt;h3&gt;Mouth Mask&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Retain your original mouth for accurate movement using Mouth Mask&lt;/strong&gt;&lt;/p&gt; &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/ludwig.gif" alt="resizable-gif" /&gt; &lt;/p&gt; &lt;h3&gt;Face Mapping&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Use different faces on multiple subjects simultaneously&lt;/strong&gt;&lt;/p&gt; &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/streamers.gif" alt="face_mapping_source" /&gt; &lt;/p&gt; &lt;h3&gt;Your Movie, Your Face&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Watch movies with any face in real-time&lt;/strong&gt;&lt;/p&gt; &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/movie.gif" alt="movie" /&gt; &lt;/p&gt; &lt;h3&gt;Live Show&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Run Live shows and performances&lt;/strong&gt;&lt;/p&gt; &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/live_show.gif" alt="show" /&gt; &lt;/p&gt; &lt;h3&gt;Memes&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Create Your Most Viral Meme Yet&lt;/strong&gt;&lt;/p&gt; &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/meme.gif" alt="show" width="450" /&gt; &lt;br /&gt; &lt;sub&gt;Created using Many Faces feature in Deep-Live-Cam&lt;/sub&gt; &lt;/p&gt; &lt;h3&gt;Omegle&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Surprise people on Omegle&lt;/strong&gt;&lt;/p&gt; &lt;p align="center"&gt; 
  &lt;video src="https://github.com/user-attachments/assets/2e9b9b82-fa04-4b70-9f56-b1f68e7672d0" width="450" controls&gt;&lt;/video&gt; &lt;/p&gt; &lt;h2&gt;Installation (Manual)&lt;/h2&gt; &lt;p&gt;&lt;strong&gt;Please be aware that the installation requires technical skills and is not for beginners. Consider downloading the quickstart version.&lt;/strong&gt;&lt;/p&gt; &lt;/a&gt;
&lt;details&gt;
 &lt;a href="https://deeplivecam.net/index.php/quickstart"&gt; &lt;summary&gt;Click to see the process&lt;/summary&gt; &lt;h3&gt;Installation&lt;/h3&gt; &lt;p&gt;This is more likely to work on your computer but will be slower as it utilizes the CPU.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;1. Set up Your Platform&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Python (3.11 recommended)&lt;/li&gt; 
   &lt;li&gt;pip&lt;/li&gt; 
   &lt;li&gt;git&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=OlNWCpFdVMA"&gt;ffmpeg&lt;/a&gt; - &lt;code&gt;iex (irm ffmpeg.tc.ht)&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://visualstudio.microsoft.com/visual-cpp-build-tools/"&gt;Visual Studio 2022 Runtimes (Windows)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt;&lt;/a&gt; 
 &lt;p&gt;&lt;strong&gt;2. Clone the Repository&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/hacksider/Deep-Live-Cam.git
cd Deep-Live-Cam
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;3. Download the Models&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/hacksider/deep-live-cam/resolve/main/GFPGANv1.4.pth"&gt;GFPGANv1.4&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/hacksider/deep-live-cam/resolve/main/inswapper_128_fp16.onnx"&gt;inswapper_128_fp16.onnx&lt;/a&gt;&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;Place these files in the "&lt;strong&gt;models&lt;/strong&gt;" folder.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;4. Install Dependencies&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;We highly recommend using a &lt;code&gt;venv&lt;/code&gt; to avoid issues.&lt;/p&gt; 
 &lt;p&gt;For Windows:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;python -m venv venv
venv\Scripts\activate
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;For Linux:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Ensure you use the installed Python 3.10
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;For macOS:&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Apple Silicon (M1/M2/M3) requires specific setup:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Install Python 3.11 (specific version is important)
brew install python@3.11

# Install tkinter package (required for the GUI)
brew install python-tk@3.10

# Create and activate virtual environment with Python 3.11
python3.11 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;** In case something goes wrong and you need to reinstall the virtual environment **&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Deactivate the virtual environment
rm -rf venv

# Reinstall the virtual environment
python -m venv venv
source venv/bin/activate

# install the dependencies again
pip install -r requirements.txt

# gfpgan and basicsrs issue fix
pip install git+https://github.com/xinntao/BasicSR.git@master
pip uninstall gfpgan -y
pip install git+https://github.com/TencentARC/GFPGAN.git@master
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Run:&lt;/strong&gt; If you don't have a GPU, you can run Deep-Live-Cam using &lt;code&gt;python run.py&lt;/code&gt;. Note that initial execution will download models (~300MB).&lt;/p&gt; 
 &lt;h3&gt;GPU Acceleration&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;CUDA Execution Provider (Nvidia)&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Install &lt;a href="https://developer.nvidia.com/cuda-12-8-0-download-archive"&gt;CUDA Toolkit 12.8.0&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Install &lt;a href="https://developer.nvidia.com/rdp/cudnn-archive"&gt;cuDNN v8.9.7 for CUDA 12.x&lt;/a&gt; (required for onnxruntime-gpu): 
   &lt;ul&gt; 
    &lt;li&gt;Download cuDNN v8.9.7 for CUDA 12.x&lt;/li&gt; 
    &lt;li&gt;Make sure the cuDNN bin directory is in your system PATH&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Install dependencies:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;pip install -U torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128
pip uninstall onnxruntime onnxruntime-gpu
pip install onnxruntime-gpu==1.21.0
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="3"&gt; 
  &lt;li&gt;Usage:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;python run.py --execution-provider cuda
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;CoreML Execution Provider (Apple Silicon)&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Apple Silicon (M1/M2/M3) specific installation:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Make sure you've completed the macOS setup above using Python 3.10.&lt;/li&gt; 
  &lt;li&gt;Install dependencies:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;pip uninstall onnxruntime onnxruntime-silicon
pip install onnxruntime-silicon==1.13.1
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="3"&gt; 
  &lt;li&gt;Usage (important: specify Python 3.10):&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;python3.10 run.py --execution-provider coreml
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Important Notes for macOS:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;You &lt;strong&gt;must&lt;/strong&gt; use Python 3.10, not newer versions like 3.11 or 3.13&lt;/li&gt; 
  &lt;li&gt;Always run with &lt;code&gt;python3.10&lt;/code&gt; command not just &lt;code&gt;python&lt;/code&gt; if you have multiple Python versions installed&lt;/li&gt; 
  &lt;li&gt;If you get error about &lt;code&gt;_tkinter&lt;/code&gt; missing, reinstall the tkinter package: &lt;code&gt;brew reinstall python-tk@3.10&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;If you get model loading errors, check that your models are in the correct folder&lt;/li&gt; 
  &lt;li&gt;If you encounter conflicts with other Python versions, consider uninstalling them: &lt;pre&gt;&lt;code class="language-bash"&gt;# List all installed Python versions
brew list | grep python

# Uninstall conflicting versions if needed
brew uninstall --ignore-dependencies python@3.11 python@3.13

# Keep only Python 3.11
brew cleanup
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;CoreML Execution Provider (Apple Legacy)&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Install dependencies:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;pip uninstall onnxruntime onnxruntime-coreml
pip install onnxruntime-coreml==1.21.0
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="2"&gt; 
  &lt;li&gt;Usage:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;python run.py --execution-provider coreml
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;DirectML Execution Provider (Windows)&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Install dependencies:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;pip uninstall onnxruntime onnxruntime-directml
pip install onnxruntime-directml==1.21.0
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="2"&gt; 
  &lt;li&gt;Usage:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;python run.py --execution-provider directml
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;OpenVINO‚Ñ¢ Execution Provider (Intel)&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Install dependencies:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;pip uninstall onnxruntime onnxruntime-openvino
pip install onnxruntime-openvino==1.21.0
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="2"&gt; 
  &lt;li&gt;Usage:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;python run.py --execution-provider openvino
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;1. Image/Video Mode&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Execute &lt;code&gt;python run.py&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Choose a source face image and a target image/video.&lt;/li&gt; 
 &lt;li&gt;Click "Start".&lt;/li&gt; 
 &lt;li&gt;The output will be saved in a directory named after the target video.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2. Webcam Mode&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Execute &lt;code&gt;python run.py&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Select a source face image.&lt;/li&gt; 
 &lt;li&gt;Click "Live".&lt;/li&gt; 
 &lt;li&gt;Wait for the preview to appear (10-30 seconds).&lt;/li&gt; 
 &lt;li&gt;Use a screen capture tool like OBS to stream.&lt;/li&gt; 
 &lt;li&gt;To change the face, select a new source image.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Command Line Arguments (Unmaintained)&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;options:
  -h, --help                                               show this help message and exit
  -s SOURCE_PATH, --source SOURCE_PATH                     select a source image
  -t TARGET_PATH, --target TARGET_PATH                     select a target image or video
  -o OUTPUT_PATH, --output OUTPUT_PATH                     select output file or directory
  --frame-processor FRAME_PROCESSOR [FRAME_PROCESSOR ...]  frame processors (choices: face_swapper, face_enhancer, ...)
  --keep-fps                                               keep original fps
  --keep-audio                                             keep original audio
  --keep-frames                                            keep temporary frames
  --many-faces                                             process every face
  --map-faces                                              map source target faces
  --mouth-mask                                             mask the mouth region
  --video-encoder {libx264,libx265,libvpx-vp9}             adjust output video encoder
  --video-quality [0-51]                                   adjust output video quality
  --live-mirror                                            the live camera display as you see it in the front-facing camera frame
  --live-resizable                                         the live camera frame is resizable
  --max-memory MAX_MEMORY                                  maximum amount of RAM in GB
  --execution-provider {cpu} [{cpu} ...]                   available execution provider (choices: cpu, ...)
  --execution-threads EXECUTION_THREADS                    number of execution threads
  -v, --version                                            show program's version number and exit
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Looking for a CLI mode? Using the -s/--source argument will make the run program in cli mode.&lt;/p&gt; 
&lt;h2&gt;Press&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;We are always open to criticism and are ready to improve, that's why we didn't cherry-pick anything.&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://arstechnica.com/information-technology/2024/08/new-ai-tool-enables-real-time-face-swapping-on-webcams-raising-fraud-concerns/"&gt;&lt;em&gt;"Deep-Live-Cam goes viral, allowing anyone to become a digital doppelganger"&lt;/em&gt;&lt;/a&gt; - Ars Technica&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://dataconomy.com/2024/08/15/what-is-deep-live-cam-github-deepfake/"&gt;&lt;em&gt;"Thanks Deep Live Cam, shapeshifters are among us now"&lt;/em&gt;&lt;/a&gt; - Dataconomy&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.newsbytesapp.com/news/science/deep-live-cam-ai-impersonation-tool-goes-viral/story"&gt;&lt;em&gt;"This free AI tool lets you become anyone during video-calls"&lt;/em&gt;&lt;/a&gt; - NewsBytes&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.creativebloq.com/ai/ok-this-viral-ai-live-stream-software-is-truly-terrifying"&gt;&lt;em&gt;"OK, this viral AI live stream software is truly terrifying"&lt;/em&gt;&lt;/a&gt; - Creative Bloq&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://petapixel.com/2024/08/14/deep-live-cam-deepfake-ai-tool-lets-you-become-anyone-in-a-video-call-with-single-photo-mark-zuckerberg-jd-vance-elon-musk/"&gt;&lt;em&gt;"Deepfake AI Tool Lets You Become Anyone in a Video Call With Single Photo"&lt;/em&gt;&lt;/a&gt; - PetaPixel&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.techeblog.com/deep-live-cam-ai-transform-face/"&gt;&lt;em&gt;"Deep-Live-Cam Uses AI to Transform Your Face in Real-Time, Celebrities Included"&lt;/em&gt;&lt;/a&gt; - TechEBlog&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://telegrafi.com/en/a-tool-that-makes-you-look-like-anyone-during-a-video-call-is-going-viral-on-the-Internet/"&gt;&lt;em&gt;"An AI tool that "makes you look like anyone" during a video call is going viral online"&lt;/em&gt;&lt;/a&gt; - Telegrafi&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://decrypt.co/244565/this-deepfake-tool-turning-images-into-livestreams-is-topping-the-github-charts"&gt;&lt;em&gt;"This Deepfake Tool Turning Images Into Livestreams is Topping the GitHub Charts"&lt;/em&gt;&lt;/a&gt; - Emerge&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.digitalmusicnews.com/2024/08/15/face-swapping-ai-real-time-mimic/"&gt;&lt;em&gt;"New Real-Time Face-Swapping AI Allows Anyone to Mimic Famous Faces"&lt;/em&gt;&lt;/a&gt; - Digital Music News&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.diyphotography.net/this-real-time-webcam-deepfake-tool-raises-alarms-about-the-future-of-identity-theft/"&gt;&lt;em&gt;"This real-time webcam deepfake tool raises alarms about the future of identity theft"&lt;/em&gt;&lt;/a&gt; - DIYPhotography&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?time_continue=1074&amp;amp;v=py4Tc-Y8BcY"&gt;&lt;em&gt;"That's Crazy, Oh God. That's Fucking Freaky Dude... That's So Wild Dude"&lt;/em&gt;&lt;/a&gt; - SomeOrdinaryGamers&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/live/mFsCe7AIxq8?feature=shared&amp;amp;t=2686"&gt;&lt;em&gt;"Alright look look look, now look chat, we can do any face we want to look like chat"&lt;/em&gt;&lt;/a&gt; - IShowSpeed&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=wnCghLjqv3s&amp;amp;t=551s"&gt;&lt;em&gt;"They do a pretty good job matching poses, expression and even the lighting"&lt;/em&gt;&lt;/a&gt; - TechLinked (LTT)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.golem.de/news/deepfakes-als-sean-connery-an-der-redaktionskonferenz-teilnahm-2408-188172.html"&gt;&lt;em&gt;"Als Sean Connery an der Redaktionskonferenz teilnahm"&lt;/em&gt;&lt;/a&gt; - Golem.de (German)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/JbUPRmXRUtE?t=3964"&gt;&lt;em&gt;"What the F&lt;/em&gt;**! Why do I look like Vinny Jr? I look exactly like Vinny Jr!? No, this shit is crazy! Bro This is F*** Crazy! "*&lt;/a&gt; - IShowSpeed&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Credits&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://ffmpeg.org/"&gt;ffmpeg&lt;/a&gt;: for making video-related operations easy&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/henryruhs"&gt;Henry&lt;/a&gt;: One of the major contributor in this repo&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/deepinsight"&gt;deepinsight&lt;/a&gt;: for their &lt;a href="https://github.com/deepinsight/insightface"&gt;insightface&lt;/a&gt; project which provided a well-made library and models. Please be reminded that the &lt;a href="https://github.com/deepinsight/insightface?tab=readme-ov-file#license"&gt;use of the model is for non-commercial research purposes only&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/havok2-htwo"&gt;havok2-htwo&lt;/a&gt;: for sharing the code for webcam&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/GosuDRM"&gt;GosuDRM&lt;/a&gt;: for the open version of roop&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pereiraroland26"&gt;pereiraroland26&lt;/a&gt;: Multiple faces support&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/vic4key"&gt;vic4key&lt;/a&gt;: For supporting/contributing to this project&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kier007"&gt;kier007&lt;/a&gt;: for improving the user experience&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/qitianai"&gt;qitianai&lt;/a&gt;: for multi-lingual support&lt;/li&gt; 
 &lt;li&gt;and &lt;a href="https://github.com/hacksider/Deep-Live-Cam/graphs/contributors"&gt;all developers&lt;/a&gt; behind libraries used in this project.&lt;/li&gt; 
 &lt;li&gt;Footnote: Please be informed that the base author of the code is &lt;a href="https://github.com/s0md3v/roop"&gt;s0md3v&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;All the wonderful users who helped make this project go viral by starring the repo ‚ù§Ô∏è&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://github.com/hacksider/Deep-Live-Cam/stargazers"&gt;&lt;img src="https://reporoster.com/stars/hacksider/Deep-Live-Cam" alt="Stargazers" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributions&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://repobeats.axiom.co/api/embed/fec8e29c45dfdb9c5916f3a7830e1249308d20e1.svg?sanitize=true" alt="Alt" title="Repobeats analytics image" /&gt;&lt;/p&gt; 
&lt;h2&gt;Stars to the Moon üöÄ&lt;/h2&gt; 
&lt;a href="https://star-history.com/#hacksider/deep-live-cam&amp;amp;Date"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=hacksider/deep-live-cam&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=hacksider/deep-live-cam&amp;amp;type=Date" /&gt; 
  &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=hacksider/deep-live-cam&amp;amp;type=Date" /&gt; 
 &lt;/picture&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>OpenBMB/ChatDev</title>
      <link>https://github.com/OpenBMB/ChatDev</link>
      <description>&lt;p&gt;ChatDev 2.0: Dev All through LLM-powered Multi-Agent Collaboration&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ChatDev 2.0 - DevAll&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/frontend/public/media/logo.png" alt="DevAll Logo" width="500" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;strong&gt;A Zero-Code Multi-Agent Platform for Developing Everything&lt;/strong&gt; &lt;/p&gt; 
&lt;p align="center"&gt; „Äê&lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/README.md"&gt;English&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/README-zh.md"&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt;„Äë &lt;/p&gt; 
&lt;p align="center"&gt; „Äêüìö &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/#developers"&gt;Developers&lt;/a&gt; | üë• &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/#primary-contributors"&gt;Contributors&lt;/a&gt;ÔΩú‚≠êÔ∏è &lt;a href="https://github.com/OpenBMB/ChatDev/tree/chatdev1.0"&gt;ChatDev 1.0 (Legacy)&lt;/a&gt;„Äë &lt;/p&gt; 
&lt;h2&gt;üìñ Overview&lt;/h2&gt; 
&lt;p&gt;ChatDev has evolved from a specialized software development multi-agent system into a comprehensive multi-agent orchestration platform.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/OpenBMB/ChatDev/tree/main"&gt;&lt;strong&gt;ChatDev 2.0 (DevAll)&lt;/strong&gt;&lt;/a&gt; is a &lt;strong&gt;Zero-Code Multi-Agent Platform&lt;/strong&gt; for "Developing Everything". It empowers users to rapidly build and execute customized multi-agent systems through simple configuration. No coding is required‚Äîusers can define agents, workflows, and tasks to orchestrate complex scenarios such as data visualization, 3D generation, and deep research.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/OpenBMB/ChatDev/tree/chatdev1.0"&gt;&lt;strong&gt;ChatDev 1.0 (Legacy)&lt;/strong&gt;&lt;/a&gt; operates as a &lt;strong&gt;Virtual Software Company&lt;/strong&gt;. It utilizes various intelligent agents (e.g., CEO, CTO, Programmer) participating in specialized functional seminars to automate the entire software development life cycle‚Äîincluding designing, coding, testing, and documenting. It serves as the foundational paradigm for communicative agent collaboration.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üéâ News&lt;/h2&gt; 
&lt;p&gt;‚Ä¢ &lt;strong&gt;Jan 07, 2026: üöÄ We are excited to announce the official release of ChatDev 2.0 (DevAll)!&lt;/strong&gt; This version introduces a zero-code multi-agent orchestration platform. The classic ChatDev (v1.x) has been moved to the &lt;a href="https://github.com/OpenBMB/ChatDev/tree/chatdev1.0"&gt;&lt;code&gt;chatdev1.0&lt;/code&gt;&lt;/a&gt; branch for maintenance. More details about ChatDev 2.0 can be found on &lt;a href="https://x.com/OpenBMB/status/2008916790399701335"&gt;our official post&lt;/a&gt;.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Old News&lt;/summary&gt; 
 &lt;p&gt;‚Ä¢Sep 24, 2025: üéâ Our paper &lt;a href="https://arxiv.org/abs/2505.19591"&gt;Multi-Agent Collaboration via Evolving Orchestration&lt;/a&gt; has been accepted to NeurIPS 2025. The implementation is available in the &lt;code&gt;puppeteer&lt;/code&gt; branch of this repository.&lt;/p&gt; 
 &lt;p&gt;‚Ä¢May 26, 2025: üéâ We propose a novel puppeteer-style paradigm for multi-agent collaboration among large language model based agents. By leveraging a learnable central orchestrator optimized with reinforcement learning, our method dynamically activates and sequences agents to construct efficient, context-aware reasoning paths. This approach not only improves reasoning quality but also reduces computational costs, enabling scalable and adaptable multi-agent cooperation in complex tasks. See our paper in &lt;a href="https://arxiv.org/abs/2505.19591"&gt;Multi-Agent Collaboration via Evolving Orchestration&lt;/a&gt;.&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/puppeteer.png" width="800" /&gt; &lt;/p&gt; 
 &lt;p&gt;‚Ä¢June 25, 2024: üéâTo foster development in LLM-powered multi-agent collaborationü§ñü§ñ and related fields, the ChatDev team has curated a collection of seminal papersüìÑ presented in a &lt;a href="https://github.com/OpenBMB/ChatDev/tree/main/MultiAgentEbook"&gt;open-source&lt;/a&gt; interactive e-booküìö format. Now you can explore the latest advancements on the &lt;a href="https://thinkwee.top/multiagent_ebook"&gt;Ebook Website&lt;/a&gt; and download the &lt;a href="https://github.com/OpenBMB/ChatDev/raw/main/MultiAgentEbook/papers.csv"&gt;paper list&lt;/a&gt;.&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/ebook.png" width="800" /&gt; &lt;/p&gt; 
 &lt;p&gt;‚Ä¢June 12, 2024: We introduced Multi-Agent Collaboration Networks (MacNet) üéâ, which utilize directed acyclic graphs to facilitate effective task-oriented collaboration among agents through linguistic interactions ü§ñü§ñ. MacNet supports co-operation across various topologies and among more than a thousand agents without exceeding context limits. More versatile and scalable, MacNet can be considered as a more advanced version of ChatDev's chain-shaped topology. Our preprint paper is available at &lt;a href="https://arxiv.org/abs/2406.07155"&gt;https://arxiv.org/abs/2406.07155&lt;/a&gt;. This technique has been incorporated into the &lt;a href="https://github.com/OpenBMB/ChatDev/tree/macnet"&gt;macnet&lt;/a&gt; branch, enhancing support for diverse organizational structures and offering richer solutions beyond software development (e.g., logical reasoning, data analysis, story generation, and more).&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/macnet.png" width="500" /&gt; &lt;/p&gt; 
 &lt;p&gt;‚Ä¢ May 07, 2024, we introduced "Iterative Experience Refinement" (IER), a novel method where instructor and assistant agents enhance shortcut-oriented experiences to efficiently adapt to new tasks. This approach encompasses experience acquisition, utilization, propagation and elimination across a series of tasks and making the pricess shorter and efficient. Our preprint paper is available at &lt;a href="https://arxiv.org/abs/2405.04219"&gt;https://arxiv.org/abs/2405.04219&lt;/a&gt;, and this technique will soon be incorporated into ChatDev.&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/ier.png" width="220" /&gt; &lt;/p&gt; 
 &lt;p&gt;‚Ä¢ January 25, 2024: We have integrated Experiential Co-Learning Module into ChatDev. Please see the &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/wiki.md#co-tracking"&gt;Experiential Co-Learning Guide&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;‚Ä¢ December 28, 2023: We present Experiential Co-Learning, an innovative approach where instructor and assistant agents accumulate shortcut-oriented experiences to effectively solve new tasks, reducing repetitive errors and enhancing efficiency. Check out our preprint paper at &lt;a href="https://arxiv.org/abs/2312.17025"&gt;https://arxiv.org/abs/2312.17025&lt;/a&gt; and this technique will soon be integrated into ChatDev.&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/ecl.png" width="860" /&gt; &lt;/p&gt; ‚Ä¢ November 15, 2023: We launched ChatDev as a SaaS platform that enables software developers and innovative entrepreneurs to build software efficiently at a very low cost and remove the barrier to entry. Try it out at https://chatdev.modelbest.cn/. 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/saas.png" width="560" /&gt; &lt;/p&gt; 
 &lt;p&gt;‚Ä¢ November 2, 2023: ChatDev is now supported with a new feature: incremental development, which allows agents to develop upon existing codes. Try &lt;code&gt;--config "incremental" --path "[source_code_directory_path]"&lt;/code&gt; to start it.&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/increment.png" width="700" /&gt; &lt;/p&gt; 
 &lt;p&gt;‚Ä¢ October 26, 2023: ChatDev is now supported with Docker for safe execution (thanks to contribution from &lt;a href="https://github.com/ManindraDeMel"&gt;ManindraDeMel&lt;/a&gt;). Please see &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/wiki.md#docker-start"&gt;Docker Start Guide&lt;/a&gt;.&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/docker.png" width="400" /&gt; &lt;/p&gt; 
 &lt;p&gt;‚Ä¢ September 25, 2023: The &lt;strong&gt;Git&lt;/strong&gt; mode is now available, enabling the programmer &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/visualizer/static/figures/programmer.png" height="20" /&gt; to utilize Git for version control. To enable this feature, simply set &lt;code&gt;"git_management"&lt;/code&gt; to &lt;code&gt;"True"&lt;/code&gt; in &lt;code&gt;ChatChainConfig.json&lt;/code&gt;. See &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/wiki.md#git-mode"&gt;guide&lt;/a&gt;.&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/github.png" width="600" /&gt; &lt;/p&gt; 
 &lt;p&gt;‚Ä¢ September 20, 2023: The &lt;strong&gt;Human-Agent-Interaction&lt;/strong&gt; mode is now available! You can get involved with the ChatDev team by playing the role of reviewer &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/visualizer/static/figures/reviewer.png" height="20" /&gt; and making suggestions to the programmer &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/visualizer/static/figures/programmer.png" height="20" /&gt;; try &lt;code&gt;python3 run.py --task [description_of_your_idea] --config "Human"&lt;/code&gt;. See &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/wiki.md#human-agent-interaction"&gt;guide&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/WareHouse/Gomoku_HumanAgentInteraction_20230920135038"&gt;example&lt;/a&gt;.&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/Human_intro.png" width="600" /&gt; &lt;/p&gt; 
 &lt;p&gt;‚Ä¢ September 1, 2023: The &lt;strong&gt;Art&lt;/strong&gt; mode is available now! You can activate the designer agent &lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/visualizer/static/figures/designer.png" height="20" /&gt; to generate images used in the software; try &lt;code&gt;python3 run.py --task [description_of_your_idea] --config "Art"&lt;/code&gt;. See &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/wiki.md#art"&gt;guide&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/WareHouse/gomokugameArtExample_THUNLP_20230831122822"&gt;example&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;‚Ä¢ August 28, 2023: The system is publicly available.&lt;/p&gt; 
 &lt;p&gt;‚Ä¢ August 17, 2023: The v1.0.0 version was ready for release.&lt;/p&gt; 
 &lt;p&gt;‚Ä¢ July 30, 2023: Users can customize ChatChain, Phasea and Role settings. Additionally, both online Log mode and replay mode are now supported.&lt;/p&gt; 
 &lt;p&gt;‚Ä¢ July 16, 2023: The &lt;a href="https://arxiv.org/abs/2307.07924"&gt;preprint paper&lt;/a&gt; associated with this project was published.&lt;/p&gt; 
 &lt;p&gt;‚Ä¢ June 30, 2023: The initial version of the ChatDev repository was released.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;üöÄ Quick Start&lt;/h2&gt; 
&lt;h3&gt;üìã Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;OS&lt;/strong&gt;: macOS / Linux / WSL / Windows&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Python&lt;/strong&gt;: 3.12+&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Node.js&lt;/strong&gt;: 18+&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Package Manager&lt;/strong&gt;: &lt;a href="https://docs.astral.sh/uv/"&gt;uv&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üì¶ Installation&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Backend Dependencies&lt;/strong&gt; (Python managed by &lt;code&gt;uv&lt;/code&gt;):&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;uv sync
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Frontend Dependencies&lt;/strong&gt; (Vite + Vue 3):&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;cd frontend &amp;amp;&amp;amp; npm install
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;‚ö°Ô∏è Run the Application&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Start Backend&lt;/strong&gt; :&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# Run from the project root
uv run python server_main.py --port 6400 --reload
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Start Frontend&lt;/strong&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;cd frontend
VITE_API_BASE_URL=http://localhost:6400 npm run dev
&lt;/code&gt;&lt;/pre&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;Then access the Web Console at &lt;strong&gt;&lt;a href="http://localhost:5173"&gt;http://localhost:5173&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;üîë Configuration&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Environment Variables&lt;/strong&gt;: Create a &lt;code&gt;.env&lt;/code&gt; file in the project root.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Model Keys&lt;/strong&gt;: Set &lt;code&gt;API_KEY&lt;/code&gt; and &lt;code&gt;BASE_URL&lt;/code&gt; in &lt;code&gt;.env&lt;/code&gt; for your LLM provider.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;YAML placeholders&lt;/strong&gt;: Use &lt;code&gt;${VAR}&lt;/code&gt;Ôºàe.g., &lt;code&gt;${API_KEY}&lt;/code&gt;Ôºâin configuration files to reference these variables.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üí° How to Use&lt;/h2&gt; 
&lt;h3&gt;üñ•Ô∏è Web Console&lt;/h3&gt; 
&lt;p&gt;The DevAll interface provides a seamless experience for both construction and execution&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Tutorial&lt;/strong&gt;: Comprehensive step-by-step guides and documentation integrated directly into the platform to help you get started quickly.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/tutorial-en.png" /&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Workflow&lt;/strong&gt;: A visual canvas to design your multi-agent systems. Configure node parameters, define context flows, and orchestrate complex agent interactions with drag-and-drop ease.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/workflow.gif" /&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Launch&lt;/strong&gt;: Initiate workflows, monitor real-time logs, inspect intermediate artifacts, and provide human-in-the-loop feedback.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/launch.gif" /&gt; 
&lt;h3&gt;üß∞ Python SDK&lt;/h3&gt; 
&lt;p&gt;For automation and batch processing, use our lightweight Python SDK to execute workflows programmatically and retrieve results directly.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from runtime.sdk import run_workflow

# Execute a workflow and get the final node message
result = run_workflow(
    yaml_file="yaml_instance/demo.yaml",
    task_prompt="Summarize the attached document in one sentence.",
    attachments=["/path/to/document.pdf"],
    variables={"API_KEY": "sk-xxxx"} # Override .env variables if needed
)

if result.final_message:
    print(f"Output: {result.final_message.text_content()}")
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;a id="developers"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;‚öôÔ∏è For Developers&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;For secondary development and extensions, please proceed with this section.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Extend DevAll with new nodes, providers, and tools. The project is organized into a modular structure:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Core Systems&lt;/strong&gt;: &lt;code&gt;server/&lt;/code&gt; hosts the FastAPI backend, while &lt;code&gt;runtime/&lt;/code&gt; manages agent abstraction and tool execution.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Orchestration&lt;/strong&gt;: &lt;code&gt;workflow/&lt;/code&gt; handles the multi-agent logic, driven by configurations in &lt;code&gt;entity/&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Frontend&lt;/strong&gt;: &lt;code&gt;frontend/&lt;/code&gt; contains the Vue 3 Web Console.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Extensibility&lt;/strong&gt;: &lt;code&gt;functions/&lt;/code&gt; is the place for custom Python tools.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Relevant reference documentation:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Getting Started&lt;/strong&gt;: &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/docs/user_guide/en/index.md"&gt;Start Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Core Modules&lt;/strong&gt;: &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/docs/user_guide/en/workflow_authoring.md"&gt;Workflow Authoring&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/docs/user_guide/en/modules/memory.md"&gt;Memory&lt;/a&gt;, and &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/docs/user_guide/en/modules/tooling/index.md"&gt;Tooling&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üåü Featured Workflows&lt;/h2&gt; 
&lt;p&gt;We provide robust, out-of-the-box templates for common scenarios. All runnable workflow configs are located in &lt;code&gt;yaml_instance/&lt;/code&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Demos&lt;/strong&gt;: Files named &lt;code&gt;demo_*.yaml&lt;/code&gt; showcase specific features or modules.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Implementations&lt;/strong&gt;: Files named directly (e.g., &lt;code&gt;ChatDev_v1.yaml&lt;/code&gt;) are full in-house or recreated workflows. As follows:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üìã Workflow Collection&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Category&lt;/th&gt; 
   &lt;th align="left"&gt;Workflow&lt;/th&gt; 
   &lt;th align="left"&gt;Case&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;üìà Data Visualization&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;data_visualization_basic.yaml&lt;/code&gt;&lt;br /&gt;&lt;code&gt;data_visualization_enhanced.yaml&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/cases/data_analysis/data_analysis.gif" width="100%" /&gt;&lt;br /&gt;Prompt: &lt;em&gt;"Create 4‚Äì6 high-quality PNG charts for my large real-estate transactions dataset."&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;üõ†Ô∏è 3D Generation&lt;/strong&gt;&lt;br /&gt;&lt;em&gt;(Requires &lt;a href="https://www.blender.org/"&gt;Blender&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/ahujasid/blender-mcp"&gt;blender-mcp&lt;/a&gt;)&lt;/em&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;blender_3d_builder_simple.yaml&lt;/code&gt;&lt;br /&gt;&lt;code&gt;blender_3d_builder_hub.yaml&lt;/code&gt;&lt;br /&gt;&lt;code&gt;blender_scientific_illustration.yaml&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/cases/3d_generation/3d.gif" width="100%" /&gt;&lt;br /&gt;Prompt: &lt;em&gt;"Please build a Christmas tree."&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;üéÆ Game Dev&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;GameDev_v1.yaml&lt;/code&gt;&lt;br /&gt;&lt;code&gt;ChatDev_v1.yaml&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/cases/game_development/game.gif" width="100%" /&gt;&lt;br /&gt;Prompt: &lt;em&gt;"Please help me design and develop a Tank Battle game."&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;üìö Deep Research&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;deep_research_v1.yaml&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/cases/deep_research/deep_research.gif" width="85%" /&gt;&lt;br /&gt;Prompt: &lt;em&gt;"Research about recent advances in the field of LLM-based agent RL"&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;üéì Teach Video&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;teach_video.yaml&lt;/code&gt; (Please run command &lt;code&gt;uv add manim&lt;/code&gt; before running this workflow)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/cases/video_generation/video.gif" width="140%" /&gt;&lt;br /&gt;Prompt: &lt;em&gt;"ËÆ≤‰∏Ä‰∏ã‰ªÄ‰πàÊòØÂá∏‰ºòÂåñ"&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h3&gt;üí° Usage Guide&lt;/h3&gt; 
&lt;p&gt;For those implementations, you can use the &lt;strong&gt;Launch&lt;/strong&gt; tab to execute them.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Select&lt;/strong&gt;: Choose a workflow in the &lt;strong&gt;Launch&lt;/strong&gt; tab.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Upload&lt;/strong&gt;: Upload necessary files (e.g., &lt;code&gt;.csv&lt;/code&gt; for data analysis) if required.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Prompt&lt;/strong&gt;: Enter your request (e.g., &lt;em&gt;"Visualize the sales trends"&lt;/em&gt; or &lt;em&gt;"Design a snake game"&lt;/em&gt;).&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions from the community! Whether you're fixing bugs, adding new workflow templates, or sharing high-quality cases/artifacts produced by DevAll, your help is much appreciated. Feel free to contribute by submitting &lt;strong&gt;Issues&lt;/strong&gt; or &lt;strong&gt;Pull Requests&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;By contributing to DevAll, you'll be recognized in our &lt;strong&gt;Contributors&lt;/strong&gt; list below. Check out our &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/#developers"&gt;Developer Guide&lt;/a&gt; to get started!&lt;/p&gt; 
&lt;h3&gt;üë• Contributors&lt;/h3&gt; 
&lt;h4&gt;Primary Contributors&lt;/h4&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/NA-Wen"&gt;&lt;img src="https://github.com/NA-Wen.png?size=100" width="64px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;NA-Wen&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/zxrys"&gt;&lt;img src="https://github.com/zxrys.png?size=100" width="64px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;zxrys&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/swugi"&gt;&lt;img src="https://github.com/swugi.png?size=100" width="64px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;swugi&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/huatl98"&gt;&lt;img src="https://github.com/huatl98.png?size=100" width="64px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;huatl98&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h4&gt;Contributors&lt;/h4&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/shiowen"&gt;&lt;img src="https://github.com/shiowen.png?size=100" width="64px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;shiowen&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/kilo2127"&gt;&lt;img src="https://github.com/kilo2127.png?size=100" width="64px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;kilo2127&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/AckerlyLau"&gt;&lt;img src="https://github.com/AckerlyLau.png?size=100" width="64px;" alt="" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;AckerlyLau&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;ü§ù Acknowledgments&lt;/h2&gt; 
&lt;p&gt;&lt;a href="http://nlp.csai.tsinghua.edu.cn/"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/thunlp.png" height="50pt" /&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp; &lt;a href="https://modelbest.cn/"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/modelbest.png" height="50pt" /&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp; &lt;a href="https://github.com/OpenBMB/AgentVerse/"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/agentverse.png" height="50pt" /&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp; &lt;a href="https://github.com/OpenBMB/RepoAgent"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/repoagent.png" height="50pt" /&gt;&lt;/a&gt; &lt;a href="https://app.commanddash.io/agent?github=https://github.com/OpenBMB/ChatDev"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/CommandDash.png" height="50pt" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/www.teachmaster.cn"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/teachmaster.png" height="50pt" /&gt;&lt;/a&gt; &lt;a href="https://github.com/OpenBMB/AppCopilot"&gt;&lt;img src="https://raw.githubusercontent.com/OpenBMB/ChatDev/main/assets/appcopilot.png" height="50pt" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üîé Citation&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;@article{chatdev,
    title = {ChatDev: Communicative Agents for Software Development},
    author = {Chen Qian and Wei Liu and Hongzhang Liu and Nuo Chen and Yufan Dang and Jiahao Li and Cheng Yang and Weize Chen and Yusheng Su and Xin Cong and Juyuan Xu and Dahai Li and Zhiyuan Liu and Maosong Sun},
    journal = {arXiv preprint arXiv:2307.07924},
    url = {https://arxiv.org/abs/2307.07924},
    year = {2023}
}

@article{colearning,
    title = {Experiential Co-Learning of Software-Developing Agents},
    author = {Chen Qian and Yufan Dang and Jiahao Li and Wei Liu and Zihao Xie and Yifei Wang and Weize Chen and Cheng Yang and Xin Cong and Xiaoyin Che and Zhiyuan Liu and Maosong Sun},
    journal = {arXiv preprint arXiv:2312.17025},
    url = {https://arxiv.org/abs/2312.17025},
    year = {2023}
}

@article{macnet,
    title={Scaling Large-Language-Model-based Multi-Agent Collaboration},
    author={Chen Qian and Zihao Xie and Yifei Wang and Wei Liu and Yufan Dang and Zhuoyun Du and Weize Chen and Cheng Yang and Zhiyuan Liu and Maosong Sun}
    journal={arXiv preprint arXiv:2406.07155},
    url = {https://arxiv.org/abs/2406.07155},
    year={2024}
}

@article{iagents,
    title={Autonomous Agents for Collaborative Task under Information Asymmetry},
    author={Wei Liu and Chenxi Wang and Yifei Wang and Zihao Xie and Rennai Qiu and Yufan Dnag and Zhuoyun Du and Weize Chen and Cheng Yang and Chen Qian},
    journal={arXiv preprint arXiv:2406.14928},
    url = {https://arxiv.org/abs/2406.14928},
    year={2024}
}

@article{puppeteer,
      title={Multi-Agent Collaboration via Evolving Orchestration}, 
      author={Yufan Dang and Chen Qian and Xueheng Luo and Jingru Fan and Zihao Xie and Ruijie Shi and Weize Chen and Cheng Yang and Xiaoyin Che and Ye Tian and Xuantang Xiong and Lei Han and Zhiyuan Liu and Maosong Sun},
      journal={arXiv preprint arXiv:2505.19591},
      url={https://arxiv.org/abs/2505.19591},
      year={2025}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üì¨ Contact&lt;/h2&gt; 
&lt;p&gt;If you have any questions, feedback, or would like to get in touch, please feel free to reach out to us via email at &lt;a href="mailto:qianc62@gmail.com"&gt;qianc62@gmail.com&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>MiroMindAI/MiroThinker</title>
      <link>https://github.com/MiroMindAI/MiroThinker</link>
      <description>&lt;p&gt;MiroThinker is an open-source search agent model, built for tool-augmented reasoning and real-world information seeking, aiming to match the deep research experience of OpenAI Deep Research and Gemini Deep Research.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/assets/miro_thinker.png" width="55%" alt="MiroThinker" /&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://dr.miromind.ai/"&gt;&lt;img src="https://img.shields.io/badge/Demo-FFB300?style=for-the-badge&amp;amp;logo=airplayvideo&amp;amp;logoColor=white" alt="DEMO" /&gt;&lt;/a&gt; &lt;a href="https://huggingface.co/collections/miromind-ai/mirothinker-v15"&gt;&lt;img src="https://img.shields.io/badge/Models-5EDDD2?style=for-the-badge&amp;amp;logo=huggingface&amp;amp;logoColor=ffffff&amp;amp;labelColor" alt="MODELS" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/abs/2511.11793"&gt;&lt;img src="https://img.shields.io/badge/Paper-B31B1B?style=for-the-badge&amp;amp;logo=arxiv&amp;amp;logoColor=white" alt="Paper" /&gt;&lt;/a&gt; &lt;a href="https://miromind.ai/#blog"&gt;&lt;img src="https://img.shields.io/badge/Blog-4285F4?style=for-the-badge&amp;amp;logo=google-chrome&amp;amp;logoColor=white" alt="Blog" /&gt;&lt;/a&gt; &lt;a href="https://huggingface.co/datasets/miromind-ai/MiroVerse-v0.1"&gt;&lt;img src="https://img.shields.io/badge/Data-0040A1?style=for-the-badge&amp;amp;logo=huggingface&amp;amp;logoColor=ffffff&amp;amp;labelColor" alt="DATA" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/MiroMindAI"&gt;&lt;img src="https://img.shields.io/badge/Github-24292F?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white" alt="GITHUB" /&gt;&lt;/a&gt; &lt;a href="https://miromind.ai/"&gt;&lt;img src="https://img.shields.io/badge/Website-4285F4?style=for-the-badge&amp;amp;logo=google-chrome&amp;amp;logoColor=white" alt="WEBSITE" /&gt;&lt;/a&gt; &lt;a href="https://discord.com/invite/GPqEnkzQZd"&gt;&lt;img src="https://img.shields.io/badge/Discord-5865F2?style=for-the-badge&amp;amp;logo=discord&amp;amp;logoColor=white" alt="DISCORD" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/refs/heads/main/assets/miromind_wechat.png"&gt;&lt;img src="https://img.shields.io/badge/WeChat-07C160?style=for-the-badge&amp;amp;logo=wechat&amp;amp;logoColor=white" alt="WeChat" /&gt;&lt;/a&gt; &lt;a href="https://www.xiaohongshu.com/user/profile/5e353bd80000000001000239"&gt;&lt;img src="https://img.shields.io/badge/RedNote-FF2442?style=for-the-badge&amp;amp;logo=revoltdotchat&amp;amp;logoColor=white" alt="RedNote" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;üöÄ &lt;a href="https://dr.miromind.ai/"&gt;Try our Demo!&lt;/a&gt;&lt;/h3&gt; 
&lt;/div&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;MiroThinker&lt;/strong&gt; is MiroMind's Flagship Research Agent Model. It is an open-source search model designed to advance tool-augmented reasoning and information-seeking capabilities, enabling complex real-world research workflows across diverse challenges.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;The project currently comprises four key components:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üí° &lt;strong&gt;MiroThinker&lt;/strong&gt;: An open-source search &lt;strong&gt;model&lt;/strong&gt; that natively supports tool-assisted reasoning, achieving leading performance across multiple benchmarks (e.g., HLE, HLE-Text-2158, HLE-Text-500, BrowseComp, BrowseComp-ZH, GAIA, XBench-DeepSearch, FutureX, and Frames). See &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/#-quick-start"&gt;Quick Start&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;ü§ñ &lt;strong&gt;MiroFlow&lt;/strong&gt;: An open-source research agent framework that offers reproducible state-of-the-art performance across multiple benchmarks. See &lt;a href="https://github.com/MiroMindAI/MiroFlow"&gt;MiroFlow&lt;/a&gt; for details.&lt;/li&gt; 
 &lt;li&gt;üìö &lt;strong&gt;MiroVerse&lt;/strong&gt;: A premium open-source training dataset with 147k samples supporting research agent training. See &lt;a href="https://huggingface.co/datasets/miromind-ai/MiroVerse-v0.1"&gt;MiroVerse&lt;/a&gt; on HuggingFace.&lt;/li&gt; 
 &lt;li&gt;üîß &lt;strong&gt;MiroTrain / MiroRL&lt;/strong&gt;: Training infrastructure that supports stable and efficient training for research agent models. See &lt;a href="https://github.com/MiroMindAI/MiroTrain"&gt;MiroTrain&lt;/a&gt; and &lt;a href="https://github.com/MiroMindAI/MiroRL"&gt;MiroRL&lt;/a&gt; for details.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìã Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üì∞ &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/#-news--updates"&gt;News &amp;amp; Updates&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üìù &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/#-introduction"&gt;Introduction&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;‚ú® &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/#-key-features"&gt;Key Features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üìà &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/#-performance-on-benchmarks"&gt;Performance on Benchmarks&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üöÄ &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/#-quick-start"&gt;Quick Start&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üìä &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/#-benchmark-evaluation"&gt;Benchmark Evaluation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üî¨ &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/#-trace-collection"&gt;Trace Collection&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;‚ùì &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/#-faq--troubleshooting"&gt;FAQ &amp;amp; Troubleshooting&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üìÑ &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/#-license"&gt;License&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üôè &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/#-acknowledgments"&gt;Acknowledgments&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üì∞ News &amp;amp; Updates&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;[2026-01-05]&lt;/strong&gt; üéâüéâ We release &lt;a href="https://huggingface.co/collections/miromind-ai/mirothinker-v15"&gt;MiroThinker-v1.5&lt;/a&gt;, a world-leading open-source search agent. &lt;a href="https://huggingface.co/miromind-ai/MiroThinker-v1.5-30B"&gt;MiroThinker-v1.5-30B&lt;/a&gt; surpasses Kimi-K2-Thinking on BrowseComp-ZH at much lower cost, using only 1/30 of the parameters. &lt;a href="https://huggingface.co/miromind-ai/MiroThinker-v1.5-235B"&gt;MiroThinker-v1.5-235B&lt;/a&gt; scores 39.2% on HLE-Text, 69.8% on BrowseComp, 71.5% on BrowseComp-ZH, and 80.8% on GAIA-Val-165, setting a new state-of-the-art among search agents.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;[2025-11-13]&lt;/strong&gt; üéâ &lt;a href="https://huggingface.co/collections/miromind-ai/mirothinker-v10"&gt;MiroThinker-v1.0&lt;/a&gt; is now released! Introducing &lt;strong&gt;interactive scaling&lt;/strong&gt; as a third dimension of performance improvement, MiroThinker v1.0 supports 256K context window and up to 600 tool calls per task. Available in 8B, 30B, and 72B parameter scales, achieving 37.7%, 47.1%, 55.6%, and 81.9% on HLE-Text, BrowseComp, BrowseComp-ZH, and GAIA-Text-103, respectively. See &lt;a href="https://arxiv.org/abs/2511.11793"&gt;Technical Report&lt;/a&gt; for more details.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;[2025-09-11]&lt;/strong&gt; MiroThinker-72B-Preview ranked 4th in this week's FutureX benchmark. See &lt;a href="https://futurex-ai.github.io/"&gt;FutureX&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;üìú Click to expand older updates&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;[2025-09-08]&lt;/strong&gt; &lt;a href="https://huggingface.co/collections/miromind-ai/mirothinker-v02"&gt;MiroThinker-v0.2&lt;/a&gt; is now released, achieving open-source SOTA performance across multiple benchmarks, including HLE (17.8%), HLE-Text-Only (19.1%), BrowseComp-EN (17.2%), BrowseComp-ZH (29.4%), XBench-DeepSearch (56.0%), and Frames (74.8%).&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;[2025-09-07]&lt;/strong&gt; We supported more benchmarks, including &lt;a href="https://arxiv.org/abs/2504.19314"&gt;BrowseComp-ZH&lt;/a&gt;, &lt;a href="https://xbench.org/agi/aisearch"&gt;XBench-DeepSearch&lt;/a&gt;, and &lt;a href="https://futurex-ai.github.io/"&gt;FutureX&lt;/a&gt;. We plan to add more benchmarks in the future.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;[2025-08-22]&lt;/strong&gt; Introducing streamlined deployment options for MiroThinker models with optimized resource usage and faster startup times. Experience the interactive demo: &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/apps/gradio-demo"&gt;üöÄ Try Gradio Demo&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;[2025-08-08]&lt;/strong&gt; &lt;a href="https://huggingface.co/collections/miromind-ai/mirothinker-v01-689301b6d0563321862d44a1"&gt;MiroThinker-v0.1&lt;/a&gt; released. Models, framework, and data are now fully open-sourced!&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;üìù Introduction&lt;/h2&gt; 
&lt;h3&gt;MiroThinker-v1.5&lt;/h3&gt; 
&lt;p&gt;MiroThinker v1.5 is the world-leading open-source search agent that advances tool-augmented reasoning through &lt;strong&gt;interactive scaling&lt;/strong&gt; ‚Äî training the model to handle deeper and more frequent agent-environment interactions as a third dimension of performance improvement, beyond model size and context length.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://huggingface.co/datasets/miromind-ai/MiroFlow-Benchmarks/resolve/main/assets/mirothinker_v1.5_framework.png" alt="image" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Key Features&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üöÄ MiroThinker v1.5 supports a 256K context window, long-horizon reasoning, and deep multi-step analysis.&lt;/li&gt; 
 &lt;li&gt;üîß Handles up to 400 tool calls per task ‚Äî a substantial improvement over previous open-source research agents.&lt;/li&gt; 
 &lt;li&gt;üì¶ Released in 30B and 235B parameter scales, accompanied by a comprehensive suite of tools and workflows to flexibly support diverse research settings and compute budgets.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th align="center"&gt;Model Name&lt;/th&gt; 
    &lt;th align="center"&gt;Base Model&lt;/th&gt; 
    &lt;th align="center"&gt;Max Context&lt;/th&gt; 
    &lt;th align="center"&gt;Max Tool Calls&lt;/th&gt; 
    &lt;th align="center"&gt;HF Link&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;MiroThinker-v1.5-30B&lt;/td&gt; 
    &lt;td align="center"&gt;Qwen3-30B-A3B-Thinking-2507&lt;/td&gt; 
    &lt;td align="center"&gt;256K&lt;/td&gt; 
    &lt;td align="center"&gt;400&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-v1.5-30B"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;MiroThinker-v1.5-235B&lt;/td&gt; 
    &lt;td align="center"&gt;Qwen3-235B-A22B-Thinking-2507&lt;/td&gt; 
    &lt;td align="center"&gt;256K&lt;/td&gt; 
    &lt;td align="center"&gt;400&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-v1.5-235B"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;p&gt;MiroThinker v1.5 demonstrates strong general-research performance across a broad range of benchmarks, achieving&amp;nbsp;39.2%,&amp;nbsp;69.8%, 71.5%, and&amp;nbsp;80.8%&amp;nbsp;on HLE-Text, BrowseComp, BrowseComp-ZH, and GAIA-Val-165, respectively. These results surpass previous open-source agents and set the new world-leading BrowseComp performance.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://huggingface.co/datasets/miromind-ai/MiroFlow-Benchmarks/resolve/main/assets/mirothinker_v1.5_browsecomp.png" alt="image" /&gt;&lt;/p&gt; 
&lt;h3&gt;MiroThinker-v1.0&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;üì¶ Click to expand MiroThinker-v1.0 details&lt;/summary&gt; 
 &lt;p&gt;Unlike previous agents that scale only model size or context length, MiroThinker v1.0 introduces &lt;strong&gt;interactive scaling&lt;/strong&gt; at the model level, systematically training the model to handle deeper and more frequent agent‚Äìenvironment interactions as a third dimension of performance improvement. Interactive scaling leverages environment feedback and external information acquisition to correct errors and refine trajectories.&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://huggingface.co/datasets/miromind-ai/MiroFlow-Benchmarks/resolve/main/assets/MiroThinker_v1.0_Overall.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;‚ú® Key Features&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;üöÄ &lt;strong&gt;256K Context Window&lt;/strong&gt;: Supports long-horizon reasoning and deep multi-step analysis&lt;/li&gt; 
  &lt;li&gt;üîß &lt;strong&gt;600 Tool Calls&lt;/strong&gt;: Handles up to 600 tool calls per task ‚Äî a substantial improvement over previous open-source research agents&lt;/li&gt; 
  &lt;li&gt;üì¶ &lt;strong&gt;Multiple Scales&lt;/strong&gt;: Released in 8B, 30B, and 72B parameter scales, accompanied by a comprehensive suite of tools and workflows to flexibly support diverse research settings and compute budgets&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;div align="center"&gt; 
  &lt;table&gt; 
   &lt;thead&gt; 
    &lt;tr&gt; 
     &lt;th align="center"&gt;Model Name&lt;/th&gt; 
     &lt;th align="center"&gt;Base Model&lt;/th&gt; 
     &lt;th align="center"&gt;Max Context&lt;/th&gt; 
     &lt;th align="center"&gt;Max Tool Calls&lt;/th&gt; 
     &lt;th align="center"&gt;HF Link&lt;/th&gt; 
    &lt;/tr&gt; 
   &lt;/thead&gt; 
   &lt;tbody&gt; 
    &lt;tr&gt; 
     &lt;td align="center"&gt;MiroThinker-v1.0-8B&lt;/td&gt; 
     &lt;td align="center"&gt;Qwen3-8B&lt;/td&gt; 
     &lt;td align="center"&gt;256K&lt;/td&gt; 
     &lt;td align="center"&gt;600&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-v1.0-8B"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td align="center"&gt;MiroThinker-v1.0-30B&lt;/td&gt; 
     &lt;td align="center"&gt;Qwen3-30B-A3B-Thinking-2507&lt;/td&gt; 
     &lt;td align="center"&gt;256K&lt;/td&gt; 
     &lt;td align="center"&gt;600&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-v1.0-30B"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td align="center"&gt;MiroThinker-v1.0-72B&lt;/td&gt; 
     &lt;td align="center"&gt;Qwen2.5-72B-Instruct&lt;/td&gt; 
     &lt;td align="center"&gt;256K&lt;/td&gt; 
     &lt;td align="center"&gt;600&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-v1.0-72B"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
   &lt;/tbody&gt; 
  &lt;/table&gt; 
 &lt;/div&gt; 
 &lt;p&gt;MiroThinker v1.0 demonstrates strong general-research performance across a broad range of benchmarks, achieving &lt;strong&gt;37.7%&lt;/strong&gt;, &lt;strong&gt;47.1%&lt;/strong&gt;, &lt;strong&gt;55.6%&lt;/strong&gt;, and &lt;strong&gt;81.9%&lt;/strong&gt; on HLE-Text, BrowseComp, BrowseComp-ZH, and GAIA-Text-103, respectively. These results surpass previous open-source agents and narrow the gap with commercial counterparts such as &lt;strong&gt;GPT-5-high&lt;/strong&gt;.&lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;img src="https://huggingface.co/datasets/miromind-ai/MiroFlow-Benchmarks/resolve/main/assets/MiroThinker_v1.0_Performance_1.png" width="100%" alt="MiroThinker" /&gt; 
 &lt;/div&gt; 
&lt;/details&gt; 
&lt;h3&gt;MiroThinker-v0.2&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;üì¶ Click to expand MiroThinker-v0.2 details&lt;/summary&gt; 
 &lt;p&gt;In this new version, we introduced three key improvements:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;üìö &lt;strong&gt;Richer training data&lt;/strong&gt; from both English and Chinese sources, yielding significant gains in benchmark performance and generalization&lt;/li&gt; 
  &lt;li&gt;üéØ &lt;strong&gt;Unified DPO training&lt;/strong&gt; with a single preference dataset across all models&lt;/li&gt; 
  &lt;li&gt;üìè &lt;strong&gt;Extended context length&lt;/strong&gt; from 40k to 64k for more challenging multi-turn tool-use tasks&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;Compared to v0.1, MiroThinker v0.2 delivers consistent gains across benchmarks. For example, scores improved from &lt;strong&gt;57.3 ‚Üí 64.1&lt;/strong&gt; on &lt;strong&gt;GAIA-Text-103&lt;/strong&gt; and from &lt;strong&gt;17.0 ‚Üí 29.4&lt;/strong&gt; on &lt;strong&gt;BrowseComp-ZH&lt;/strong&gt;, reflecting substantial advancements in the model‚Äôs general research agent capabilities.&lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;table&gt; 
   &lt;thead&gt; 
    &lt;tr&gt; 
     &lt;th align="center"&gt;Model Name&lt;/th&gt; 
     &lt;th align="center"&gt;Base Model&lt;/th&gt; 
     &lt;th align="center"&gt;Max Context&lt;/th&gt; 
     &lt;th align="center"&gt;HF Link&lt;/th&gt; 
    &lt;/tr&gt; 
   &lt;/thead&gt; 
   &lt;tbody&gt; 
    &lt;tr&gt; 
     &lt;td align="center"&gt;MiroThinker-4B-SFT-v0.2&lt;/td&gt; 
     &lt;td align="center"&gt;Qwen3-4B&lt;/td&gt; 
     &lt;td align="center"&gt;64K&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-4B-SFT-v0.2"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td align="center"&gt;MiroThinker-4B-DPO-v0.2&lt;/td&gt; 
     &lt;td align="center"&gt;Qwen3-4B&lt;/td&gt; 
     &lt;td align="center"&gt;64K&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-4B-DPO-v0.2"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td align="center"&gt;MiroThinker-8B-SFT-v0.2&lt;/td&gt; 
     &lt;td align="center"&gt;Qwen3-8B&lt;/td&gt; 
     &lt;td align="center"&gt;64K&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-8B-SFT-v0.2"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td align="center"&gt;MiroThinker-8B-DPO-v0.2&lt;/td&gt; 
     &lt;td align="center"&gt;Qwen3-8B&lt;/td&gt; 
     &lt;td align="center"&gt;64K&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-8B-DPO-v0.2"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td align="center"&gt;MiroThinker-14B-SFT-v0.2&lt;/td&gt; 
     &lt;td align="center"&gt;Qwen3-14B&lt;/td&gt; 
     &lt;td align="center"&gt;64K&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-14B-SFT-v0.2"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td align="center"&gt;MiroThinker-14B-DPO-v0.2&lt;/td&gt; 
     &lt;td align="center"&gt;Qwen3-14B&lt;/td&gt; 
     &lt;td align="center"&gt;64K&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-14B-DPO-v0.2"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td align="center"&gt;MiroThinker-32B-SFT-v0.2&lt;/td&gt; 
     &lt;td align="center"&gt;Qwen3-32B&lt;/td&gt; 
     &lt;td align="center"&gt;64K&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-32B-SFT-v0.2"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td align="center"&gt;MiroThinker-32B-DPO-v0.2&lt;/td&gt; 
     &lt;td align="center"&gt;Qwen3-32B&lt;/td&gt; 
     &lt;td align="center"&gt;64K&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-32B-DPO-v0.2"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
   &lt;/tbody&gt; 
  &lt;/table&gt; 
 &lt;/div&gt; 
&lt;/details&gt; 
&lt;h3&gt;MiroThinker-v0.1&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;üì¶ Click to expand MiroThinker-v0.1 details&lt;/summary&gt; 
 &lt;div align="center"&gt; 
  &lt;img src="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/assets/gaia_text_103.png" width="98%" alt="MiroFlow Performance on GAIA-Validation" /&gt; 
  &lt;p&gt;&lt;strong&gt;Performance of Open-Source Models on GAIA-Validation Benchmark.&lt;/strong&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;p&gt;We have released the &lt;strong&gt;MiroThinker v0.1&lt;/strong&gt; series, including both SFT and DPO variants at parameter scales of &lt;strong&gt;8B&lt;/strong&gt;, &lt;strong&gt;14B&lt;/strong&gt;, and &lt;strong&gt;32B&lt;/strong&gt;. Notably, MiroThinker v0.1 achieves &lt;strong&gt;state-of-the-art performance&lt;/strong&gt; among open-source models on the &lt;a href="https://huggingface.co/datasets/gaia-benchmark/GAIA"&gt;GAIA benchmark&lt;/a&gt;, a rigorous evaluation suite for advanced agentic capabilities, demonstrating its strength in long-context, decision-intensive, and real-world task scenarios.&lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;table&gt; 
   &lt;thead&gt; 
    &lt;tr&gt; 
     &lt;th align="center"&gt;Model Name&lt;/th&gt; 
     &lt;th align="center"&gt;Base Model&lt;/th&gt; 
     &lt;th align="center"&gt;Max Context&lt;/th&gt; 
     &lt;th align="center"&gt;HF Link&lt;/th&gt; 
    &lt;/tr&gt; 
   &lt;/thead&gt; 
   &lt;tbody&gt; 
    &lt;tr&gt; 
     &lt;td align="center"&gt;MiroThinker-8B-SFT-v0.1&lt;/td&gt; 
     &lt;td align="center"&gt;Qwen3-8B&lt;/td&gt; 
     &lt;td align="center"&gt;40K&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-8B-SFT-v0.1"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td align="center"&gt;MiroThinker-8B-DPO-v0.1&lt;/td&gt; 
     &lt;td align="center"&gt;Qwen3-8B&lt;/td&gt; 
     &lt;td align="center"&gt;40K&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-8B-DPO-v0.1"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td align="center"&gt;MiroThinker-14B-SFT-v0.1&lt;/td&gt; 
     &lt;td align="center"&gt;Qwen3-14B&lt;/td&gt; 
     &lt;td align="center"&gt;40K&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-14B-SFT-v0.1"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td align="center"&gt;MiroThinker-14B-DPO-v0.1&lt;/td&gt; 
     &lt;td align="center"&gt;Qwen3-14B&lt;/td&gt; 
     &lt;td align="center"&gt;40K&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-14B-DPO-v0.1"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td align="center"&gt;MiroThinker-32B-SFT-v0.1&lt;/td&gt; 
     &lt;td align="center"&gt;Qwen3-32B&lt;/td&gt; 
     &lt;td align="center"&gt;40K&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-32B-SFT-v0.1"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td align="center"&gt;MiroThinker-32B-DPO-v0.1&lt;/td&gt; 
     &lt;td align="center"&gt;Qwen3-32B&lt;/td&gt; 
     &lt;td align="center"&gt;40K&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;a href="https://huggingface.co/miromind-ai/MiroThinker-32B-DPO-v0.1"&gt;ü§ó link&lt;/a&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
   &lt;/tbody&gt; 
  &lt;/table&gt; 
 &lt;/div&gt; 
&lt;/details&gt; 
&lt;h2&gt;‚ú® Key Features&lt;/h2&gt; 
&lt;h3&gt;ü§ñ &lt;strong&gt;MiroThinker-Optimized Framework&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üîì &lt;strong&gt;Fully Open-Source Agent Framework&lt;/strong&gt;: Complete transparency with open framework and open models&lt;/li&gt; 
 &lt;li&gt;üîó &lt;strong&gt;Tool Integration&lt;/strong&gt;: Seamless integration with external tools and APIs&lt;/li&gt; 
 &lt;li&gt;üìù &lt;strong&gt;Trace Collection&lt;/strong&gt;: Comprehensive logging and analysis of agent interactions with elapsed time and estimated completion time displayed in minutes. Ready for SFT and DPO&lt;/li&gt; 
 &lt;li&gt;üìä &lt;strong&gt;Benchmark Evaluation&lt;/strong&gt;: Extensive testing across multiple benchmark datasets&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üìä &lt;strong&gt;Comprehensive Benchmark Suite&lt;/strong&gt;&lt;/h3&gt; 
&lt;details open&gt; 
 &lt;summary&gt;üìã Click to expand benchmark list&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;GAIA Validation&lt;/strong&gt;: A benchmark for General AI Assistants. (&lt;a href="https://arxiv.org/abs/2311.12983"&gt;paper&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;GAIA-Text-103&lt;/strong&gt;: A subset of GAIA Validation for text-only tasks. (&lt;a href="https://arxiv.org/abs/2505.22648"&gt;paper&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;HLE&lt;/strong&gt;: Humanity's Last Exam. (&lt;a href="https://arxiv.org/abs/2501.14249"&gt;paper&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;HLE-Text-2158&lt;/strong&gt;: A subset of HLE for text-only tasks. (&lt;a href="https://arxiv.org/abs/2501.14249"&gt;paper&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;HLE-Text-500&lt;/strong&gt;: A subset of HLE for text-only tasks, created by &lt;a href="https://arxiv.org/pdf/2504.21776"&gt;WebThinker&lt;/a&gt;. (&lt;a href="https://arxiv.org/pdf/2504.21776"&gt;paper&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;BrowseComp-EN&lt;/strong&gt;: Web browsing and comprehension tasks. (&lt;a href="https://arxiv.org/abs/2504.12516"&gt;paper&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;BrowseComp-ZH&lt;/strong&gt;: A Chinese version of BrowseComp. (&lt;a href="https://arxiv.org/abs/2504.19314"&gt;paper&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;WebWalkerQA&lt;/strong&gt;: Web navigation and question answering. (&lt;a href="https://arxiv.org/abs/2501.07572"&gt;paper&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Frames&lt;/strong&gt;: Factuality, Retrieval, And reasoning MEasurement Set. (&lt;a href="https://arxiv.org/abs/2409.12941"&gt;paper&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;XBench-DeepSearch&lt;/strong&gt;: A benchmark for deep research agents. (&lt;a href="https://xbench.org/agi/aisearch"&gt;website&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;FutureX&lt;/strong&gt;: A live benchmark designed for predicting unknown future. (&lt;a href="https://futurex-ai.github.io/"&gt;website&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;SEAL-0&lt;/strong&gt;: A benchmark for evaluating LLMs on conflicting-evidence web questions. (&lt;a href="https://arxiv.org/abs/2506.01062"&gt;paper&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;AIME2025&lt;/strong&gt;: American Invitational Mathematics Examination 2025. (&lt;a href="https://artificialanalysis.ai/evaluations/aime-2025"&gt;website&lt;/a&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;DeepSearchQA&lt;/strong&gt;: Google's Deep Search Question Answering benchmark. (&lt;a href="https://arxiv.org/abs/2505.20827"&gt;paper&lt;/a&gt;)&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;üìà Performance on Benchmarks&lt;/h2&gt; 
&lt;h3&gt;MiroThinker-v1.5&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;To prevent potential information leakage (e.g., searching benchmark answers from HuggingFace), access to HuggingFace has been explicitly disabled in these tools.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;We further perform canary string testing on the tool outputs of all trajectories and disregard any trajectory found to be contaminated, treating it as an incorrect answer.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;div&gt; 
 &lt;img src="https://huggingface.co/datasets/miromind-ai/MiroFlow-Benchmarks/resolve/main/assets/mirothinker_v1.5_performance.png" width="100%" alt="MiroThinker" /&gt; 
&lt;/div&gt; 
&lt;h3&gt;MiroThinker-v1.0&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;üì¶ Click to expand MiroThinker-v1.0 details&lt;/summary&gt; 
 &lt;div align="center"&gt; 
  &lt;img src="https://github.com/user-attachments/assets/108a2105-4e1d-499e-a001-4713a03fd8ac" width="100%" alt="MiroThinker" /&gt; 
 &lt;/div&gt; 
&lt;/details&gt; 
&lt;h3&gt;MiroThinker-v0.2&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;üì¶ Click to expand MiroThinker-v0.2 details&lt;/summary&gt; 
 &lt;h4&gt;Comparison with SOTA Research Agents&lt;/h4&gt; 
 &lt;div align="center"&gt; 
  &lt;img src="https://huggingface.co/datasets/miromind-ai/MiroFlow-Benchmarks/resolve/main/assets/MiroThinker_v0.2_Performance_2.png" width="90%" alt="MiroThinker" /&gt; 
 &lt;/div&gt; 
 &lt;h4&gt;GAIA Benchmark&lt;/h4&gt; 
 &lt;div align="center"&gt; 
  &lt;img src="https://huggingface.co/datasets/miromind-ai/MiroFlow-Benchmarks/resolve/main/assets/MiroThinker_v0.2_Performance_1.png" width="80%" alt="MiroThinker" /&gt; 
 &lt;/div&gt; 
&lt;/details&gt; 
&lt;h3&gt;MiroThinker-v0.1&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;üì¶ Click to expand MiroThinker-v0.1 details&lt;/summary&gt; 
 &lt;h4&gt;GAIA Benchmark&lt;/h4&gt; 
 &lt;div align="center"&gt; 
  &lt;table&gt; 
   &lt;thead&gt; 
    &lt;tr&gt; 
     &lt;th&gt;&lt;strong&gt;Method&lt;/strong&gt;&lt;/th&gt; 
     &lt;th align="center"&gt;Text-103&lt;br /&gt;Best Pass@1&lt;/th&gt; 
     &lt;th align="center"&gt;Text-103&lt;br /&gt;Pass@1 (Avg@8)&lt;/th&gt; 
     &lt;th align="center"&gt;Val-165&lt;br /&gt;Best Pass@1&lt;/th&gt; 
     &lt;th align="center"&gt;Val-165&lt;br /&gt;Pass@1 (Avg@8)&lt;/th&gt; 
    &lt;/tr&gt; 
   &lt;/thead&gt; 
   &lt;tbody&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;strong&gt;üîπ‚Äî‚Äî 7B/8B Models ‚Äî‚Äî&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;Search-o1-7B&lt;/td&gt; 
     &lt;td align="center"&gt;17.5&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;R1-Searcher-7B&lt;/td&gt; 
     &lt;td align="center"&gt;20.4&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;WebDancer-7B&lt;/td&gt; 
     &lt;td align="center"&gt;31.0&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;WebSailor-7B&lt;/td&gt; 
     &lt;td align="center"&gt;37.9&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;CK-Pro-8B&lt;/td&gt; 
     &lt;td align="center"&gt;40.3&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;32.7&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;strong&gt;MiroThinker-8B-SFT-v0.1&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;44.7&lt;/td&gt; 
     &lt;td align="center"&gt;40.1&lt;/td&gt; 
     &lt;td align="center"&gt;34.6&lt;/td&gt; 
     &lt;td align="center"&gt;31.8&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;+ Commercial Tools&lt;/td&gt; 
     &lt;td align="center"&gt;46.6&lt;/td&gt; 
     &lt;td align="center"&gt;42.1&lt;/td&gt; 
     &lt;td align="center"&gt;37.6&lt;/td&gt; 
     &lt;td align="center"&gt;33.9&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;strong&gt;MiroThinker-8B-DPO-v0.1&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;46.6&lt;/td&gt; 
     &lt;td align="center"&gt;44.8&lt;/td&gt; 
     &lt;td align="center"&gt;37.0&lt;/td&gt; 
     &lt;td align="center"&gt;35.4&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;+ Commercial Tools&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;strong&gt;50.5&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;strong&gt;46.7&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;strong&gt;38.2&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;strong&gt;35.9&lt;/strong&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;strong&gt;üîπ‚Äî‚Äî 14B Models ‚Äî‚Äî&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;strong&gt;MiroThinker-14B-SFT-v0.1&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;47.6&lt;/td&gt; 
     &lt;td align="center"&gt;44.4&lt;/td&gt; 
     &lt;td align="center"&gt;37.0&lt;/td&gt; 
     &lt;td align="center"&gt;34.4&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;+ Commercial Tools&lt;/td&gt; 
     &lt;td align="center"&gt;49.5&lt;/td&gt; 
     &lt;td align="center"&gt;47.5&lt;/td&gt; 
     &lt;td align="center"&gt;41.8&lt;/td&gt; 
     &lt;td align="center"&gt;39.8&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;strong&gt;MiroThinker-14B-DPO-v0.1&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;48.5&lt;/td&gt; 
     &lt;td align="center"&gt;46.6&lt;/td&gt; 
     &lt;td align="center"&gt;42.4&lt;/td&gt; 
     &lt;td align="center"&gt;39.2&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;+ Commercial Tools&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;strong&gt;52.4&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;strong&gt;48.5&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;strong&gt;45.5&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;strong&gt;42.0&lt;/strong&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;strong&gt;üîπ‚Äî‚Äî 32B Models ‚Äî‚Äî&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;Qwen3-32B&lt;/td&gt; 
     &lt;td align="center"&gt;31.1&lt;/td&gt; 
     &lt;td align="center"&gt;26.7&lt;/td&gt; 
     &lt;td align="center"&gt;29.7&lt;/td&gt; 
     &lt;td align="center"&gt;26.4&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;Search-o1-32B&lt;/td&gt; 
     &lt;td align="center"&gt;28.2&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;WebThinker-32B-RL&lt;/td&gt; 
     &lt;td align="center"&gt;48.5&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;WebDancer-QwQ-32B&lt;/td&gt; 
     &lt;td align="center"&gt;51.5&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;WebSailor-32B&lt;/td&gt; 
     &lt;td align="center"&gt;53.2&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;WebShaper-QwQ-32B&lt;/td&gt; 
     &lt;td align="center"&gt;53.3&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;strong&gt;MiroThinker-32B-SFT-v0.1&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;55.3&lt;/td&gt; 
     &lt;td align="center"&gt;51.3&lt;/td&gt; 
     &lt;td align="center"&gt;44.9&lt;/td&gt; 
     &lt;td align="center"&gt;42.7&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;+ Commercial Tools&lt;/td&gt; 
     &lt;td align="center"&gt;58.3&lt;/td&gt; 
     &lt;td align="center"&gt;54.2&lt;/td&gt; 
     &lt;td align="center"&gt;48.5&lt;/td&gt; 
     &lt;td align="center"&gt;45.8&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;strong&gt;MiroThinker-32B-DPO-v0.1&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;57.3&lt;/td&gt; 
     &lt;td align="center"&gt;54.1&lt;/td&gt; 
     &lt;td align="center"&gt;48.5&lt;/td&gt; 
     &lt;td align="center"&gt;45.9&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;+ Commercial Tools&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;strong&gt;60.2&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;strong&gt;57.9&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;strong&gt;50.9&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;strong&gt;48.9&lt;/strong&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
   &lt;/tbody&gt; 
  &lt;/table&gt; 
 &lt;/div&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;Following the practices of WebThinker, WebAgents, and CognitiveKernel, we report the Best Pass@1, the highest score across three runs, which often reflects stronger performance, though it may exhibit some variability. To provide a more stable measure, we additionally report Pass@1 (Avg@8), which offers greater consistency at the cost of slightly lower scores.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;For consistency with prior open-source works, we evaluate GAIA-Text-103 using the WebAgents LLM-as-a-Judge template, and report results on GAIA-Val-165 using the official GAIA scorer script.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;By default, we use open-source tools wherever possible, except for the code tool &lt;a href="https://github.com/e2b-dev/E2B"&gt;E2B&lt;/a&gt; and the Google search tool &lt;a href="https://serper.dev/"&gt;Serper&lt;/a&gt;. We use &lt;a href="https://huggingface.co/openai/whisper-large-v3-turbo"&gt;Whisper&lt;/a&gt;, &lt;a href="https://huggingface.co/Qwen/Qwen2.5-VL-72B-Instruct"&gt;Qwen2.5-VL-72B-Instruct&lt;/a&gt;, and &lt;a href="https://huggingface.co/Qwen/Qwen3-235B-A22B-Thinking-2507"&gt;Qwen3-235B-A22B-Thinking-2507&lt;/a&gt; in our implementation. The framework can be easily extended to other open-source tools of your choice.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Replacing these open-source tools with commercial alternatives can yield performance gains. Commercial tools were mainly used for multimodal capabilities and certain complex reasoning subtasks. The majority of tasks, including planning, browsing, refinement, navigation, and more, were handled by our models.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;h4&gt;More Benchmarks&lt;/h4&gt; 
 &lt;div align="center"&gt; 
  &lt;table&gt; 
   &lt;thead&gt; 
    &lt;tr&gt; 
     &lt;th&gt;Method&lt;/th&gt; 
     &lt;th align="center"&gt;HLE&lt;br /&gt;Pass@1&lt;/th&gt; 
     &lt;th align="center"&gt;Frames&lt;br /&gt;Pass@1&lt;/th&gt; 
     &lt;th align="center"&gt;BrowseComp&lt;br /&gt;Pass@1&lt;/th&gt; 
     &lt;th align="center"&gt;BrowseComp-ZH&lt;br /&gt;Pass@1&lt;/th&gt; 
     &lt;th align="center"&gt;WebWalkerQA&lt;br /&gt;Pass@1&lt;/th&gt; 
    &lt;/tr&gt; 
   &lt;/thead&gt; 
   &lt;tbody&gt; 
    &lt;tr&gt; 
     &lt;td&gt;OpenAI Deep Research&lt;/td&gt; 
     &lt;td align="center"&gt;26.6&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;51.5&lt;/td&gt; 
     &lt;td align="center"&gt;42.9&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;Gemini Deep Research&lt;/td&gt; 
     &lt;td align="center"&gt;26.9&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;Kimi-Researcher&lt;/td&gt; 
     &lt;td align="center"&gt;26.9&lt;/td&gt; 
     &lt;td align="center"&gt;78.8&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;WebDancer-7B&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;36.0&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;WebSailor-7B&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;6.7&lt;/td&gt; 
     &lt;td align="center"&gt;14.2&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;strong&gt;MiroThinker-8B-SFT-v0.1&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;58.0&lt;/td&gt; 
     &lt;td align="center"&gt;5.5&lt;/td&gt; 
     &lt;td align="center"&gt;9.3&lt;/td&gt; 
     &lt;td align="center"&gt;41.3&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;strong&gt;MiroThinker-8B-DPO-v0.1&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;64.4&lt;/td&gt; 
     &lt;td align="center"&gt;8.7&lt;/td&gt; 
     &lt;td align="center"&gt;13.6&lt;/td&gt; 
     &lt;td align="center"&gt;45.7&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;WebThinker-32B-RL&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;46.5&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;WebDancer-QwQ-32B&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;3.8&lt;/td&gt; 
     &lt;td align="center"&gt;18.0&lt;/td&gt; 
     &lt;td align="center"&gt;47.9&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;WebSailor-32B&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;10.5&lt;/td&gt; 
     &lt;td align="center"&gt;25.5&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;WebShaper-32B&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;-&lt;/td&gt; 
     &lt;td align="center"&gt;51.4&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;strong&gt;MiroThinker-32B-SFT-v0.1&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;10.2&lt;/td&gt; 
     &lt;td align="center"&gt;70.4&lt;/td&gt; 
     &lt;td align="center"&gt;10.6&lt;/td&gt; 
     &lt;td align="center"&gt;13.8&lt;/td&gt; 
     &lt;td align="center"&gt;45.7&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;strong&gt;MiroThinker-32B-DPO-v0.1&lt;/strong&gt;&lt;/td&gt; 
     &lt;td align="center"&gt;11.8&lt;/td&gt; 
     &lt;td align="center"&gt;71.7&lt;/td&gt; 
     &lt;td align="center"&gt;13.0&lt;/td&gt; 
     &lt;td align="center"&gt;17.0&lt;/td&gt; 
     &lt;td align="center"&gt;49.3&lt;/td&gt; 
    &lt;/tr&gt; 
   &lt;/tbody&gt; 
  &lt;/table&gt; 
 &lt;/div&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;MiroThinker‚Äôs performance was tested with this repository and open-source tools; other models‚Äô results are from their papers and official sites.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;As &lt;a href="https://huggingface.co/datasets/miromind-ai/MiroVerse-v0.1"&gt;MiroVerse-v0.1&lt;/a&gt; mainly contains English data, the model‚Äôs Chinese capability is limited. We plan to add more Chinese data to improve performance in the next version.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;h2&gt;üöÄ Quick Start&lt;/h2&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üêç &lt;strong&gt;Python 3.10+&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;üì¶ &lt;strong&gt;uv package manager&lt;/strong&gt; (&lt;a href="https://github.com/astral-sh/uv"&gt;Installation guide&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;üîë &lt;strong&gt;Required API keys&lt;/strong&gt; (see configuration section below)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone the repository
git clone https://github.com/MiroMindAI/MiroThinker
cd MiroThinker

# Setup environment
cd apps/miroflow-agent
uv sync

# Configure API keys
cp .env.example .env
# Edit .env with your API keys (SERPER_API_KEY, JINA_API_KEY, E2B_API_KEY, etc.)
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;üìù Environment Variables&lt;/strong&gt;: See &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/#tool-configuration"&gt;Tool Configuration&lt;/a&gt; section for required API keys.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Tool Configuration&lt;/h3&gt; 
&lt;h4&gt;Minimal Configuration for MiroThinker v1.5 and v1.0&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Server&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Tools Provided&lt;/th&gt; 
   &lt;th align="left"&gt;Required Environment Variables&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;code&gt;tool-python&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Execution environment and file management (E2B sandbox)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;create_sandbox&lt;/code&gt;, &lt;code&gt;run_command&lt;/code&gt;, &lt;code&gt;run_python_code&lt;/code&gt;, &lt;code&gt;upload_file_from_local_to_sandbox&lt;/code&gt;, &lt;code&gt;download_file_from_sandbox_to_local&lt;/code&gt;, &lt;code&gt;download_file_from_internet_to_sandbox&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;E2B_API_KEY&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;code&gt;search_and_scrape_webpage&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Google search via Serper API&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;google_search&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;SERPER_API_KEY&lt;/code&gt;, &lt;code&gt;SERPER_BASE_URL&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;code&gt;jina_scrape_llm_summary&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Web scraping with LLM-based information extraction&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;scrape_and_extract_info&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;JINA_API_KEY&lt;/code&gt;, &lt;code&gt;JINA_BASE_URL&lt;/code&gt;, &lt;code&gt;SUMMARY_LLM_BASE_URL&lt;/code&gt;, &lt;code&gt;SUMMARY_LLM_MODEL_NAME&lt;/code&gt;, &lt;code&gt;SUMMARY_LLM_API_KEY&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Minimal &lt;code&gt;.env&lt;/code&gt; configuration example:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Required for MiroThinker v1.5 and v1.0 (minimal setup)
SERPER_API_KEY=your_serper_key
SERPER_BASE_URL="https://google.serper.dev"
JINA_API_KEY=your_jina_key
JINA_BASE_URL="https://r.jina.ai"
E2B_API_KEY=your_e2b_key

# Required for jina_scrape_llm_summary
# Note: Summary LLM can be a small model (e.g., Qwen3-14B or GPT-5-Nano)
# The choice has minimal impact on performance, use what's most convenient
SUMMARY_LLM_BASE_URL="https://your_summary_llm_base_url/v1/chat/completions"
SUMMARY_LLM_MODEL_NAME=your_llm_model_name  # e.g., "Qwen/Qwen3-14B" or "gpt-5-nano"
SUMMARY_LLM_API_KEY=your_llm_api_key  # Optional, depends on LLM provider

# Required for benchmark evaluation (LLM-as-a-Judge)
OPENAI_API_KEY=your_openai_key  # Required for running benchmark evaluations
OPENAI_BASE_URL="https://api.openai.com/v1"  # Optional, defaults to OpenAI's API
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;üí° Why this is minimal&lt;/strong&gt;: These 3 MCP servers cover the core capabilities needed for research tasks: web search, content extraction, and code execution. All other servers are optional enhancements.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;ü§ñ Summary LLM&lt;/strong&gt;: The &lt;code&gt;SUMMARY_LLM&lt;/code&gt; can be a small model like Qwen3-14B or GPT-5-Nano. The choice has minimal impact on overall performance, use whichever is most convenient for your setup.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;üìä For Benchmark Evaluation&lt;/strong&gt;: If you plan to run benchmark evaluations, you also need &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; (and optionally &lt;code&gt;OPENAI_BASE_URL&lt;/code&gt;) for LLM-as-a-Judge functionality used in evaluation scripts.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;üñºÔ∏è For GAIA Multimodal Tasks&lt;/strong&gt;: GAIA-Val-165 includes tasks with image/audio/video files. Since MiroThinker is a text-only LLM, GPT-4o is used to pre-process these files into text descriptions. The same &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; is used for both this preprocessing and LLM-as-a-Judge.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;üìñ For more details&lt;/strong&gt;: See &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/libs/miroflow-tools/README.md"&gt;MiroFlow Tools README&lt;/a&gt; for complete documentation of all available tools.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;details&gt; 
 &lt;summary&gt;üîß Click to expand additional available tools&lt;/summary&gt; 
 &lt;p&gt;The following optional tools are available but were not used in MiroThinker v1.5 and v1.0 evaluation:&lt;/p&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th align="left"&gt;Server Name&lt;/th&gt; 
    &lt;th align="left"&gt;Type&lt;/th&gt; 
    &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;tool-vqa&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Commercial&lt;/td&gt; 
    &lt;td align="left"&gt;Vision processing using Claude&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;tool-vqa-os&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Open-Source&lt;/td&gt; 
    &lt;td align="left"&gt;Vision processing (open-source alternative)&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;tool-transcribe&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Commercial&lt;/td&gt; 
    &lt;td align="left"&gt;Audio transcription using OpenAI&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;tool-transcribe-os&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Open-Source&lt;/td&gt; 
    &lt;td align="left"&gt;Audio transcription using Whisper&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;tool-reasoning&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Commercial&lt;/td&gt; 
    &lt;td align="left"&gt;Reasoning engine using Claude&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;tool-reasoning-os&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Open-Source&lt;/td&gt; 
    &lt;td align="left"&gt;Reasoning engine (open-source alternative)&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;tool-reading&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Open-Source&lt;/td&gt; 
    &lt;td align="left"&gt;Document reading using MarkItDown&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;tool-google-search&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Commercial&lt;/td&gt; 
    &lt;td align="left"&gt;Web search using Google + scraping&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;code&gt;tool-sogou-search&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Commercial&lt;/td&gt; 
    &lt;td align="left"&gt;Web search using Sogou (Chinese)&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;&lt;strong&gt;üìñ Local Deployment&lt;/strong&gt;: For instructions on deploying open-source tools (&lt;code&gt;tool-vqa-os&lt;/code&gt;, &lt;code&gt;tool-transcribe-os&lt;/code&gt;, &lt;code&gt;tool-reasoning-os&lt;/code&gt;) locally, see &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/assets/LOCAL-TOOL-DEPLOYMENT.md"&gt;Local Tool Deployment Guide&lt;/a&gt;.&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/libs/miroflow-tools/README.md"&gt;MiroFlow Tools README&lt;/a&gt; for complete documentation of all available tools.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h4&gt;Pre-configured Agent Settings&lt;/h4&gt; 
&lt;p&gt;The &lt;code&gt;apps/miroflow-agent/conf/agent/&lt;/code&gt; directory contains several pre-configured agent settings. Each configuration uses different tools and requires corresponding environment variables in your &lt;code&gt;.env&lt;/code&gt; file.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;üí° Recommended&lt;/strong&gt;: For MiroThinker v1.5, use &lt;code&gt;mirothinker_v1.5_keep5_max200&lt;/code&gt; (with context management, recommended for most tasks) or &lt;code&gt;mirothinker_v1.5_keep5_max400&lt;/code&gt; (only used for BrowseComp and BrowseComp-ZH). For v1.0, use &lt;code&gt;mirothinker_v1.0_keep5&lt;/code&gt; (with context management). All use minimal configuration with only 3 MCP servers.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Configuration&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Max Turns&lt;/th&gt; 
   &lt;th align="left"&gt;Context Retention&lt;/th&gt; 
   &lt;th align="left"&gt;Required Environment Variables&lt;/th&gt; 
   &lt;th align="left"&gt;Recommended For&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;code&gt;mirothinker_v1.5_keep5_max200&lt;/code&gt;&lt;/strong&gt; ‚≠ê&lt;/td&gt; 
   &lt;td align="left"&gt;Single-agent with context management&lt;/td&gt; 
   &lt;td align="left"&gt;200&lt;/td&gt; 
   &lt;td align="left"&gt;Keep 5 most recent&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;SERPER_API_KEY&lt;/code&gt;, &lt;code&gt;SERPER_BASE_URL&lt;/code&gt;, &lt;code&gt;JINA_API_KEY&lt;/code&gt;, &lt;code&gt;JINA_BASE_URL&lt;/code&gt;, &lt;code&gt;E2B_API_KEY&lt;/code&gt;, &lt;code&gt;SUMMARY_LLM_BASE_URL&lt;/code&gt;, &lt;code&gt;SUMMARY_LLM_MODEL_NAME&lt;/code&gt;, &lt;code&gt;SUMMARY_LLM_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;v1.5 (recommended for most tasks)&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;code&gt;mirothinker_v1.5_keep5_max400&lt;/code&gt;&lt;/strong&gt; ‚≠ê&lt;/td&gt; 
   &lt;td align="left"&gt;Single-agent with context management&lt;/td&gt; 
   &lt;td align="left"&gt;400&lt;/td&gt; 
   &lt;td align="left"&gt;Keep 5 most recent&lt;/td&gt; 
   &lt;td align="left"&gt;Same as above&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;v1.5 (for BrowseComp &amp;amp; BrowseComp-ZH)&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;code&gt;mirothinker_v1.5&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Single-agent for MiroThinker v1.5&lt;/td&gt; 
   &lt;td align="left"&gt;600&lt;/td&gt; 
   &lt;td align="left"&gt;Keep all results&lt;/td&gt; 
   &lt;td align="left"&gt;Same as above&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;v1.5&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;code&gt;mirothinker_v1.0_keep5&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Single-agent with context management&lt;/td&gt; 
   &lt;td align="left"&gt;600&lt;/td&gt; 
   &lt;td align="left"&gt;Keep 5 most recent&lt;/td&gt; 
   &lt;td align="left"&gt;Same as above&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;v1.0&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;&lt;code&gt;mirothinker_v1.0&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Single-agent for MiroThinker v1.0&lt;/td&gt; 
   &lt;td align="left"&gt;600&lt;/td&gt; 
   &lt;td align="left"&gt;Keep all results&lt;/td&gt; 
   &lt;td align="left"&gt;Same as above&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;v1.0&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;details&gt; 
 &lt;summary&gt;üì¶ Click to expand legacy configurations (v0.1/v0.2)&lt;/summary&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th align="left"&gt;Configuration&lt;/th&gt; 
    &lt;th align="left"&gt;Description&lt;/th&gt; 
    &lt;th align="left"&gt;Max Turns&lt;/th&gt; 
    &lt;th align="left"&gt;Context Retention&lt;/th&gt; 
    &lt;th align="left"&gt;Required Environment Variables&lt;/th&gt; 
    &lt;th align="left"&gt;Recommended For&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;strong&gt;&lt;code&gt;multi_agent&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Multi-agent with commercial tools (v0.1/v0.2)&lt;/td&gt; 
    &lt;td align="left"&gt;50&lt;/td&gt; 
    &lt;td align="left"&gt;Keep all results&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;E2B_API_KEY&lt;/code&gt;, &lt;code&gt;ANTHROPIC_API_KEY&lt;/code&gt;, &lt;code&gt;ANTHROPIC_BASE_URL&lt;/code&gt;, &lt;code&gt;OPENAI_API_KEY&lt;/code&gt;, &lt;code&gt;OPENAI_BASE_URL&lt;/code&gt;, &lt;code&gt;SERPER_API_KEY&lt;/code&gt;, &lt;code&gt;SERPER_BASE_URL&lt;/code&gt;, &lt;code&gt;JINA_API_KEY&lt;/code&gt;, &lt;code&gt;JINA_BASE_URL&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;v0.1/v0.2&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="left"&gt;&lt;strong&gt;&lt;code&gt;multi_agent_os&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;Multi-agent with open-source tools (v0.1/v0.2)&lt;/td&gt; 
    &lt;td align="left"&gt;50&lt;/td&gt; 
    &lt;td align="left"&gt;Keep all results&lt;/td&gt; 
    &lt;td align="left"&gt;&lt;code&gt;E2B_API_KEY&lt;/code&gt;, &lt;code&gt;VISION_API_KEY&lt;/code&gt;, &lt;code&gt;VISION_BASE_URL&lt;/code&gt;, &lt;code&gt;VISION_MODEL_NAME&lt;/code&gt;, &lt;code&gt;WHISPER_API_KEY&lt;/code&gt;, &lt;code&gt;WHISPER_BASE_URL&lt;/code&gt;, &lt;code&gt;WHISPER_MODEL_NAME&lt;/code&gt;, &lt;code&gt;REASONING_API_KEY&lt;/code&gt;, &lt;code&gt;REASONING_BASE_URL&lt;/code&gt;, &lt;code&gt;REASONING_MODEL_NAME&lt;/code&gt;, &lt;code&gt;SERPER_API_KEY&lt;/code&gt;, &lt;code&gt;SERPER_BASE_URL&lt;/code&gt;, &lt;code&gt;JINA_API_KEY&lt;/code&gt;, &lt;code&gt;JINA_BASE_URL&lt;/code&gt;&lt;/td&gt; 
    &lt;td align="left"&gt;v0.1/v0.2&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;üí° Note&lt;/strong&gt;: All environment variables are listed in &lt;code&gt;apps/miroflow-agent/.env.example&lt;/code&gt;. Copy it to &lt;code&gt;.env&lt;/code&gt; and fill in the values for the tools you plan to use.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Creating Custom Tool Configurations&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt;üîß Click to expand custom tool configuration guide&lt;/summary&gt; 
 &lt;p&gt;You can create your own YAML configuration file to freely combine MCP servers. Here's how:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;strong&gt;Create a new YAML file&lt;/strong&gt; in &lt;code&gt;apps/miroflow-agent/conf/agent/&lt;/code&gt;:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;# conf/agent/my_custom_config.yaml
defaults:
  - default
  - _self_

main_agent:
  tools:
    - tool-python                    # Execution environment
    - search_and_scrape_webpage      # Google search
    - jina_scrape_llm_summary        # Web scraping with LLM
    - tool-vqa                       # Vision processing (optional)
    - tool-transcribe                # Audio processing (optional)
    - tool-reasoning                 # Reasoning engine (optional)
    - tool-reading                   # Document reading (optional)
  max_turns: 400  # Maximum number of turns

sub_agents:
  agent-browsing:  # Optional sub-agent
    tools:
      - tool-google-search
      - tool-vqa
      - tool-reading
      - tool-python
    max_turns: 50

keep_tool_result: -1  # Context retention budget: -1 keeps all tool results, or specify K to keep only the K most recent tool responses
&lt;/code&gt;&lt;/pre&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;&lt;strong&gt;üí° Context Retention Strategy&lt;/strong&gt;: The &lt;code&gt;keep_tool_result&lt;/code&gt; parameter implements a &lt;strong&gt;recency-based context retention&lt;/strong&gt; strategy. In the standard ReAct paradigm, all tool outputs are retained in the message history, which can lead to inefficient context utilization. Empirically, we observe that the model's subsequent actions depend primarily on recent observations rather than distant ones. This strategy retains only the most recent K tool responses (where K is the &lt;code&gt;keep_tool_result&lt;/code&gt; value) while preserving the complete sequence of thoughts and actions.&lt;/p&gt; 
  &lt;p&gt;&lt;strong&gt;Benefits:&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;‚úÖ Preserves the reasoning and action trace&lt;/li&gt; 
   &lt;li&gt;‚úÖ Focuses the model's attention on the most contextually relevant observations&lt;/li&gt; 
   &lt;li&gt;‚úÖ Frees additional context space for extended reasoning and deeper tool-use trajectories&lt;/li&gt; 
   &lt;li&gt;‚úÖ Does not lead to performance degradation while allowing more context space for interactive scaling&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p&gt;&lt;strong&gt;Usage:&lt;/strong&gt; Set &lt;code&gt;keep_tool_result: -1&lt;/code&gt; to keep all tool results, or specify a positive integer K (e.g., &lt;code&gt;keep_tool_result: 5&lt;/code&gt;) to keep only the K most recent tool responses.&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;ol start="2"&gt; 
  &lt;li&gt;&lt;strong&gt;Use your custom configuration&lt;/strong&gt; when running evaluations:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;cd apps/miroflow-agent
uv run main.py llm=qwen-3 agent=my_custom_config llm.base_url=https://your_base_url/v1
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="3"&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Configure environment variables&lt;/strong&gt; in &lt;code&gt;.env&lt;/code&gt; based on the tools you use.&lt;/p&gt; &lt;p&gt;All available environment variables are listed in &lt;code&gt;apps/miroflow-agent/.env.example&lt;/code&gt;. Copy it to &lt;code&gt;.env&lt;/code&gt; and configure the variables according to your chosen configuration:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;cd apps/miroflow-agent
cp .env.example .env
# Edit .env with your actual API keys
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;For MiroThinker v1.5&lt;/strong&gt; (&lt;code&gt;mirothinker_v1.5_keep5_max200.yaml&lt;/code&gt;, &lt;code&gt;mirothinker_v1.5_keep5_max400.yaml&lt;/code&gt;, or &lt;code&gt;mirothinker_v1.5.yaml&lt;/code&gt;) and &lt;strong&gt;v1.0&lt;/strong&gt; (&lt;code&gt;mirothinker_v1.0_keep5.yaml&lt;/code&gt; or &lt;code&gt;mirothinker_v1.0.yaml&lt;/code&gt;), see the &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/#minimal-configuration-for-mirothinker-v15-and-v10"&gt;Minimal Configuration&lt;/a&gt; section above for the complete configuration example.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;For other configurations&lt;/strong&gt;, refer to the &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/#pre-configured-agent-settings"&gt;Pre-configured Agent Settings&lt;/a&gt; table above to see which environment variables are required.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;üîë Click to expand optional API keys&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# API for LLM-as-a-Judge (for benchmark testing, required for benchmark evaluation)
OPENAI_API_KEY=your_openai_key
OPENAI_BASE_URL="https://api.openai.com/v1"  # Optional, defaults to OpenAI's API

# API for Open-Source Audio Transcription Tool (for benchmark testing, optional)
WHISPER_MODEL_NAME="openai/whisper-large-v3-turbo"
WHISPER_API_KEY=your_whisper_key
WHISPER_BASE_URL="https://your_whisper_base_url/v1"

# API for Open-Source VQA Tool (for benchmark testing, optional)
VISION_MODEL_NAME="Qwen/Qwen2.5-VL-72B-Instruct"
VISION_API_KEY=your_vision_key
VISION_BASE_URL="https://your_vision_base_url/v1/chat/completions"

# API for Open-Source Reasoning Tool (for benchmark testing, optional)
REASONING_MODEL_NAME="Qwen/Qwen3-235B-A22B-Thinking-2507"
REASONING_API_KEY=your_reasoning_key
REASONING_BASE_URL="https://your_reasoning_base_url/v1/chat/completions"

# API for Claude Sonnet 3.7 as Commercial Tools (optional)
ANTHROPIC_API_KEY=your_anthropic_key

# API for Sogou Search (optional)
TENCENTCLOUD_SECRET_ID=your_tencent_cloud_secret_id
TENCENTCLOUD_SECRET_KEY=your_tencent_cloud_secret_key

# API for Summary LLM (can use small models like Qwen3-14B or GPT-5-Nano)
SUMMARY_LLM_BASE_URL="https://your_summary_llm_base_url/v1/chat/completions"
SUMMARY_LLM_MODEL_NAME=your_summary_llm_model_name  # e.g., "Qwen/Qwen3-14B" or "gpt-5-nano"
SUMMARY_LLM_API_KEY=your_summary_llm_api_key
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;Serve the MiroThinker Model&lt;/h3&gt; 
&lt;h4&gt;Option 1 (Recommended): Serve with SGLang or vLLM&lt;/h4&gt; 
&lt;p&gt;Use SGLang to serve MiroThinker models at port 61002:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;NUM_GPUS=4
PORT=61002

# Downloading model from HF (v1.5 recommended)
MODEL_PATH=miromind-ai/MiroThinker-v1.5-30B

# Or use v1.0
# MODEL_PATH=miromind-ai/MiroThinker-v1.0-30B

python3 -m sglang.launch_server \
    --model-path $MODEL_PATH \
    --tp $NUM_GPUS \
    --dp 1 \
    --host 0.0.0.0 \
    --port $PORT \
    --trust-remote-code
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;üìç Server URL&lt;/strong&gt;: This will start a server at &lt;code&gt;http://0.0.0.0:$PORT&lt;/code&gt;. Use this as your server base URL (e.g., &lt;code&gt;http://0.0.0.0:61002/v1&lt;/code&gt;).&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Option 2: Quantized Light-Weight Options&lt;/h4&gt; 
&lt;p&gt;We also provide comprehensive guidance for serving MiroThinker models using CPU-optimized and GPU-accelerated quantization techniques, along with detailed analysis and guidelines for deployment with llama.cpp, Ollama, SGLang, and other inference frameworks.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;üìñ Complete Guide&lt;/strong&gt;: See &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/apps/gradio-demo/"&gt;Deployment Documentation&lt;/a&gt; for detailed deployment instructions.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Run Your First Task&lt;/h3&gt; 
&lt;p&gt;After setting up the environment and starting your model server, run &lt;code&gt;main.py&lt;/code&gt; to test with a default question: &lt;em&gt;"What is the title of today's arxiv paper in computer science?"&lt;/em&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd apps/miroflow-agent

# Using MiroThinker models (requires your own model server)
uv run python main.py llm=qwen-3 agent=mirothinker_v1.5_keep5_max200 llm.base_url=http://localhost:61002/v1

# Or using Claude (requires ANTHROPIC_API_KEY in .env)
uv run python main.py llm=claude-3-7 agent=single_agent_keep5

# Or using GPT-5 (requires OPENAI_API_KEY in .env)
uv run python main.py llm=gpt-5 agent=single_agent_keep5
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;To customize your question&lt;/strong&gt;, edit &lt;code&gt;main.py&lt;/code&gt; line 32:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;task_description = "Your custom question here"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The agent will search the web, execute code if needed, and provide an answer with sources.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;üìñ More details&lt;/strong&gt;: See &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/apps/miroflow-agent/README.md"&gt;apps/miroflow-agent/README.md&lt;/a&gt; for available configurations and troubleshooting.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;üìä Benchmark Evaluation&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;For researchers who want to reproduce our benchmark results or evaluate on standard benchmarks.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Download Benchmark Data&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd MiroThinker  # Back to project root
wget https://huggingface.co/datasets/miromind-ai/MiroFlow-Benchmarks/resolve/main/data_20251115_password_protected.zip
unzip data_20251115_password_protected.zip
# Password: pf4*
rm data_20251115_password_protected.zip
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Run Benchmark Evaluation&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; For MiroThinker v1.5, use &lt;code&gt;mirothinker_v1.5_keep5_max200&lt;/code&gt; (with context management), &lt;code&gt;mirothinker_v1.5_keep5_max400&lt;/code&gt; (with context management), or &lt;code&gt;mirothinker_v1.5&lt;/code&gt; configurations. For v1.0, use &lt;code&gt;mirothinker_v1.0_keep5&lt;/code&gt; (with context management) or &lt;code&gt;mirothinker_v1.0&lt;/code&gt; configurations.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Available Parameters:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;You can customize the evaluation by setting the following environment variables before running the script:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Parameter&lt;/th&gt; 
   &lt;th align="left"&gt;Default&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;LLM_MODEL&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;"MiroThinker-Models"&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Model name identifier&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;BASE_URL&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;"https://your-api.com/v1"&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Base URL of your model server&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;NUM_RUNS&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Varies by benchmark&lt;/td&gt; 
   &lt;td align="left"&gt;Number of evaluation runs (3 for most benchmarks, 8 for GAIA/XBench/FutureX/SEAL-0, 32 for AIME2025)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;LLM_PROVIDER&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;"qwen"&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;LLM provider (e.g., &lt;code&gt;qwen&lt;/code&gt;, &lt;code&gt;openai&lt;/code&gt;, &lt;code&gt;anthropic&lt;/code&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;AGENT_SET&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;"mirothinker_v1.5_keep5_max200"&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Agent configuration (e.g., &lt;code&gt;mirothinker_v1.5_keep5_max200&lt;/code&gt;, &lt;code&gt;mirothinker_v1.5_keep5_max400&lt;/code&gt;, &lt;code&gt;mirothinker_v1.0_keep5&lt;/code&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;MAX_CONTEXT_LENGTH&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;262144&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Maximum context length (256K)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;MAX_CONCURRENT&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;10&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Maximum concurrent tasks&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;PASS_AT_K&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;1&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Pass@K evaluation metric&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;TEMPERATURE&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;1.0&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Sampling temperature&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;"xxx"&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;API key for the model server&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Example Usage:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Navigate to the miroflow-agent directory first
cd apps/miroflow-agent

# Basic usage with v1.5 (recommended)
NUM_RUNS=8 LLM_MODEL="MiroThinker-v1.5-30B" BASE_URL="https://your-api.com/v1" bash scripts/run_evaluate_multiple_runs_gaia-validation-text-103.sh

# Or with v1.0
# NUM_RUNS=8 LLM_MODEL="MiroThinker-v1.0-30B" BASE_URL="https://your-api.com/v1" bash scripts/run_evaluate_multiple_runs_gaia-validation-text-103.sh

# Customize number of runs and agent configuration (v1.5 with context management)
LLM_MODEL="MiroThinker-v1.5-30B" \
BASE_URL="https://your-api.com/v1" \
NUM_RUNS=8 \
AGENT_SET="mirothinker_v1.5_keep5_max200" \
bash scripts/run_evaluate_multiple_runs_gaia-validation-text-103.sh

# Or with v1.0 configuration (with context management)
# LLM_MODEL="MiroThinker-v1.0-30B" \
# BASE_URL="https://your-api.com/v1" \
# NUM_RUNS=8 \
# AGENT_SET="mirothinker_v1.0_keep5" \
# bash scripts/run_evaluate_multiple_runs_gaia-validation-text-103.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;details open&gt; 
 &lt;summary&gt;üìã Click to expand all benchmark commands&lt;/summary&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;&lt;strong&gt;‚ö†Ô∏è Important for MiroThinker v1.5&lt;/strong&gt;: To reproduce our reported results, you must set the correct &lt;code&gt;AGENT_SET&lt;/code&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;BrowseComp &amp;amp; BrowseComp-ZH&lt;/strong&gt;: Use &lt;code&gt;AGENT_SET="mirothinker_v1.5_keep5_max400"&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;All other benchmarks&lt;/strong&gt;: Use &lt;code&gt;AGENT_SET="mirothinker_v1.5_keep5_max200"&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/blockquote&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Navigate to the miroflow-agent directory first
cd apps/miroflow-agent

# HLE
NUM_RUNS=3 LLM_MODEL="xxx" BASE_URL="xxx" AGENT_SET="mirothinker_v1.5_keep5_max200" bash scripts/run_evaluate_multiple_runs_hle.sh

# HLE-Text-2158
NUM_RUNS=3 LLM_MODEL="xxx" BASE_URL="xxx" AGENT_SET="mirothinker_v1.5_keep5_max200" bash scripts/run_evaluate_multiple_runs_hle-text-2158.sh

# HLE-Text-500
NUM_RUNS=3 LLM_MODEL="xxx" BASE_URL="xxx" AGENT_SET="mirothinker_v1.5_keep5_max200" bash scripts/run_evaluate_multiple_runs_hle-text-500.sh

# GAIA-Text-103
NUM_RUNS=8 LLM_MODEL="xxx" BASE_URL="xxx" AGENT_SET="mirothinker_v1.5_keep5_max200" bash scripts/run_evaluate_multiple_runs_gaia-validation-text-103.sh

# GAIA-Validation (GAIA-Val-165)
NUM_RUNS=8 LLM_MODEL="xxx" BASE_URL="xxx" AGENT_SET="mirothinker_v1.5_keep5_max200" bash scripts/run_evaluate_multiple_runs_gaia-validation.sh

# BrowseComp-EN (‚ö†Ô∏è use max400)
NUM_RUNS=3 LLM_MODEL="xxx" BASE_URL="xxx" AGENT_SET="mirothinker_v1.5_keep5_max400" bash scripts/run_evaluate_multiple_runs_browsecomp.sh

# BrowseComp-ZH (‚ö†Ô∏è use max400)
NUM_RUNS=3 LLM_MODEL="xxx" BASE_URL="xxx" AGENT_SET="mirothinker_v1.5_keep5_max400" bash scripts/run_evaluate_multiple_runs_browsecomp_zh.sh

# WebWalkerQA
NUM_RUNS=3 LLM_MODEL="xxx" BASE_URL="xxx" AGENT_SET="mirothinker_v1.5_keep5_max200" bash scripts/run_evaluate_multiple_runs_webwalkerqa.sh

# XBench-DeepSearch
NUM_RUNS=8 LLM_MODEL="xxx" BASE_URL="xxx" AGENT_SET="mirothinker_v1.5_keep5_max200" bash scripts/run_evaluate_multiple_runs_xbench_deepsearch.sh

# FRAMES
NUM_RUNS=3 LLM_MODEL="xxx" BASE_URL="xxx" AGENT_SET="mirothinker_v1.5_keep5_max200" bash scripts/run_evaluate_multiple_runs_frames.sh

# SEAL-0
NUM_RUNS=8 LLM_MODEL="xxx" BASE_URL="xxx" AGENT_SET="mirothinker_v1.5_keep5_max200" bash scripts/run_evaluate_multiple_runs_seal-0.sh

# FutureX
NUM_RUNS=8 LLM_MODEL="xxx" BASE_URL="xxx" AGENT_SET="mirothinker_v1.5_keep5_max200" bash scripts/run_evaluate_multiple_runs_futurex.sh

# AIME2025
NUM_RUNS=32 LLM_MODEL="xxx" BASE_URL="xxx" AGENT_SET="mirothinker_v1.5_keep5_max200" bash scripts/run_evaluate_multiple_runs_aime2025.sh

# DeepSearchQA
NUM_RUNS=3 LLM_MODEL="xxx" BASE_URL="xxx" AGENT_SET="mirothinker_v1.5_keep5_max200" bash scripts/run_evaluate_multiple_runs_deepsearchqa.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h4&gt;3. &lt;strong&gt;Monitor evaluation progress&lt;/strong&gt;&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt;üìä Click to expand progress monitoring commands&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Navigate to the miroflow-agent directory first
cd apps/miroflow-agent

# For HLE
python benchmarks/check_progress/check_progress_hle.py /path/to/evaluation/logs

# For HLE-Text-2158
python benchmarks/check_progress/check_progress_hle-text-2158.py /path/to/evaluation/logs

# For HLE-Text-500
python benchmarks/check_progress/check_progress_hle-text-500.py /path/to/evaluation/logs

# For BrowseComp-EN
python benchmarks/check_progress/check_progress_browsecomp.py /path/to/evaluation/logs

# For BrowseComp-ZH
python benchmarks/check_progress/check_progress_browsecomp_zh.py /path/to/evaluation/logs

# For GAIA-Validation
python benchmarks/check_progress/check_progress_gaia-validation.py /path/to/evaluation/logs

# For GAIA-Text-103
python benchmarks/check_progress/check_progress_gaia-validation-text-103.py /path/to/evaluation/logs

# For WebWalkerQA
python benchmarks/check_progress/check_progress_webwalkerqa.py /path/to/evaluation/logs

# For Frames
python benchmarks/check_progress/check_progress_frames.py /path/to/evaluation/logs

# For XBench-DeepSearch
python benchmarks/check_progress/check_progress_xbench_deepsearch.py /path/to/evaluation/logs

# For SEAL-0
python benchmarks/check_progress/check_progress_seal-0.py /path/to/evaluation/logs

# For AIME2025
python benchmarks/check_progress/check_progress_aime2025.py /path/to/evaluation/logs

# For DeepSearchQA
python benchmarks/check_progress/check_progress_deepsearchqa.py /path/to/evaluation/logs
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;üî¨ Trace Collection&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;üìã Click to expand trace collection commands&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;cd apps/collect-trace

# Collect Traces for SFT
bash scripts/collect_trace_claude37.sh
bash scripts/collect_trace_gpt5.sh

# Collect Traces for DPO
bash scripts/collect_trace_qwen3.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;‚ùì FAQ &amp;amp; Troubleshooting&lt;/h2&gt; 
&lt;h3&gt;Common Issues&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;üîß Click to expand troubleshooting guide&lt;/summary&gt; 
 &lt;h4&gt;&lt;strong&gt;Q: Which version should I use?&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; We recommend &lt;strong&gt;MiroThinker v1.5&lt;/strong&gt; ‚≠ê with the minimal configuration:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;v1.5&lt;/strong&gt; ‚≠ê: Latest version with 256K context, world-leading performance. Use config (with context management): 
   &lt;ul&gt; 
    &lt;li&gt;&lt;code&gt;mirothinker_v1.5_keep5_max200&lt;/code&gt; (up to 200 turns, recommended for most tasks)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;mirothinker_v1.5_keep5_max400&lt;/code&gt; (up to 400 turns, only used for BrowseComp and BrowseComp-ZH)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h4&gt;&lt;strong&gt;Q: How do I get API keys?&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; You need these keys for minimal setup:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;SERPER_API_KEY&lt;/strong&gt;: Get from &lt;a href="https://serper.dev/"&gt;Serper.dev&lt;/a&gt; (Google search API)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;JINA_API_KEY&lt;/strong&gt;: Get from &lt;a href="https://jina.ai/"&gt;Jina.ai&lt;/a&gt; (Web scraping)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;E2B_API_KEY&lt;/strong&gt;: Get from &lt;a href="https://e2b.dev/"&gt;E2B.dev&lt;/a&gt; (Code execution sandbox)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;SUMMARY_LLM_API_KEY&lt;/strong&gt;: Your LLM API credentials (for content summarization). Can be a small model like Qwen3-14B or GPT-5-Nano‚Äîthe choice has minimal impact on performance.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;OPENAI_API_KEY&lt;/strong&gt;: Get from &lt;a href="https://platform.openai.com/"&gt;OpenAI&lt;/a&gt; (Required for benchmark evaluation, used for LLM-as-a-Judge)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;OPENAI_BASE_URL&lt;/strong&gt;: Optional, defaults to &lt;code&gt;https://api.openai.com/v1&lt;/code&gt;. Can be changed to use OpenAI-compatible APIs.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h4&gt;&lt;strong&gt;Q: Model server connection errors&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; Common issues:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Check base URL format&lt;/strong&gt;: Should end with &lt;code&gt;/v1&lt;/code&gt; (e.g., &lt;code&gt;https://your-api.com/v1&lt;/code&gt;)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Verify API key&lt;/strong&gt;: Ensure &lt;code&gt;API_KEY&lt;/code&gt; is set correctly in environment or script&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Check server status&lt;/strong&gt;: Make sure your model server is running and accessible&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Network issues&lt;/strong&gt;: Verify firewall/network settings allow connections&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h4&gt;&lt;strong&gt;Q: Evaluation script fails to run&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; Troubleshooting steps:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;strong&gt;Check working directory&lt;/strong&gt;: Make sure you're in &lt;code&gt;apps/miroflow-agent&lt;/code&gt; directory&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Verify environment&lt;/strong&gt;: Run &lt;code&gt;uv sync&lt;/code&gt; to ensure dependencies are installed&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Check .env file&lt;/strong&gt;: Ensure all required environment variables are set&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Review logs&lt;/strong&gt;: Check &lt;code&gt;logs/&lt;/code&gt; directory for detailed error messages&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Verify data path&lt;/strong&gt;: Ensure benchmark data is downloaded and in correct location&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;h4&gt;&lt;strong&gt;Q: Out of memory errors&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; Solutions:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Reduce context length&lt;/strong&gt;: Set &lt;code&gt;MAX_CONTEXT_LENGTH&lt;/code&gt; to a smaller value (e.g., 131072 for 128K)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Use context management with fewer turns&lt;/strong&gt;: 
   &lt;ul&gt; 
    &lt;li&gt;For v1.5: Use &lt;code&gt;mirothinker_v1.5_keep5_max200&lt;/code&gt; or &lt;code&gt;mirothinker_v1.5_keep5_max400&lt;/code&gt; (with context management)&lt;/li&gt; 
    &lt;li&gt;For v1.0: Use &lt;code&gt;mirothinker_v1.0_keep5&lt;/code&gt; (with context management)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Reduce concurrent tasks&lt;/strong&gt;: Set &lt;code&gt;MAX_CONCURRENT&lt;/code&gt; to a smaller number (e.g., 5)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Use smaller model&lt;/strong&gt;: 
   &lt;ul&gt; 
    &lt;li&gt;For v1.5: Try 30B instead of 235B&lt;/li&gt; 
    &lt;li&gt;For v1.0: Try 8B or 30B instead of 72B&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h4&gt;&lt;strong&gt;Q: Tool execution errors&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; Common fixes:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;E2B errors&lt;/strong&gt;: Verify &lt;code&gt;E2B_API_KEY&lt;/code&gt; is valid and account has credits&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Serper errors&lt;/strong&gt;: Check &lt;code&gt;SERPER_API_KEY&lt;/code&gt; and rate limits&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Jina errors&lt;/strong&gt;: Verify &lt;code&gt;JINA_API_KEY&lt;/code&gt; and &lt;code&gt;JINA_BASE_URL&lt;/code&gt; are correct&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;LLM summarization errors&lt;/strong&gt;: Check &lt;code&gt;SUMMARY_LLM_*&lt;/code&gt; variables and model availability&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h4&gt;&lt;strong&gt;Q: How to monitor long-running evaluations?&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; Use the progress monitoring scripts:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;cd apps/miroflow-agent
python benchmarks/check_progress/check_progress_&amp;lt;benchmark_name&amp;gt;.py /path/to/logs
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;The scripts show completion status, elapsed time, and estimated remaining time.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h3&gt;Getting Help&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üìñ &lt;strong&gt;Documentation&lt;/strong&gt;: Check &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/libs/miroflow-tools/README.md"&gt;MiroFlow Tools README&lt;/a&gt; for tool details&lt;/li&gt; 
 &lt;li&gt;üí¨ &lt;strong&gt;Discord&lt;/strong&gt;: Join our &lt;a href="https://discord.com/invite/GPqEnkzQZd"&gt;Discord community&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üêõ &lt;strong&gt;Issues&lt;/strong&gt;: Report bugs on &lt;a href="https://github.com/MiroMindAI/MiroThinker/issues"&gt;GitHub Issues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üìß &lt;strong&gt;Contact&lt;/strong&gt;: Visit &lt;a href="https://miromind.ai/"&gt;our website&lt;/a&gt; for more information&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the MIT License - see the &lt;a href="https://raw.githubusercontent.com/MiroMindAI/MiroThinker/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;h2&gt;üôè Acknowledgments&lt;/h2&gt; 
&lt;p&gt;We extend our sincere gratitude to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üèÜ &lt;strong&gt;Benchmark Contributors&lt;/strong&gt; for the comprehensive evaluation datasets&lt;/li&gt; 
 &lt;li&gt;üåç &lt;strong&gt;Open Source Community&lt;/strong&gt; for the tools and libraries that make this possible&lt;/li&gt; 
 &lt;li&gt;üë• &lt;strong&gt;All Contributors&lt;/strong&gt; who have helped make MiroThinker better&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/MiroMindAI/MiroThinker/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=MiroMindAI/MiroThinker" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;p&gt;Join our community and help us build the future of AI agents!&lt;/p&gt; 
&lt;h3&gt;References&lt;/h3&gt; 
&lt;p&gt;If you find this project useful in your research, please consider citing:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@article{miromind2025mirothinker,
  title={MiroThinker: Pushing the Performance Boundaries of Open-Source Research Agents via Model, Context, and Interactive Scaling},
  author={MiroMind Team and Bai, Song and Bing, Lidong and Chen, Carson and Chen, Guanzheng and Chen, Yuntao and Chen, Zhe and Chen, Ziyi and Dai, Jifeng and Dong, Xuan and others},
  journal={arXiv preprint arXiv:2511.11793},
  year={2025}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#MiroMindAI/MiroThinker&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=MiroMindAI/MiroThinker&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>trycua/cua</title>
      <link>https://github.com/trycua/cua</link>
      <description>&lt;p&gt;Open-source infrastructure for Computer-Use Agents. Sandboxes, SDKs, and benchmarks to train and evaluate AI agents that can control full desktops (macOS, Linux, Windows).&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a href="https://cua.ai" target="_blank" rel="noopener noreferrer"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" alt="Cua logo" width="150" srcset="img/logo_white.png" /&gt; 
   &lt;source media="(prefers-color-scheme: light)" alt="Cua logo" width="150" srcset="img/logo_black.png" /&gt; 
   &lt;img alt="Cua logo" width="500" src="https://raw.githubusercontent.com/trycua/cua/main/img/logo_black.png" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; 
 &lt;p align="center"&gt;Any OS. Any agent. Self-hostable.&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;a href="https://cua.ai" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://img.shields.io/badge/cua.ai-0ea5e9" alt="cua.ai" /&gt;&lt;/a&gt; &lt;a href="https://discord.com/invite/cua-ai" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://img.shields.io/badge/Discord-Join%20Server-10b981?logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://x.com/trycua" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://img.shields.io/twitter/follow/trycua?style=social" alt="Twitter" /&gt;&lt;/a&gt; &lt;a href="https://cua.ai/docs" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://img.shields.io/badge/Docs-0ea5e9.svg?sanitize=true" alt="Documentation" /&gt;&lt;/a&gt; &lt;br /&gt; &lt;a href="https://trendshift.io/repositories/13685" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/13685" alt="trycua%2Fcua | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;strong&gt;Cua&lt;/strong&gt; is an open-source platform for building, benchmarking, and deploying agents that can use any computer, with isolated, self-hostable sandboxes (Docker, QEMU, Apple Vz).&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;video src="https://github.com/user-attachments/assets/c619b4ea-bb8e-4382-860e-f3757e36af20" width="600" controls&gt;&lt;/video&gt; 
&lt;/div&gt; 
&lt;h2&gt;Choose Your Path&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;If you want to...&lt;/th&gt; 
   &lt;th&gt;Check out&lt;/th&gt; 
   &lt;th&gt;For&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Build AI agents or run isolated code execution&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/trycua/cua/main/#cua---agentic-ui-automation--code-execution"&gt;&lt;strong&gt;Cua&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;AI Engineers&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Benchmark or train computer-use models with RL&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/trycua/cua/main/#cua-bench---benchmarks--rl-environments"&gt;&lt;strong&gt;Cua-Bench&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Researchers&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Run macOS/Linux VMs on Apple Silicon&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/trycua/cua/main/#lume---macos-virtualization"&gt;&lt;strong&gt;Lume&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Developers, System Engineers&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Cua - Agentic UI Automation &amp;amp; Code Execution&lt;/h2&gt; 
&lt;p&gt;Build agents that see screens, click buttons, and complete tasks autonomously. Run isolated code execution environments for AI coding assistants like Claude Code, Codex CLI, or OpenCode.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Requires Python 3.12 or 3.13
from computer import Computer
from agent import ComputerAgent

computer = Computer(os_type="linux", provider_type="cloud")
agent = ComputerAgent(model="anthropic/claude-sonnet-4-5-20250929", computer=computer)

async for result in agent.run([{"role": "user", "content": "Open Firefox and search for Cua"}]):
    print(result)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://cua.ai/docs/cua/guide/get-started/set-up-sandbox"&gt;Get Started&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href="https://cua.ai/docs/cua/guide/examples"&gt;Examples&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href="https://cua.ai/docs/cua/reference/agent-sdk"&gt;API Reference&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Cua-Bench - Benchmarks &amp;amp; RL Environments&lt;/h2&gt; 
&lt;p&gt;Evaluate computer-use agents on OSWorld, ScreenSpot, Windows Arena, and custom tasks. Export trajectories for training.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install and create base image
cd cua-bench
uv tool install -e . &amp;amp;&amp;amp; cb image create linux-docker

# Run benchmark with agent
cb run dataset datasets/cua-bench-basic --agent cua-agent --max-parallel 4
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://cua.ai/docs/cuabench/guide/getting-started/first-steps"&gt;Get Started&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href="https://cuabench.ai/registry"&gt;Registry&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href="https://cua.ai/docs/cuabench/reference/cli-reference"&gt;CLI Reference&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Lume - macOS Virtualization&lt;/h2&gt; 
&lt;p&gt;Create and manage macOS/Linux VMs with near-native performance on Apple Silicon using Apple's Virtualization.Framework.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install Lume
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/trycua/cua/main/libs/lume/scripts/install.sh)"

# Pull &amp;amp; start a macOS VM
lume run macos-sequoia-vanilla:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://cua.ai/docs/lume/guide/getting-started/installation"&gt;Get Started&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href="https://cua.ai/docs/lume/guide/fundamentals/prebuilt-images"&gt;Prebuilt Images&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href="https://cua.ai/docs/lume/reference/cli-reference"&gt;CLI Reference&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Packages&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Package&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://cua.ai/docs/cua/reference/agent-sdk"&gt;cua-agent&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;AI agent framework for computer-use tasks&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://cua.ai/docs/cua/reference/computer-sdk"&gt;cua-computer&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;SDK for controlling desktop environments&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://cua.ai/docs/cua/reference/computer-server"&gt;cua-computer-server&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Driver for UI interactions and code execution in sandboxes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://cua.ai/docs/cuabench"&gt;cua-bench&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Benchmarks and RL environments for computer-use&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://cua.ai/docs/lume"&gt;lume&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;macOS/Linux VM management on Apple Silicon&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://cua.ai/docs/lume/reference/lumier"&gt;lumier&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Docker-compatible interface for Lume VMs&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Resources&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://cua.ai/docs"&gt;Documentation&lt;/a&gt; ‚Äî Guides, examples, and API reference&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.cua.ai/blog"&gt;Blog&lt;/a&gt; ‚Äî Tutorials, updates, and research&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://discord.com/invite/mVnXXpdE85"&gt;Discord&lt;/a&gt; ‚Äî Community support and discussions&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/trycua/cua/issues"&gt;GitHub Issues&lt;/a&gt; ‚Äî Bug reports and feature requests&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions! See our &lt;a href="https://raw.githubusercontent.com/trycua/cua/main/CONTRIBUTING.md"&gt;Contributing Guidelines&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;MIT License ‚Äî see &lt;a href="https://raw.githubusercontent.com/trycua/cua/main/LICENSE.md"&gt;LICENSE&lt;/a&gt; for details.&lt;/p&gt; 
&lt;p&gt;Third-party components have their own licenses:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/trycua/cua/main/libs/kasm/LICENSE"&gt;Kasm&lt;/a&gt; (MIT)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/OmniParser/raw/master/LICENSE"&gt;OmniParser&lt;/a&gt; (CC-BY-4.0)&lt;/li&gt; 
 &lt;li&gt;Optional &lt;code&gt;cua-agent[omni]&lt;/code&gt; includes ultralytics (AGPL-3.0)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Trademarks&lt;/h2&gt; 
&lt;p&gt;Apple, macOS, Ubuntu, Canonical, and Microsoft are trademarks of their respective owners. This project is not affiliated with or endorsed by these companies.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://starchart.cc/trycua/cua"&gt;&lt;img src="https://starchart.cc/trycua/cua.svg?variant=adaptive" alt="Stargazers over time" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;Thank you to all our &lt;a href="https://github.com/sponsors/trycua"&gt;GitHub Sponsors&lt;/a&gt;!&lt;/p&gt; 
 &lt;img width="300" alt="coderabbit-cli" src="https://github.com/user-attachments/assets/23a98e38-7897-4043-8ef7-eb990520dccc" /&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>microsoft/BitNet</title>
      <link>https://github.com/microsoft/BitNet</link>
      <description>&lt;p&gt;Official inference framework for 1-bit LLMs&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;bitnet.cpp&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://opensource.org/licenses/MIT"&gt;&lt;img src="https://img.shields.io/badge/license-MIT-blue.svg?sanitize=true" alt="License: MIT" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/badge/version-1.0-blue" alt="version" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://huggingface.co/microsoft/BitNet-b1.58-2B-4T"&gt;&lt;img src="https://raw.githubusercontent.com/microsoft/BitNet/main/assets/header_model_release.png" alt="BitNet Model on Hugging Face" width="800" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Try it out via this &lt;a href="https://bitnet-demo.azurewebsites.net/"&gt;demo&lt;/a&gt;, or build and run it on your own &lt;a href="https://github.com/microsoft/BitNet?tab=readme-ov-file#build-from-source"&gt;CPU&lt;/a&gt; or &lt;a href="https://github.com/microsoft/BitNet/raw/main/gpu/README.md"&gt;GPU&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;bitnet.cpp is the official inference framework for 1-bit LLMs (e.g., BitNet b1.58). It offers a suite of optimized kernels, that support &lt;strong&gt;fast&lt;/strong&gt; and &lt;strong&gt;lossless&lt;/strong&gt; inference of 1.58-bit models on CPU and GPU (NPU support will coming next).&lt;/p&gt; 
&lt;p&gt;The first release of bitnet.cpp is to support inference on CPUs. bitnet.cpp achieves speedups of &lt;strong&gt;1.37x&lt;/strong&gt; to &lt;strong&gt;5.07x&lt;/strong&gt; on ARM CPUs, with larger models experiencing greater performance gains. Additionally, it reduces energy consumption by &lt;strong&gt;55.4%&lt;/strong&gt; to &lt;strong&gt;70.0%&lt;/strong&gt;, further boosting overall efficiency. On x86 CPUs, speedups range from &lt;strong&gt;2.37x&lt;/strong&gt; to &lt;strong&gt;6.17x&lt;/strong&gt; with energy reductions between &lt;strong&gt;71.9%&lt;/strong&gt; to &lt;strong&gt;82.2%&lt;/strong&gt;. Furthermore, bitnet.cpp can run a 100B BitNet b1.58 model on a single CPU, achieving speeds comparable to human reading (5-7 tokens per second), significantly enhancing the potential for running LLMs on local devices. Please refer to the &lt;a href="https://arxiv.org/abs/2410.16144"&gt;technical report&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/microsoft/BitNet/main/assets/m2_performance.jpg" alt="m2_performance" width="800" /&gt; 
&lt;img src="https://raw.githubusercontent.com/microsoft/BitNet/main/assets/intel_performance.jpg" alt="m2_performance" width="800" /&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;The tested models are dummy setups used in a research context to demonstrate the inference performance of bitnet.cpp.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Demo&lt;/h2&gt; 
&lt;p&gt;A demo of bitnet.cpp running a BitNet b1.58 3B model on Apple M2:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/7f46b736-edec-4828-b809-4be780a3e5b1"&gt;https://github.com/user-attachments/assets/7f46b736-edec-4828-b809-4be780a3e5b1&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;What's New:&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;05/20/2025 &lt;a href="https://github.com/microsoft/BitNet/raw/main/gpu/README.md"&gt;BitNet Official GPU inference kernel&lt;/a&gt; &lt;img src="https://img.shields.io/badge/NEW-red" alt="NEW" /&gt;&lt;/li&gt; 
 &lt;li&gt;04/14/2025 &lt;a href="https://huggingface.co/microsoft/BitNet-b1.58-2B-4T"&gt;BitNet Official 2B Parameter Model on Hugging Face&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;02/18/2025 &lt;a href="https://arxiv.org/abs/2502.11880"&gt;Bitnet.cpp: Efficient Edge Inference for Ternary LLMs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;11/08/2024 &lt;a href="https://arxiv.org/abs/2411.04965"&gt;BitNet a4.8: 4-bit Activations for 1-bit LLMs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;10/21/2024 &lt;a href="https://arxiv.org/abs/2410.16144"&gt;1-bit AI Infra: Part 1.1, Fast and Lossless BitNet b1.58 Inference on CPUs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;10/17/2024 bitnet.cpp 1.0 released.&lt;/li&gt; 
 &lt;li&gt;03/21/2024 &lt;a href="https://github.com/microsoft/unilm/raw/master/bitnet/The-Era-of-1-bit-LLMs__Training_Tips_Code_FAQ.pdf"&gt;The-Era-of-1-bit-LLMs__Training_Tips_Code_FAQ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;02/27/2024 &lt;a href="https://arxiv.org/abs/2402.17764"&gt;The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;10/17/2023 &lt;a href="https://arxiv.org/abs/2310.11453"&gt;BitNet: Scaling 1-bit Transformers for Large Language Models&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;p&gt;This project is based on the &lt;a href="https://github.com/ggerganov/llama.cpp"&gt;llama.cpp&lt;/a&gt; framework. We would like to thank all the authors for their contributions to the open-source community. Also, bitnet.cpp's kernels are built on top of the Lookup Table methodologies pioneered in &lt;a href="https://github.com/microsoft/T-MAC/"&gt;T-MAC&lt;/a&gt;. For inference of general low-bit LLMs beyond ternary models, we recommend using T-MAC.&lt;/p&gt; 
&lt;h2&gt;Official Models&lt;/h2&gt; 
&lt;table&gt;  
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;th rowspan="2"&gt;Model&lt;/th&gt; 
   &lt;th rowspan="2"&gt;Parameters&lt;/th&gt; 
   &lt;th rowspan="2"&gt;CPU&lt;/th&gt; 
   &lt;th colspan="3"&gt;Kernel&lt;/th&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;th&gt;I2_S&lt;/th&gt; 
   &lt;th&gt;TL1&lt;/th&gt; 
   &lt;th&gt;TL2&lt;/th&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;a href="https://huggingface.co/microsoft/BitNet-b1.58-2B-4T"&gt;BitNet-b1.58-2B-4T&lt;/a&gt;&lt;/td&gt; 
   &lt;td rowspan="2"&gt;2.4B&lt;/td&gt; 
   &lt;td&gt;x86&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ARM&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;Supported Models&lt;/h2&gt; 
&lt;p&gt;‚ùóÔ∏è&lt;strong&gt;We use existing 1-bit LLMs available on &lt;a href="https://huggingface.co/"&gt;Hugging Face&lt;/a&gt; to demonstrate the inference capabilities of bitnet.cpp. We hope the release of bitnet.cpp will inspire the development of 1-bit LLMs in large-scale settings in terms of model size and training tokens.&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt;  
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;th rowspan="2"&gt;Model&lt;/th&gt; 
   &lt;th rowspan="2"&gt;Parameters&lt;/th&gt; 
   &lt;th rowspan="2"&gt;CPU&lt;/th&gt; 
   &lt;th colspan="3"&gt;Kernel&lt;/th&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;th&gt;I2_S&lt;/th&gt; 
   &lt;th&gt;TL1&lt;/th&gt; 
   &lt;th&gt;TL2&lt;/th&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;a href="https://huggingface.co/1bitLLM/bitnet_b1_58-large"&gt;bitnet_b1_58-large&lt;/a&gt;&lt;/td&gt; 
   &lt;td rowspan="2"&gt;0.7B&lt;/td&gt; 
   &lt;td&gt;x86&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ARM&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;a href="https://huggingface.co/1bitLLM/bitnet_b1_58-3B"&gt;bitnet_b1_58-3B&lt;/a&gt;&lt;/td&gt; 
   &lt;td rowspan="2"&gt;3.3B&lt;/td&gt; 
   &lt;td&gt;x86&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ARM&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;a href="https://huggingface.co/HF1BitLLM/Llama3-8B-1.58-100B-tokens"&gt;Llama3-8B-1.58-100B-tokens&lt;/a&gt;&lt;/td&gt; 
   &lt;td rowspan="2"&gt;8.0B&lt;/td&gt; 
   &lt;td&gt;x86&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ARM&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;a href="https://huggingface.co/collections/tiiuae/falcon3-67605ae03578be86e4e87026"&gt;Falcon3 Family&lt;/a&gt;&lt;/td&gt; 
   &lt;td rowspan="2"&gt;1B-10B&lt;/td&gt; 
   &lt;td&gt;x86&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ARM&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;a href="https://huggingface.co/collections/tiiuae/falcon-edge-series-6804fd13344d6d8a8fa71130"&gt;Falcon-E Family&lt;/a&gt;&lt;/td&gt; 
   &lt;td rowspan="2"&gt;1B-3B&lt;/td&gt; 
   &lt;td&gt;x86&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ARM&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;Requirements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;python&amp;gt;=3.9&lt;/li&gt; 
 &lt;li&gt;cmake&amp;gt;=3.22&lt;/li&gt; 
 &lt;li&gt;clang&amp;gt;=18 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;For Windows users, install &lt;a href="https://visualstudio.microsoft.com/downloads/"&gt;Visual Studio 2022&lt;/a&gt;. In the installer, toggle on at least the following options(this also automatically installs the required additional tools like CMake):&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Desktop-development with C++&lt;/li&gt; 
     &lt;li&gt;C++-CMake Tools for Windows&lt;/li&gt; 
     &lt;li&gt;Git for Windows&lt;/li&gt; 
     &lt;li&gt;C++-Clang Compiler for Windows&lt;/li&gt; 
     &lt;li&gt;MS-Build Support for LLVM-Toolset (clang)&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;For Debian/Ubuntu users, you can download with &lt;a href="https://apt.llvm.org/"&gt;Automatic installation script&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;bash -c "$(wget -O - https://apt.llvm.org/llvm.sh)"&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;conda (highly recommend)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Build from source&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] If you are using Windows, please remember to always use a Developer Command Prompt / PowerShell for VS2022 for the following commands. Please refer to the FAQs below if you see any issues.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone the repo&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone --recursive https://github.com/microsoft/BitNet.git
cd BitNet
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Install the dependencies&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# (Recommended) Create a new conda environment
conda create -n bitnet-cpp python=3.9
conda activate bitnet-cpp

pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Build the project&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Manually download the model and run with local path
huggingface-cli download microsoft/BitNet-b1.58-2B-4T-gguf --local-dir models/BitNet-b1.58-2B-4T
python setup_env.py -md models/BitNet-b1.58-2B-4T -q i2_s

&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;
usage: setup_env.py [-h] [--hf-repo {1bitLLM/bitnet_b1_58-large,1bitLLM/bitnet_b1_58-3B,HF1BitLLM/Llama3-8B-1.58-100B-tokens,tiiuae/Falcon3-1B-Instruct-1.58bit,tiiuae/Falcon3-3B-Instruct-1.58bit,tiiuae/Falcon3-7B-Instruct-1.58bit,tiiuae/Falcon3-10B-Instruct-1.58bit}] [--model-dir MODEL_DIR] [--log-dir LOG_DIR] [--quant-type {i2_s,tl1}] [--quant-embd]
                    [--use-pretuned]

Setup the environment for running inference

optional arguments:
  -h, --help            show this help message and exit
  --hf-repo {1bitLLM/bitnet_b1_58-large,1bitLLM/bitnet_b1_58-3B,HF1BitLLM/Llama3-8B-1.58-100B-tokens,tiiuae/Falcon3-1B-Instruct-1.58bit,tiiuae/Falcon3-3B-Instruct-1.58bit,tiiuae/Falcon3-7B-Instruct-1.58bit,tiiuae/Falcon3-10B-Instruct-1.58bit}, -hr {1bitLLM/bitnet_b1_58-large,1bitLLM/bitnet_b1_58-3B,HF1BitLLM/Llama3-8B-1.58-100B-tokens,tiiuae/Falcon3-1B-Instruct-1.58bit,tiiuae/Falcon3-3B-Instruct-1.58bit,tiiuae/Falcon3-7B-Instruct-1.58bit,tiiuae/Falcon3-10B-Instruct-1.58bit}
                        Model used for inference
  --model-dir MODEL_DIR, -md MODEL_DIR
                        Directory to save/load the model
  --log-dir LOG_DIR, -ld LOG_DIR
                        Directory to save the logging info
  --quant-type {i2_s,tl1}, -q {i2_s,tl1}
                        Quantization type
  --quant-embd          Quantize the embeddings to f16
  --use-pretuned, -p    Use the pretuned kernel parameters
&lt;/pre&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;h3&gt;Basic usage&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Run inference with the quantized model
python run_inference.py -m models/BitNet-b1.58-2B-4T/ggml-model-i2_s.gguf -p "You are a helpful assistant" -cnv
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;
usage: run_inference.py [-h] [-m MODEL] [-n N_PREDICT] -p PROMPT [-t THREADS] [-c CTX_SIZE] [-temp TEMPERATURE] [-cnv]

Run inference

optional arguments:
  -h, --help            show this help message and exit
  -m MODEL, --model MODEL
                        Path to model file
  -n N_PREDICT, --n-predict N_PREDICT
                        Number of tokens to predict when generating text
  -p PROMPT, --prompt PROMPT
                        Prompt to generate text from
  -t THREADS, --threads THREADS
                        Number of threads to use
  -c CTX_SIZE, --ctx-size CTX_SIZE
                        Size of the prompt context
  -temp TEMPERATURE, --temperature TEMPERATURE
                        Temperature, a hyperparameter that controls the randomness of the generated text
  -cnv, --conversation  Whether to enable chat mode or not (for instruct models.)
                        (When this option is turned on, the prompt specified by -p will be used as the system prompt.)
&lt;/pre&gt; 
&lt;h3&gt;Benchmark&lt;/h3&gt; 
&lt;p&gt;We provide scripts to run the inference benchmark providing a model.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;usage: e2e_benchmark.py -m MODEL [-n N_TOKEN] [-p N_PROMPT] [-t THREADS]  
   
Setup the environment for running the inference  
   
required arguments:  
  -m MODEL, --model MODEL  
                        Path to the model file. 
   
optional arguments:  
  -h, --help  
                        Show this help message and exit. 
  -n N_TOKEN, --n-token N_TOKEN  
                        Number of generated tokens. 
  -p N_PROMPT, --n-prompt N_PROMPT  
                        Prompt to generate text from. 
  -t THREADS, --threads THREADS  
                        Number of threads to use. 
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Here's a brief explanation of each argument:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;-m&lt;/code&gt;, &lt;code&gt;--model&lt;/code&gt;: The path to the model file. This is a required argument that must be provided when running the script.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-n&lt;/code&gt;, &lt;code&gt;--n-token&lt;/code&gt;: The number of tokens to generate during the inference. It is an optional argument with a default value of 128.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-p&lt;/code&gt;, &lt;code&gt;--n-prompt&lt;/code&gt;: The number of prompt tokens to use for generating text. This is an optional argument with a default value of 512.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-t&lt;/code&gt;, &lt;code&gt;--threads&lt;/code&gt;: The number of threads to use for running the inference. It is an optional argument with a default value of 2.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-h&lt;/code&gt;, &lt;code&gt;--help&lt;/code&gt;: Show the help message and exit. Use this argument to display usage information.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python utils/e2e_benchmark.py -m /path/to/model -n 200 -p 256 -t 4  
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This command would run the inference benchmark using the model located at &lt;code&gt;/path/to/model&lt;/code&gt;, generating 200 tokens from a 256 token prompt, utilizing 4 threads.&lt;/p&gt; 
&lt;p&gt;For the model layout that do not supported by any public model, we provide scripts to generate a dummy model with the given model layout, and run the benchmark on your machine:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python utils/generate-dummy-bitnet-model.py models/bitnet_b1_58-large --outfile models/dummy-bitnet-125m.tl1.gguf --outtype tl1 --model-size 125M

# Run benchmark with the generated model, use -m to specify the model path, -p to specify the prompt processed, -n to specify the number of token to generate
python utils/e2e_benchmark.py -m models/dummy-bitnet-125m.tl1.gguf -p 512 -n 128
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Convert from &lt;code&gt;.safetensors&lt;/code&gt; Checkpoints&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# Prepare the .safetensors model file
huggingface-cli download microsoft/bitnet-b1.58-2B-4T-bf16 --local-dir ./models/bitnet-b1.58-2B-4T-bf16

# Convert to gguf model
python ./utils/convert-helper-bitnet.py ./models/bitnet-b1.58-2B-4T-bf16
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;FAQ (Frequently Asked Questions)üìå&lt;/h3&gt; 
&lt;h4&gt;Q1: The build dies with errors building llama.cpp due to issues with std::chrono in log.cpp?&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; This is an issue introduced in recent version of llama.cpp. Please refer to this &lt;a href="https://github.com/tinglou/llama.cpp/commit/4e3db1e3d78cc1bcd22bcb3af54bd2a4628dd323"&gt;commit&lt;/a&gt; in the &lt;a href="https://github.com/abetlen/llama-cpp-python/issues/1942"&gt;discussion&lt;/a&gt; to fix this issue.&lt;/p&gt; 
&lt;h4&gt;Q2: How to build with clang in conda environment on windows?&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; Before building the project, verify your clang installation and access to Visual Studio tools by running:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;clang -v
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This command checks that you are using the correct version of clang and that the Visual Studio tools are available. If you see an error message such as:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;'clang' is not recognized as an internal or external command, operable program or batch file.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;It indicates that your command line window is not properly initialized for Visual Studio tools.&lt;/p&gt; 
&lt;p&gt;‚Ä¢ If you are using Command Prompt, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;"C:\Program Files\Microsoft Visual Studio\2022\Professional\Common7\Tools\VsDevCmd.bat" -startdir=none -arch=x64 -host_arch=x64
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;‚Ä¢ If you are using Windows PowerShell, run the following commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Import-Module "C:\Program Files\Microsoft Visual Studio\2022\Professional\Common7\Tools\Microsoft.VisualStudio.DevShell.dll" Enter-VsDevShell 3f0e31ad -SkipAutomaticLocation -DevCmdArguments "-arch=x64 -host_arch=x64"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;These steps will initialize your environment and allow you to use the correct Visual Studio tools.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>HunxByts/GhostTrack</title>
      <link>https://github.com/HunxByts/GhostTrack</link>
      <description>&lt;p&gt;Useful tool to track location or mobile number&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;GhostTrack&lt;/h1&gt; 
&lt;p&gt;Useful tool to track location or mobile number, so this tool can be called osint or also information gathering&lt;/p&gt; 
&lt;img src="https://github.com/HunxByts/GhostTrack/raw/main/asset/bn.png" /&gt; 
&lt;p&gt;New update : &lt;code&gt;Version 2.2&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Instalation on Linux (deb)&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;sudo apt-get install git
sudo apt-get install python3
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Instalation on Termux&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;pkg install git
pkg install python3
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Usage Tool&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/HunxByts/GhostTrack.git
cd GhostTrack
pip3 install -r requirements.txt
python3 GhostTR.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Display on the menu &lt;code&gt;IP Tracker&lt;/code&gt;&lt;/p&gt; 
&lt;img src="https://github.com/HunxByts/GhostTrack/blob/main/asset/ip.png " /&gt; 
&lt;p&gt;on the IP Track menu, you can combo with the seeker tool to get the target IP&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;span&gt;‚ö°&lt;/span&gt; Install Seeker :&lt;/summary&gt; - 
 &lt;strong&gt;&lt;a href="https://github.com/thewhiteh4t/seeker"&gt;Get Seeker&lt;/a&gt;&lt;/strong&gt; 
&lt;/details&gt; 
&lt;p&gt;Display on the menu &lt;code&gt;Phone Tracker&lt;/code&gt;&lt;/p&gt; 
&lt;img src="https://github.com/HunxByts/GhostTrack/raw/main/asset/phone.png" /&gt; 
&lt;p&gt;on this menu you can search for information from the target phone number&lt;/p&gt; 
&lt;p&gt;Display on the menu &lt;code&gt;Username Tracker&lt;/code&gt;&lt;/p&gt; 
&lt;img src="https://github.com/HunxByts/GhostTrack/raw/main/asset/User.png" /&gt; on this menu you can search for information from the target username on social media 
&lt;details&gt; 
 &lt;summary&gt;&lt;span&gt;‚ö°&lt;/span&gt; Author :&lt;/summary&gt; - 
 &lt;strong&gt;&lt;a href="https://github.com/HunxByts"&gt;HunxByts&lt;/a&gt;&lt;/strong&gt; 
&lt;/details&gt;</description>
    </item>
    
    <item>
      <title>gyoridavid/ai_agents_az</title>
      <link>https://github.com/gyoridavid/ai_agents_az</link>
      <description>&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;AI Agents A-Z&lt;/h1&gt; 
&lt;p&gt;In this repo, you can find the n8n templates we created for the episodes of &lt;a href="https://www.youtube.com/channel/UCloXqLhp_KGhHBe1kwaL2Tg"&gt;AI Agents A-Z&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Season 1&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gyoridavid/ai_agents_az/main/episode_1"&gt;Episode 1: Creating a prescription agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gyoridavid/ai_agents_az/main/episode_2"&gt;Episode 2: Making a daily digest agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gyoridavid/ai_agents_az/main/episode_3"&gt;Episode 3: Making LinkedIn posts using Human in the Loop approval process&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gyoridavid/ai_agents_az/main/episode_4"&gt;Episode 4: Deep Research Agent using Google&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gyoridavid/ai_agents_az/main/episode_5"&gt;Episode 5: Creating a blog writing system using deep research&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gyoridavid/ai_agents_az/main/episode_6"&gt;Episode 6: Lead generation with X-Ray search and LinkedIn&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gyoridavid/ai_agents_az/main/episode_7"&gt;Episode 7: Creating Youtube short videos using our custom MCP server&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gyoridavid/ai_agents_az/main/episode_8"&gt;Episode 8: Creating an AI influencer on Instagram using n8n&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gyoridavid/ai_agents_az/main/episode_9"&gt;Episode 9: Create revenge story videos for YouTube&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gyoridavid/ai_agents_az/main/episode_10"&gt;Episode 10: n8n best practices&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gyoridavid/ai_agents_az/main/episode_11"&gt;Episode 11: Create short (motivational) stories for YouTube and TikTok&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gyoridavid/ai_agents_az/main/episode_12"&gt;Episode 12: Scheduling social media posts with Postiz and n8n&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gyoridavid/ai_agents_az/main/episode_13"&gt;Episode 13: Create AI videos with MiniMax Hailuo 2 and n8n&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gyoridavid/ai_agents_az/main/episode_14"&gt;Episode 14: Create AI videos with Seedance and n8n&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gyoridavid/ai_agents_az/main/episode_15"&gt;Episode 15: Generate AI startup ideas from Reddit&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gyoridavid/ai_agents_az/main/episode_16"&gt;Episode 16: Create AI poem videos with n8n for TikTok&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gyoridavid/ai_agents_az/main/episode_17"&gt;Episode 17: Create Shopify product videos with Seedance, ElevenLabs, Latentsync, Flux Kontext and n8n&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gyoridavid/ai_agents_az/main/episode_18"&gt;Episode 18: Scary story TikTok videos workflow&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gyoridavid/ai_agents_az/main/episode_19"&gt;Episode 19: Run FLUX.1 Kontext [dev] with modal.com&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gyoridavid/ai_agents_az/main/episode_20"&gt;Episode 20: Use Wan 2.2, ComfyUI and n8n to generate videos for free&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gyoridavid/ai_agents_az/main/episode_21"&gt;Episode 21: 10 EASY faceless niches that pay well - monetize in a MONTH (2025)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gyoridavid/ai_agents_az/main/episode_22"&gt;Episode 22: Sleep long-form videos with GPT-5, ElevenMusic, Imagen4, Seendance and n8n&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gyoridavid/ai_agents_az/main/episode_23"&gt;Episode 23: UGC videos with nanobanana and n8n&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gyoridavid/ai_agents_az/main/episode_24"&gt;Episode 24: generate images with Qwen Image, Flux.1 [dev] and Flux.1 Schnell with modal.com and Cloudflare Workers AI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gyoridavid/ai_agents_az/main/episode_25"&gt;Episode 25: Fal.ai n8n subworkflows for Qwen Image Edit Plus and Wan 2.2 animate&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gyoridavid/ai_agents_az/main/episode_31"&gt;Episode 31: Veo 3.1 is now in n8n - how to use it for FREE&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gyoridavid/ai_agents_az/main/episode_35"&gt;Episode 35: Instagram influencer machine&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gyoridavid/ai_agents_az/main/episode_36"&gt;Episode 36: Viral bodycam footage creator with Sora 2&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gyoridavid/ai_agents_az/main/episode_38"&gt;Episode 38: Create AI reaction videos with Veo 3.1 and n8n&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gyoridavid/ai_agents_az/main/episode_39"&gt;Episode 39: Create infographics with Nano Banana Pro in n8n&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gyoridavid/ai_agents_az/main/episode_40"&gt;Episode 40: Flux.2[dev] with n8n&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gyoridavid/ai_agents_az/main/episode_41"&gt;Episode 41: FREE z-image-turbo with n8n&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gyoridavid/ai_agents_az/main/episode_42"&gt;Episode 42: 100% FREE explainer videos with n8n and Z-Image&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;servers&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://hub.docker.com/r/gyoridavid/ai-agents-no-code-tools"&gt;AI Agents No-Code Tools&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gyoridavid/short-video-maker"&gt;Short video maker MCP/REST server&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://hub.docker.com/r/gyoridavid/narrated-story-creator"&gt;Narrated story creator REST/MCP server&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>HKUDS/VideoRAG</title>
      <link>https://github.com/HKUDS/VideoRAG</link>
      <description>&lt;p&gt;[KDD'2026] "VideoRAG: Chat with Your Videos"&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;picture&gt; 
  &lt;img src="https://raw.githubusercontent.com/HKUDS/VideoRAG/main/cover.png" width="80%" style="border: none; box-shadow: none;" alt="Vimo: Chat with Your Videos" /&gt; 
 &lt;/picture&gt; 
 &lt;h1&gt; &lt;strong&gt;VideoRAG: Chat with Your Videos&lt;/strong&gt; ‚Ä¢ &lt;strong&gt;Vimo Desktop&lt;/strong&gt; &lt;/h1&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/16146" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/16146" alt="HKUDS%2FVideoRAG | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://arxiv.org/abs/2502.01549"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2502.01549-b31b1b" /&gt;&lt;/a&gt; &lt;a href="https://github.com/HKUDS/VideoRAG/issues/1"&gt;&lt;img src="https://img.shields.io/badge/Áæ§ËÅä-wechat/feishu-green" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/ZzU55kz3"&gt;&lt;img src="https://discordapp.com/api/guilds/1296348098003734629/widget.png?style=shield" /&gt;&lt;/a&gt; &lt;a href="https://www.youtube.com/watch?v=D5vsxcp4QZI"&gt;&lt;img src="https://img.shields.io/badge/YouTube-Watch%20Demo-red?style=flat&amp;amp;logo=youtube" /&gt;&lt;/a&gt; &lt;a href="https://learnopencv.com/videorag-long-context-video-comprehension/"&gt;&lt;img src="https://img.shields.io/badge/Blog-LearnOpenCV-blue?style=flat&amp;amp;logo=data:image/png;base64,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" alt="Blog" /&gt;&lt;/a&gt; &lt;a href=""&gt;&lt;img src="https://img.shields.io/badge/platform-macOS%20%7C%20Windows%20%7C%20Linux-lightgrey.svg?sanitize=true" alt="Platform" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;üé¨ Intelligent Video Conversations | Powered by Advanced AI | Extreme Long-Context Processing&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;img src="https://raw.githubusercontent.com/HKUDS/VideoRAG/main/VideoRAG-algorithm/VideoRAG_cover.png" /&gt; 
&lt;p&gt;Vimo is a revolutionary desktop application that lets you &lt;strong&gt;chat with your videos&lt;/strong&gt; using cutting-edge AI technology. Built on the powerful &lt;a href="https://arxiv.org/abs/2502.01549"&gt;VideoRAG framework&lt;/a&gt;, Vimo can understand and analyze videos of any length - from short clips to hundreds of hours of content - and answer your questions with remarkable accuracy.&lt;/p&gt; 
&lt;h3&gt;üé• Watch Vimo in Action&lt;/h3&gt; 
&lt;p&gt;See how Vimo transforms video interaction with intelligent conversations and deep understanding capabilities.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://www.youtube.com/watch?v=D5vsxcp4QZI"&gt; &lt;img src="https://img.youtube.com/vi/D5vsxcp4QZI/maxresdefault.jpg" width="80%" alt="Vimo Introduction Video" /&gt; &lt;/a&gt; 
 &lt;p&gt;&lt;em&gt;üëÜ Click to watch the Vimo demo video&lt;/em&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;‚ú® Key Features&lt;/h2&gt; 
&lt;h3&gt;For Everyone&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Drag &amp;amp; Drop Upload&lt;/strong&gt;: Simply drag video files into Vimo&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Smart Conversations&lt;/strong&gt;: Ask questions in natural language&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-Format Support&lt;/strong&gt;: Works with MP4, MKV, AVI, and more&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cross-Platform&lt;/strong&gt;: Available on macOS, Windows, and Linux&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;For Power Users&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Extreme Long Videos&lt;/strong&gt;: Process videos up to hundreds of hours&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-Video Analysis&lt;/strong&gt;: Compare and analyze multiple videos simultaneously&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Advanced Retrieval&lt;/strong&gt;: Find specific moments and scenes with precision&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Export Capabilities&lt;/strong&gt;: Save insights and references for later use&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;For Researchers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;VideoRAG Framework&lt;/strong&gt;: Access to cutting-edge retrieval-augmented generation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Benchmark Dataset&lt;/strong&gt;: LongerVideos benchmark with 134+ hours of content&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Performance Metrics&lt;/strong&gt;: Detailed evaluation against existing methods&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Extensible Architecture&lt;/strong&gt;: Build upon our open-source foundation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üåü Why Vimo?&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;For Video Enthusiasts &amp;amp; Professionals:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Effortless Video Analysis&lt;/strong&gt;: Upload any video and start asking questions immediately&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Natural Conversations&lt;/strong&gt;: Chat with your videos as if talking to a human expert&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;No Length Limits&lt;/strong&gt;: Process everything from 30-second clips to 100+ hour documentaries&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Deep Understanding&lt;/strong&gt;: Combines visual content, audio, and context for comprehensive answers&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;For Researchers &amp;amp; Developers:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;State-of-the-Art Algorithm&lt;/strong&gt;: Built on VideoRAG, featuring graph-driven knowledge indexing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Benchmark Performance&lt;/strong&gt;: Evaluated on 134+ hours across lectures, documentaries, and entertainment&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Open Source&lt;/strong&gt;: Full access to VideoRAG implementation and research findings&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Scalable Architecture&lt;/strong&gt;: Efficient processing with single GPU (RTX 3090) capability&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìã Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/VideoRAG/main/#-quick-start"&gt;üöÄ Quick Start&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/VideoRAG/main/#-key-features"&gt;‚ú® Key Features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/VideoRAG/main/#-videorag-algorithm"&gt;üî¨ VideoRAG Algorithm&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/VideoRAG/main/#%EF%B8%8F-development-setup"&gt;üõ†Ô∏è Development Setup&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/VideoRAG/main/#-benchmarks--evaluation"&gt;üß™ Benchmarks &amp;amp; Evaluation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/VideoRAG/main/#-citation"&gt;üìñ Citation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/VideoRAG/main/#-contributing"&gt;ü§ù Contributing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/VideoRAG/main/#-acknowledgement"&gt;üôè Acknowledgement&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üöÄ Quick Start of Vimo&lt;/h2&gt; 
&lt;h3&gt;Option 1: Download Vimo App (Coming Soon)&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] We are preparing the &lt;strong&gt;Beta release&lt;/strong&gt; for macOS Apple Silicon first, with Windows and Linux versions coming soon!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;div align="left"&gt; 
 &lt;a href="https://github.com/HKUDS/Vimo/releases"&gt; &lt;img src="https://img.shields.io/badge/Coming%20Soon-Mac%20Download-007ACC?style=for-the-badge&amp;amp;logo=apple&amp;amp;logoColor=white" alt="Coming Soon - Mac Release" height="50" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h3&gt;Option 2: Run from Source Code&lt;/h3&gt; 
&lt;p&gt;For detailed setup instructions:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Vimo Desktop App&lt;/strong&gt;: See &lt;a href="https://raw.githubusercontent.com/HKUDS/VideoRAG/main/Vimo-desktop"&gt;Vimo-desktop&lt;/a&gt; for complete installation and configuration steps&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Quick Overview:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Set up the Python backend environment and start the VideoRAG server&lt;/li&gt; 
 &lt;li&gt;Launch the Electron frontend application&lt;/li&gt; 
 &lt;li&gt;Start chatting with your videos!&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;üî¨ VideoRAG Algorithm&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/HKUDS/VideoRAG/main/VideoRAG-algorithm/VideoRAG.png" alt="VideoRAG Architecture" width="80%" /&gt; &lt;/p&gt; 
&lt;p&gt;VideoRAG introduces a novel dual-channel architecture that combines:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Graph-Driven Knowledge Indexing&lt;/strong&gt;: Multi-modal knowledge graphs for structured video understanding&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Hierarchical Context Encoding&lt;/strong&gt;: Preserves spatiotemporal visual patterns across long sequences&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Adaptive Retrieval&lt;/strong&gt;: Dynamic retrieval mechanisms optimized for video content&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cross-Video Understanding&lt;/strong&gt;: Semantic relationship modeling across multiple videos&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Technical Highlights&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Efficient Processing&lt;/strong&gt;: Handle hundreds of hours on a single RTX 3090 (24GB)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Structured Indexing&lt;/strong&gt;: Distill long videos into concise knowledge representations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-Modal Retrieval&lt;/strong&gt;: Align textual queries with visual and audio content&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;LongerVideos Benchmark&lt;/strong&gt;: 160+ videos, 134+ hours across diverse domains&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Performance Comparison&lt;/h3&gt; 
&lt;p&gt;Our VideoRAG algorithm significantly outperforms existing methods in long-context video understanding:&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/HKUDS/VideoRAG/main/Vimo-desktop/figures/table.png" width="80%" alt="Performance Comparison" /&gt; 
&lt;/div&gt; 
&lt;h3&gt;Experiments and Evaluation&lt;/h3&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/HKUDS/VideoRAG/main/VideoRAG-algorithm"&gt;VideoRAG-algorithm&lt;/a&gt; for detailed development setup including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Conda environment creation&lt;/li&gt; 
 &lt;li&gt;Model checkpoints download&lt;/li&gt; 
 &lt;li&gt;Dependencies installation&lt;/li&gt; 
 &lt;li&gt;Evaluation scripts&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üß™ LongerVideos Benchmark&lt;/h2&gt; 
&lt;p&gt;We created the LongerVideos benchmark to evaluate long-context video understanding:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Video Type&lt;/th&gt; 
   &lt;th&gt;#Collections&lt;/th&gt; 
   &lt;th&gt;#Videos&lt;/th&gt; 
   &lt;th&gt;#Queries&lt;/th&gt; 
   &lt;th&gt;Avg. Duration&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Lectures&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;12&lt;/td&gt; 
   &lt;td&gt;135&lt;/td&gt; 
   &lt;td&gt;376&lt;/td&gt; 
   &lt;td&gt;~64.3 hours&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Documentaries&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;5&lt;/td&gt; 
   &lt;td&gt;12&lt;/td&gt; 
   &lt;td&gt;114&lt;/td&gt; 
   &lt;td&gt;~28.5 hours&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Entertainment&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;5&lt;/td&gt; 
   &lt;td&gt;17&lt;/td&gt; 
   &lt;td&gt;112&lt;/td&gt; 
   &lt;td&gt;~41.9 hours&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Total&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;22&lt;/td&gt; 
   &lt;td&gt;164&lt;/td&gt; 
   &lt;td&gt;602&lt;/td&gt; 
   &lt;td&gt;~134.6 hours&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;For detailed evaluation instructions and reproduction scripts, see &lt;a href="https://raw.githubusercontent.com/HKUDS/VideoRAG/main/VideoRAG-algorithm/reproduce"&gt;VideoRAG-algorithm/reproduce&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üìñ Citation&lt;/h2&gt; 
&lt;p&gt;If you find Vimo or VideoRAG helpful in your research, please cite our paper:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@article{VideoRAG,
  title={VideoRAG: Retrieval-Augmented Generation with Extreme Long-Context Videos},
  author={Ren, Xubin and Xu, Lingrui and Xia, Long and Wang, Shuaiqiang and Yin, Dawei and Huang, Chao},
  journal={arXiv preprint arXiv:2502.01549},
  year={2025}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions from the community! Whether you're:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Reporting bugs&lt;/strong&gt; or suggesting features for Vimo&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Improving VideoRAG algorithms&lt;/strong&gt; or adding new capabilities&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enhancing documentation&lt;/strong&gt; or creating tutorials&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Designing UI/UX improvements&lt;/strong&gt; for better user experience&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Feel free to submit issues and pull requests. Together, we're building the future of intelligent video interaction!&lt;/p&gt; 
&lt;h2&gt;üôè Acknowledgement&lt;/h2&gt; 
&lt;p&gt;Vimo builds upon the incredible work of the open-source community:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://arxiv.org/abs/2502.01549"&gt;VideoRAG&lt;/a&gt;&lt;/strong&gt;: The core algorithm powering Vimo's intelligence&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/gusye1234/nano-graphrag"&gt;nano-graphrag&lt;/a&gt;&lt;/strong&gt; &amp;amp; &lt;strong&gt;&lt;a href="https://github.com/HKUDS/LightRAG"&gt;LightRAG&lt;/a&gt;&lt;/strong&gt;: Graph-based retrieval foundations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/facebookresearch/ImageBind"&gt;ImageBind&lt;/a&gt;&lt;/strong&gt;: Multi-modal representation learning&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/bytedance/UI-TARS-desktop"&gt;uitars-desktop&lt;/a&gt;&lt;/strong&gt;: Desktop application architecture inspiration&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;üåü Transform how you interact with videos. Start your journey with Vimo today!&lt;/strong&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;sub&gt;Built with ‚ù§Ô∏è by the VideoRAG@HKUDS team.&lt;/sub&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>hesreallyhim/awesome-claude-code</title>
      <link>https://github.com/hesreallyhim/awesome-claude-code</link>
      <description>&lt;p&gt;A curated list of awesome commands, files, and workflows for Claude Code&lt;/p&gt;&lt;hr&gt;&lt;h3 align="center"&gt;Pick Your Style:&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/"&gt;&lt;img src="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/assets/badge-style-awesome.svg?sanitize=true" alt="Awesome" height="28" style="border: 2px solid #cc3366; border-radius: 4px;" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/README_ALTERNATIVES/README_EXTRA.md"&gt;&lt;img src="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/assets/badge-style-extra.svg?sanitize=true" alt="Extra" height="28" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/README_ALTERNATIVES/README_CLASSIC.md"&gt;&lt;img src="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/assets/badge-style-classic.svg?sanitize=true" alt="Classic" height="28" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/README_ALTERNATIVES/README_FLAT_ALL_AZ.md"&gt;&lt;img src="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/assets/badge-style-flat.svg?sanitize=true" alt="Flat" height="28" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;img src="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/assets/awesome-claude-code-social-clawd-2.png" alt="Awesome Claude Code" width="600" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;h1&gt;Awesome Claude Code&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://awesome.re"&gt;&lt;img src="https://awesome.re/badge.svg?sanitize=true" alt="Awesome" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;A curated list of slash-commands, CLAUDE.md files, CLI tools, and other resources for enhancing your &lt;a href="https://docs.anthropic.com/en/docs/claude-code"&gt;Claude Code&lt;/a&gt; workflow.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Claude Code is a CLI-based coding assistant from &lt;a href="https://www.anthropic.com/"&gt;Anthropic&lt;/a&gt; that you can access in your terminal or IDE. This list helps the community share knowledge and best practices.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/assets/repo-ticker-awesome.svg?sanitize=true" alt="Featured Claude Code Projects" width="100%" /&gt; 
&lt;/div&gt; 
&lt;h2&gt;Latest Additions&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/muratcankoylan/ralph-wiggum-marketer"&gt;Ralph Wiggum Marketer&lt;/a&gt; by &lt;a href="https://github.com/muratcankoylan"&gt;Muratcan Koylan&lt;/a&gt; - A Claude Code plugin that provides an autonomous AI copywriter, integrating the Ralph loop with customized knowledge bases for market research agents. The agents do the research, Ralph writes the copy, you stay in bed. Whether or not you practice Ralph-Driven Development (RDD), I think these projects are interesting and creative explorations of general agentic patterns.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ClaytonFarr/ralph-playbook"&gt;The Ralph Playbook&lt;/a&gt; by &lt;a href="https://github.com/ClaytonFarr"&gt;Clayton Farr&lt;/a&gt; - A remarkably detailed and comprehensive guide to the Ralph Wiggum technique, featuring well-written theoretical commentary paired with practical guidelines and advice.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anthropics/claude-code/tree/4f18698a9ed25517861a75125b526e319bcf8354/plugins/ralph-wiggum"&gt;Ralph Wiggum Plugin&lt;/a&gt; by &lt;a href="https://github.com/anthropics"&gt;Anthropic PBC&lt;/a&gt; - The official Anthropic implementation of the Ralph Wiggum technique for iterative, self-referential AI development loops in Claude Code.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mikeyobrien/ralph-orchestrator"&gt;ralph-orchestrator&lt;/a&gt; by &lt;a href="https://github.com/mikeyobrien"&gt;mikeyobrien&lt;/a&gt; - Ralph Orchestrator implements the simple but effective "Ralph Wiggum" technique for autonomous task completion, continuously running an AI agent against a prompt file until the task is marked as complete or limits are reached. This implementation provides a robust, well-tested, and feature-complete orchestration system for AI-driven development. Also cited in the Anthropic Ralph plugin documentation.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/frankbria/ralph-claude-code"&gt;Ralph for Claude Code&lt;/a&gt; by &lt;a href="https://github.com/frankbria"&gt;Frank Bria&lt;/a&gt; - An autonomous AI development framework that enables Claude Code to work iteratively on projects until completion. Features intelligent exit detection, rate limiting, circuit breaker patterns, and comprehensive safety guardrails to prevent infinite loops and API overuse. Built with Bash, integrated with tmux for live monitoring, and includes 75+ comprehensive tests.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#agent-skills-"&gt;Agent Skills ü§ñ&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#general"&gt;General&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#workflows--knowledge-guides-"&gt;Workflows &amp;amp; Knowledge Guides üß†&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#general-1"&gt;General&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#ralph-wiggum"&gt;Ralph Wiggum&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#tooling-"&gt;Tooling üß∞&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#general-2"&gt;General&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#ide-integrations"&gt;IDE Integrations&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#usage-monitors"&gt;Usage Monitors&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#orchestrators"&gt;Orchestrators&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#status-lines-"&gt;Status Lines üìä&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#general-3"&gt;General&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#hooks-"&gt;Hooks ü™ù&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#general-4"&gt;General&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#slash-commands-"&gt;Slash-Commands üî™&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#general-5"&gt;General&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#version-control--git"&gt;Version Control &amp;amp; Git&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#code-analysis--testing"&gt;Code Analysis &amp;amp; Testing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#context-loading--priming"&gt;Context Loading &amp;amp; Priming&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#documentation--changelogs"&gt;Documentation &amp;amp; Changelogs&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#ci--deployment"&gt;CI / Deployment&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#project--task-management"&gt;Project &amp;amp; Task Management&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#miscellaneous"&gt;Miscellaneous&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#claudemd-files-"&gt;CLAUDE.md Files üìÇ&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#language-specific"&gt;Language-Specific&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#domain-specific"&gt;Domain-Specific&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#project-scaffolding--mcp"&gt;Project Scaffolding &amp;amp; MCP&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#alternative-clients-"&gt;Alternative Clients üì±&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#general-6"&gt;General&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#official-documentation-%EF%B8%8F"&gt;Official Documentation üèõÔ∏è&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#general-7"&gt;General&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Agent Skills ü§ñ&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Agent skills are model-controlled configurations (files, scripts, resources, etc.) that enable Claude Code to perform specialized tasks requiring specific knowledge or capabilities.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;General&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/fcakyon/claude-codex-settings"&gt;Claude Codex Settings&lt;/a&gt; by &lt;a href="https://github.com/fcakyon"&gt;fatih akyon&lt;/a&gt; - A well-organized, well-written set of plugins covering core developer activities, such as working with common cloud platforms like GitHub, Azure, MongoDB, and popular services such as Tavily, Playwright, and more. Clear, not overly-opinionated, and compatible with a few other providers.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dreamiurg/claude-mountaineering-skills"&gt;Claude Mountaineering Skills&lt;/a&gt; by &lt;a href="https://github.com/dreamiurg"&gt;Dmytro Gaivoronsky&lt;/a&gt; - Claude Code skill that automates mountain route research for North American peaks. Aggregates data from 10+ mountaineering sources like Mountaineers.org, PeakBagger.com and SummitPost.com to generate detailed route beta reports with weather, avalanche conditions, and trip reports.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/skills-directory/skill-codex"&gt;Codex Skill&lt;/a&gt; by &lt;a href="https://github.com/klaudworks"&gt;klaudworks&lt;/a&gt; - Enables users to prompt codex from claude code. Unlike the raw codex mcp server, this skill infers parameters such as model, reasoning effort, sandboxing from your prompt or asks you to specify them. It also simplifies continuing prior codex sessions so that codex can continue with the prior context.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/NeoLabHQ/context-engineering-kit"&gt;Context Engineering Kit&lt;/a&gt; by &lt;a href="https://github.com/LeoVS09"&gt;Vlad Goncharov&lt;/a&gt; - Hand-crafted collection of advanced context engineering techniques and patterns with minimal token footprint focused on improving agent result quality.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/obra/superpowers"&gt;Superpowers&lt;/a&gt; by &lt;a href="https://github.com/obra"&gt;Jesse Vincent&lt;/a&gt; - A strong bundle of core competencies for software engineering, with good coverage of a large portion of the SDLC - from planning, reviewing, testing, debugging... Well written, well organized, and adaptable. The author refers to them as "superpowers", but many of them are just consolidating engineering best practices - which sometimes does feel like a superpower when working with Claude Code.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/glittercowboy/taches-cc-resources"&gt;T√ÇCHES Claude Code Resources&lt;/a&gt; by &lt;a href="https://github.com/glittercowboy"&gt;T√ÇCHES&lt;/a&gt; - A well-balanced, "down-to-Earth" set of sub agents, skills, and commands, that are well-organized, easy to read, and a healthy focus on "meta"-skills/agents, like "skill-auditor", hook creation, etc. - the kind of things you can adapt to your workflow, and not the other way around.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/alonw0/web-asset-generator"&gt;Web Assets Generator Skill&lt;/a&gt; by &lt;a href="https://github.com/alonw0"&gt;Alon Wolenitz&lt;/a&gt; - Easily generate web assets from Claude Code including favicons, app icons (PWA), and social media meta images (Open Graph) for Facebook, Twitter, WhatsApp, and LinkedIn. Handles image resizing, text-to-image generation, emojis, and provides proper HTML meta tags.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;h2&gt;Workflows &amp;amp; Knowledge Guides üß†&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;A workflow is a tightly coupled set of Claude Code-native resources that facilitate specific projects&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;General&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ayoubben18/ab-method"&gt;AB Method&lt;/a&gt; by &lt;a href="https://github.com/ayoubben18"&gt;Ayoub Bensalah&lt;/a&gt; - A principled, spec-driven workflow that transforms large problems into focused, incremental missions using Claude Code's specialized sub agents. Includes slash-commands, sub agents, and specialized workflows designed for specific parts of the SDLC.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ThibautMelen/agentic-workflow-patterns"&gt;Agentic Workflow Patterns&lt;/a&gt; by &lt;a href="https://github.com/ThibautMelen"&gt;ThibautMelen&lt;/a&gt; - A comprehensive and well-documented collection of agentic patterns from Anthropic docs, with colorful Mermaid diagrams and code examples for each pattern. Covers Subagent Orchestration, Progressive Skills, Parallel Tool Calling, Master-Clone Architecture, Wizard Workflows, and more. Also compatible with other providers.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cloudartisan/cloudartisan.github.io/tree/main/.claude/commands"&gt;Blogging Platform Instructions&lt;/a&gt; by &lt;a href="https://github.com/cloudartisan"&gt;cloudartisan&lt;/a&gt; - Provides a well-structured set of commands for publishing and maintaining a blogging platform, including commands for creating posts, managing categories, and handling media files.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ericbuess/claude-code-docs"&gt;Claude Code Documentation Mirror&lt;/a&gt; by &lt;a href="https://github.com/ericbuess"&gt;Eric Buess&lt;/a&gt; - A mirror of the Anthropic ¬© PBC documentation pages for Claude Code, updated every few hours. Can come in handy when trying to stay on top of the ever-expanding feature-set of Dr. Claw D. Code, Ph.D.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://nikiforovall.blog/claude-code-rules/"&gt;Claude Code Handbook&lt;/a&gt; by &lt;a href="https://github.com/nikiforovall"&gt;nikiforovall&lt;/a&gt; - Collection of best practices, tips, and techniques for Claude Code development workflows, enhanced with distributable plugins.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/diet103/claude-code-infrastructure-showcase"&gt;Claude Code Infrastructure Showcase&lt;/a&gt; by &lt;a href="https://github.com/diet103"&gt;diet103&lt;/a&gt; - A remarkably innovative approach to working with Skills, the centerpiece of which being a technique that leverages hooks to ensure that Claude intelligently selects and activates the appropriate Skill given the current context. Well-documented and adaptable to different projects and workflows.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/automazeio/ccpm"&gt;Claude Code PM&lt;/a&gt; by &lt;a href="https://github.com/ranaroussi"&gt;Ran Aroussi&lt;/a&gt; - Really comprehensive and feature-packed project-management workflow for Claude Code. Numerous specialized agents, slash-commands, and strong documentation.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/danielrosehill/Claude-Code-Repos-Index"&gt;Claude Code Repos Index&lt;/a&gt; by &lt;a href="https://github.com/danielrosehill"&gt;Daniel Rosehill&lt;/a&gt; - This is either the work of a prolific genius, or a very clever bot (or both), although it hardly matters because the quality is so good - an index of 75+ Claude Code repositories published by the author - and I'm not talking about slop. CMS, system design, deep research, IoT, agentic workflows, server management, personal health... If you spot the lie, let me know, otherwise please check these out.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Piebald-AI/claude-code-system-prompts"&gt;Claude Code System Prompts&lt;/a&gt; by &lt;a href="https://github.com/Piebald-AI"&gt;Piebald AI&lt;/a&gt; - All parts of Claude Code's system prompt, including builtin tool descriptions, sub agent prompts (Plan/Explore/Task), utility prompts (CLAUDE.md, compact, Bash cmd, security review, agent creation, etc.). Updated for each Claude Code version.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ykdojo/claude-code-tips"&gt;Claude Code Tips&lt;/a&gt; by &lt;a href="https://github.com/ykdojo"&gt;ykdojo&lt;/a&gt; - A nice variety of 35+ brief but information-dense Claude Code tips covering voice input, system prompt patching, container workflows for risky tasks, conversation cloning(!), multi-model orchestration with Gemini CLI, and plenty more. Nice demos, working scripts, a plugin, I'd say this probably has a little something for everyone.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/maxritter/claude-codepro"&gt;Claude CodePro&lt;/a&gt; by &lt;a href="https://www.maxritter.net"&gt;Max Ritter&lt;/a&gt; - Professional development environment for Claude Code with spec-driven workflow, TDD enforcement, cross-session memory, semantic search, quality hooks, and modular rules integration. A bit "heavyweight" but feature-packed and has wide coverage.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/costiash/claude-code-docs"&gt;claude-code-docs&lt;/a&gt; by &lt;a href="https://github.com/costiash"&gt;Constantin Shafranski&lt;/a&gt; - A mirror of the Anthropic¬© PBC documentation site for Claude/Code, but with bonus features like full-text search and query-time updates - a nice companion to &lt;code&gt;claude-code-docs&lt;/code&gt; for up-to-the-minute, fully-indexed information so that Claude Code can read about itself.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/JSONbored/claudepro-directory"&gt;ClaudoPro Directory&lt;/a&gt; by &lt;a href="https://github.com/JSONbored"&gt;ghost&lt;/a&gt; - Well-crafted, wide selection of Claude Code hooks, slash commands, subagent files, and more, covering a range of specialized tasks and workflows. Better resources than your average "Claude-template-for-everything" site.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/disler/just-prompt/tree/main/.claude/commands"&gt;Context Priming&lt;/a&gt; by &lt;a href="https://github.com/disler"&gt;disler&lt;/a&gt; - Provides a systematic approach to priming Claude Code with comprehensive project context through specialized commands for different project scenarios and development contexts.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/OneRedOak/claude-code-workflows/tree/main/design-review"&gt;Design Review Workflow&lt;/a&gt; by &lt;a href="https://github.com/OneRedOak"&gt;Patrick Ellis&lt;/a&gt; - A tailored workflow for enabling automated UI/UX design review, including specialized sub agents, slash commands, &lt;code&gt;CLAUDE.md&lt;/code&gt; excerpts, and more. Covers a broad range of criteria from responsive design to accessibility.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tott/laravel-tall-claude-ai-configs"&gt;Laravel TALL Stack AI Development Starter Kit&lt;/a&gt; by &lt;a href="https://github.com/tott"&gt;tott&lt;/a&gt; - Transform your Laravel TALL (Tailwind, AlpineJS, Laravel, Livewire) stack development with comprehensive Claude Code configurations that provide intelligent assistance, systematic workflows, and domain expert consultation.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cheukyin175/learn-faster-kit"&gt;learn-faster-kit&lt;/a&gt; by &lt;a href="https://github.com/cheukyin175"&gt;Hugo Lau&lt;/a&gt; - A creative educational framework for Claude Code, inspired by the "FASTER" approach to self-teaching. Ships with a variety of agents, slash commands, and tools that enable Claude Code to help you progress at your own pace, employing well-established pedagogical techniques like active learning and spaced repetition.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kingler/n8n_agent/tree/main/.claude/commands"&gt;n8n_agent&lt;/a&gt; by &lt;a href="https://github.com/kingler"&gt;kingler&lt;/a&gt; - Amazing comprehensive set of comments for code analysis, QA, design, documentation, project structure, project management, optimization, and many more.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/steadycursor/steadystart/tree/main/.claude/commands"&gt;Project Bootstrapping and Task Management&lt;/a&gt; by &lt;a href="https://github.com/steadycursor"&gt;steadycursor&lt;/a&gt; - Provides a structured set of commands for bootstrapping and managing a new project, including meta-commands for creating and editing custom slash-commands.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/scopecraft/command/tree/main/.claude/commands"&gt;Project Management, Implementation, Planning, and Release&lt;/a&gt; by &lt;a href="https://github.com/scopecraft"&gt;scopecraft&lt;/a&gt; - Really comprehensive set of commands for all aspects of SDLC.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/harperreed/dotfiles/tree/master/.claude/commands"&gt;Project Workflow System&lt;/a&gt; by &lt;a href="https://github.com/harperreed"&gt;harperreed&lt;/a&gt; - A set of commands that provide a comprehensive workflow system for managing projects, including task management, code review, and deployment processes.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tony/claude-code-riper-5"&gt;RIPER Workflow&lt;/a&gt; by &lt;a href="https://tony.sh"&gt;Tony Narlock&lt;/a&gt; - Structured development workflow enforcing separation between Research, Innovate, Plan, Execute, and Review phases. Features consolidated subagents for context-efficiency, branch-aware memory bank, and strict mode enforcement for guided development.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://diwank.space/field-notes-from-shipping-real-code-with-claude"&gt;Shipping Real Code w/ Claude&lt;/a&gt; by &lt;a href="https://github.com/creatorrr"&gt;Diwank&lt;/a&gt; - A detailed blog post explaining the author's process for shipping a product with Claude Code, including CLAUDE.md files and other interesting resources.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Helmi/claude-simone"&gt;Simone&lt;/a&gt; by &lt;a href="https://github.com/Helmi"&gt;Helmi&lt;/a&gt; - A broader project management workflow for Claude Code that encompasses not just a set of commands, but a system of documents, guidelines, and processes to facilitate project planning and execution.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Ralph Wiggum&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/frankbria/ralph-claude-code"&gt;Ralph for Claude Code&lt;/a&gt; by &lt;a href="https://github.com/frankbria"&gt;Frank Bria&lt;/a&gt; - An autonomous AI development framework that enables Claude Code to work iteratively on projects until completion. Features intelligent exit detection, rate limiting, circuit breaker patterns, and comprehensive safety guardrails to prevent infinite loops and API overuse. Built with Bash, integrated with tmux for live monitoring, and includes 75+ comprehensive tests.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/muratcankoylan/ralph-wiggum-marketer"&gt;Ralph Wiggum Marketer&lt;/a&gt; by &lt;a href="https://github.com/muratcankoylan"&gt;Muratcan Koylan&lt;/a&gt; - A Claude Code plugin that provides an autonomous AI copywriter, integrating the Ralph loop with customized knowledge bases for market research agents. The agents do the research, Ralph writes the copy, you stay in bed. Whether or not you practice Ralph-Driven Development (RDD), I think these projects are interesting and creative explorations of general agentic patterns.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anthropics/claude-code/tree/4f18698a9ed25517861a75125b526e319bcf8354/plugins/ralph-wiggum"&gt;Ralph Wiggum Plugin&lt;/a&gt; by &lt;a href="https://github.com/anthropics"&gt;Anthropic PBC&lt;/a&gt; - The official Anthropic implementation of the Ralph Wiggum technique for iterative, self-referential AI development loops in Claude Code.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mikeyobrien/ralph-orchestrator"&gt;ralph-orchestrator&lt;/a&gt; by &lt;a href="https://github.com/mikeyobrien"&gt;mikeyobrien&lt;/a&gt; - Ralph Orchestrator implements the simple but effective "Ralph Wiggum" technique for autonomous task completion, continuously running an AI agent against a prompt file until the task is marked as complete or limits are reached. This implementation provides a robust, well-tested, and feature-complete orchestration system for AI-driven development. Also cited in the Anthropic Ralph plugin documentation.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ClaytonFarr/ralph-playbook"&gt;The Ralph Playbook&lt;/a&gt; by &lt;a href="https://github.com/ClaytonFarr"&gt;Clayton Farr&lt;/a&gt; - A remarkably detailed and comprehensive guide to the Ralph Wiggum technique, featuring well-written theoretical commentary paired with practical guidelines and advice.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;h2&gt;Tooling üß∞&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Tooling denotes applications that are built on top of Claude Code and consist of more components than slash-commands and &lt;code&gt;CLAUDE.md&lt;/code&gt; files&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;General&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/GWUDCAP/cc-sessions"&gt;cc-sessions&lt;/a&gt; by &lt;a href="https://github.com/satoastshi"&gt;toastdev&lt;/a&gt; - An opinionated approach to productive development with Claude Code.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Veraticus/cc-tools"&gt;cc-tools&lt;/a&gt; by &lt;a href="https://github.com/Veraticus"&gt;Josh Symonds&lt;/a&gt; - High-performance Go implementation of Claude Code hooks and utilities. Provides smart linting, testing, and statusline generation with minimal overhead.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nyatinte/ccexp"&gt;ccexp&lt;/a&gt; by &lt;a href="https://github.com/nyatinte"&gt;nyatinte&lt;/a&gt; - Interactive CLI tool for discovering and managing Claude Code configuration files and slash commands with a beautiful terminal UI.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/eckardt/cchistory"&gt;cchistory&lt;/a&gt; by &lt;a href="https://github.com/eckardt"&gt;eckardt&lt;/a&gt; - Like the shell history command but for your Claude Code sessions. Easily list all Bash or "Bash-mode" (&lt;code&gt;!&lt;/code&gt;) commands Claude Code ran in a session for reference.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Brads3290/cclogviewer"&gt;cclogviewer&lt;/a&gt; by &lt;a href="https://github.com/Brads3290"&gt;Brad S.&lt;/a&gt; - A humble but handy utility for viewing Claude Code &lt;code&gt;.jsonl&lt;/code&gt; conversation files in a pretty HTML UI.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/davila7/claude-code-templates"&gt;Claude Code Templates&lt;/a&gt; by &lt;a href="https://github.com/davila7"&gt;Daniel Avila&lt;/a&gt; - Incredibly awesome collection of resources from every category in this list, presented with a neatly polished UI, great features like usage dashboard, analytics, and everything from slash commands to hooks to agents. An awesome companion for this awesome list.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/possibilities/claude-composer"&gt;Claude Composer&lt;/a&gt; by &lt;a href="https://github.com/possibilities"&gt;Mike Bannister&lt;/a&gt; - A tool that adds small enhancements to Claude Code.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/claude-did-this/claude-hub"&gt;Claude Hub&lt;/a&gt; by &lt;a href="https://github.com/claude-did-this"&gt;Claude Did This&lt;/a&gt; - A webhook service that connects Claude Code to GitHub repositories, enabling AI-powered code assistance directly through pull requests and issues. This integration allows Claude to analyze repositories, answer technical questions, and help developers understand and improve their codebase through simple @mentions.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pchalasani/claude-code-tools"&gt;claude-code-tools&lt;/a&gt; by &lt;a href="https://github.com/pchalasani"&gt;Prasad Chalasani&lt;/a&gt; - Well-crafted toolset for session continuity, featuring skills/commands to avoid compaction and recover context across sessions with cross-agent handoff between Claude Code and Codex CLI. Includes a fast Rust/Tantivy-powered full-text session search (TUI for humans, skill/CLI for agents), tmux-cli skill + command for interacting with scripts and CLI agents, and safety hooks to block dangerous commands.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/serpro69/claude-starter-kit"&gt;claude-starter-kit&lt;/a&gt; by &lt;a href="https://github.com/serpro69"&gt;serpro69&lt;/a&gt; - This is a starter template repository designed to provide a complete development environment for Claude-Code with pre-configured MCP servers and tools for AI-powered development workflows. The repository is intentionally minimal, containing only configuration templates for three primary systems: Claude Code, Serena, and Task Master.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/carlrannaberg/claudekit"&gt;claudekit&lt;/a&gt; by &lt;a href="https://github.com/carlrannaberg"&gt;Carl Rannaberg&lt;/a&gt; - Impressive CLI toolkit providing auto-save checkpointing, code quality hooks, specification generation and execution, and 20+ specialized subagents including oracle (gpt-5), code-reviewer (6-aspect deep analysis), ai-sdk-expert (Vercel AI SDK), typescript-expert and many more for Claude Code workflows.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dagger/container-use"&gt;Container Use&lt;/a&gt; by &lt;a href="https://github.com/dagger"&gt;dagger&lt;/a&gt; - Development environments for coding agents. Enable multiple agents to work safely and independently with your preferred stack.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/FlineDev/ContextKit"&gt;ContextKit&lt;/a&gt; by &lt;a href="https://github.com/Jeehut"&gt;Cihat G√ºnd√ºz&lt;/a&gt; - A systematic development framework that transforms Claude Code into a proactive development partner. Features 4-phase planning methodology, specialized quality agents, and structured workflows that help AI produce production-ready code on first try.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zippoxer/recall"&gt;recall&lt;/a&gt; by &lt;a href="https://github.com/zippoxer"&gt;zippoxer&lt;/a&gt; - Full-text search your Claude Code sessions. Run &lt;code&gt;recall&lt;/code&gt; in terminal, type to search, Enter to resume. Alternative to &lt;code&gt;claude --resume&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dyoshikawa/rulesync"&gt;Rulesync&lt;/a&gt; by &lt;a href="https://github.com/dyoshikawa"&gt;dyoshikawa&lt;/a&gt; - A Node.js CLI tool that automatically generates configs (rules, ignore files, MCP servers, commands, and subagents) for various AI coding agents. Rulesync can convert configs between Claude Code and other AI agents in both directions.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/icanhasjonas/run-claude-docker"&gt;run-claude-docker&lt;/a&gt; by &lt;a href="https://github.com/icanhasjonas/"&gt;Jonas&lt;/a&gt; - A self-contained Docker runner that forwards your current workspace into a safe(r) isolated docker container, where you still have access to your Claude Code settings, authentication, ssh agent, pgp, optionally aws keys etc.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/marcindulak/stt-mcp-server-linux"&gt;stt-mcp-server-linux&lt;/a&gt; by &lt;a href="https://github.com/marcindulak"&gt;marcindulak&lt;/a&gt; - A push-to-talk speech transcription setup for Linux using a Python MCP server. Runs locally in Docker with no external API calls. Your speech is recorded, transcribed into text, and then sent to Claude running in a Tmux session.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/SuperClaude-Org/SuperClaude_Framework"&gt;SuperClaude&lt;/a&gt; by &lt;a href="https://github.com/SuperClaude-Org"&gt;SuperClaude-Org&lt;/a&gt; - A versatile configuration framework that enhances Claude Code with specialized commands, cognitive personas, and development methodologies, such as "Introspection" and "Orchestration".&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Piebald-AI/tweakcc"&gt;tweakcc&lt;/a&gt; by &lt;a href="https://github.com/Piebald-AI"&gt;Piebald-AI&lt;/a&gt; - Command-line tool to customize your Claude Code styling.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/vibe-log/vibe-log-cli"&gt;Vibe-Log&lt;/a&gt; by &lt;a href="https://github.com/vibe-log"&gt;Vibe-Log&lt;/a&gt; - Analyzes your Claude Code prompts locally (using CC), provides intelligent session analysis and actionable strategic guidance - works in the statusline and produces very pretty HTML reports as well. Easy to install and remove.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/OverseedAI/viwo"&gt;viwo-cli&lt;/a&gt; by &lt;a href="https://github.com/hal-shin"&gt;Hal Shin&lt;/a&gt; - Run Claude Code in a Docker container with git worktrees as volume mounts to enable safer usage of &lt;code&gt;--dangerously-skip-permissions&lt;/code&gt; for frictionless one-shotting prompts. Allows users to spin up multiple instances of Claude Code in the background easily with reduced permission fatigue.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mbailey/voicemode"&gt;VoiceMode MCP&lt;/a&gt; by &lt;a href="https://github.com/mbailey"&gt;Mike Bailey&lt;/a&gt; - VoiceMode MCP brings natural conversations to Claude Code. It supports any OpenAI API compatible voice services and installs free and open source voice services (Whisper.cpp and Kokoro-FastAPI).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;IDE Integrations&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://marketplace.visualstudio.com/items?itemName=AndrePimenta.claude-code-chat"&gt;Claude Code Chat&lt;/a&gt; by &lt;a href="https://github.com/andrepimenta"&gt;andrepimenta&lt;/a&gt; - An elegant and user-friendly Claude Code chat interface for VS Code.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/manzaltu/claude-code-ide.el"&gt;claude-code-ide.el&lt;/a&gt; by &lt;a href="https://github.com/manzaltu"&gt;manzaltu&lt;/a&gt; - claude-code-ide.el integrates Claude Code with Emacs, like Anthropic‚Äôs VS Code/IntelliJ extensions. It shows ediff-based code suggestions, pulls LSP/flymake/flycheck diagnostics, and tracks buffer context. It adds an extensible MCP tool support for symbol refs/defs, project metadata, and tree-sitter AST queries.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/stevemolitor/claude-code.el"&gt;claude-code.el&lt;/a&gt; by &lt;a href="https://github.com/stevemolitor"&gt;stevemolitor&lt;/a&gt; - An Emacs interface for Claude Code CLI.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/greggh/claude-code.nvim"&gt;claude-code.nvim&lt;/a&gt; by &lt;a href="https://github.com/greggh"&gt;greggh&lt;/a&gt; - A seamless integration between Claude Code AI assistant and Neovim.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Haleclipse/Claudix"&gt;Claudix - Claude Code for VSCode&lt;/a&gt; by &lt;a href="https://github.com/Haleclipse"&gt;Haleclipse&lt;/a&gt; - A VSCode extension that brings Claude Code directly into your editor with interactive chat interface, session management, intelligent file operations, terminal execution, and real-time streaming responses. Built with Vue 3, TypeScript.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/stravu/crystal"&gt;crystal&lt;/a&gt; by &lt;a href="https://github.com/stravu"&gt;stravu&lt;/a&gt; - A full-fledged desktop application for orchestrating, monitoring, and interacting with Claude Code agents.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Usage Monitors&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ryoppippi/ccusage"&gt;CC Usage&lt;/a&gt; by &lt;a href="https://github.com/ryoppippi"&gt;ryoppippi&lt;/a&gt; - Handy CLI tool for managing and analyzing Claude Code usage, based on analyzing local Claude Code logs. Presents a nice dashboard regarding cost information, token consumption, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/snipeship/ccflare"&gt;ccflare&lt;/a&gt; by &lt;a href="https://github.com/snipeship"&gt;snipeship&lt;/a&gt; - Claude Code usage dashboard with a web-UI that would put Tableau to shame. Thoroughly comprehensive metrics, frictionless setup, detailed logging, really really nice UI.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tombii/better-ccflare/"&gt;ccflare -&amp;gt; &lt;strong&gt;better-ccflare&lt;/strong&gt;&lt;/a&gt; by &lt;a href="https://github.com/tombii"&gt;tombii&lt;/a&gt; - A well-maintained and feature-enhanced fork of the glorious &lt;code&gt;ccflare&lt;/code&gt; usage dashboard by @snipeship (which at the time of writing has not had an update in a few months). &lt;code&gt;better-ccflare&lt;/code&gt; builds on this foundation with some performance enhancements, extended provider support, bug fixes, Docker deployment, and more.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Maciek-roboblog/Claude-Code-Usage-Monitor"&gt;Claude Code Usage Monitor&lt;/a&gt; by &lt;a href="https://github.com/Maciek-roboblog"&gt;Maciek-roboblog&lt;/a&gt; - A real-time terminal-based tool for monitoring Claude Code token usage. It shows live token consumption, burn rate, and predictions for token depletion. Features include visual progress bars, session-aware analytics, and support for multiple subscription plans.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kunwar-shah/claudex"&gt;Claudex&lt;/a&gt; by &lt;a href="https://github.com/kunwar-shah"&gt;Kunwar Shah&lt;/a&gt; - Claudex - A web-based browser for exploring your Claude Code conversation history across projects. Indexes your codebase for full-text search. Nice, easy-to-navigate UI. Simple dashboard interface for high-level analytics, and multiple export options as well. (And completely local w/ no telemetry!).&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sculptdotfun/viberank"&gt;viberank&lt;/a&gt; by &lt;a href="https://github.com/nikshepsvn"&gt;nikshepsvn&lt;/a&gt; - A community-driven leaderboard tool that enables developers to visualize, track, and compete based on their Claude Code usage statistics. It features robust data analytics, GitHub OAuth, data validation, and user-friendly CLI/web submission methods.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Orchestrators&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ruvnet/claude-code-flow"&gt;Claude Code Flow&lt;/a&gt; by &lt;a href="https://github.com/ruvnet"&gt;ruvnet&lt;/a&gt; - This mode serves as a code-first orchestration layer, enabling Claude to write, edit, test, and optimize code autonomously across recursive agent cycles.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/smtg-ai/claude-squad"&gt;Claude Squad&lt;/a&gt; by &lt;a href="https://github.com/smtg-ai"&gt;smtg-ai&lt;/a&gt; - Claude Squad is a terminal app that manages multiple Claude Code, Codex (and other local agents including Aider) in separate workspaces, allowing you to work on multiple tasks simultaneously.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/parruda/claude-swarm"&gt;Claude Swarm&lt;/a&gt; by &lt;a href="https://github.com/parruda"&gt;parruda&lt;/a&gt; - Launch Claude Code session that is connected to a swarm of Claude Code Agents.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/eyaltoledano/claude-task-master"&gt;Claude Task Master&lt;/a&gt; by &lt;a href="https://github.com/eyaltoledano"&gt;eyaltoledano&lt;/a&gt; - A task management system for AI-driven development with Claude, designed to work seamlessly with Cursor AI.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/grahama1970/claude-task-runner"&gt;Claude Task Runner&lt;/a&gt; by &lt;a href="https://github.com/grahama1970"&gt;grahama1970&lt;/a&gt; - A specialized tool to manage context isolation and focused task execution with Claude Code, solving the critical challenge of context length limitations and task focus when working with Claude on complex, multi-step projects.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/slopus/happy"&gt;Happy Coder&lt;/a&gt; by &lt;a href="https://peoplesgrocers.com/en/projects"&gt;GrocerPublishAgent&lt;/a&gt; - Spawn and control multiple Claude Codes in parallel from your phone or desktop. Happy Coder runs Claude Code on your hardware, sends push notifications when Claude needs more input or permission, and costs nothing.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rsmdt/the-startup"&gt;The Agentic Startup&lt;/a&gt; by &lt;a href="https://github.com/rsmdt"&gt;Rudolf Schmidt&lt;/a&gt; - Yet Another Claude Orchestrator - a collection of agents, commands, etc., for shipping production code - but I like this because it's comprehensive, well-written, and one of the few resources that actually uses Output Styles! +10 points!&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dtormoen/tsk"&gt;TSK - AI Agent Task Manager and Sandbox&lt;/a&gt; by &lt;a href="https://github.com/dtormoen"&gt;dtormoen&lt;/a&gt; - A Rust CLI tool that lets you delegate development tasks to AI agents running in sandboxed Docker environments. Multiple agents work in parallel, returning git branches for human review.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;h2&gt;Status Lines üìä&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Status lines - Configurations and customizations for Claude Code's status bar functionality&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;General&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Haleclipse/CCometixLine"&gt;CCometixLine - Claude Code Statusline&lt;/a&gt; by &lt;a href="https://github.com/Haleclipse"&gt;Haleclipse&lt;/a&gt; - A high-performance Claude Code statusline tool written in Rust with Git integration, usage tracking, interactive TUI configuration, and Claude Code enhancement utilities.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sirmalloc/ccstatusline"&gt;ccstatusline&lt;/a&gt; by &lt;a href="https://github.com/sirmalloc"&gt;sirmalloc&lt;/a&gt; - A highly customizable status line formatter for Claude Code CLI that displays model info, git branch, token usage, and other metrics in your terminal.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rz1989s/claude-code-statusline"&gt;claude-code-statusline&lt;/a&gt; by &lt;a href="https://github.com/rz1989s"&gt;rz1989s&lt;/a&gt; - Enhanced 4-line statusline for Claude Code with themes, cost tracking, and MCP server monitoring.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Owloops/claude-powerline"&gt;claude-powerline&lt;/a&gt; by &lt;a href="https://github.com/Owloops"&gt;Owloops&lt;/a&gt; - A vim-style powerline statusline for Claude Code with real-time usage tracking, git integration, custom themes, and more.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hagan/claudia-statusline"&gt;claudia-statusline&lt;/a&gt; by &lt;a href="https://github.com/hagan"&gt;Hagan Franks&lt;/a&gt; - High-performance Rust-based statusline for Claude Code with persistent stats tracking, progress bars, and optional cloud sync. Features SQLite-first persistence, git integration, context progress bars, burn rate calculation, XDG-compliant with theme support (dark/light, NO_COLOR).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;h2&gt;Hooks ü™ù&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Hooks are a powerful API for Claude Code that allows users to activate commands and run scripts at different points in Claude's agentic lifecycle.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;General&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Talieisin/britfix"&gt;Britfix&lt;/a&gt; by &lt;a href="https://github.com/Talieisin"&gt;Talieisin&lt;/a&gt; - Claude outputs American spellings by default, which can have an impact on: professional credibility, compliance, documentation, and more. Britfix converts to British English, with a Claude Code hook for automatic conversion as files are written. Context-aware: handles code files intelligently by only converting comments and docstrings, never identifiers or string literals.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dazuiba/CCNotify"&gt;CC Notify&lt;/a&gt; by &lt;a href="https://github.com/dazuiba"&gt;dazuiba&lt;/a&gt; - CCNotify provides desktop notifications for Claude Code, alerting you to input needs or task completion, with one-click jumps back to VS Code and task duration display.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/GowayLee/cchooks"&gt;cchooks&lt;/a&gt; by &lt;a href="https://github.com/GowayLee"&gt;GowayLee&lt;/a&gt; - A lightweight Python SDK with a clean API and good documentation; simplifies the process of writing hooks and integrating them into your codebase, providing a nice abstraction over the JSON configuration files.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aannoo/claude-hook-comms"&gt;Claude Code Hook Comms (HCOM)&lt;/a&gt; by &lt;a href="https://github.com/aannoo"&gt;aannoo&lt;/a&gt; - Lightweight CLI tool for real-time communication between Claude Code sub agents using hooks. Enables multi-agent collaboration with @-mention targeting, live dashboard monitoring, and zero-dependency implementation. [NOTE: At the time of posting, this resource is a little unstable - I'm sharing it anyway, because I think it's incredibly promising and creative. I hope by the time you read this, it is production-ready.].&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/beyondcode/claude-hooks-sdk"&gt;claude-code-hooks-sdk&lt;/a&gt; by &lt;a href="https://github.com/beyondcode"&gt;beyondcode&lt;/a&gt; - A Laravel-inspired PHP SDK for building Claude Code hook responses with a clean, fluent API. This SDK makes it easy to create structured JSON responses for Claude Code hooks using an expressive, chainable interface.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/johnlindquist/claude-hooks"&gt;claude-hooks&lt;/a&gt; by &lt;a href="https://github.com/johnlindquist"&gt;John Lindquist&lt;/a&gt; - A TypeScript-based system for configuring and customizing Claude Code hooks with a powerful and flexible interface.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ctoth/claudio"&gt;Claudio&lt;/a&gt; by &lt;a href="https://github.com/ctoth"&gt;Christopher Toth&lt;/a&gt; - A no-frills little library that adds delightful OS-native sounds to Claude Code via simple hooks. It really sparks joy.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nizos/tdd-guard"&gt;TDD Guard&lt;/a&gt; by &lt;a href="https://github.com/nizos"&gt;Nizar Selander&lt;/a&gt; - A hooks-driven system that monitors file operations in real-time and blocks changes that violate TDD principles.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bartolli/claude-code-typescript-hooks"&gt;TypeScript Quality Hooks&lt;/a&gt; by &lt;a href="https://github.com/bartolli"&gt;bartolli&lt;/a&gt; - Quality check hook for Node.js TypeScript projects with TypeScript compilation. ESLint auto-fixing, and Prettier formatting. Uses SHA256 config caching for &amp;lt; 5ms validation performance during real-time editing.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;h2&gt;Slash-Commands üî™&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;"Slash Commands are customized, carefully refined prompts that control Claude's behavior in order to perform a specific task"&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;General&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/omril321/automated-notebooklm/raw/main/.claude/commands/create-hook.md"&gt;/create-hook&lt;/a&gt; by &lt;a href="https://github.com/omril321"&gt;Omri Lavi&lt;/a&gt; - Slash command for hook creation - intelligently prompts you through the creation process with smart suggestions based on your project setup (TS, Prettier, ESLint...).&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/danielrosehill/Claude-Code-Linux-Desktop-Slash-Commands"&gt;/linux-desktop-slash-commands&lt;/a&gt; by &lt;a href="https://github.com/danielrosehill"&gt;Daniel Rosehill&lt;/a&gt; - A library of slash commands intended specifically to facilitate common and advanced operations on Linux desktop environments (although many would also be useful on Linux servers). Command groups include hardware benchmarking, filesystem organisation, and security posture validation.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Version Control &amp;amp; Git&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jerseycheese/Narraitor/raw/feature/issue-227-ai-suggestions/.claude/commands/analyze-issue.md"&gt;/analyze-issue&lt;/a&gt; by &lt;a href="https://github.com/jerseycheese"&gt;jerseycheese&lt;/a&gt; - Fetches GitHub issue details to create comprehensive implementation specifications, analyzing requirements and planning structured approach with clear implementation steps.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/evmts/tevm-monorepo/raw/main/.claude/commands/commit.md"&gt;/commit&lt;/a&gt; by &lt;a href="https://github.com/evmts"&gt;evmts&lt;/a&gt; - Creates git commits using conventional commit format with appropriate emojis, following project standards and creating descriptive messages that explain the purpose of changes.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/steadycursor/steadystart/raw/main/.claude/commands/2-commit-fast.md"&gt;/commit-fast&lt;/a&gt; by &lt;a href="https://github.com/steadycursor"&gt;steadycursor&lt;/a&gt; - Automates git commit process by selecting the first suggested message, generating structured commits with consistent formatting while skipping manual confirmation and removing Claude co-Contributorship footer.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/toyamarinyon/giselle/raw/main/.claude/commands/create-pr.md"&gt;/create-pr&lt;/a&gt; by &lt;a href="https://github.com/toyamarinyon"&gt;toyamarinyon&lt;/a&gt; - Streamlines pull request creation by handling the entire workflow: creating a new branch, committing changes, formatting modified files with Biome, and submitting the PR.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/liam-hq/liam/raw/main/.claude/commands/create-pull-request.md"&gt;/create-pull-request&lt;/a&gt; by &lt;a href="https://github.com/liam-hq"&gt;liam-hq&lt;/a&gt; - Provides comprehensive PR creation guidance with GitHub CLI, enforcing title conventions, following template structure, and offering concrete command examples with best practices.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/evmts/tevm-monorepo/raw/main/.claude/commands/create-worktrees.md"&gt;/create-worktrees&lt;/a&gt; by &lt;a href="https://github.com/evmts"&gt;evmts&lt;/a&gt; - Creates git worktrees for all open PRs or specific branches, handling branches with slashes, cleaning up stale worktrees, and supporting custom branch creation for development.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jeremymailen/kotlinter-gradle/raw/master/.claude/commands/fix-github-issue.md"&gt;/fix-github-issue&lt;/a&gt; by &lt;a href="https://github.com/jeremymailen"&gt;jeremymailen&lt;/a&gt; - Analyzes and fixes GitHub issues using a structured approach with GitHub CLI for issue details, implementing necessary code changes, running tests, and creating proper commit messages.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/metabase/metabase/raw/master/.claude/commands/fix-issue.md"&gt;/fix-issue&lt;/a&gt; by &lt;a href="https://github.com/metabase"&gt;metabase&lt;/a&gt; - Addresses GitHub issues by taking issue number as parameter, analyzing context, implementing solution, and testing/validating the fix for proper integration.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/metabase/metabase/raw/master/.claude/commands/fix-pr.md"&gt;/fix-pr&lt;/a&gt; by &lt;a href="https://github.com/metabase"&gt;metabase&lt;/a&gt; - Fetches and fixes unresolved PR comments by automatically retrieving feedback, addressing reviewer concerns, making targeted code improvements, and streamlining the review process.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/evmts/tevm-monorepo/raw/main/.claude/commands/husky.md"&gt;/husky&lt;/a&gt; by &lt;a href="https://github.com/evmts"&gt;evmts&lt;/a&gt; - Sets up and manages Husky Git hooks by configuring pre-commit hooks, establishing commit message standards, integrating with linting tools, and ensuring code quality on commits.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/giselles-ai/giselle/raw/main/.claude/commands/update-branch-name.md"&gt;/update-branch-name&lt;/a&gt; by &lt;a href="https://github.com/giselles-ai"&gt;giselles-ai&lt;/a&gt; - Updates branch names with proper prefixes and formats, enforcing naming conventions, supporting semantic prefixes, and managing remote branch updates.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Code Analysis &amp;amp; Testing&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rygwdn/slack-tools/raw/main/.claude/commands/check.md"&gt;/check&lt;/a&gt; by &lt;a href="https://github.com/rygwdn"&gt;rygwdn&lt;/a&gt; - Performs comprehensive code quality and security checks, featuring static analysis integration, security vulnerability scanning, code style enforcement, and detailed reporting.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kingler/n8n_agent/raw/main/.claude/commands/code_analysis.md"&gt;/code_analysis&lt;/a&gt; by &lt;a href="https://github.com/kingler"&gt;kingler&lt;/a&gt; - Provides a menu of advanced code analysis commands for deep inspection, including knowledge graph generation, optimization suggestions, and quality evaluation.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/to4iki/ai-project-rules/raw/main/.claude/commands/optimize.md"&gt;/optimize&lt;/a&gt; by &lt;a href="https://github.com/to4iki"&gt;to4iki&lt;/a&gt; - Analyzes code performance to identify bottlenecks, proposing concrete optimizations with implementation guidance for improved application performance.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rzykov/metabase/raw/master/.claude/commands/repro-issue.md"&gt;/repro-issue&lt;/a&gt; by &lt;a href="https://github.com/rzykov"&gt;rzykov&lt;/a&gt; - Creates reproducible test cases for GitHub issues, ensuring tests fail reliably and documenting clear reproduction steps for developers.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zscott/pane/raw/main/.claude/commands/tdd.md"&gt;/tdd&lt;/a&gt; by &lt;a href="https://github.com/zscott"&gt;zscott&lt;/a&gt; - Guides development using Test-Driven Development principles, enforcing Red-Green-Refactor discipline, integrating with git workflow, and managing PR creation.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jerseycheese/Narraitor/raw/feature/issue-227-ai-suggestions/.claude/commands/tdd-implement.md"&gt;/tdd-implement&lt;/a&gt; by &lt;a href="https://github.com/jerseycheese"&gt;jerseycheese&lt;/a&gt; - Implements Test-Driven Development by analyzing feature requirements, creating tests first (red), implementing minimal passing code (green), and refactoring while maintaining tests.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Context Loading &amp;amp; Priming&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/elizaOS/elizaos.github.io/raw/main/.claude/commands/context-prime.md"&gt;/context-prime&lt;/a&gt; by &lt;a href="https://github.com/elizaOS"&gt;elizaOS&lt;/a&gt; - Primes Claude with comprehensive project understanding by loading repository structure, setting development context, establishing project goals, and defining collaboration parameters.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/okuvshynov/cubestat/raw/main/.claude/commands/initref.md"&gt;/initref&lt;/a&gt; by &lt;a href="https://github.com/okuvshynov"&gt;okuvshynov&lt;/a&gt; - Initializes reference documentation structure with standard doc templates, API reference setup, documentation conventions, and placeholder content generation.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ethpandaops/xatu-data/raw/master/.claude/commands/load-llms-txt.md"&gt;/load-llms-txt&lt;/a&gt; by &lt;a href="https://github.com/ethpandaops"&gt;ethpandaops&lt;/a&gt; - Loads LLM configuration files to context, importing specific terminology, model configurations, and establishing baseline terminology for AI discussions.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Mjvolk3/torchcell/raw/main/.claude/commands/load_coo_context.md"&gt;/load_coo_context&lt;/a&gt; by &lt;a href="https://github.com/Mjvolk3"&gt;Mjvolk3&lt;/a&gt; - References specific files for sparse matrix operations, explains transform usage, compares with previous approaches, and sets data formatting context for development.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Mjvolk3/torchcell/raw/main/.claude/commands/load_dango_pipeline.md"&gt;/load_dango_pipeline&lt;/a&gt; by &lt;a href="https://github.com/Mjvolk3"&gt;Mjvolk3&lt;/a&gt; - Sets context for model training by referencing pipeline files, establishing working context, and preparing for pipeline work with relevant documentation.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/yzyydev/AI-Engineering-Structure/raw/main/.claude/commands/prime.md"&gt;/prime&lt;/a&gt; by &lt;a href="https://github.com/yzyydev"&gt;yzyydev&lt;/a&gt; - Sets up initial project context by viewing directory structure and reading key files, creating standardized context with directory visualization and key documentation focus.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ddisisto/si/raw/main/.claude/commands/rsi.md"&gt;/rsi&lt;/a&gt; by &lt;a href="https://github.com/ddisisto"&gt;ddisisto&lt;/a&gt; - Reads all commands and key project files to optimize AI-assisted development by streamlining the process, loading command context, and setting up for better development workflow.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Documentation &amp;amp; Changelogs&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/berrydev-ai/blockdoc-python/raw/main/.claude/commands/add-to-changelog.md"&gt;/add-to-changelog&lt;/a&gt; by &lt;a href="https://github.com/berrydev-ai"&gt;berrydev-ai&lt;/a&gt; - Adds new entries to changelog files while maintaining format consistency, properly documenting changes, and following established project standards for version tracking.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jerseycheese/Narraitor/raw/feature/issue-227-ai-suggestions/.claude/commands/create-docs.md"&gt;/create-docs&lt;/a&gt; by &lt;a href="https://github.com/jerseycheese"&gt;jerseycheese&lt;/a&gt; - Analyzes code structure and purpose to create comprehensive documentation detailing inputs/outputs, behavior, user interaction flows, and edge cases with error handling.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/slunsford/coffee-analytics/raw/main/.claude/commands/docs.md"&gt;/docs&lt;/a&gt; by &lt;a href="https://github.com/slunsford"&gt;slunsford&lt;/a&gt; - Generates comprehensive documentation that follows project structure, documenting APIs and usage patterns with consistent formatting for better user understanding.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hackdays-io/toban-contribution-viewer/raw/main/.claude/commands/explain-issue-fix.md"&gt;/explain-issue-fix&lt;/a&gt; by &lt;a href="https://github.com/hackdays-io"&gt;hackdays-io&lt;/a&gt; - Documents solution approaches for GitHub issues, explaining technical decisions, detailing challenges overcome, and providing implementation context for better understanding.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Consiliency/Flutter-Structurizr/raw/main/.claude/commands/update-docs.md"&gt;/update-docs&lt;/a&gt; by &lt;a href="https://github.com/Consiliency"&gt;Consiliency&lt;/a&gt; - Reviews current documentation status, updates implementation progress, reviews phase documents, and maintains documentation consistency across the project.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;CI / Deployment&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kelp/webdown/raw/main/.claude/commands/release.md"&gt;/release&lt;/a&gt; by &lt;a href="https://github.com/kelp"&gt;kelp&lt;/a&gt; - Manages software releases by updating changelogs, reviewing README changes, evaluating version increments, and documenting release changes for better version tracking.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hackdays-io/toban-contribution-viewer/raw/main/.claude/commands/run-ci.md"&gt;/run-ci&lt;/a&gt; by &lt;a href="https://github.com/hackdays-io"&gt;hackdays-io&lt;/a&gt; - Activates virtual environments, runs CI-compatible check scripts, iteratively fixes errors, and ensures all tests pass before completion.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Project &amp;amp; Task Management&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/scopecraft/command/raw/main/.claude/commands/create-command.md"&gt;/create-command&lt;/a&gt; by &lt;a href="https://github.com/scopecraft"&gt;scopecraft&lt;/a&gt; - Guides Claude through creating new custom commands with proper structure by analyzing requirements, templating commands by category, enforcing command standards, and creating supporting documentation.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/taddyorg/inkverse/raw/main/.claude/commands/create-jtbd.md"&gt;/create-jtbd&lt;/a&gt; by &lt;a href="https://github.com/taddyorg"&gt;taddyorg&lt;/a&gt; - Creates Jobs-to-be-Done frameworks that outline user needs with structured format, focusing on specific user problems and organizing by job categories for product development.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/taddyorg/inkverse/raw/main/.claude/commands/create-prd.md"&gt;/create-prd&lt;/a&gt; by &lt;a href="https://github.com/taddyorg"&gt;taddyorg&lt;/a&gt; - Generates comprehensive product requirement documents outlining detailed specifications, requirements, and features following standardized document structure and format.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Wirasm/claudecode-utils/raw/main/.claude/commands/create-prp.md"&gt;/create-prp&lt;/a&gt; by &lt;a href="https://github.com/Wirasm"&gt;Wirasm&lt;/a&gt; - Creates product requirement plans by reading PRP methodology, following template structure, creating comprehensive requirements, and structuring product definitions for development.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jerseycheese/Narraitor/raw/feature/issue-227-ai-suggestions/.claude/commands/do-issue.md"&gt;/do-issue&lt;/a&gt; by &lt;a href="https://github.com/jerseycheese"&gt;jerseycheese&lt;/a&gt; - Implements GitHub issues with manual review points, following a structured approach with issue number parameter and offering alternative automated mode for efficiency.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/disler/just-prompt/raw/main/.claude/commands/project_hello_w_name.md"&gt;/project_hello_w_name&lt;/a&gt; by &lt;a href="https://github.com/disler"&gt;disler&lt;/a&gt; - Creates customizable greeting components with name input, demonstrating argument passing, component reusability, state management, and user input handling.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/chrisleyva/todo-slash-command/raw/main/todo.md"&gt;/todo&lt;/a&gt; by &lt;a href="https://github.com/chrisleyva"&gt;chrisleyva&lt;/a&gt; - A convenient command to quickly manage project todo items without leaving the Claude Code interface, featuring due dates, sorting, task prioritization, and comprehensive todo list management.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Miscellaneous&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Mjvolk3/torchcell/raw/main/.claude/commands/fixing_go_in_graph.md"&gt;/fixing_go_in_graph&lt;/a&gt; by &lt;a href="https://github.com/Mjvolk3"&gt;Mjvolk3&lt;/a&gt; - Focuses on Gene Ontology annotation integration in graph databases, handling multiple data sources, addressing graph representation issues, and ensuring correct data incorporation.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/GaloyMoney/lana-bank/raw/main/.claude/commands/mermaid.md"&gt;/mermaid&lt;/a&gt; by &lt;a href="https://github.com/GaloyMoney"&gt;GaloyMoney&lt;/a&gt; - Generates Mermaid diagrams from SQL schema files, creating entity relationship diagrams with table properties, validating diagram compilation, and ensuring complete entity coverage.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Mjvolk3/torchcell/raw/main/.claude/commands/review_dcell_model.md"&gt;/review_dcell_model&lt;/a&gt; by &lt;a href="https://github.com/Mjvolk3"&gt;Mjvolk3&lt;/a&gt; - Reviews old Dcell implementation files, comparing with newer Dango model, noting changes over time, and analyzing refactoring approaches for better code organization.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zuplo/docs/raw/main/.claude/commands/use-stepper.md"&gt;/use-stepper&lt;/a&gt; by &lt;a href="https://github.com/zuplo"&gt;zuplo&lt;/a&gt; - Reformats documentation to use React Stepper component, transforming heading formats, applying proper indentation, and maintaining markdown compatibility with admonition formatting.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;h2&gt;CLAUDE.md Files üìÇ&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;code&gt;CLAUDE.md&lt;/code&gt; files are files that contain important guidelines and context-specific information or instructions that help Claude Code to better understand your project and your coding standards&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Language-Specific&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/didalgolab/ai-intellij-plugin/raw/main/CLAUDE.md"&gt;AI IntelliJ Plugin&lt;/a&gt; by &lt;a href="https://github.com/didalgolab"&gt;didalgolab&lt;/a&gt; - Provides comprehensive Gradle commands for IntelliJ plugin development with platform-specific coding patterns, detailed package structure guidelines, and clear internationalization standards.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/alexei-led/aws-mcp-server/raw/main/CLAUDE.md"&gt;AWS MCP Server&lt;/a&gt; by &lt;a href="https://github.com/alexei-led"&gt;alexei-led&lt;/a&gt; - Features multiple Python environment setup options with detailed code style guidelines, comprehensive error handling recommendations, and security considerations for AWS CLI interactions.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/touchlab/DroidconKotlin/raw/main/CLAUDE.md"&gt;DroidconKotlin&lt;/a&gt; by &lt;a href="https://github.com/touchlab"&gt;touchlab&lt;/a&gt; - Delivers comprehensive Gradle commands for cross-platform Kotlin Multiplatform development with clear module structure and practical guidance for dependency injection.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hesreallyhim/awesome-claude-code/raw/main/resources/claude.md-files/EDSL/CLAUDE.md"&gt;EDSL&lt;/a&gt; by &lt;a href="https://github.com/expectedparrot"&gt;expectedparrot&lt;/a&gt; - Offers detailed build and test commands with strict code style enforcement, comprehensive testing requirements, and standardized development workflow using Black and mypy. &lt;em&gt;(Removed from origin)&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/giselles-ai/giselle/raw/main/CLAUDE.md"&gt;Giselle&lt;/a&gt; by &lt;a href="https://github.com/giselles-ai"&gt;giselles-ai&lt;/a&gt; - Provides detailed build and test commands using pnpm and Vitest with strict code formatting requirements and comprehensive naming conventions for code consistency.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hashintel/hash/raw/main/CLAUDE.md"&gt;HASH&lt;/a&gt; by &lt;a href="https://github.com/hashintel"&gt;hashintel&lt;/a&gt; - Features comprehensive repository structure breakdown with strong emphasis on coding standards, detailed Rust documentation guidelines, and systematic PR review process.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/inkline/inkline/raw/main/CLAUDE.md"&gt;Inkline&lt;/a&gt; by &lt;a href="https://github.com/inkline"&gt;inkline&lt;/a&gt; - Structures development workflow using pnpm with emphasis on TypeScript and Vue 3 Composition API, detailed component creation process, and comprehensive testing recommendations.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mattgodbolt/jsbeeb/raw/main/CLAUDE.md"&gt;JSBeeb&lt;/a&gt; by &lt;a href="https://github.com/mattgodbolt"&gt;mattgodbolt&lt;/a&gt; - Provides development guide for JavaScript BBC Micro emulator with build and testing instructions, architecture documentation, and debugging workflows.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/LamoomAI/lamoom-python/raw/main/CLAUDE.md"&gt;Lamoom Python&lt;/a&gt; by &lt;a href="https://github.com/LamoomAI"&gt;LamoomAI&lt;/a&gt; - Serves as reference for production prompt engineering library with load balancing of AI Models, API documentation, and usage patterns with examples.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/langchain-ai/langgraphjs/raw/main/CLAUDE.md"&gt;LangGraphJS&lt;/a&gt; by &lt;a href="https://github.com/langchain-ai"&gt;langchain-ai&lt;/a&gt; - Offers comprehensive build and test commands with detailed TypeScript style guidelines, layered library architecture, and monorepo structure using yarn workspaces.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/metabase/metabase/raw/master/CLAUDE.md"&gt;Metabase&lt;/a&gt; by &lt;a href="https://github.com/metabase"&gt;metabase&lt;/a&gt; - Details workflow for REPL-driven development in Clojure/ClojureScript with emphasis on incremental development, testing, and step-by-step approach for feature implementation.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sgcarstrends/backend/raw/main/CLAUDE.md"&gt;SG Cars Trends Backend&lt;/a&gt; by &lt;a href="https://github.com/sgcarstrends"&gt;sgcarstrends&lt;/a&gt; - Provides comprehensive structure for TypeScript monorepo projects with detailed commands for development, testing, deployment, and AWS/Cloudflare integration.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/spylang/spy/raw/main/CLAUDE.md"&gt;SPy&lt;/a&gt; by &lt;a href="https://github.com/spylang"&gt;spylang&lt;/a&gt; - Enforces strict coding conventions with comprehensive testing guidelines, multiple code compilation options, and backend-specific test decorators for targeted filtering.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/KarpelesLab/tpl/raw/master/CLAUDE.md"&gt;TPL&lt;/a&gt; by &lt;a href="https://github.com/KarpelesLab"&gt;KarpelesLab&lt;/a&gt; - Details Go project conventions with comprehensive error handling recommendations, table-driven testing approach guidelines, and modernization suggestions for latest Go features.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Domain-Specific&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Layr-Labs/avs-vibe-developer-guide/raw/master/CLAUDE.md"&gt;AVS Vibe Developer Guide&lt;/a&gt; by &lt;a href="https://github.com/Layr-Labs"&gt;Layr-Labs&lt;/a&gt; - Structures AI-assisted EigenLayer AVS development workflow with consistent naming conventions for prompt files and established terminology standards for blockchain concepts.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/CommE2E/comm/raw/master/CLAUDE.md"&gt;Comm&lt;/a&gt; by &lt;a href="https://github.com/CommE2E"&gt;CommE2E&lt;/a&gt; - Serves as a development reference for E2E-encrypted messaging applications with code organization architecture, security implementation details, and testing procedures.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/badass-courses/course-builder/raw/main/CLAUDE.md"&gt;Course Builder&lt;/a&gt; by &lt;a href="https://github.com/badass-courses"&gt;badass-courses&lt;/a&gt; - Enables real-time multiplayer capabilities for collaborative course creation with diverse tech stack integration and monorepo architecture using Turborepo.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/eastlondoner/cursor-tools/raw/main/CLAUDE.md"&gt;Cursor Tools&lt;/a&gt; by &lt;a href="https://github.com/eastlondoner"&gt;eastlondoner&lt;/a&gt; - Creates a versatile AI command interface supporting multiple providers and models with flexible command options and browser automation through "Stagehand" feature.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/soramimi/Guitar/raw/master/CLAUDE.md"&gt;Guitar&lt;/a&gt; by &lt;a href="https://github.com/soramimi"&gt;soramimi&lt;/a&gt; - Serves as development guide for Guitar Git GUI Client with build commands for various platforms, code style guidelines for contributing, and project structure explanation.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Fimeg/NetworkChronicles/raw/legacy-v1/CLAUDE.md"&gt;Network Chronicles&lt;/a&gt; by &lt;a href="https://github.com/Fimeg"&gt;Fimeg&lt;/a&gt; - Presents detailed implementation plan for AI-driven game characters with technical specifications for LLM integration, character guidelines, and service discovery mechanics.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ParetoSecurity/pareto-mac/raw/main/CLAUDE.md"&gt;Pareto Mac&lt;/a&gt; by &lt;a href="https://github.com/ParetoSecurity"&gt;ParetoSecurity&lt;/a&gt; - Serves as development guide for Mac security audit tool with build instructions, contribution guidelines, testing procedures, and workflow documentation.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/steadycursor/steadystart/raw/main/CLAUDE.md"&gt;SteadyStart&lt;/a&gt; by &lt;a href="https://github.com/steadycursor"&gt;steadycursor&lt;/a&gt; - Clear and direct instructives about style, permissions, Claude's "role", communications, and documentation of Claude Code sessions for other team members to stay abreast.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Project Scaffolding &amp;amp; MCP&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/basicmachines-co/basic-memory/raw/main/CLAUDE.md"&gt;Basic Memory&lt;/a&gt; by &lt;a href="https://github.com/basicmachines-co"&gt;basicmachines-co&lt;/a&gt; - Presents an innovative AI-human collaboration framework with Model Context Protocol for bidirectional LLM-markdown communication and flexible knowledge structure for complex projects.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/grahama1970/claude-code-mcp-enhanced/raw/main/CLAUDE.md"&gt;claude-code-mcp-enhanced&lt;/a&gt; by &lt;a href="https://github.com/grahama1970"&gt;grahama1970&lt;/a&gt; - Provides detailed and emphatic instructions for Claude to follow as a coding agent, with testing guidance, code examples, and compliance checks.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;h2&gt;Alternative Clients üì±&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Alternative Clients are alternative UIs and front-ends for interacting with Claude Code, either on mobile or on the desktop.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;General&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/opactorai/Claudable"&gt;Claudable&lt;/a&gt; by &lt;a href="https://www.linkedin.com/in/seongil-park/"&gt;Ethan Park&lt;/a&gt; - Claudable is an open-source web builder that leverages local CLI agents, such as Claude Code and Cursor Agent, to build and deploy products effortlessly.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/omnara-ai/omnara"&gt;Omnara&lt;/a&gt; by &lt;a href="https://github.com/ishaansehgal99"&gt;Ishaan Sehgal&lt;/a&gt; - A command center for AI agents that syncs Claude Code sessions across terminal, web, and mobile. Allows for remote monitoring, human-in-the-loop interaction, and team collaboration.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;h2&gt;Official Documentation üèõÔ∏è&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Links to some of Anthropic's terrific documentation and resources regarding Claude Code&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;General&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.claude.com/en/home"&gt;Anthropic Documentation&lt;/a&gt; by &lt;a href="https://github.com/anthropics"&gt;Anthropic&lt;/a&gt; - The official documentation for Claude Code, including installation instructions, usage guidelines, API references, tutorials, examples, loads of information that I won't list individually. Like Claude Code, the documentation is frequently updated.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anthropics/claude-quickstarts"&gt;Anthropic Quickstarts&lt;/a&gt; by &lt;a href="https://github.com/anthropics"&gt;Anthropic&lt;/a&gt; - Offers comprehensive development guides for three distinct AI-powered demo projects with standardized workflows, strict code style guidelines, and containerization instructions.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anthropics/claude-code-action/tree/main/examples"&gt;Claude Code GitHub Actions&lt;/a&gt; by &lt;a href="https://github.com/anthropics"&gt;Anthropic&lt;/a&gt; - Official GitHub Actions integration for Claude Code with examples and documentation for automating AI-powered workflows in CI/CD pipelines.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing &lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#awesome-claude-code"&gt;üîù&lt;/a&gt;&lt;/h2&gt; 
&lt;h3&gt;&lt;strong&gt;&lt;a href="https://github.com/hesreallyhim/awesome-claude-code/issues/new?template=recommend-resource.yml"&gt;Recommend a new resource here!&lt;/a&gt;&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Recommending a resource for the list is very simple, and the automated system handles everything for you. Please do not open a PR to submit a recommendation - the only person who is allowed to submit PRs to this repo is Claude.&lt;/p&gt; 
&lt;p&gt;Make sure that you have read the CONTRIBUTING.md document and CODE_OF_CONDUCT.md before you submit a recommendation.&lt;/p&gt; 
&lt;p&gt;For suggestions about the repository itself, please &lt;a href="https://github.com/hesreallyhim/awesome-claude-code/issues/new?template=repository-enhancement.yml"&gt;open a repository enhancement issue&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;This project is released with a Code of Conduct. By participating, you agree to abide by its terms. And although I take strong measures to uphold the quality and safety of this list, I take no responsibility or liability for anything that might happen as a result of these third-party resources.&lt;/p&gt; 
&lt;h2&gt;Growing thanks to you&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://starchart.cc/hesreallyhim/awesome-claude-code"&gt;&lt;img src="https://starchart.cc/hesreallyhim/awesome-claude-code.svg?variant=adaptive" alt="Stargazers over time" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This list is licensed under &lt;a href="https://creativecommons.org/licenses/by-nc-nd/4.0/"&gt;Creative Commons CC BY-NC-ND 4.0&lt;/a&gt; - this means you are welcome to fork, clone, copy and redistribute the list, provided you include appropriate attribution; however you are not permitted to distribute any modified versions or to use it for any commercial purposes. This is to prevent disregard for the licenses of the authors whose resources are listed here. Please note that all resources included in this list have their own license terms.&lt;/p&gt; 
&lt;!-- OBLIGATORY GUARD AGAINST SILLY END-OF-FILE PROBLEM --&gt;</description>
    </item>
    
    <item>
      <title>NevaMind-AI/memU</title>
      <link>https://github.com/NevaMind-AI/memU</link>
      <description>&lt;p&gt;Memory infrastructure for LLMs and AI agents&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/NevaMind-AI/memU/main/assets/banner.png" alt="MemU Banner" /&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;h1&gt;MemU&lt;/h1&gt; 
 &lt;h3&gt;A Future-Oriented Agentic Memory System&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://badge.fury.io/py/memu-py"&gt;&lt;img src="https://badge.fury.io/py/memu-py.svg?sanitize=true" alt="PyPI version" /&gt;&lt;/a&gt; &lt;a href="https://opensource.org/licenses/Apache-2.0"&gt;&lt;img src="https://img.shields.io/badge/License-Apache%202.0-blue.svg?sanitize=true" alt="License: Apache 2.0" /&gt;&lt;/a&gt; &lt;a href="https://www.python.org/downloads/"&gt;&lt;img src="https://img.shields.io/badge/python-3.13+-blue.svg?sanitize=true" alt="Python 3.13+" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/memu"&gt;&lt;img src="https://img.shields.io/badge/Discord-Join%20Chat-5865F2?logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://x.com/memU_ai"&gt;&lt;img src="https://img.shields.io/badge/Twitter-Follow-1DA1F2?logo=x&amp;amp;logoColor=white" alt="Twitter" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/17374" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/17374" alt="NevaMind-AI%2FmemU | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;p&gt;MemU is an agentic memory framework for LLM and AI agent backends. It receives &lt;strong&gt;multimodal inputs&lt;/strong&gt; (conversations, documents, images), extracts them into structured memory, and organizes them into a &lt;strong&gt;hierarchical file system&lt;/strong&gt; that supports both &lt;strong&gt;embedding-based (RAG)&lt;/strong&gt; and &lt;strong&gt;non-embedding (LLM)&lt;/strong&gt; retrieval.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;‚≠êÔ∏è Star the repository&lt;/h2&gt; 
&lt;img width="100%" src="https://github.com/NevaMind-AI/memU/raw/main/assets/star.gif" /&gt; If you find memU useful or interesting, a GitHub Star ‚≠êÔ∏è would be greatly appreciated. 
&lt;hr /&gt; 
&lt;p&gt;MemU is collaborating with four open-source projects to launch the 2026 New Year Challenge. üéâBetween January 8‚Äì18, contributors can submit PRs to memU and earn cash rewards, community recognition, and platform credits. üéÅ&lt;a href="https://discord.gg/KaWy6SBAsx"&gt;Learn more &amp;amp; get involved&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;‚ú® Core Features&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Feature&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;üóÇÔ∏è &lt;strong&gt;Hierarchical File System&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Three-layer architecture: Resource ‚Üí Item ‚Üí Category with full traceability&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;üîç &lt;strong&gt;Dual Retrieval Methods&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;RAG (embedding-based) for speed, LLM (non-embedding) for deep semantic understanding&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;üé® &lt;strong&gt;Multimodal Support&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Process conversations, documents, images, audio, and video&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;üîÑ &lt;strong&gt;Self-Evolving Memory&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Memory structure adapts and improves based on usage patterns&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üóÇÔ∏è Hierarchical File System&lt;/h2&gt; 
&lt;p&gt;MemU organizes memory using a &lt;strong&gt;three-layer architecture&lt;/strong&gt; inspired by hierarchical storage systems:&lt;/p&gt; 
&lt;img width="100%" alt="structure" src="https://raw.githubusercontent.com/NevaMind-AI/memU/main/assets/structure.png" /&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Layer&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Examples&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Resource&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Raw multimodal data warehouse&lt;/td&gt; 
   &lt;td&gt;JSON conversations, text documents, images, videos&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Item&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Discrete extracted memory units&lt;/td&gt; 
   &lt;td&gt;Individual preferences, skills, opinions, habits&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Category&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Aggregated textual memory with summaries&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;preferences.md&lt;/code&gt;, &lt;code&gt;work_life.md&lt;/code&gt;, &lt;code&gt;relationships.md&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Key Benefits:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Full Traceability&lt;/strong&gt;: Track from raw data ‚Üí items ‚Üí categories and back&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Progressive Summarization&lt;/strong&gt;: Each layer provides increasingly abstracted views&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexible Organization&lt;/strong&gt;: Categories evolve based on content patterns&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üé® Multimodal Support&lt;/h2&gt; 
&lt;p&gt;MemU processes diverse content types into unified memory:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Modality&lt;/th&gt; 
   &lt;th&gt;Input&lt;/th&gt; 
   &lt;th&gt;Processing&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;conversation&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;JSON chat logs&lt;/td&gt; 
   &lt;td&gt;Extract preferences, opinions, habits, relationships&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;document&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Text files (.txt, .md)&lt;/td&gt; 
   &lt;td&gt;Extract knowledge, skills, facts&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;image&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;PNG, JPG, etc.&lt;/td&gt; 
   &lt;td&gt;Vision model extracts visual concepts and descriptions&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;video&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Video files&lt;/td&gt; 
   &lt;td&gt;Frame extraction + vision analysis&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;audio&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Audio files&lt;/td&gt; 
   &lt;td&gt;Transcription + text processing&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;All modalities are unified into the same three-layer hierarchy, enabling cross-modal retrieval.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üöÄ Quick Start&lt;/h2&gt; 
&lt;h3&gt;Option 1: Cloud Version&lt;/h3&gt; 
&lt;p&gt;Try MemU instantly without any setup:&lt;/p&gt; 
&lt;p&gt;üëâ &lt;strong&gt;&lt;a href="https://memu.so"&gt;memu.so&lt;/a&gt;&lt;/strong&gt; - Hosted cloud service with full API access&lt;/p&gt; 
&lt;p&gt;For enterprise deployment and custom solutions, contact &lt;strong&gt;&lt;a href="mailto:info@nevamind.ai"&gt;info@nevamind.ai&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h4&gt;Cloud API (v3)&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Base URL&lt;/th&gt; 
   &lt;th&gt;&lt;code&gt;https://api.memu.so&lt;/code&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Auth&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;Authorization: Bearer YOUR_API_KEY&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Method&lt;/th&gt; 
   &lt;th&gt;Endpoint&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;POST&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;/api/v3/memory/memorize&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Register a memorization task&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;GET&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;/api/v3/memory/memorize/status/{task_id}&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Get task status&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;POST&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;/api/v3/memory/categories&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;List memory categories&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;POST&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;/api/v3/memory/retrieve&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Retrieve memories (semantic search)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;üìö &lt;strong&gt;&lt;a href="https://memu.pro/docs#cloud-version"&gt;Full API Documentation&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Option 2: Self-Hosted&lt;/h3&gt; 
&lt;h4&gt;Installation&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -e .
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Basic Example&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Requirements&lt;/strong&gt;: Python 3.13+ and an OpenAI API key&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Test with In-Memory Storage&lt;/strong&gt; (no database required):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export OPENAI_API_KEY=your_api_key
cd tests
python test_inmemory.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Test with PostgreSQL Storage&lt;/strong&gt; (requires pgvector):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Start PostgreSQL with pgvector
docker run -d \
  --name memu-postgres \
  -e POSTGRES_USER=postgres \
  -e POSTGRES_PASSWORD=postgres \
  -e POSTGRES_DB=memu \
  -p 5432:5432 \
  pgvector/pgvector:pg16

# Run the test
export OPENAI_API_KEY=your_api_key
cd tests
python test_postgres.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Both examples demonstrate the complete workflow:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Memorize&lt;/strong&gt;: Process a conversation file and extract structured memory&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Retrieve (RAG)&lt;/strong&gt;: Fast embedding-based search&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Retrieve (LLM)&lt;/strong&gt;: Deep semantic understanding search&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/NevaMind-AI/memU/main/tests/test_inmemory.py"&gt;&lt;code&gt;tests/test_inmemory.py&lt;/code&gt;&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/NevaMind-AI/memU/main/tests/test_postgres.py"&gt;&lt;code&gt;tests/test_postgres.py&lt;/code&gt;&lt;/a&gt; for the full source code.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Custom LLM and Embedding Providers&lt;/h3&gt; 
&lt;p&gt;MemU supports custom LLM and embedding providers beyond OpenAI. Configure them via &lt;code&gt;llm_profiles&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from memu import MemUService

service = MemUService(
    llm_profiles={
        # Default profile for LLM operations
        "default": {
            "base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1",
            "api_key": "your_api_key",
            "chat_model": "qwen3-max",
            "client_backend": "sdk"  # "sdk" or "http"
        },
        # Separate profile for embeddings
        "embedding": {
            "base_url": "https://api.voyageai.com/v1",
            "api_key": "your_voyage_api_key",
            "embed_model": "voyage-3.5-lite"
        }
    },
    # ... other configuration
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìñ Core APIs&lt;/h2&gt; 
&lt;h3&gt;&lt;code&gt;memorize()&lt;/code&gt; - Extract and Store Memory&lt;/h3&gt; 
&lt;p&gt;Processes input resources and extracts structured memory:&lt;/p&gt; 
&lt;img width="100%" alt="memorize" src="https://raw.githubusercontent.com/NevaMind-AI/memU/main/assets/memorize.png" /&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;result = await service.memorize(
    resource_url="path/to/file.json",  # File path or URL
    modality="conversation",            # conversation | document | image | video | audio
    user={"user_id": "123"}             # Optional: scope to a user
)

# Returns:
{
    "resource": {...},      # Stored resource metadata
    "items": [...],         # Extracted memory items
    "categories": [...]     # Updated category summaries
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;code&gt;retrieve()&lt;/code&gt; - Query Memory&lt;/h3&gt; 
&lt;p&gt;Retrieves relevant memory based on queries. MemU supports &lt;strong&gt;two retrieval strategies&lt;/strong&gt;:&lt;/p&gt; 
&lt;img width="100%" alt="retrieve" src="https://raw.githubusercontent.com/NevaMind-AI/memU/main/assets/retrieve.png" /&gt; 
&lt;h4&gt;RAG-based Retrieval (&lt;code&gt;method="rag"&lt;/code&gt;)&lt;/h4&gt; 
&lt;p&gt;Fast &lt;strong&gt;embedding vector search&lt;/strong&gt; using cosine similarity:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Fast&lt;/strong&gt;: Pure vector computation&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Scalable&lt;/strong&gt;: Efficient for large memory stores&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Returns scores&lt;/strong&gt;: Each result includes similarity score&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;LLM-based Retrieval (&lt;code&gt;method="llm"&lt;/code&gt;)&lt;/h4&gt; 
&lt;p&gt;Deep &lt;strong&gt;semantic understanding&lt;/strong&gt; through direct LLM reasoning:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Deep understanding&lt;/strong&gt;: LLM comprehends context and nuance&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Query rewriting&lt;/strong&gt;: Automatically refines query at each tier&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Adaptive&lt;/strong&gt;: Stops early when sufficient information is found&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Comparison&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Aspect&lt;/th&gt; 
   &lt;th&gt;RAG&lt;/th&gt; 
   &lt;th&gt;LLM&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Speed&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‚ö° Fast&lt;/td&gt; 
   &lt;td&gt;üê¢ Slower&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Cost&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;üí∞ Low&lt;/td&gt; 
   &lt;td&gt;üí∞üí∞ Higher&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Semantic depth&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Medium&lt;/td&gt; 
   &lt;td&gt;Deep&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Tier 2 scope&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;All items&lt;/td&gt; 
   &lt;td&gt;Only items in relevant categories&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Output&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;With similarity scores&lt;/td&gt; 
   &lt;td&gt;Ranked by LLM reasoning&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Both methods support:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Context-aware rewriting&lt;/strong&gt;: Resolves pronouns using conversation history&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Progressive search&lt;/strong&gt;: Categories ‚Üí Items ‚Üí Resources&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Sufficiency checking&lt;/strong&gt;: Stops when enough information is retrieved&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Usage&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;result = await service.retrieve(
    queries=[
        {"role": "user", "content": {"text": "What are their preferences?"}},
        {"role": "user", "content": {"text": "Tell me about work habits"}}
    ],
    where={"user_id": "123"}  # Optional: scope filter
)

# Returns:
{
    "categories": [...],     # Relevant categories (with scores for RAG)
    "items": [...],          # Relevant memory items
    "resources": [...],      # Related raw resources
    "next_step_query": "..." # Rewritten query for follow-up (if applicable)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Scope Filtering&lt;/strong&gt;: Use &lt;code&gt;where&lt;/code&gt; to filter by user model fields:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;where={"user_id": "123"}&lt;/code&gt; - exact match&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;where={"agent_id__in": ["1", "2"]}&lt;/code&gt; - match any in list&lt;/li&gt; 
 &lt;li&gt;Omit &lt;code&gt;where&lt;/code&gt; to retrieve across all scopes&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;üìö &lt;strong&gt;For complete API documentation&lt;/strong&gt;, see &lt;a href="https://raw.githubusercontent.com/NevaMind-AI/memU/main/docs/SERVICE_API.md"&gt;SERVICE_API.md&lt;/a&gt; - includes all methods, CRUD operations, pipeline configuration, and configuration types.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üí° Use Cases&lt;/h2&gt; 
&lt;h3&gt;Example 1: Conversation Memory&lt;/h3&gt; 
&lt;p&gt;Extract and organize memory from multi-turn conversations:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export OPENAI_API_KEY=your_api_key
python examples/example_1_conversation_memory.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;What it does:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Processes multiple conversation JSON files&lt;/li&gt; 
 &lt;li&gt;Extracts memory items (preferences, habits, opinions, relationships)&lt;/li&gt; 
 &lt;li&gt;Generates category markdown files (&lt;code&gt;preferences.md&lt;/code&gt;, &lt;code&gt;work_life.md&lt;/code&gt;, etc.)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Best for:&lt;/strong&gt; Personal AI assistants, customer support bots, social chatbots&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Example 2: Skill Extraction from Logs&lt;/h3&gt; 
&lt;p&gt;Extract skills and lessons learned from agent execution logs:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export OPENAI_API_KEY=your_api_key
python examples/example_2_skill_extraction.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;What it does:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Processes agent logs sequentially&lt;/li&gt; 
 &lt;li&gt;Extracts actions, outcomes, and lessons learned&lt;/li&gt; 
 &lt;li&gt;Demonstrates &lt;strong&gt;incremental learning&lt;/strong&gt; - memory evolves with each file&lt;/li&gt; 
 &lt;li&gt;Generates evolving skill guides (&lt;code&gt;log_1.md&lt;/code&gt; ‚Üí &lt;code&gt;log_2.md&lt;/code&gt; ‚Üí &lt;code&gt;skill.md&lt;/code&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Best for:&lt;/strong&gt; DevOps teams, agent self-improvement, knowledge management&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Example 3: Multimodal Memory&lt;/h3&gt; 
&lt;p&gt;Process diverse content types into unified memory:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export OPENAI_API_KEY=your_api_key
python examples/example_3_multimodal_memory.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;What it does:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Processes documents and images together&lt;/li&gt; 
 &lt;li&gt;Extracts memory from different content types&lt;/li&gt; 
 &lt;li&gt;Unifies into cross-modal categories (&lt;code&gt;technical_documentation&lt;/code&gt;, &lt;code&gt;visual_diagrams&lt;/code&gt;, etc.)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Best for:&lt;/strong&gt; Documentation systems, learning platforms, research tools&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìä Performance&lt;/h2&gt; 
&lt;p&gt;MemU achieves &lt;strong&gt;92.09% average accuracy&lt;/strong&gt; on the Locomo benchmark across all reasoning tasks.&lt;/p&gt; 
&lt;img width="100%" alt="benchmark" src="https://github.com/user-attachments/assets/6fec4884-94e5-4058-ad5c-baac3d7e76d9" /&gt; 
&lt;p&gt;View detailed experimental data: &lt;a href="https://github.com/NevaMind-AI/memU-experiment"&gt;memU-experiment&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üß© Ecosystem&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Repository&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Use Case&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;a href="https://github.com/NevaMind-AI/memU"&gt;memU&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Core algorithm engine&lt;/td&gt; 
   &lt;td&gt;Embed AI memory into your product&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;a href="https://github.com/NevaMind-AI/memU-server"&gt;memU-server&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Backend service with CRUD, user system, RBAC&lt;/td&gt; 
   &lt;td&gt;Self-host a memory backend&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;a href="https://github.com/NevaMind-AI/memU-ui"&gt;memU-ui&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Visual dashboard&lt;/td&gt; 
   &lt;td&gt;Ready-to-use memory console&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Quick Links:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üöÄ &lt;a href="https://app.memu.so/quick-start"&gt;Try MemU Cloud&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üìö &lt;a href="https://memu.pro/docs"&gt;API Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üí¨ &lt;a href="https://discord.gg/memu"&gt;Discord Community&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ü§ù Partners&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/TEN-framework/ten-framework"&gt;&lt;img src="https://avatars.githubusercontent.com/u/113095513?s=200&amp;amp;v=4" alt="Ten" height="40" style="margin: 10px;" /&gt;&lt;/a&gt; &lt;a href="https://openagents.org"&gt;&lt;img src="https://raw.githubusercontent.com/NevaMind-AI/memU/main/assets/partners/openagents.png" alt="OpenAgents" height="40" style="margin: 10px;" /&gt;&lt;/a&gt; &lt;a href="https://github.com/milvus-io/milvus"&gt;&lt;img src="https://miro.medium.com/v2/resize:fit:2400/1*-VEGyAgcIBD62XtZWavy8w.png" alt="Milvus" height="40" style="margin: 10px;" /&gt;&lt;/a&gt; &lt;a href="https://xroute.ai/"&gt;&lt;img src="https://raw.githubusercontent.com/NevaMind-AI/memU/main/assets/partners/xroute.png" alt="xRoute" height="40" style="margin: 10px;" /&gt;&lt;/a&gt; &lt;a href="https://jaaz.app/"&gt;&lt;img src="https://raw.githubusercontent.com/NevaMind-AI/memU/main/assets/partners/jazz.png" alt="Jazz" height="40" style="margin: 10px;" /&gt;&lt;/a&gt; &lt;a href="https://github.com/Buddie-AI/Buddie"&gt;&lt;img src="https://raw.githubusercontent.com/NevaMind-AI/memU/main/assets/partners/buddie.png" alt="Buddie" height="40" style="margin: 10px;" /&gt;&lt;/a&gt; &lt;a href="https://github.com/bytebase/bytebase"&gt;&lt;img src="https://raw.githubusercontent.com/NevaMind-AI/memU/main/assets/partners/bytebase.png" alt="Bytebase" height="40" style="margin: 10px;" /&gt;&lt;/a&gt; &lt;a href="https://github.com/LazyAGI/LazyLLM"&gt;&lt;img src="https://raw.githubusercontent.com/NevaMind-AI/memU/main/assets/partners/LazyLLM.png" alt="LazyLLM" height="40" style="margin: 10px;" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ü§ù How to Contribute&lt;/h2&gt; 
&lt;p&gt;We welcome contributions from the community! Whether you're fixing bugs, adding features, or improving documentation, your help is appreciated.&lt;/p&gt; 
&lt;h3&gt;Getting Started&lt;/h3&gt; 
&lt;p&gt;To start contributing to MemU, you'll need to set up your development environment:&lt;/p&gt; 
&lt;h4&gt;Prerequisites&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Python 3.13+&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/astral-sh/uv"&gt;uv&lt;/a&gt; (Python package manager)&lt;/li&gt; 
 &lt;li&gt;Git&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Setup Development Environment&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# 1. Fork and clone the repository
git clone https://github.com/YOUR_USERNAME/memU.git
cd memU

# 2. Install development dependencies
make install
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;code&gt;make install&lt;/code&gt; command will:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Create a virtual environment using &lt;code&gt;uv&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Install all project dependencies&lt;/li&gt; 
 &lt;li&gt;Set up pre-commit hooks for code quality checks&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Running Quality Checks&lt;/h4&gt; 
&lt;p&gt;Before submitting your contribution, ensure your code passes all quality checks:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make check
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;code&gt;make check&lt;/code&gt; command runs:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Lock file verification&lt;/strong&gt;: Ensures &lt;code&gt;pyproject.toml&lt;/code&gt; consistency&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Pre-commit hooks&lt;/strong&gt;: Lints code with Ruff, formats with Black&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Type checking&lt;/strong&gt;: Runs &lt;code&gt;mypy&lt;/code&gt; for static type analysis&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dependency analysis&lt;/strong&gt;: Uses &lt;code&gt;deptry&lt;/code&gt; to find obsolete dependencies&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Contributing Guidelines&lt;/h3&gt; 
&lt;p&gt;For detailed contribution guidelines, code standards, and development practices, please see &lt;a href="https://raw.githubusercontent.com/NevaMind-AI/memU/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Quick tips:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Create a new branch for each feature or bug fix&lt;/li&gt; 
 &lt;li&gt;Write clear commit messages&lt;/li&gt; 
 &lt;li&gt;Add tests for new functionality&lt;/li&gt; 
 &lt;li&gt;Update documentation as needed&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;make check&lt;/code&gt; before pushing&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/NevaMind-AI/memU/main/LICENSE.txt"&gt;Apache License 2.0&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üåç Community&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub Issues&lt;/strong&gt;: &lt;a href="https://github.com/NevaMind-AI/memU/issues"&gt;Report bugs &amp;amp; request features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Discord&lt;/strong&gt;: &lt;a href="https://discord.com/invite/hQZntfGsbJ"&gt;Join the community&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;X (Twitter)&lt;/strong&gt;: &lt;a href="https://x.com/memU_ai"&gt;Follow @memU_ai&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Contact&lt;/strong&gt;: &lt;a href="mailto:info@nevamind.ai"&gt;info@nevamind.ai&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;‚≠ê &lt;strong&gt;Star us on GitHub&lt;/strong&gt; to get notified about new releases!&lt;/p&gt; 
&lt;/div&gt;</description>
    </item>
    
  </channel>
</rss>