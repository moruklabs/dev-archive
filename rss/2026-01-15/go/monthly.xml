<rss version="2.0">
  <channel>
    <title>GitHub Go Monthly Trending</title>
    <description>Monthly Trending of Go in GitHub</description>
    <pubDate>Wed, 14 Jan 2026 01:54:21 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>steveyegge/beads</title>
      <link>https://github.com/steveyegge/beads</link>
      <description>&lt;p&gt;Beads - A memory upgrade for your coding agent&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;bd - Beads&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;Distributed, git-backed graph issue tracker for AI agents.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/steveyegge/beads/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/steveyegge/beads" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/steveyegge/beads"&gt;&lt;img src="https://goreportcard.com/badge/github.com/steveyegge/beads" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://github.com/steveyegge/beads/releases"&gt;&lt;img src="https://img.shields.io/github/v/release/steveyegge/beads" alt="Release" /&gt;&lt;/a&gt; &lt;a href="https://www.npmjs.com/package/@beads/bd"&gt;&lt;img src="https://img.shields.io/npm/v/@beads/bd" alt="npm version" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/beads-mcp/"&gt;&lt;img src="https://img.shields.io/pypi/v/beads-mcp" alt="PyPI" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Beads provides a persistent, structured memory for coding agents. It replaces messy markdown plans with a dependency-aware graph, allowing agents to handle long-horizon tasks without losing context.&lt;/p&gt; 
&lt;h2&gt;‚ö° Quick Start&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install (macOS/Linux/FreeBSD)
curl -fsSL https://raw.githubusercontent.com/steveyegge/beads/main/scripts/install.sh | bash

# Initialize (Humans run this once)
bd init

# Tell your agent
echo "Use 'bd' for task tracking" &amp;gt;&amp;gt; AGENTS.md

&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üõ† Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Git as Database:&lt;/strong&gt; Issues stored as JSONL in &lt;code&gt;.beads/&lt;/code&gt;. Versioned, branched, and merged like code.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Agent-Optimized:&lt;/strong&gt; JSON output, dependency tracking, and auto-ready task detection.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Zero Conflict:&lt;/strong&gt; Hash-based IDs (&lt;code&gt;bd-a1b2&lt;/code&gt;) prevent merge collisions in multi-agent/multi-branch workflows.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Invisible Infrastructure:&lt;/strong&gt; SQLite local cache for speed; background daemon for auto-sync.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Compaction:&lt;/strong&gt; Semantic "memory decay" summarizes old closed tasks to save context window.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìñ Essential Commands&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Command&lt;/th&gt; 
   &lt;th&gt;Action&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;bd ready&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;List tasks with no open blockers.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;bd create "Title" -p 0&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Create a P0 task.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;bd dep add &amp;lt;child&amp;gt; &amp;lt;parent&amp;gt;&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Link tasks (blocks, related, parent-child).&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;bd show &amp;lt;id&amp;gt;&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;View task details and audit trail.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üîó Hierarchy &amp;amp; Workflow&lt;/h2&gt; 
&lt;p&gt;Beads supports hierarchical IDs for epics:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;bd-a3f8&lt;/code&gt; (Epic)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;bd-a3f8.1&lt;/code&gt; (Task)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;bd-a3f8.1.1&lt;/code&gt; (Sub-task)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Stealth Mode:&lt;/strong&gt; Run &lt;code&gt;bd init --stealth&lt;/code&gt; to use Beads locally without committing files to the main repo. Perfect for personal use on shared projects.&lt;/p&gt; 
&lt;h2&gt;üì¶ Installation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;npm:&lt;/strong&gt; &lt;code&gt;npm install -g @beads/bd&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Homebrew:&lt;/strong&gt; &lt;code&gt;brew install steveyegge/beads/bd&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Go:&lt;/strong&gt; &lt;code&gt;go install github.com/steveyegge/beads/cmd/bd@latest&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Requirements:&lt;/strong&gt; Linux, FreeBSD, macOS, or Windows.&lt;/p&gt; 
&lt;h2&gt;üåê Community Tools&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/steveyegge/beads/main/docs/COMMUNITY_TOOLS.md"&gt;docs/COMMUNITY_TOOLS.md&lt;/a&gt; for a curated list of community-built UIs, extensions, and integrations‚Äîincluding terminal interfaces, web UIs, editor extensions, and native apps.&lt;/p&gt; 
&lt;h2&gt;üìù Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/steveyegge/beads/main/docs/INSTALLING.md"&gt;Installing&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/steveyegge/beads/main/AGENT_INSTRUCTIONS.md"&gt;Agent Workflow&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/steveyegge/beads/main/docs/PROTECTED_BRANCHES.md"&gt;Sync Branch Mode&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/steveyegge/beads/main/docs/TROUBLESHOOTING.md"&gt;Troubleshooting&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/steveyegge/beads/main/docs/FAQ.md"&gt;FAQ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://deepwiki.com/steveyegge/beads"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>v2fly/domain-list-community</title>
      <link>https://github.com/v2fly/domain-list-community</link>
      <description>&lt;p&gt;Community managed domain list. Generate geosite.dat for V2Ray.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Domain list community&lt;/h1&gt; 
&lt;p&gt;This project manages a list of domains, to be used as geosites for routing purpose in Project V.&lt;/p&gt; 
&lt;h2&gt;Purpose of this project&lt;/h2&gt; 
&lt;p&gt;This project is not opinionated. In other words, it does NOT endorse, claim or imply that a domain should be blocked or proxied. It can be used to generate routing rules on demand.&lt;/p&gt; 
&lt;h2&gt;Download links&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;dlc.dat&lt;/strong&gt;Ôºö&lt;a href="https://github.com/v2fly/domain-list-community/releases/latest/download/dlc.dat"&gt;https://github.com/v2fly/domain-list-community/releases/latest/download/dlc.dat&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;dlc.dat.sha256sum&lt;/strong&gt;Ôºö&lt;a href="https://github.com/v2fly/domain-list-community/releases/latest/download/dlc.dat.sha256sum"&gt;https://github.com/v2fly/domain-list-community/releases/latest/download/dlc.dat.sha256sum&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Usage example&lt;/h2&gt; 
&lt;p&gt;Each file in the &lt;code&gt;data&lt;/code&gt; directory can be used as a rule in this format: &lt;code&gt;geosite:filename&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;"routing": {
  "domainStrategy": "IPIfNonMatch",
  "rules": [
    {
      "type": "field",
      "outboundTag": "Reject",
      "domain": [
        "geosite:category-ads-all",
        "geosite:category-porn"
      ]
    },
    {
      "type": "field",
      "outboundTag": "Direct",
      "domain": [
        "domain:icloud.com",
        "domain:icloud-content.com",
        "domain:cdn-apple.com",
        "geosite:cn",
        "geosite:private"
      ]
    },
    {
      "type": "field",
      "outboundTag": "Proxy-1",
      "domain": [
        "geosite:category-anticensorship",
        "geosite:category-media",
        "geosite:category-vpnservices"
      ]
    },
    {
      "type": "field",
      "outboundTag": "Proxy-2",
      "domain": [
        "geosite:category-dev"
      ]
    },
    {
      "type": "field",
      "outboundTag": "Proxy-3",
      "domain": [
        "geosite:geolocation-!cn"
      ]
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Generate &lt;code&gt;dlc.dat&lt;/code&gt; manually&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install &lt;code&gt;golang&lt;/code&gt; and &lt;code&gt;git&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Clone project code: &lt;code&gt;git clone https://github.com/v2fly/domain-list-community.git&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Navigate to project root directory: &lt;code&gt;cd domain-list-community&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Install project dependencies: &lt;code&gt;go mod download&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Generate &lt;code&gt;dlc.dat&lt;/code&gt; (without &lt;code&gt;datapath&lt;/code&gt; option means to use domain lists in &lt;code&gt;data&lt;/code&gt; directory of current working directory): 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;go run ./&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;go run ./ --datapath=/path/to/your/custom/data/directory&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Run &lt;code&gt;go run ./ --help&lt;/code&gt; for more usage information.&lt;/p&gt; 
&lt;h2&gt;Structure of data&lt;/h2&gt; 
&lt;p&gt;All data are under &lt;code&gt;data&lt;/code&gt; directory. Each file in the directory represents a sub-list of domains, named by the file name. File content is in the following format.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# comments
include:another-file
domain:google.com @attr1 @attr2
keyword:google
regexp:www\.google\.com$
full:www.google.com
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Syntax:&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;The following types of rules are &lt;strong&gt;NOT&lt;/strong&gt; fully compatible with the ones that defined by user in V2Ray config file. Do &lt;strong&gt;Not&lt;/strong&gt; copy and paste directly.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;Comment begins with &lt;code&gt;#&lt;/code&gt;. It may begin anywhere in the file. The content in the line after &lt;code&gt;#&lt;/code&gt; is treated as comment and ignored in production.&lt;/li&gt; 
 &lt;li&gt;Inclusion begins with &lt;code&gt;include:&lt;/code&gt;, followed by the file name of an existing file in the same directory.&lt;/li&gt; 
 &lt;li&gt;Subdomain begins with &lt;code&gt;domain:&lt;/code&gt;, followed by a valid domain name. The prefix &lt;code&gt;domain:&lt;/code&gt; may be omitted.&lt;/li&gt; 
 &lt;li&gt;Keyword begins with &lt;code&gt;keyword:&lt;/code&gt;, followed by a string.&lt;/li&gt; 
 &lt;li&gt;Regular expression begins with &lt;code&gt;regexp:&lt;/code&gt;, followed by a valid regular expression (per Golang's standard).&lt;/li&gt; 
 &lt;li&gt;Full domain begins with &lt;code&gt;full:&lt;/code&gt;, followed by a complete and valid domain name.&lt;/li&gt; 
 &lt;li&gt;Domains (including &lt;code&gt;domain&lt;/code&gt;, &lt;code&gt;keyword&lt;/code&gt;, &lt;code&gt;regexp&lt;/code&gt; and &lt;code&gt;full&lt;/code&gt;) may have one or more attributes. Each attribute begins with &lt;code&gt;@&lt;/code&gt; and followed by the name of the attribute.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Adding new &lt;code&gt;regexp&lt;/code&gt; and &lt;code&gt;keyword&lt;/code&gt; rules is discouraged because it is easy to use them incorrectly, and proxy software cannot efficiently match these types of rules.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;How it works&lt;/h2&gt; 
&lt;p&gt;The entire &lt;code&gt;data&lt;/code&gt; directory will be built into an external &lt;code&gt;geosite&lt;/code&gt; file for Project V. Each file in the directory represents a section in the generated file.&lt;/p&gt; 
&lt;p&gt;To generate a section:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Remove all the comments in the file.&lt;/li&gt; 
 &lt;li&gt;Replace &lt;code&gt;include:&lt;/code&gt; lines with the actual content of the file.&lt;/li&gt; 
 &lt;li&gt;Omit all empty lines.&lt;/li&gt; 
 &lt;li&gt;Generate each &lt;code&gt;domain:&lt;/code&gt; line into a &lt;a href="https://github.com/v2fly/v2ray-core/raw/master/app/router/routercommon/common.proto#L21"&gt;sub-domain routing rule&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Generate each &lt;code&gt;full:&lt;/code&gt; line into a &lt;a href="https://github.com/v2fly/v2ray-core/raw/master/app/router/routercommon/common.proto#L23"&gt;full domain routing rule&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Generate each &lt;code&gt;keyword:&lt;/code&gt; line into a &lt;a href="https://github.com/v2fly/v2ray-core/raw/master/app/router/routercommon/common.proto#L17"&gt;plain domain routing rule&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Generate each &lt;code&gt;regexp:&lt;/code&gt; line into a &lt;a href="https://github.com/v2fly/v2ray-core/raw/master/app/router/routercommon/common.proto#L19"&gt;regex domain routing rule&lt;/a&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;How to organize domains&lt;/h2&gt; 
&lt;h3&gt;File name&lt;/h3&gt; 
&lt;p&gt;Theoretically any string can be used as the name, as long as it is a valid file name. In practice, we prefer names for determinic group of domains, such as the owner (usually a company name) of the domains, e.g., "google", "netflix". Names with unclear scope are generally unrecommended, such as "evil", or "local".&lt;/p&gt; 
&lt;h3&gt;Attributes&lt;/h3&gt; 
&lt;p&gt;Attribute is useful for sub-group of domains, especially for filtering purpose. For example, the list of &lt;code&gt;google&lt;/code&gt; domains may contains its main domains, as well as domains that serve ads. The ads domains may be marked by attribute &lt;code&gt;@ads&lt;/code&gt;, and can be used as &lt;code&gt;geosite:google@ads&lt;/code&gt; in V2Ray routing.&lt;/p&gt; 
&lt;h2&gt;Contribution guideline&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fork this repo, make modifications to your own repo, file a PR.&lt;/li&gt; 
 &lt;li&gt;Please begin with small size PRs, say modification in a single file.&lt;/li&gt; 
 &lt;li&gt;A PR must be reviewed and approved by another member.&lt;/li&gt; 
 &lt;li&gt;A script will verify your pull request to test whether your PR is correct or not every time you update the PR. Only the PR which passes the test will be merged. Please go to the Action label to get detailed information if you didn't pass it. We also provide the file which has been generated to make you test.&lt;/li&gt; 
 &lt;li&gt;After a few successful PRs, you may apply for manager access to this repository.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>danielmiessler/Fabric</title>
      <link>https://github.com/danielmiessler/Fabric</link>
      <description>&lt;p&gt;Fabric is an open-source framework for augmenting humans using AI. It provides a modular system for solving specific problems using a crowdsourced set of AI prompts that can be used anywhere.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a href="https://go.warp.dev/fabric" target="_blank"&gt; &lt;sup&gt;Special thanks to:&lt;/sup&gt; &lt;br /&gt; &lt;img alt="Warp sponsorship" width="400" src="https://raw.githubusercontent.com/warpdotdev/brand-assets/refs/heads/main/Github/Sponsor/Warp-Github-LG-02.png" /&gt; &lt;br /&gt; 
  &lt;h&gt;
   Warp, built for coding with multiple AI agents 
   &lt;br /&gt; 
   &lt;sup&gt;Available for macOS, Linux and Windows&lt;/sup&gt; 
  &lt;/h&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/danielmiessler/Fabric/main/docs/images/fabric-logo-gif.gif" alt="fabriclogo" width="400" height="400" /&gt; 
 &lt;h1&gt;&lt;code&gt;fabric&lt;/code&gt;&lt;/h1&gt; 
 &lt;p&gt;&lt;img src="https://img.shields.io/badge/mission-human_flourishing_via_AI_augmentation-purple" alt="Static Badge" /&gt; &lt;br /&gt; &lt;img src="https://img.shields.io/github/languages/top/danielmiessler/fabric" alt="GitHub top language" /&gt; &lt;img src="https://img.shields.io/github/last-commit/danielmiessler/fabric" alt="GitHub last commit" /&gt; &lt;a href="https://opensource.org/licenses/MIT"&gt;&lt;img src="https://img.shields.io/badge/License-MIT-green.svg?sanitize=true" alt="License: MIT" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/danielmiessler/fabric"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;h4&gt;&lt;code&gt;fabric&lt;/code&gt; is an open-source framework for augmenting humans using AI.&lt;/h4&gt; 
 &lt;/div&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/danielmiessler/Fabric/main/docs/images/fabric-summarize.png" alt="Screenshot of fabric" /&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#updates"&gt;Updates&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#what-and-why"&gt;What and Why&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#philosophy"&gt;Philosophy&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#installation"&gt;Installation&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#usage"&gt;Usage&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#rest-api-server"&gt;REST API&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#examples"&gt;Examples&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#just-use-the-patterns"&gt;Just Use the Patterns&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#custom-patterns"&gt;Custom Patterns&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#helper-apps"&gt;Helper Apps&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#meta"&gt;Meta&lt;/a&gt;&lt;/p&gt;  
&lt;h2&gt;What and why&lt;/h2&gt; 
&lt;p&gt;Since the start of modern AI in late 2022 we've seen an &lt;strong&gt;&lt;em&gt;extraordinary&lt;/em&gt;&lt;/strong&gt; number of AI applications for accomplishing tasks. There are thousands of websites, chat-bots, mobile apps, and other interfaces for using all the different AI out there.&lt;/p&gt; 
&lt;p&gt;It's all really exciting and powerful, but &lt;em&gt;it's not easy to integrate this functionality into our lives.&lt;/em&gt;&lt;/p&gt; 
&lt;div class="align center"&gt; 
 &lt;h4&gt;In other words, AI doesn't have a capabilities problem‚Äîit has an &lt;em&gt;integration&lt;/em&gt; problem.&lt;/h4&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;strong&gt;Fabric was created to address this by creating and organizing the fundamental units of AI‚Äîthe prompts themselves!&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Fabric organizes prompts by real-world task, allowing people to create, collect, and organize their most important AI solutions in a single place for use in their favorite tools. And if you're command-line focused, you can use Fabric itself as the interface!&lt;/p&gt; 
&lt;h2&gt;Updates&lt;/h2&gt; 
&lt;p&gt;For a deep dive into Fabric and its internals, read the documentation in the &lt;a href="https://github.com/danielmiessler/Fabric/tree/main/docs"&gt;docs folder&lt;/a&gt;. There is also the extremely useful and regularly updated &lt;a href="https://deepwiki.com/danielmiessler/Fabric"&gt;DeepWiki&lt;/a&gt; for Fabric.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Click to view recent updates&lt;/summary&gt; 
 &lt;p&gt;Dear Users,&lt;/p&gt; 
 &lt;p&gt;We've been doing so many exciting things here at Fabric, I wanted to give a quick summary here to give you a sense of our development velocity!&lt;/p&gt; 
 &lt;p&gt;Below are the &lt;strong&gt;new features and capabilities&lt;/strong&gt; we've added (newest first):&lt;/p&gt; 
 &lt;h3&gt;Recent Major Features&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.356"&gt;v1.4.356&lt;/a&gt; (Dec 22, 2025) ‚Äî &lt;strong&gt;Complete Internationalization&lt;/strong&gt;: Full i18n support for setup prompts across all 10 languages with intelligent environment variable handling‚Äîmaking Fabric truly accessible worldwide while maintaining configuration consistency.&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.350"&gt;v1.4.350&lt;/a&gt; (Dec 18, 2025) ‚Äî &lt;strong&gt;Interactive API Documentation&lt;/strong&gt;: Adds Swagger/OpenAPI UI at &lt;code&gt;/swagger/index.html&lt;/code&gt; with comprehensive REST API documentation, enhanced developer guides, and improved endpoint discoverability for easier integration.&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.338"&gt;v1.4.338&lt;/a&gt; (Dec 4, 2025) ‚Äî Add Abacus vendor support for Chat-LLM models (see &lt;a href="https://abacus.ai/app/route-llm-apis"&gt;RouteLLM APIs&lt;/a&gt;).&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.337"&gt;v1.4.337&lt;/a&gt; (Dec 4, 2025) ‚Äî Add "Z AI" vendor support. See the &lt;a href="https://docs.z.ai/guides/overview/overview"&gt;Z AI overview&lt;/a&gt; page for more details.&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.334"&gt;v1.4.334&lt;/a&gt; (Nov 26, 2025) ‚Äî &lt;strong&gt;Claude Opus 4.5&lt;/strong&gt;: Updates the Anthropic SDK to the latest and adds the new &lt;a href="https://www.anthropic.com/news/claude-opus-4-5"&gt;Claude Opus 4.5&lt;/a&gt; to the available models.&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.331"&gt;v1.4.331&lt;/a&gt; (Nov 23, 2025) ‚Äî &lt;strong&gt;Support for GitHub Models&lt;/strong&gt;: Adds support for using GitHub Models.&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.322"&gt;v1.4.322&lt;/a&gt; (Nov 5, 2025) ‚Äî &lt;strong&gt;Interactive HTML Concept Maps and Claude Sonnet 4.5&lt;/strong&gt;: Adds &lt;code&gt;create_conceptmap&lt;/code&gt; pattern for visual knowledge representation using Vis.js, introduces WELLNESS category with psychological analysis patterns, and upgrades to Claude Sonnet 4.5&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.317"&gt;v1.4.317&lt;/a&gt; (Sep 21, 2025) ‚Äî &lt;strong&gt;Portuguese Language Variants&lt;/strong&gt;: Adds BCP 47 locale normalization with support for Brazilian Portuguese (pt-BR) and European Portuguese (pt-PT) with intelligent fallback chains&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.314"&gt;v1.4.314&lt;/a&gt; (Sep 17, 2025) ‚Äî &lt;strong&gt;Azure OpenAI Migration&lt;/strong&gt;: Migrates to official &lt;code&gt;openai-go/azure&lt;/code&gt; SDK with improved authentication and default API version support&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.311"&gt;v1.4.311&lt;/a&gt; (Sep 13, 2025) ‚Äî &lt;strong&gt;More internationalization support&lt;/strong&gt;: Adds de (German), fa (Persian / Farsi), fr (French), it (Italian), ja (Japanese), pt (Portuguese), zh (Chinese)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.309"&gt;v1.4.309&lt;/a&gt; (Sep 9, 2025) ‚Äî &lt;strong&gt;Comprehensive internationalization support&lt;/strong&gt;: Includes English and Spanish locale files.&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.303"&gt;v1.4.303&lt;/a&gt; (Aug 29, 2025) ‚Äî &lt;strong&gt;New Binary Releases&lt;/strong&gt;: Linux ARM and Windows ARM targets. You can run Fabric on the Raspberry PI and on your Windows Surface!&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.294"&gt;v1.4.294&lt;/a&gt; (Aug 20, 2025) ‚Äî &lt;strong&gt;Venice AI Support&lt;/strong&gt;: Added the Venice AI provider. Venice is a Privacy-First, Open-Source AI provider. See their &lt;a href="https://docs.venice.ai/overview/about-venice"&gt;"About Venice"&lt;/a&gt; page for details.&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.291"&gt;v1.4.291&lt;/a&gt; (Aug 18, 2025) ‚Äî &lt;strong&gt;Speech To Text&lt;/strong&gt;: Add OpenAI speech-to-text support with &lt;code&gt;--transcribe-file&lt;/code&gt;, &lt;code&gt;--transcribe-model&lt;/code&gt;, and &lt;code&gt;--split-media-file&lt;/code&gt; flags.&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.287"&gt;v1.4.287&lt;/a&gt; (Aug 16, 2025) ‚Äî &lt;strong&gt;AI Reasoning&lt;/strong&gt;: Add Thinking to Gemini models and introduce &lt;code&gt;readme_updates&lt;/code&gt; python script&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.286"&gt;v1.4.286&lt;/a&gt; (Aug 14, 2025) ‚Äî &lt;strong&gt;AI Reasoning&lt;/strong&gt;: Introduce Thinking Config Across Anthropic and OpenAI Providers&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.285"&gt;v1.4.285&lt;/a&gt; (Aug 13, 2025) ‚Äî &lt;strong&gt;Extended Context&lt;/strong&gt;: Enable One Million Token Context Beta Feature for Sonnet-4&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.284"&gt;v1.4.284&lt;/a&gt; (Aug 12, 2025) ‚Äî &lt;strong&gt;Easy Shell Completions Setup&lt;/strong&gt;: Introduce One-Liner Curl Install for Completions&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.283"&gt;v1.4.283&lt;/a&gt; (Aug 12, 2025) ‚Äî &lt;strong&gt;Model Management&lt;/strong&gt;: Add Vendor Selection Support for Models&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.282"&gt;v1.4.282&lt;/a&gt; (Aug 11, 2025) ‚Äî &lt;strong&gt;Enhanced Shell Completions&lt;/strong&gt;: Enhanced Shell Completions for Fabric CLI Binaries&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.281"&gt;v1.4.281&lt;/a&gt; (Aug 11, 2025) ‚Äî &lt;strong&gt;Gemini Search Tool&lt;/strong&gt;: Add Web Search Tool Support for Gemini Models&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.278"&gt;v1.4.278&lt;/a&gt; (Aug 9, 2025) ‚Äî &lt;strong&gt;Enhance YouTube Transcripts&lt;/strong&gt;: Enhance YouTube Support with Custom yt-dlp Arguments&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.277"&gt;v1.4.277&lt;/a&gt; (Aug 8, 2025) ‚Äî &lt;strong&gt;Desktop Notifications&lt;/strong&gt;: Add cross-platform desktop notifications to Fabric CLI&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.274"&gt;v1.4.274&lt;/a&gt; (Aug 7, 2025) ‚Äî &lt;strong&gt;Claude 4.1 Added&lt;/strong&gt;: Add Support for Claude Opus 4.1 Model&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.271"&gt;v1.4.271&lt;/a&gt; (Jul 28, 2025) ‚Äî &lt;strong&gt;AI Summarized Release Notes&lt;/strong&gt;: Enable AI summary updates for GitHub releases&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.268"&gt;v1.4.268&lt;/a&gt; (Jul 26, 2025) ‚Äî &lt;strong&gt;Gemini TTS Voice Selection&lt;/strong&gt;: add Gemini TTS voice selection and listing functionality&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.267"&gt;v1.4.267&lt;/a&gt; (Jul 26, 2025) ‚Äî &lt;strong&gt;Text-to-Speech&lt;/strong&gt;: Update Gemini Plugin to New SDK with TTS Support&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.258"&gt;v1.4.258&lt;/a&gt; (Jul 17, 2025) ‚Äî &lt;strong&gt;Onboarding Improved&lt;/strong&gt;: Add startup check to initialize config and .env file automatically&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.257"&gt;v1.4.257&lt;/a&gt; (Jul 17, 2025) ‚Äî &lt;strong&gt;OpenAI Routing Control&lt;/strong&gt;: Introduce CLI Flag to Disable OpenAI Responses API&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.252"&gt;v1.4.252&lt;/a&gt; (Jul 16, 2025) ‚Äî &lt;strong&gt;Hide Thinking Block&lt;/strong&gt;: Optional Hiding of Model Thinking Process with Configurable Tags&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.246"&gt;v1.4.246&lt;/a&gt; (Jul 14, 2025) ‚Äî &lt;strong&gt;Automatic ChangeLog Updates&lt;/strong&gt;: Add AI-powered changelog generation with high-performance Go tool and comprehensive caching&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.245"&gt;v1.4.245&lt;/a&gt; (Jul 11, 2025) ‚Äî &lt;strong&gt;Together AI&lt;/strong&gt;: Together AI Support with OpenAI Fallback Mechanism Added&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.232"&gt;v1.4.232&lt;/a&gt; (Jul 6, 2025) ‚Äî &lt;strong&gt;Add Custom&lt;/strong&gt;: Add Custom Patterns Directory Support&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.231"&gt;v1.4.231&lt;/a&gt; (Jul 5, 2025) ‚Äî &lt;strong&gt;OAuth Auto-Auth&lt;/strong&gt;: OAuth Authentication Support for Anthropic (Use your Max Subscription)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.230"&gt;v1.4.230&lt;/a&gt; (Jul 5, 2025) ‚Äî &lt;strong&gt;Model Management&lt;/strong&gt;: Add advanced image generation parameters for OpenAI models with four new CLI flags&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.227"&gt;v1.4.227&lt;/a&gt; (Jul 4, 2025) ‚Äî &lt;strong&gt;Add Image&lt;/strong&gt;: Add Image Generation Support to Fabric&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.226"&gt;v1.4.226&lt;/a&gt; (Jul 4, 2025) ‚Äî &lt;strong&gt;Web Search&lt;/strong&gt;: OpenAI Plugin Now Supports Web Search Functionality&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.225"&gt;v1.4.225&lt;/a&gt; (Jul 4, 2025) ‚Äî &lt;strong&gt;Web Search&lt;/strong&gt;: Runtime Web Search Control via Command-Line &lt;code&gt;--search&lt;/code&gt; Flag&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.224"&gt;v1.4.224&lt;/a&gt; (Jul 1, 2025) ‚Äî &lt;strong&gt;Add code_review&lt;/strong&gt;: Add code_review pattern and updates in Pattern_Descriptions&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.222"&gt;v1.4.222&lt;/a&gt; (Jul 1, 2025) ‚Äî &lt;strong&gt;OpenAI Plugin&lt;/strong&gt;: OpenAI Plugin Migrates to New Responses API&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.218"&gt;v1.4.218&lt;/a&gt; (Jun 27, 2025) ‚Äî &lt;strong&gt;Model Management&lt;/strong&gt;: Add Support for OpenAI Search and Research Model Variants&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.217"&gt;v1.4.217&lt;/a&gt; (Jun 26, 2025) ‚Äî &lt;strong&gt;New YouTube&lt;/strong&gt;: New YouTube Transcript Endpoint Added to REST API&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.212"&gt;v1.4.212&lt;/a&gt; (Jun 23, 2025) ‚Äî &lt;strong&gt;Add Langdock&lt;/strong&gt;: Add Langdock AI and enhance generic OpenAI compatible support&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.211"&gt;v1.4.211&lt;/a&gt; (Jun 19, 2025) ‚Äî &lt;strong&gt;REST API&lt;/strong&gt;: REST API and Web UI Now Support Dynamic Pattern Variables&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.210"&gt;v1.4.210&lt;/a&gt; (Jun 18, 2025) ‚Äî &lt;strong&gt;Add Citations&lt;/strong&gt;: Add Citation Support to Perplexity Response&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.208"&gt;v1.4.208&lt;/a&gt; (Jun 17, 2025) ‚Äî &lt;strong&gt;Add Perplexity&lt;/strong&gt;: Add Perplexity AI Provider with Token Limits Support&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/danielmiessler/fabric/releases/tag/v1.4.203"&gt;v1.4.203&lt;/a&gt; (Jun 14, 2025) ‚Äî &lt;strong&gt;Add Amazon Bedrock&lt;/strong&gt;: Add support for Amazon Bedrock&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;These features represent our commitment to making Fabric the most powerful and flexible AI augmentation framework available!&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;Intro videos&lt;/h2&gt; 
&lt;p&gt;Keep in mind that many of these were recorded when Fabric was Python-based, so remember to use the current &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#installation"&gt;install instructions&lt;/a&gt; below.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=UbDyjIIGaxQ"&gt;Network Chuck&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=vF-MQmVxnCs"&gt;David Bombal&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=wPEyyigh10g"&gt;My Own Intro to the Tool&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/results?search_query=fabric+ai"&gt;More Fabric YouTube Videos&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Navigation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#fabric"&gt;&lt;code&gt;fabric&lt;/code&gt;&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#what-and-why"&gt;What and why&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#updates"&gt;Updates&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#recent-major-features"&gt;Recent Major Features&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#intro-videos"&gt;Intro videos&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#navigation"&gt;Navigation&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#changelog"&gt;Changelog&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#philosophy"&gt;Philosophy&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#breaking-problems-into-components"&gt;Breaking problems into components&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#too-many-prompts"&gt;Too many prompts&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#installation"&gt;Installation&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#one-line-install-recommended"&gt;One-Line Install (Recommended)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#manual-binary-downloads"&gt;Manual Binary Downloads&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#using-package-managers"&gt;Using package managers&lt;/a&gt; 
      &lt;ul&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#macos-homebrew"&gt;macOS (Homebrew)&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#arch-linux-aur"&gt;Arch Linux (AUR)&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#windows"&gt;Windows&lt;/a&gt;&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#from-source"&gt;From Source&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#docker"&gt;Docker&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#environment-variables"&gt;Environment Variables&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#setup"&gt;Setup&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#supported-ai-providers"&gt;Supported AI Providers&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#per-pattern-model-mapping"&gt;Per-Pattern Model Mapping&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#add-aliases-for-all-patterns"&gt;Add aliases for all patterns&lt;/a&gt; 
      &lt;ul&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#save-your-files-in-markdown-using-aliases"&gt;Save your files in markdown using aliases&lt;/a&gt;&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#migration"&gt;Migration&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#upgrading"&gt;Upgrading&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#shell-completions"&gt;Shell Completions&lt;/a&gt; 
      &lt;ul&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#quick-install-no-clone-required"&gt;Quick install (no clone required)&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#zsh-completion"&gt;Zsh Completion&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#bash-completion"&gt;Bash Completion&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#fish-completion"&gt;Fish Completion&lt;/a&gt;&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#usage"&gt;Usage&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#debug-levels"&gt;Debug Levels&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#dry-run-mode"&gt;Dry Run Mode&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#extensions"&gt;Extensions&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#rest-api-server"&gt;REST API Server&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#ollama-compatibility-mode"&gt;Ollama Compatibility Mode&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#our-approach-to-prompting"&gt;Our approach to prompting&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#examples"&gt;Examples&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#just-use-the-patterns"&gt;Just use the Patterns&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#prompt-strategies"&gt;Prompt Strategies&lt;/a&gt; 
      &lt;ul&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#available-strategies"&gt;Available Strategies&lt;/a&gt;&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#custom-patterns"&gt;Custom Patterns&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#setting-up-custom-patterns"&gt;Setting Up Custom Patterns&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#using-custom-patterns"&gt;Using Custom Patterns&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#how-it-works"&gt;How It Works&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#helper-apps"&gt;Helper Apps&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#to_pdf"&gt;&lt;code&gt;to_pdf&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#to_pdf-installation"&gt;&lt;code&gt;to_pdf&lt;/code&gt; Installation&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#code2context"&gt;&lt;code&gt;code2context&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#generate_changelog"&gt;&lt;code&gt;generate_changelog&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#pbpaste"&gt;pbpaste&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#web-interface-fabric-web-app"&gt;Web Interface (Fabric Web App)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#meta"&gt;Meta&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#primary-contributors"&gt;Primary contributors&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#contributors"&gt;Contributors&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#-support-this-project"&gt;üíú Support This Project&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;h2&gt;Changelog&lt;/h2&gt; 
&lt;p&gt;Fabric is evolving rapidly.&lt;/p&gt; 
&lt;p&gt;Stay current with the latest features by reviewing the &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/CHANGELOG.md"&gt;CHANGELOG&lt;/a&gt; for all recent changes.&lt;/p&gt; 
&lt;h2&gt;Philosophy&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;AI isn't a thing; it's a &lt;em&gt;magnifier&lt;/em&gt; of a thing. And that thing is &lt;strong&gt;human creativity&lt;/strong&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;We believe the purpose of technology is to help humans flourish, so when we talk about AI we start with the &lt;strong&gt;human&lt;/strong&gt; problems we want to solve.&lt;/p&gt; 
&lt;h3&gt;Breaking problems into components&lt;/h3&gt; 
&lt;p&gt;Our approach is to break problems into individual pieces (see below) and then apply AI to them one at a time. See below for some examples.&lt;/p&gt; 
&lt;img width="2078" alt="augmented_challenges" src="https://github.com/danielmiessler/fabric/assets/50654/31997394-85a9-40c2-879b-b347e4701f06" /&gt; 
&lt;h3&gt;Too many prompts&lt;/h3&gt; 
&lt;p&gt;Prompts are good for this, but the biggest challenge I faced in 2023‚Äî‚Äîwhich still exists today‚Äîis &lt;strong&gt;the sheer number of AI prompts out there&lt;/strong&gt;. We all have prompts that are useful, but it's hard to discover new ones, know if they are good or not, &lt;em&gt;and manage different versions of the ones we like&lt;/em&gt;.&lt;/p&gt; 
&lt;p&gt;One of &lt;code&gt;fabric&lt;/code&gt;'s primary features is helping people collect and integrate prompts, which we call &lt;em&gt;Patterns&lt;/em&gt;, into various parts of their lives.&lt;/p&gt; 
&lt;p&gt;Fabric has Patterns for all sorts of life and work activities, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Extracting the most interesting parts of YouTube videos and podcasts&lt;/li&gt; 
 &lt;li&gt;Writing an essay in your own voice with just an idea as an input&lt;/li&gt; 
 &lt;li&gt;Summarizing opaque academic papers&lt;/li&gt; 
 &lt;li&gt;Creating perfectly matched AI art prompts for a piece of writing&lt;/li&gt; 
 &lt;li&gt;Rating the quality of content to see if you want to read/watch the whole thing&lt;/li&gt; 
 &lt;li&gt;Getting summaries of long, boring content&lt;/li&gt; 
 &lt;li&gt;Explaining code to you&lt;/li&gt; 
 &lt;li&gt;Turning bad documentation into usable documentation&lt;/li&gt; 
 &lt;li&gt;Creating social media posts from any content input&lt;/li&gt; 
 &lt;li&gt;And a million more‚Ä¶&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;One-Line Install (Recommended)&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Unix/Linux/macOS:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -fsSL https://raw.githubusercontent.com/danielmiessler/fabric/main/scripts/installer/install.sh | bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Windows PowerShell:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;iwr -useb https://raw.githubusercontent.com/danielmiessler/fabric/main/scripts/installer/install.ps1 | iex
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/scripts/installer/README.md"&gt;scripts/installer/README.md&lt;/a&gt; for custom installation options and troubleshooting.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Manual Binary Downloads&lt;/h3&gt; 
&lt;p&gt;The latest release binary archives and their expected SHA256 hashes can be found at &lt;a href="https://github.com/danielmiessler/fabric/releases/latest"&gt;https://github.com/danielmiessler/fabric/releases/latest&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Using package managers&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; using Homebrew or the Arch Linux package managers makes &lt;code&gt;fabric&lt;/code&gt; available as &lt;code&gt;fabric-ai&lt;/code&gt;, so add the following alias to your shell startup files to account for this:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;alias fabric='fabric-ai'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;macOS (Homebrew)&lt;/h4&gt; 
&lt;p&gt;&lt;code&gt;brew install fabric-ai&lt;/code&gt;&lt;/p&gt; 
&lt;h4&gt;Arch Linux (AUR)&lt;/h4&gt; 
&lt;p&gt;&lt;code&gt;yay -S fabric-ai&lt;/code&gt;&lt;/p&gt; 
&lt;h4&gt;Windows&lt;/h4&gt; 
&lt;p&gt;Use the official Microsoft supported &lt;code&gt;Winget&lt;/code&gt; tool:&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;winget install danielmiessler.Fabric&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;From Source&lt;/h3&gt; 
&lt;p&gt;To install Fabric, &lt;a href="https://go.dev/doc/install"&gt;make sure Go is installed&lt;/a&gt;, and then run the following command.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install Fabric directly from the repo
go install github.com/danielmiessler/fabric/cmd/fabric@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Docker&lt;/h3&gt; 
&lt;p&gt;Run Fabric using pre-built Docker images:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Use latest image from Docker Hub
docker run --rm -it kayvan/fabric:latest --version

# Use specific version from GHCR
docker run --rm -it ghcr.io/ksylvan/fabric:v1.4.305 --version

# Run setup (first time)
mkdir -p $HOME/.fabric-config
docker run --rm -it -v $HOME/.fabric-config:/root/.config/fabric kayvan/fabric:latest --setup

# Use Fabric with your patterns
docker run --rm -it -v $HOME/.fabric-config:/root/.config/fabric kayvan/fabric:latest -p summarize

# Run the REST API server (see REST API Server section)
docker run --rm -it -p 8080:8080 -v $HOME/.fabric-config:/root/.config/fabric kayvan/fabric:latest --serve
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Images available at:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Docker Hub: &lt;a href="https://hub.docker.com/repository/docker/kayvan/fabric/general"&gt;kayvan/fabric&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;GHCR: &lt;a href="https://github.com/ksylvan/fabric/pkgs/container/fabric"&gt;ksylvan/fabric&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/scripts/docker/README.md"&gt;scripts/docker/README.md&lt;/a&gt; for building custom images and advanced configuration.&lt;/p&gt; 
&lt;h3&gt;Environment Variables&lt;/h3&gt; 
&lt;p&gt;You may need to set some environment variables in your &lt;code&gt;~/.bashrc&lt;/code&gt; on linux or &lt;code&gt;~/.zshrc&lt;/code&gt; file on mac to be able to run the &lt;code&gt;fabric&lt;/code&gt; command. Here is an example of what you can add:&lt;/p&gt; 
&lt;p&gt;For Intel based macs or linux&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Golang environment variables
export GOROOT=/usr/local/go
export GOPATH=$HOME/go

# Update PATH to include GOPATH and GOROOT binaries
export PATH=$GOPATH/bin:$GOROOT/bin:$HOME/.local/bin:$PATH
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;for Apple Silicon based macs&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Golang environment variables
export GOROOT=$(brew --prefix go)/libexec
export GOPATH=$HOME/go
export PATH=$GOPATH/bin:$GOROOT/bin:$HOME/.local/bin:$PATH
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Setup&lt;/h3&gt; 
&lt;p&gt;Now run the following command&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Run the setup to set up your directories and keys
fabric --setup
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If everything works you are good to go.&lt;/p&gt; 
&lt;h3&gt;Supported AI Providers&lt;/h3&gt; 
&lt;p&gt;Fabric supports a wide range of AI providers:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Native Integrations:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;OpenAI&lt;/li&gt; 
 &lt;li&gt;Anthropic (Claude)&lt;/li&gt; 
 &lt;li&gt;Google Gemini&lt;/li&gt; 
 &lt;li&gt;Ollama (local models)&lt;/li&gt; 
 &lt;li&gt;Azure OpenAI&lt;/li&gt; 
 &lt;li&gt;Amazon Bedrock&lt;/li&gt; 
 &lt;li&gt;Vertex AI&lt;/li&gt; 
 &lt;li&gt;LM Studio&lt;/li&gt; 
 &lt;li&gt;Perplexity&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;OpenAI-Compatible Providers:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Abacus&lt;/li&gt; 
 &lt;li&gt;AIML&lt;/li&gt; 
 &lt;li&gt;Cerebras&lt;/li&gt; 
 &lt;li&gt;DeepSeek&lt;/li&gt; 
 &lt;li&gt;GitHub Models&lt;/li&gt; 
 &lt;li&gt;GrokAI&lt;/li&gt; 
 &lt;li&gt;Groq&lt;/li&gt; 
 &lt;li&gt;Langdock&lt;/li&gt; 
 &lt;li&gt;LiteLLM&lt;/li&gt; 
 &lt;li&gt;MiniMax&lt;/li&gt; 
 &lt;li&gt;Mistral&lt;/li&gt; 
 &lt;li&gt;OpenRouter&lt;/li&gt; 
 &lt;li&gt;SiliconCloud&lt;/li&gt; 
 &lt;li&gt;Together&lt;/li&gt; 
 &lt;li&gt;Venice AI&lt;/li&gt; 
 &lt;li&gt;Z AI&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Run &lt;code&gt;fabric --setup&lt;/code&gt; to configure your preferred provider(s), or use &lt;code&gt;fabric --listvendors&lt;/code&gt; to see all available vendors.&lt;/p&gt; 
&lt;h3&gt;Per-Pattern Model Mapping&lt;/h3&gt; 
&lt;p&gt;You can configure specific models for individual patterns using environment variables like &lt;code&gt;FABRIC_MODEL_PATTERN_NAME=vendor|model&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;This makes it easy to maintain these per-pattern model mappings in your shell startup files.&lt;/p&gt; 
&lt;h3&gt;Add aliases for all patterns&lt;/h3&gt; 
&lt;p&gt;In order to add aliases for all your patterns and use them directly as commands, for example, &lt;code&gt;summarize&lt;/code&gt; instead of &lt;code&gt;fabric --pattern summarize&lt;/code&gt; You can add the following to your &lt;code&gt;.zshrc&lt;/code&gt; or &lt;code&gt;.bashrc&lt;/code&gt; file. You can also optionally set the &lt;code&gt;FABRIC_ALIAS_PREFIX&lt;/code&gt; environment variable before, if you'd prefer all the fabric aliases to start with the same prefix.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Loop through all files in the ~/.config/fabric/patterns directory
for pattern_file in $HOME/.config/fabric/patterns/*; do
    # Get the base name of the file (i.e., remove the directory path)
    pattern_name="$(basename "$pattern_file")"
    alias_name="${FABRIC_ALIAS_PREFIX:-}${pattern_name}"

    # Create an alias in the form: alias pattern_name="fabric --pattern pattern_name"
    alias_command="alias $alias_name='fabric --pattern $pattern_name'"

    # Evaluate the alias command to add it to the current shell
    eval "$alias_command"
done

yt() {
    if [ "$#" -eq 0 ] || [ "$#" -gt 2 ]; then
        echo "Usage: yt [-t | --timestamps] youtube-link"
        echo "Use the '-t' flag to get the transcript with timestamps."
        return 1
    fi

    transcript_flag="--transcript"
    if [ "$1" = "-t" ] || [ "$1" = "--timestamps" ]; then
        transcript_flag="--transcript-with-timestamps"
        shift
    fi
    local video_link="$1"
    fabric -y "$video_link" $transcript_flag
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can add the below code for the equivalent aliases inside PowerShell by running &lt;code&gt;notepad $PROFILE&lt;/code&gt; inside a PowerShell window:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;# Path to the patterns directory
$patternsPath = Join-Path $HOME ".config/fabric/patterns"
foreach ($patternDir in Get-ChildItem -Path $patternsPath -Directory) {
    # Prepend FABRIC_ALIAS_PREFIX if set; otherwise use empty string
    $prefix = $env:FABRIC_ALIAS_PREFIX ?? ''
    $patternName = "$($patternDir.Name)"
    $aliasName = "$prefix$patternName"
    # Dynamically define a function for each pattern
    $functionDefinition = @"
function $aliasName {
    [CmdletBinding()]
    param(
        [Parameter(ValueFromPipeline = `$true)]
        [string] `$InputObject,

        [Parameter(ValueFromRemainingArguments = `$true)]
        [String[]] `$patternArgs
    )

    begin {
        # Initialize an array to collect pipeline input
        `$collector = @()
    }

    process {
        # Collect pipeline input objects
        if (`$InputObject) {
            `$collector += `$InputObject
        }
    }

    end {
        # Join all pipeline input into a single string, separated by newlines
        `$pipelineContent = `$collector -join "`n"

        # If there's pipeline input, include it in the call to fabric
        if (`$pipelineContent) {
            `$pipelineContent | fabric --pattern $patternName `$patternArgs
        } else {
            # No pipeline input; just call fabric with the additional args
            fabric --pattern $patternName `$patternArgs
        }
    }
}
"@
    # Add the function to the current session
    Invoke-Expression $functionDefinition
}

# Define the 'yt' function as well
function yt {
    [CmdletBinding()]
    param(
        [Parameter()]
        [Alias("timestamps")]
        [switch]$t,

        [Parameter(Position = 0, ValueFromPipeline = $true)]
        [string]$videoLink
    )

    begin {
        $transcriptFlag = "--transcript"
        if ($t) {
            $transcriptFlag = "--transcript-with-timestamps"
        }
    }

    process {
        if (-not $videoLink) {
            Write-Error "Usage: yt [-t | --timestamps] youtube-link"
            return
        }
    }

    end {
        if ($videoLink) {
            # Execute and allow output to flow through the pipeline
            fabric -y $videoLink $transcriptFlag
        }
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This also creates a &lt;code&gt;yt&lt;/code&gt; alias that allows you to use &lt;code&gt;yt https://www.youtube.com/watch?v=4b0iet22VIk&lt;/code&gt; to get transcripts, comments, and metadata.&lt;/p&gt; 
&lt;h4&gt;Save your files in markdown using aliases&lt;/h4&gt; 
&lt;p&gt;If in addition to the above aliases you would like to have the option to save the output to your favorite markdown note vault like Obsidian then instead of the above add the following to your &lt;code&gt;.zshrc&lt;/code&gt; or &lt;code&gt;.bashrc&lt;/code&gt; file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Define the base directory for Obsidian notes
obsidian_base="/path/to/obsidian"

# Loop through all files in the ~/.config/fabric/patterns directory
for pattern_file in ~/.config/fabric/patterns/*; do
    # Get the base name of the file (i.e., remove the directory path)
    pattern_name=$(basename "$pattern_file")

    # Remove any existing alias with the same name
    unalias "$pattern_name" 2&amp;gt;/dev/null

    # Define a function dynamically for each pattern
    eval "
    $pattern_name() {
        local title=\$1
        local date_stamp=\$(date +'%Y-%m-%d')
        local output_path=\"\$obsidian_base/\${date_stamp}-\${title}.md\"

        # Check if a title was provided
        if [ -n \"\$title\" ]; then
            # If a title is provided, use the output path
            fabric --pattern \"$pattern_name\" -o \"\$output_path\"
        else
            # If no title is provided, use --stream
            fabric --pattern \"$pattern_name\" --stream
        fi
    }
    "
done
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will allow you to use the patterns as aliases like in the above for example &lt;code&gt;summarize&lt;/code&gt; instead of &lt;code&gt;fabric --pattern summarize --stream&lt;/code&gt;, however if you pass in an extra argument like this &lt;code&gt;summarize "my_article_title"&lt;/code&gt; your output will be saved in the destination that you set in &lt;code&gt;obsidian_base="/path/to/obsidian"&lt;/code&gt; in the following format &lt;code&gt;YYYY-MM-DD-my_article_title.md&lt;/code&gt; where the date gets autogenerated for you. You can tweak the date format by tweaking the &lt;code&gt;date_stamp&lt;/code&gt; format.&lt;/p&gt; 
&lt;h3&gt;Migration&lt;/h3&gt; 
&lt;p&gt;If you have the Legacy (Python) version installed and want to migrate to the Go version, here's how you do it. It's basically two steps: 1) uninstall the Python version, and 2) install the Go version.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Uninstall Legacy Fabric
pipx uninstall fabric

# Clear any old Fabric aliases
(check your .bashrc, .zshrc, etc.)
# Install the Go version
go install github.com/danielmiessler/fabric/cmd/fabric@latest
# Run setup for the new version. Important because things have changed
fabric --setup
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#environment-variables"&gt;set your environmental variables&lt;/a&gt; as shown above.&lt;/p&gt; 
&lt;h3&gt;Upgrading&lt;/h3&gt; 
&lt;p&gt;The great thing about Go is that it's super easy to upgrade. Just run the same command you used to install it in the first place and you'll always get the latest version.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;go install github.com/danielmiessler/fabric/cmd/fabric@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Shell Completions&lt;/h3&gt; 
&lt;p&gt;Fabric provides shell completion scripts for Zsh, Bash, and Fish shells, making it easier to use the CLI by providing tab completion for commands and options.&lt;/p&gt; 
&lt;h4&gt;Quick install (no clone required)&lt;/h4&gt; 
&lt;p&gt;You can install completions directly via a one-liner:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -fsSL https://raw.githubusercontent.com/danielmiessler/Fabric/refs/heads/main/completions/setup-completions.sh | sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Optional variants:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Dry-run (see actions without changing your system)
curl -fsSL https://raw.githubusercontent.com/danielmiessler/Fabric/refs/heads/main/completions/setup-completions.sh | sh -s -- --dry-run

# Override the download source (advanced)
FABRIC_COMPLETIONS_BASE_URL="https://raw.githubusercontent.com/danielmiessler/Fabric/refs/heads/main/completions" \
    sh -c "$(curl -fsSL https://raw.githubusercontent.com/danielmiessler/Fabric/refs/heads/main/completions/setup-completions.sh)"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Zsh Completion&lt;/h4&gt; 
&lt;p&gt;To enable Zsh completion:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Copy the completion file to a directory in your $fpath
mkdir -p ~/.zsh/completions
cp completions/_fabric ~/.zsh/completions/

# Add the directory to fpath in your .zshrc before compinit
echo 'fpath=(~/.zsh/completions $fpath)' &amp;gt;&amp;gt; ~/.zshrc
echo 'autoload -Uz compinit &amp;amp;&amp;amp; compinit' &amp;gt;&amp;gt; ~/.zshrc
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Bash Completion&lt;/h4&gt; 
&lt;p&gt;To enable Bash completion:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Source the completion script in your .bashrc
echo 'source /path/to/fabric/completions/fabric.bash' &amp;gt;&amp;gt; ~/.bashrc

# Or copy to the system-wide bash completion directory
sudo cp completions/fabric.bash /etc/bash_completion.d/
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Fish Completion&lt;/h4&gt; 
&lt;p&gt;To enable Fish completion:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Copy the completion file to the fish completions directory
mkdir -p ~/.config/fish/completions
cp completions/fabric.fish ~/.config/fish/completions/
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;Once you have it all set up, here's how to use it.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;fabric -h
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-plaintext"&gt;Usage:
  fabric [OPTIONS]

Application Options:
  -p, --pattern=                    Choose a pattern from the available patterns
  -v, --variable=                   Values for pattern variables, e.g. -v=#role:expert -v=#points:30
  -C, --context=                    Choose a context from the available contexts
      --session=                    Choose a session from the available sessions
  -a, --attachment=                 Attachment path or URL (e.g. for OpenAI image recognition messages)
  -S, --setup                       Run setup for all reconfigurable parts of fabric
  -t, --temperature=                Set temperature (default: 0.7)
  -T, --topp=                       Set top P (default: 0.9)
  -s, --stream                      Stream
  -P, --presencepenalty=            Set presence penalty (default: 0.0)
  -r, --raw                         Use the defaults of the model without sending chat options
                                    (temperature, top_p, etc.). Only affects OpenAI-compatible providers.
                                    Anthropic models always use smart parameter selection to comply with
                                    model-specific requirements.
  -F, --frequencypenalty=           Set frequency penalty (default: 0.0)
  -l, --listpatterns                List all patterns
  -L, --listmodels                  List all available models
  -x, --listcontexts                List all contexts
  -X, --listsessions                List all sessions
  -U, --updatepatterns              Update patterns
  -c, --copy                        Copy to clipboard
  -m, --model=                      Choose model
  -V, --vendor=                     Specify vendor for chosen model (e.g., -V "LM Studio" -m openai/gpt-oss-20b)
      --modelContextLength=         Model context length (only affects ollama)
  -o, --output=                     Output to file
      --output-session              Output the entire session (also a temporary one) to the output file
  -n, --latest=                     Number of latest patterns to list (default: 0)
  -d, --changeDefaultModel          Change default model
  -y, --youtube=                    YouTube video or play list "URL" to grab transcript, comments from it
                                    and send to chat or print it put to the console and store it in the
                                    output file
      --playlist                    Prefer playlist over video if both ids are present in the URL
      --transcript                  Grab transcript from YouTube video and send to chat (it is used per
                                    default).
      --transcript-with-timestamps  Grab transcript from YouTube video with timestamps and send to chat
      --comments                    Grab comments from YouTube video and send to chat
      --metadata                    Output video metadata
  -g, --language=                   Specify the Language Code for the chat, e.g. -g=en -g=zh
  -u, --scrape_url=                 Scrape website URL to markdown using Jina AI
  -q, --scrape_question=            Search question using Jina AI
  -e, --seed=                       Seed to be used for LMM generation
  -w, --wipecontext=                Wipe context
  -W, --wipesession=                Wipe session
      --printcontext=               Print context
      --printsession=               Print session
      --readability                 Convert HTML input into a clean, readable view
      --input-has-vars              Apply variables to user input
      --no-variable-replacement     Disable pattern variable replacement
      --dry-run                     Show what would be sent to the model without actually sending it
      --serve                       Serve the Fabric Rest API
      --serveOllama                 Serve the Fabric Rest API with ollama endpoints
      --address=                    The address to bind the REST API (default: :8080)
      --api-key=                    API key used to secure server routes
      --config=                     Path to YAML config file
      --version                     Print current version
      --listextensions              List all registered extensions
      --addextension=               Register a new extension from config file path
      --rmextension=                Remove a registered extension by name
      --strategy=                   Choose a strategy from the available strategies
      --liststrategies              List all strategies
      --listvendors                 List all vendors
      --shell-complete-list         Output raw list without headers/formatting (for shell completion)
      --search                      Enable web search tool for supported models (Anthropic, OpenAI, Gemini)
      --search-location=            Set location for web search results (e.g., 'America/Los_Angeles')
      --image-file=                 Save generated image to specified file path (e.g., 'output.png')
      --image-size=                 Image dimensions: 1024x1024, 1536x1024, 1024x1536, auto (default: auto)
      --image-quality=              Image quality: low, medium, high, auto (default: auto)
      --image-compression=          Compression level 0-100 for JPEG/WebP formats (default: not set)
      --image-background=           Background type: opaque, transparent (default: opaque, only for
                                    PNG/WebP)
      --suppress-think              Suppress text enclosed in thinking tags
      --think-start-tag=            Start tag for thinking sections (default: &amp;lt;think&amp;gt;)
      --think-end-tag=              End tag for thinking sections (default: &amp;lt;/think&amp;gt;)
      --disable-responses-api       Disable OpenAI Responses API (default: false)
      --voice=                      TTS voice name for supported models (e.g., Kore, Charon, Puck)
                                    (default: Kore)
      --list-gemini-voices          List all available Gemini TTS voices
      --notification                Send desktop notification when command completes
      --notification-command=       Custom command to run for notifications (overrides built-in
                                    notifications)
      --yt-dlp-args=                Additional arguments to pass to yt-dlp (e.g. '--cookies-from-browser brave')
      --thinking=                   Set reasoning/thinking level (e.g., off, low, medium, high, or
                                    numeric tokens for Anthropic or Google Gemini)
      --show-metadata               Print metadata (input/output tokens) to stderr
      --debug=                     Set debug level (0: off, 1: basic, 2: detailed, 3: trace)
Help Options:
  -h, --help                        Show this help message
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Debug Levels&lt;/h3&gt; 
&lt;p&gt;Use the &lt;code&gt;--debug&lt;/code&gt; flag to control runtime logging:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;0&lt;/code&gt;: off (default)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;1&lt;/code&gt;: basic debug info&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;2&lt;/code&gt;: detailed debugging&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;3&lt;/code&gt;: trace level&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Dry Run Mode&lt;/h3&gt; 
&lt;p&gt;Use &lt;code&gt;--dry-run&lt;/code&gt; to preview what would be sent to the AI model without making an API call:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;echo "test input" | fabric --dry-run -p summarize
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This is useful for debugging patterns, checking prompt construction, and verifying input formatting before using API credits.&lt;/p&gt; 
&lt;h3&gt;Extensions&lt;/h3&gt; 
&lt;p&gt;Fabric supports extensions that can be called within patterns. See the &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/internal/plugins/template/Examples/README.md"&gt;Extension Guide&lt;/a&gt; for complete documentation.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt; Extensions only work within pattern files, not via direct stdin. See the guide for details and examples.&lt;/p&gt; 
&lt;h2&gt;REST API Server&lt;/h2&gt; 
&lt;p&gt;Fabric includes a built-in REST API server that exposes all core functionality over HTTP. Start the server with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;fabric --serve
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The server provides endpoints for:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Chat completions with streaming responses&lt;/li&gt; 
 &lt;li&gt;Pattern management (create, read, update, delete)&lt;/li&gt; 
 &lt;li&gt;Context and session management&lt;/li&gt; 
 &lt;li&gt;Model and vendor listing&lt;/li&gt; 
 &lt;li&gt;YouTube transcript extraction&lt;/li&gt; 
 &lt;li&gt;Configuration management&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For complete endpoint documentation, authentication setup, and usage examples, see &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/docs/rest-api.md"&gt;REST API Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Ollama Compatibility Mode&lt;/h3&gt; 
&lt;p&gt;Fabric can serve as a drop-in replacement for Ollama by exposing Ollama-compatible API endpoints. Start the server with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;fabric --serve --serveOllama
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This enables the following Ollama-compatible endpoints:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;GET /api/tags&lt;/code&gt; - List available patterns as models&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;POST /api/chat&lt;/code&gt; - Chat completions&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;GET /api/version&lt;/code&gt; - Server version&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Applications configured to use the Ollama API can point to your Fabric server instead, allowing you to use any of Fabric's supported AI providers through the Ollama interface. Patterns appear as models (e.g., &lt;code&gt;summarize:latest&lt;/code&gt;).&lt;/p&gt; 
&lt;h2&gt;Our approach to prompting&lt;/h2&gt; 
&lt;p&gt;Fabric &lt;em&gt;Patterns&lt;/em&gt; are different than most prompts you'll see.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;First, we use &lt;code&gt;Markdown&lt;/code&gt; to help ensure maximum readability and editability&lt;/strong&gt;. This not only helps the creator make a good one, but also anyone who wants to deeply understand what it does. &lt;em&gt;Importantly, this also includes the AI you're sending it to!&lt;/em&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Here's an example of a Fabric Pattern.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;https://github.com/danielmiessler/Fabric/blob/main/data/patterns/extract_wisdom/system.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;img width="1461" alt="pattern-example" src="https://github.com/danielmiessler/fabric/assets/50654/b910c551-9263-405f-9735-71ca69bbab6d" /&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Next, we are extremely clear in our instructions&lt;/strong&gt;, and we use the Markdown structure to emphasize what we want the AI to do, and in what order.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;And finally, we tend to use the System section of the prompt almost exclusively&lt;/strong&gt;. In over a year of being heads-down with this stuff, we've just seen more efficacy from doing that. If that changes, or we're shown data that says otherwise, we will adjust.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;The following examples use the macOS &lt;code&gt;pbpaste&lt;/code&gt; to paste from the clipboard. See the &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#pbpaste"&gt;pbpaste&lt;/a&gt; section below for Windows and Linux alternatives.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Now let's look at some things you can do with Fabric.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Run the &lt;code&gt;summarize&lt;/code&gt; Pattern based on input from &lt;code&gt;stdin&lt;/code&gt;. In this case, the body of an article.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pbpaste | fabric --pattern summarize
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run the &lt;code&gt;analyze_claims&lt;/code&gt; Pattern with the &lt;code&gt;--stream&lt;/code&gt; option to get immediate and streaming results.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pbpaste | fabric --stream --pattern analyze_claims
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run the &lt;code&gt;extract_wisdom&lt;/code&gt; Pattern with the &lt;code&gt;--stream&lt;/code&gt; option to get immediate and streaming results from any Youtube video (much like in the original introduction video).&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;fabric -y "https://youtube.com/watch?v=uXs-zPc63kM" --stream --pattern extract_wisdom
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Create patterns- you must create a .md file with the pattern and save it to &lt;code&gt;~/.config/fabric/patterns/[yourpatternname]&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run a &lt;code&gt;analyze_claims&lt;/code&gt; pattern on a website. Fabric uses Jina AI to scrape the URL into markdown format before sending it to the model.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;fabric -u https://github.com/danielmiessler/fabric/ -p analyze_claims
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Just use the Patterns&lt;/h2&gt; 
&lt;img width="1173" alt="fabric-patterns-screenshot" src="https://github.com/danielmiessler/fabric/assets/50654/9186a044-652b-4673-89f7-71cf066f32d8" /&gt; 
&lt;br /&gt; 
&lt;br /&gt; 
&lt;p&gt;If you're not looking to do anything fancy, and you just want a lot of great prompts, you can navigate to the &lt;a href="https://github.com/danielmiessler/fabric/tree/main/data/patterns"&gt;&lt;code&gt;/patterns&lt;/code&gt;&lt;/a&gt; directory and start exploring!&lt;/p&gt; 
&lt;p&gt;We hope that if you used nothing else from Fabric, the Patterns by themselves will make the project useful.&lt;/p&gt; 
&lt;p&gt;You can use any of the Patterns you see there in any AI application that you have, whether that's ChatGPT or some other app or website. Our plan and prediction is that people will soon be sharing many more than those we've published, and they will be way better than ours.&lt;/p&gt; 
&lt;p&gt;The wisdom of crowds for the win.&lt;/p&gt; 
&lt;h3&gt;Prompt Strategies&lt;/h3&gt; 
&lt;p&gt;Fabric also implements prompt strategies like "Chain of Thought" or "Chain of Draft" which can be used in addition to the basic patterns.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://arxiv.org/pdf/2502.18600"&gt;Thinking Faster by Writing Less&lt;/a&gt; paper and the &lt;a href="https://learnprompting.org/docs/advanced/thought_generation/introduction"&gt;Thought Generation section of Learn Prompting&lt;/a&gt; for examples of prompt strategies.&lt;/p&gt; 
&lt;p&gt;Each strategy is available as a small &lt;code&gt;json&lt;/code&gt; file in the &lt;a href="https://github.com/danielmiessler/fabric/tree/main/data/strategies"&gt;&lt;code&gt;/strategies&lt;/code&gt;&lt;/a&gt; directory.&lt;/p&gt; 
&lt;p&gt;The prompt modification of the strategy is applied to the system prompt and passed on to the LLM in the chat session.&lt;/p&gt; 
&lt;p&gt;Use &lt;code&gt;fabric -S&lt;/code&gt; and select the option to install the strategies in your &lt;code&gt;~/.config/fabric&lt;/code&gt; directory.&lt;/p&gt; 
&lt;h4&gt;Available Strategies&lt;/h4&gt; 
&lt;p&gt;Fabric includes several prompt strategies:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;cot&lt;/code&gt; - Chain-of-Thought: Step-by-step reasoning&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cod&lt;/code&gt; - Chain-of-Draft: Iterative drafting with minimal notes (5 words max per step)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;tot&lt;/code&gt; - Tree-of-Thought: Generate multiple reasoning paths and select the best one&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;aot&lt;/code&gt; - Atom-of-Thought: Break problems into smallest independent atomic sub-problems&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ltm&lt;/code&gt; - Least-to-Most: Solve problems from easiest to hardest sub-problems&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;self-consistent&lt;/code&gt; - Self-Consistency: Multiple reasoning paths with consensus&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;self-refine&lt;/code&gt; - Self-Refinement: Answer, critique, and refine&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;reflexion&lt;/code&gt; - Reflexion: Answer, critique briefly, and provide refined answer&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;standard&lt;/code&gt; - Standard: Direct answer without explanation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Use the &lt;code&gt;--strategy&lt;/code&gt; flag to apply a strategy:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;echo "Analyze this code" | fabric --strategy cot -p analyze_code
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;List all available strategies with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;fabric --liststrategies
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Strategies are stored as JSON files in &lt;code&gt;~/.config/fabric/strategies/&lt;/code&gt;. See the default strategies for the format specification.&lt;/p&gt; 
&lt;h2&gt;Custom Patterns&lt;/h2&gt; 
&lt;p&gt;You may want to use Fabric to create your own custom Patterns‚Äîbut not share them with others. No problem!&lt;/p&gt; 
&lt;p&gt;Fabric now supports a dedicated custom patterns directory that keeps your personal patterns separate from the built-in ones. This means your custom patterns won't be overwritten when you update Fabric's built-in patterns.&lt;/p&gt; 
&lt;h3&gt;Setting Up Custom Patterns&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Run the Fabric setup:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;fabric --setup
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Select the "Custom Patterns" option from the Tools menu and enter your desired directory path (e.g., &lt;code&gt;~/my-custom-patterns&lt;/code&gt;)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Fabric will automatically create the directory if it does not exist.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Using Custom Patterns&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Create your custom pattern directory structure:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;mkdir -p ~/my-custom-patterns/my-analyzer
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Create your pattern file&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;echo "You are an expert analyzer of ..." &amp;gt; ~/my-custom-patterns/my-analyzer/system.md
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Use your custom pattern:&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;fabric --pattern my-analyzer "analyze this text"
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;How It Works&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Priority System&lt;/strong&gt;: Custom patterns take precedence over built-in patterns with the same name&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Seamless Integration&lt;/strong&gt;: Custom patterns appear in &lt;code&gt;fabric --listpatterns&lt;/code&gt; alongside built-in ones&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Update Safe&lt;/strong&gt;: Your custom patterns are never affected by &lt;code&gt;fabric --updatepatterns&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Private by Default&lt;/strong&gt;: Custom patterns remain private unless you explicitly share them&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Your custom patterns are completely private and won't be affected by Fabric updates!&lt;/p&gt; 
&lt;h2&gt;Helper Apps&lt;/h2&gt; 
&lt;p&gt;Fabric also makes use of some core helper apps (tools) to make it easier to integrate with your various workflows. Here are some examples:&lt;/p&gt; 
&lt;h3&gt;&lt;code&gt;to_pdf&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;to_pdf&lt;/code&gt; is a helper command that converts LaTeX files to PDF format. You can use it like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;to_pdf input.tex
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will create a PDF file from the input LaTeX file in the same directory.&lt;/p&gt; 
&lt;p&gt;You can also use it with stdin which works perfectly with the &lt;code&gt;write_latex&lt;/code&gt; pattern:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;echo "ai security primer" | fabric --pattern write_latex | to_pdf
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will create a PDF file named &lt;code&gt;output.pdf&lt;/code&gt; in the current directory.&lt;/p&gt; 
&lt;h3&gt;&lt;code&gt;to_pdf&lt;/code&gt; Installation&lt;/h3&gt; 
&lt;p&gt;To install &lt;code&gt;to_pdf&lt;/code&gt;, install it the same way as you install Fabric, just with a different repo name.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;go install github.com/danielmiessler/fabric/cmd/to_pdf@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Make sure you have a LaTeX distribution (like TeX Live or MiKTeX) installed on your system, as &lt;code&gt;to_pdf&lt;/code&gt; requires &lt;code&gt;pdflatex&lt;/code&gt; to be available in your system's PATH.&lt;/p&gt; 
&lt;h3&gt;&lt;code&gt;code2context&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;code2context&lt;/code&gt; is used in conjunction with the &lt;code&gt;create_coding_feature&lt;/code&gt; pattern. It generates a &lt;code&gt;json&lt;/code&gt; representation of a directory of code that can be fed into an AI model with instructions to create a new feature or edit the code in a specified way.&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/data/patterns/create_coding_feature/README.md"&gt;the Create Coding Feature Pattern README&lt;/a&gt; for details.&lt;/p&gt; 
&lt;p&gt;Install it first using:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;go install github.com/danielmiessler/fabric/cmd/code2context@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;code&gt;generate_changelog&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;generate_changelog&lt;/code&gt; generates changelogs from git commit history and GitHub pull requests. It walks through your repository's git history, extracts PR information, and produces well-formatted markdown changelogs.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;generate_changelog --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Features include SQLite caching for fast incremental updates, GitHub GraphQL API integration for efficient PR fetching, and optional AI-enhanced summaries using Fabric.&lt;/p&gt; 
&lt;p&gt;Install it using:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;go install github.com/danielmiessler/fabric/cmd/generate_changelog@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/cmd/generate_changelog/README.md"&gt;generate_changelog README&lt;/a&gt; for detailed usage and options.&lt;/p&gt; 
&lt;h2&gt;pbpaste&lt;/h2&gt; 
&lt;p&gt;The &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/#examples"&gt;examples&lt;/a&gt; use the macOS program &lt;code&gt;pbpaste&lt;/code&gt; to paste content from the clipboard to pipe into &lt;code&gt;fabric&lt;/code&gt; as the input. &lt;code&gt;pbpaste&lt;/code&gt; is not available on Windows or Linux, but there are alternatives.&lt;/p&gt; 
&lt;p&gt;On Windows, you can use the PowerShell command &lt;code&gt;Get-Clipboard&lt;/code&gt; from a PowerShell command prompt. If you like, you can also alias it to &lt;code&gt;pbpaste&lt;/code&gt;. If you are using classic PowerShell, edit the file &lt;code&gt;~\Documents\WindowsPowerShell\.profile.ps1&lt;/code&gt;, or if you are using PowerShell Core, edit &lt;code&gt;~\Documents\PowerShell\.profile.ps1&lt;/code&gt; and add the alias,&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;Set-Alias pbpaste Get-Clipboard
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;On Linux, you can use &lt;code&gt;xclip -selection clipboard -o&lt;/code&gt; to paste from the clipboard. You will likely need to install &lt;code&gt;xclip&lt;/code&gt; with your package manager. For Debian based systems including Ubuntu,&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;sudo apt update
sudo apt install xclip -y
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also create an alias by editing &lt;code&gt;~/.bashrc&lt;/code&gt; or &lt;code&gt;~/.zshrc&lt;/code&gt; and adding the alias,&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;alias pbpaste='xclip -selection clipboard -o'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Web Interface (Fabric Web App)&lt;/h2&gt; 
&lt;p&gt;Fabric now includes a built-in web interface that provides a GUI alternative to the command-line interface. Refer to &lt;a href="https://raw.githubusercontent.com/danielmiessler/Fabric/main/web/README.md"&gt;Web App README&lt;/a&gt; for installation instructions and an overview of features.&lt;/p&gt; 
&lt;h2&gt;Meta&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Special thanks to the following people for their inspiration and contributions!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;em&gt;Jonathan Dunn&lt;/em&gt; for being the absolute MVP dev on the project, including spearheading the new Go version, as well as the GUI! All this while also being a full-time medical doctor!&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;Caleb Sima&lt;/em&gt; for pushing me over the edge of whether to make this a public project or not.&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;Eugen Eisler&lt;/em&gt; and &lt;em&gt;Frederick Ros&lt;/em&gt; for their invaluable contributions to the Go version&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;David Peters&lt;/em&gt; for his work on the web interface.&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;Joel Parish&lt;/em&gt; for super useful input on the project's Github directory structure..&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;Joseph Thacker&lt;/em&gt; for the idea of a &lt;code&gt;-c&lt;/code&gt; context flag that adds pre-created context in the &lt;code&gt;./config/fabric/&lt;/code&gt; directory to all Pattern queries.&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;Jason Haddix&lt;/em&gt; for the idea of a stitch (chained Pattern) to filter content using a local model before sending on to a cloud model, i.e., cleaning customer data using &lt;code&gt;llama2&lt;/code&gt; before sending on to &lt;code&gt;gpt-4&lt;/code&gt; for analysis.&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;Andre Guerra&lt;/em&gt; for assisting with numerous components to make things simpler and more maintainable.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Primary contributors&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/danielmiessler"&gt;&lt;img src="https://avatars.githubusercontent.com/u/50654?v=4" title="Daniel Miessler" width="50" height="50" alt="Daniel Miessler" /&gt;&lt;/a&gt; &lt;a href="https://github.com/xssdoctor"&gt;&lt;img src="https://avatars.githubusercontent.com/u/9218431?v=4" title="Jonathan Dunn" width="50" height="50" alt="Jonathan Dunn" /&gt;&lt;/a&gt; &lt;a href="https://github.com/sbehrens"&gt;&lt;img src="https://avatars.githubusercontent.com/u/688589?v=4" title="Scott Behrens" width="50" height="50" alt="Scott Behrens" /&gt;&lt;/a&gt; &lt;a href="https://github.com/agu3rra"&gt;&lt;img src="https://avatars.githubusercontent.com/u/10410523?v=4" title="Andre Guerra" width="50" height="50" alt="Andre Guerra" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Contributors&lt;/h3&gt; 
&lt;a href="https://github.com/danielmiessler/fabric/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=danielmiessler/fabric" alt="contrib.rocks" /&gt; &lt;/a&gt; 
&lt;p&gt;Made with &lt;a href="https://contrib.rocks"&gt;contrib.rocks&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;fabric&lt;/code&gt; was created by &lt;a href="https://danielmiessler.com/subscribe" target="_blank"&gt;Daniel Miessler&lt;/a&gt; in January of 2024. &lt;br /&gt;&lt;br /&gt; &lt;a href="https://twitter.com/intent/user?screen_name=danielmiessler"&gt;&lt;img src="https://img.shields.io/twitter/follow/danielmiessler" alt="X (formerly Twitter) Follow" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üíú Support This Project&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://img.shields.io/badge/Sponsor-‚ù§Ô∏è-EA4AAA?style=for-the-badge&amp;amp;logo=github-sponsors&amp;amp;logoColor=white" alt="Sponsor" /&gt; 
 &lt;p&gt;&lt;strong&gt;I spend hundreds of hours a year on open source. If you'd like to help support this project, you can &lt;a href="https://github.com/sponsors/danielmiessler"&gt;sponsor me here&lt;/a&gt;. üôèüèº&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>5rahim/seanime</title>
      <link>https://github.com/5rahim/seanime</link>
      <description>&lt;p&gt;Open-source media server with a web interface and desktop app for anime and manga.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://seanime.app/"&gt; &lt;img src="https://raw.githubusercontent.com/5rahim/seanime/main/docs/images/seanime-logo.png" alt="preview" width="70px" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h1 align="center"&gt;&lt;b&gt;Seanime&lt;/b&gt;&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;img src="https://seanime.app/bucket/gh-showcase.webp" alt="preview" width="100%" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://seanime.app/docs"&gt;Documentation&lt;/a&gt; | &lt;a href="https://github.com/5rahim/seanime/releases"&gt;Latest release&lt;/a&gt; | &lt;a href="https://www.youtube.com/playlist?list=PLgQO-Ih6JClhFFdEVuNQJejyX_8iH82gl"&gt;Tutorials&lt;/a&gt; | &lt;a href="https://discord.gg/Sbr7Phzt6m"&gt;Discord&lt;/a&gt; | &lt;a href="https://seanime.app/docs/policies"&gt;Copyright&lt;/a&gt; &lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/5rahim/seanime/releases"&gt; &lt;img src="https://img.shields.io/github/v/release/5rahim/seanime?style=flat-square&amp;amp;color=blue" alt="" /&gt; &lt;/a&gt; 
 &lt;a href="https://github.com/5rahim/seanime/releases"&gt; &lt;img src="https://img.shields.io/github/downloads/5rahim/seanime/total?style=flat-square&amp;amp;color=blue" alt="" /&gt; &lt;/a&gt; 
 &lt;a href="https://discord.gg/Aruz7wdAaf"&gt; &lt;img src="https://img.shields.io/discord/1224767201551192224?style=flat-square&amp;amp;logo=Discord&amp;amp;color=blue&amp;amp;label=Discord" alt="discord" /&gt; &lt;/a&gt; 
 &lt;a href="https://github.com/sponsors/5rahim"&gt; &lt;img src="https://img.shields.io/static/v1?label=Sponsor&amp;amp;style=flat-square&amp;amp;message=%E2%9D%A4&amp;amp;logo=GitHub&amp;amp;color=%23fe8e86" alt="" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h5 align="center"&gt; Leave a star if you like the project! ‚≠êÔ∏è &lt;/h5&gt; 
&lt;h2&gt;About&lt;/h2&gt; 
&lt;p&gt;Seanime is a &lt;strong&gt;media server&lt;/strong&gt; with a &lt;strong&gt;web interface&lt;/strong&gt; and &lt;strong&gt;desktop app&lt;/strong&gt; for managing your local library, streaming anime and reading manga.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] Seanime does not provide, host, or distribute any media content. Users are responsible for obtaining media through legal means and complying with their local laws. Extensions listed on the app are unaffiliated with Seanime and may be removed if they violated copyright laws. &lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Cross-platform web interface and desktop app&lt;/li&gt; 
 &lt;li&gt;Built-in video player with Seanime Denshi (supports SSA/ASS subtitles, Anime4K sharpening, and more)&lt;/li&gt; 
 &lt;li&gt;Complete AniList integration (browse, manage, score, discover, etc.)&lt;/li&gt; 
 &lt;li&gt;Custom source support for adding series not available on AniList and even non-anime/manga series&lt;/li&gt; 
 &lt;li&gt;Offline mode for use without an internet connection&lt;/li&gt; 
 &lt;li&gt;Scan your anime library in seconds (no renaming or special folder structure required)&lt;/li&gt; 
 &lt;li&gt;Integrated torrent search engine for extensions&lt;/li&gt; 
 &lt;li&gt;Stream torrents directly to your media player without downloading using Bittorrent, Torbox and Real-Debrid&lt;/li&gt; 
 &lt;li&gt;Support for qBittorrent, Transmission, Torbox and Real-Debrid for downloading&lt;/li&gt; 
 &lt;li&gt;Automatically download new episodes with custom filters&lt;/li&gt; 
 &lt;li&gt;MPV, VLC and MPC-HC support for watching on desktop&lt;/li&gt; 
 &lt;li&gt;Watch on mobile with external player links to mobile apps (Outplayer, VLC, etc.)&lt;/li&gt; 
 &lt;li&gt;Transcoding and direct play for streaming to any device web browser&lt;/li&gt; 
 &lt;li&gt;Online streaming support for extensions&lt;/li&gt; 
 &lt;li&gt;Read manga chapters from your local library or extensions&lt;/li&gt; 
 &lt;li&gt;Schedule for tracking upcoming or missed episodes&lt;/li&gt; 
 &lt;li&gt;Customizable UI&lt;/li&gt; 
 &lt;li&gt;And more&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Get started&lt;/h2&gt; 
&lt;p&gt;Read the installation guide to set up Seanime on your device.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://seanime.app/docs" style="font-size:18px;" align="center"&gt; How to install Seanime &lt;/a&gt; &lt;/p&gt; 
&lt;br /&gt; 
&lt;h2&gt;Goal&lt;/h2&gt; 
&lt;p&gt;This is a one-person project and may not meet every use case. If it doesn‚Äôt fully fit your needs, other tools might be a better match.&lt;/p&gt; 
&lt;h3&gt;Not planned&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Support for other trackers such as Trakt, SIMKL, etc.&lt;/li&gt; 
 &lt;li&gt;Support for other media players&lt;/li&gt; 
 &lt;li&gt;Dedicated clients (TV, mobile, etc.)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Consider sponsoring or sharing the project if you want to see more features implemented.&lt;/p&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;p&gt;The maintenance of this project is made possible by the sponsors.&lt;/p&gt; 
&lt;p align="center"&gt; 
 &lt;!-- real-sponsors --&gt;&lt;a href="https://github.com/TorBox-App"&gt;&lt;img src="https://github.com/TorBox-App.png" width="60px" alt="User avatar: TorBox-App" /&gt;&lt;/a&gt;
 &lt;!-- real-sponsors --&gt; &lt;/p&gt; 
&lt;h2&gt;Development and Build&lt;/h2&gt; 
&lt;p&gt;Building from source is straightforward, you'll need &lt;a href="https://nodejs.org/en/download"&gt;Node.js&lt;/a&gt; and &lt;a href="https://go.dev/doc/install"&gt;Go&lt;/a&gt; installed on your system. Development and testing might require additional configuration.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/5rahim/seanime/raw/main/DEVELOPMENT_AND_BUILD.md"&gt;Read more here&lt;/a&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;br /&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] For copyright-related requests, please contact the maintainer using the contact information provided on &lt;a href="https://seanime.app/docs/policies"&gt;the website&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt;</description>
    </item>
    
    <item>
      <title>woodpecker-ci/woodpecker</title>
      <link>https://github.com/woodpecker-ci/woodpecker</link>
      <description>&lt;p&gt;Woodpecker is a simple, yet powerful CI/CD engine with great extensibility.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Woodpecker&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/woodpecker-ci/woodpecker/"&gt; &lt;img alt="Woodpecker" src="https://raw.githubusercontent.com/woodpecker-ci/woodpecker/main/docs/static/img/logo.svg?sanitize=true" width="220" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;br /&gt; 
&lt;p align="center"&gt; &lt;a href="https://ci.woodpecker-ci.org/repos/3780" title="Pipeline Status"&gt; &lt;img src="https://ci.woodpecker-ci.org/api/badges/3780/status.svg?sanitize=true" alt="Pipeline Status" /&gt; &lt;/a&gt; &lt;a href="https://codecov.io/gh/woodpecker-ci/woodpecker"&gt; &lt;img src="https://codecov.io/gh/woodpecker-ci/woodpecker/branch/main/graph/badge.svg?sanitize=true" alt="Code coverage" /&gt; &lt;/a&gt; &lt;a href="https://translate.woodpecker-ci.org/engage/woodpecker-ci/"&gt; &lt;img src="https://translate.woodpecker-ci.org/widgets/woodpecker-ci/-/ui/svg-badge.svg?sanitize=true" alt="Translation status" /&gt; &lt;/a&gt; &lt;a href="https://matrix.to/#/#woodpecker:matrix.org" title="Join the Matrix space at https://matrix.to/#/#woodpecker:matrix.org"&gt; &lt;img src="https://img.shields.io/matrix/woodpecker:matrix.org?label=matrix" alt="Matrix space" /&gt; &lt;/a&gt; &lt;a href="https://goreportcard.com/report/go.woodpecker-ci.org/woodpecker/v3" title="Go Report Card"&gt; &lt;img src="https://goreportcard.com/badge/go.woodpecker-ci.org/woodpecker/v3" alt="Go Report Card" /&gt; &lt;/a&gt; &lt;a href="https://pkg.go.dev/go.woodpecker-ci.org/woodpecker/v3" title="go reference"&gt; &lt;img src="https://pkg.go.dev/badge/go.woodpecker-ci.org/woodpecker/v3" alt="go reference" /&gt; &lt;/a&gt; &lt;a href="https://github.com/woodpecker-ci/woodpecker/releases/latest" title="GitHub release"&gt; &lt;img src="https://img.shields.io/github/v/release/woodpecker-ci/woodpecker?sort=semver" alt="GitHub release" /&gt; &lt;/a&gt; &lt;a href="https://hub.docker.com/r/woodpeckerci/woodpecker-server" title="Docker pulls"&gt; &lt;img src="https://img.shields.io/docker/pulls/woodpeckerci/woodpecker-server" alt="Docker pulls" /&gt; &lt;/a&gt; &lt;a href="https://opensource.org/licenses/Apache-2.0" title="License: Apache-2.0"&gt; &lt;img src="https://img.shields.io/badge/License-Apache%202.0-blue.svg?sanitize=true" alt="License: Apache-2.0" /&gt; &lt;/a&gt; &lt;a href="https://bestpractices.coreinfrastructure.org/projects/5309"&gt; &lt;img src="https://bestpractices.coreinfrastructure.org/projects/5309/badge" alt="OpenSSF best practices" /&gt; &lt;/a&gt; &lt;a href="https://results.pre-commit.ci/repo/github/179344069" title="pre-commit.ci"&gt; &lt;img src="https://results.pre-commit.ci/badge/github/woodpecker-ci/woodpecker/main.svg?sanitize=true" alt="pre-commit.ci" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt;Woodpecker is a simple, yet powerful CI/CD engine with great extensibility.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/woodpecker-ci/woodpecker/main/docs/woodpecker.png" alt="woodpecker" /&gt;&lt;/p&gt; 
&lt;h2&gt;Installation &amp;amp; Resources&lt;/h2&gt; 
&lt;p&gt;Woodpecker can be installed in various ways (see the &lt;a href="https://woodpecker-ci.org/docs/administration/general"&gt;Installation Instructions&lt;/a&gt;) and runs with SQLite as database by default. It requires around 100 MB of RAM (Server) and 30 MB (Agent) at runtime in idle mode.&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;p&gt;You can support the project by becoming a backer on &lt;a href="https://opencollective.com/woodpecker-ci#category-CONTRIBUTE"&gt;Open Collective&lt;/a&gt; or via &lt;a href="https://github.com/sponsors/woodpecker-ci"&gt;GitHub Sponsors&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://opencollective.com/woodpecker-ci" target="_blank"&gt;&lt;img src="https://opencollective.com/woodpecker-ci/backers.svg?width=890" alt="Open Collective backers" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;Our documentation can be found at &lt;a href="https://woodpecker-ci.org/docs/intro"&gt;https://woodpecker-ci.org/docs/intro&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Translation&lt;/h2&gt; 
&lt;p&gt;We have a self-hosted &lt;a href="https://weblate.org/en/"&gt;Weblate&lt;/a&gt; instance at &lt;a href="https://translate.woodpecker-ci.org"&gt;translate.woodpecker-ci.org&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;An overview of the current translation state is available at &lt;a href="https://translate.woodpecker-ci.org/projects/woodpecker-ci/#languages"&gt;https://translate.woodpecker-ci.org/projects/woodpecker-ci/#languages&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Public Woodpecker Instances&lt;/h2&gt; 
&lt;p&gt;Woodpecker is used as the main CI/CD engine at &lt;a href="https://codeberg.org"&gt;Codeberg&lt;/a&gt;, an alternative Git hosting platform with a focus on privacy and free software development.&lt;/p&gt; 
&lt;h2&gt;Plugins&lt;/h2&gt; 
&lt;p&gt;Woodpecker can be extended via plugins. The &lt;a href="https://woodpecker-ci.org/plugins"&gt;plugin overview website&lt;/a&gt; helps browsing available plugins. It combines both plugins by the Woodpecker core team and community-maintained ones.&lt;/p&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#woodpecker-ci/woodpecker&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=woodpecker-ci/woodpecker&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Woodpecker is Apache 2.0 licensed. The source files have a header indicating which license they are under and what copyrights apply.&lt;/p&gt; 
&lt;p&gt;Everything in &lt;code&gt;docs/&lt;/code&gt; is licensed under the Creative Commons Attribution-ShareAlike 4.0 International Public License.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>keploy/keploy</title>
      <link>https://github.com/keploy/keploy</link>
      <description>&lt;p&gt;API, Integration, E2E Testing Agent for Developers that actually work. Generate tests, mocks/stubs for your APIs!&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://docs.keploy.io/img/keploy-logo-dark.svg?s=200&amp;amp;v=4" height="80" alt="Keploy Logo" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/3262" target="_blank"&gt; &lt;img src="https://trendshift.io/api/badge/repositories/3262" alt="keploy%2Fkeploy | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h3 align="center"&gt;&lt;b&gt;‚ö°Ô∏è API tests faster than unit tests, from user traffic ‚ö°Ô∏è&lt;/b&gt;&lt;/h3&gt; 
&lt;p align="center"&gt;üåü The must-have tool for developers in the AI-Gen era for 90% test coverage üåü&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p align="center"&gt; &lt;a href="https://join.slack.com/t/keploy/shared_invite/zt-357qqm9b5-PbZRVu3Yt2rJIa6ofrwWNg"&gt;&lt;img src="https://img.shields.io/badge/Slack-4A154B?style=flat&amp;amp;logo=slack&amp;amp;logoColor=white" alt="Slack" /&gt;&lt;/a&gt; &lt;a href="https://www.linkedin.com/company/keploy/"&gt;&lt;img src="https://img.shields.io/badge/LinkedIn-%230077B5.svg?style=flat&amp;amp;logo=linkedin&amp;amp;logoColor=white" alt="LinkedIn" /&gt;&lt;/a&gt; &lt;a href="https://www.youtube.com/channel/UC6OTg7F4o0WkmNtSoob34lg"&gt;&lt;img src="https://img.shields.io/badge/YouTube-%23FF0000.svg?style=flat&amp;amp;logo=YouTube&amp;amp;logoColor=white" alt="YouTube" /&gt;&lt;/a&gt; &lt;a href="https://x.com/Keployio"&gt;&lt;img src="https://img.shields.io/badge/X-%231DA1F2.svg?style=flat&amp;amp;logo=X&amp;amp;logoColor=white" alt="X" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://landscape.cncf.io/?item=app-definition-and-development--continuous-integration-delivery--keploy"&gt; &lt;img src="https://img.shields.io/badge/CNCF%20Landscape-5699C6?logo=cncf&amp;amp;style=social" alt="Keploy CNCF Landscape" /&gt; &lt;/a&gt; &lt;a href="https://github.com/Keploy/Keploy/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/keploy/keploy?color=%23EAC54F&amp;amp;logo=github" alt="GitHub Stars" /&gt;&lt;/a&gt; &lt;a href="https://github.com/Keploy/Keploy/"&gt; &lt;img src="https://img.shields.io/github/stars/keploy/keploy?color=%23EAC54F&amp;amp;logo=github&amp;amp;label=Help%20us%20reach%2020K%20stars!%20Now%20at:" alt="Help us reach 20k stars!" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;a href="https://keploy.io"&gt;Keploy&lt;/a&gt; is a &lt;strong&gt;developer‚Äëcentric API and integration testing tool&lt;/strong&gt; that auto‚Äëgenerates &lt;strong&gt;tests and data‚Äëmocks&lt;/strong&gt; faster than unit tests.&lt;/p&gt; 
&lt;p&gt;It records API calls, database queries, and streaming events ‚Äî then replays them as tests. Under the hood, Keploy &lt;strong&gt;uses eBPF to capture traffic at the network layer,&lt;/strong&gt; but for you it‚Äôs completely &lt;strong&gt;code‚Äëless&lt;/strong&gt; and &lt;strong&gt;language‚Äëagnostic&lt;/strong&gt;.&lt;/p&gt; 
&lt;img align="center" src="https://raw.githubusercontent.com/keploy/docs/main/static/gif/record-replay.gif" width="100%" alt="Convert API calls to API tests test cases and Data Mocks using AI" /&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;üê∞ &lt;strong&gt;Fun fact:&lt;/strong&gt; Keploy uses itself for testing! Check out our swanky coverage badge: &lt;a href="https://coveralls.io/github/keploy/keploy?branch=main&amp;amp;kill_cache=1"&gt;&lt;img src="https://coveralls.io/repos/github/keploy/keploy/badge.svg?branch=main&amp;amp;kill_cache=1" alt="Coverage Status" /&gt;&lt;/a&gt; &amp;nbsp;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr /&gt; 
&lt;h1&gt;Key Highlights&lt;/h1&gt; 
&lt;h2&gt;üéØ No code changes&lt;/h2&gt; 
&lt;p&gt;Just run your app with &lt;code&gt;keploy record&lt;/code&gt;. Real API + integration flows are automatically captured as tests and mocks. &lt;em&gt;(Keploy uses eBPF under the hood to capture traffic, so you &lt;strong&gt;don‚Äôt need&lt;/strong&gt; to add any SDKs or modify code.)&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;üìπ Record and Replay complex Flows&lt;/h2&gt; 
&lt;p&gt;Keploy can record and replay complex, distributed API flows as mocks and stubs. It's like having a very light-weight time machine for your tests‚Äîsaving you tons of time!&lt;/p&gt; 
&lt;p&gt;üëâ &lt;a href="https://keploy.io/docs/keploy-explained/introduction/"&gt;Read the docs on record-replay&lt;/a&gt;&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/keploy/docs/main/static/gif/record-tc.gif" width="60%" alt="Convert API calls to test cases" /&gt; 
&lt;h2&gt;üêá Complete Infra‚ÄëVirtualization (beyond HTTP mocks)&lt;/h2&gt; 
&lt;p&gt;Unlike tools that only mock HTTP endpoints, Keploy records &lt;strong&gt;databases&lt;/strong&gt; (Postgres, MySQL, MongoDB), &lt;strong&gt;streaming/queues&lt;/strong&gt; (Kafka, RabbitMQ), external APIs, and more.&lt;/p&gt; 
&lt;p&gt;It replays them deterministically so you can run tests without re‚Äëprovisioning infra.&lt;/p&gt; 
&lt;p&gt;üëâ &lt;a href="https://keploy.io/docs/keploy-explained/how-keploy-works/"&gt;Read the docs on infra virtualisation&lt;/a&gt;&lt;/p&gt; 
&lt;img src="https://keploy-devrel.s3.us-west-2.amazonaws.com/Group+1261152745.png" width="100%" alt="Convert API calls to test cases" /&gt; 
&lt;h2&gt;üß™ Combined Test Coverage&lt;/h2&gt; 
&lt;p&gt;If you‚Äôre a &lt;strong&gt;developer&lt;/strong&gt;, you probably care about &lt;em&gt;statement&lt;/em&gt; and &lt;em&gt;branch&lt;/em&gt; coverage ‚Äî Keploy calculates that for you.&lt;/p&gt; 
&lt;p&gt;If you‚Äôre a &lt;strong&gt;QA&lt;/strong&gt;, you focus more on &lt;em&gt;API schema&lt;/em&gt; and &lt;em&gt;business use‚Äëcase coverage&lt;/em&gt; ‚Äî Keploy calculates that too. This way coverage isn‚Äôt subjective anymore.&lt;/p&gt; 
&lt;p&gt;üëâ &lt;a href="https://keploy.io/docs/server/sdk-installation/go/"&gt;Read the docs on coverage&lt;/a&gt;&lt;/p&gt; 
&lt;img src="https://keploy-devrel.s3.us-west-2.amazonaws.com/keploy+ai+test+gen+for+api+statement+schema+and+branch+coverage.jpg" width="100%" alt="ai test gen for api statement schema and branch coverage" /&gt; 
&lt;h2&gt;ü§ñ Expand API Coverage using AI&lt;/h2&gt; 
&lt;p&gt;Keploy uses existing recordings, Swagger/OpenAPI Schema to find: boundary values, missing/extra fields, wrong types, out‚Äëof‚Äëorder sequences, retries/timeouts.&lt;/p&gt; 
&lt;p&gt;This helps expand API Schema, Statement, and Branch Coverage.&lt;/p&gt; 
&lt;p&gt;üëâ &lt;a href="https://app.keploy.io/"&gt;Read the docs on coverage&lt;/a&gt;&lt;/p&gt; 
&lt;img src="https://keploy-devrel.s3.us-west-2.amazonaws.com/ai+test+case+generation+that+works.png" width="100%" alt="ai test gen for api statement schema and branch coverage" /&gt; 
&lt;h3&gt;Other Capabilities&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;üåê &lt;strong&gt;CI/CD Integration:&lt;/strong&gt; Run tests with mocks anywhere you like‚Äîlocally on the CLI, in your CI pipeline (Jenkins, Github Actions..) , or even across a Kubernetes cluster. &lt;a href="https://keploy.io/docs/running-keploy/api-testing-cicd/"&gt;Read more&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;üé≠ &lt;strong&gt;Multi-Purpose Mocks&lt;/strong&gt;: You can also use Keploy-generated Mocks, as server Tests!&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;üìä &lt;strong&gt;Reporting:&lt;/strong&gt; Unified reports for API, integration, unit, and e2e coverage with insights directly in your CI or PRs.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;üñ•Ô∏è &lt;strong&gt;Console:&lt;/strong&gt; A developer-friendly console to view, manage, and debug recorded tests and mocks.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;‚è±Ô∏è &lt;strong&gt;Time Freezing:&lt;/strong&gt; Deterministically replay tests by freezing system time during execution. &lt;a href="https://keploy.io/docs/keploy-cloud/time-freezing/"&gt;Read more&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;üìö &lt;strong&gt;Mock Registry:&lt;/strong&gt; Centralized registry to manage, reuse, and version mocks across teams and environments. &lt;a href="https://keploy.io/docs/keploy-cloud/mock-registry/"&gt;Read more&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;h3&gt;1. Install Keploy Agent&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl --silent -O -L https://keploy.io/install.sh &amp;amp;&amp;amp; source install.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. Record Test Cases&lt;/h3&gt; 
&lt;p&gt;Start your app under Keploy to convert real API calls into tests and mocks.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;keploy record -c "CMD_TO_RUN_APP"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Example for Python:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;keploy record -c "python main.py"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;3. Run Tests&lt;/h3&gt; 
&lt;p&gt;Run tests offline without external dependencies.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;keploy test -c "CMD_TO_RUN_APP" --delay 10
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Resources&lt;/h2&gt; 
&lt;h3&gt;- üìò &lt;a href="https://keploy.io/docs/server/installation/"&gt;Installation&lt;/a&gt;&lt;/h3&gt; 
&lt;h3&gt;- üèÅ &lt;a href="https://keploy.io/docs/quickstart/quickstart-filter/"&gt;QuickStarts&lt;/a&gt;&lt;/h3&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Languages &amp;amp; Frameworks (Any stack)&lt;/h2&gt; 
&lt;p&gt;Because Keploy intercepts at the &lt;strong&gt;network layer (eBPF)&lt;/strong&gt;, it works with &lt;strong&gt;any language, framework, or runtime&lt;/strong&gt;‚Äîno SDK required.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Note: Some of the dependencies are not open-source by nature because their protocols and parsings are not open-sourced. It's not supported in Keploy enterprise.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p align="center"&gt; 
 &lt;!-- Languages --&gt; &lt;img src="https://img.shields.io/badge/Go-00ADD8?logo=go&amp;amp;logoColor=white" /&gt; &lt;img src="https://img.shields.io/badge/Java-ED8B00?logo=openjdk&amp;amp;logoColor=white" /&gt; &lt;img src="https://img.shields.io/badge/Node.js-43853D?logo=node.js&amp;amp;logoColor=white" /&gt; &lt;img src="https://img.shields.io/badge/Python-3776AB?logo=python&amp;amp;logoColor=white" /&gt; &lt;img src="https://img.shields.io/badge/Rust-000000?logo=rust&amp;amp;logoColor=white" /&gt; &lt;img src="https://img.shields.io/badge/C%23-239120?logo=csharp&amp;amp;logoColor=white" /&gt; &lt;img src="https://img.shields.io/badge/C/C++-00599C?logo=cplusplus&amp;amp;logoColor=white" /&gt; &lt;img src="https://img.shields.io/badge/TypeScript-3178C6?logo=typescript&amp;amp;logoColor=white" /&gt; &lt;img src="https://img.shields.io/badge/Scala-DC322F?logo=scala&amp;amp;logoColor=white" /&gt; &lt;img src="https://img.shields.io/badge/Kotlin-7F52FF?logo=kotlin&amp;amp;logoColor=white" /&gt; &lt;img src="https://img.shields.io/badge/Swift-FA7343?logo=swift&amp;amp;logoColor=white" /&gt; &lt;img src="https://img.shields.io/badge/Dart-0175C2?logo=dart&amp;amp;logoColor=white" /&gt; &lt;img src="https://img.shields.io/badge/PHP-777BB4?logo=php&amp;amp;logoColor=white" /&gt; &lt;img src="https://img.shields.io/badge/Ruby-CC342D?logo=ruby&amp;amp;logoColor=white" /&gt; &lt;img src="https://img.shields.io/badge/Elixir-4B275F?logo=elixir&amp;amp;logoColor=white" /&gt; &lt;img src="https://img.shields.io/badge/.NET-512BD4?logo=dotnet&amp;amp;logoColor=white" /&gt; 
 &lt;!-- Protocols &amp;amp; infra commonly virtualized --&gt; &lt;img src="https://img.shields.io/badge/gRPC-5E35B1?logo=grpc&amp;amp;logoColor=white" /&gt; &lt;img src="https://img.shields.io/badge/GraphQL-E10098?logo=graphql&amp;amp;logoColor=white" /&gt; &lt;img src="https://img.shields.io/badge/HTTP%2FREST-0A84FF?logo=httpie&amp;amp;logoColor=white" /&gt; &lt;img src="https://img.shields.io/badge/Kafka-231F20?logo=apachekafka&amp;amp;logoColor=white" /&gt; &lt;img src="https://img.shields.io/badge/RabbitMQ-FF6600?logo=rabbitmq&amp;amp;logoColor=white" /&gt; &lt;img src="https://img.shields.io/badge/PostgreSQL-4169E1?logo=postgresql&amp;amp;logoColor=white" /&gt; &lt;img src="https://img.shields.io/badge/MySQL-4479A1?logo=mysql&amp;amp;logoColor=white" /&gt; &lt;img src="https://img.shields.io/badge/MongoDB-47A248?logo=mongodb&amp;amp;logoColor=white" /&gt; &lt;img src="https://img.shields.io/badge/Redis-DC382D?logo=redis&amp;amp;logoColor=white" /&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Questions?&lt;/h2&gt; 
&lt;h3&gt;Book a Live Demo / Enterprise Support&lt;/h3&gt; 
&lt;p&gt;Want a guided walkthrough, dedicated support, or help planning enterprise rollout?&lt;/p&gt; 
&lt;p&gt; &lt;a href="https://calendar.app.google/4ZKd1nz9A5wLuP4W7"&gt; &lt;img src="https://img.shields.io/badge/Request%20a%20Demo-Email-2ea44f?logo=gmail" /&gt; &lt;/a&gt; &amp;nbsp; &lt;a href="https://join.slack.com/t/keploy/shared_invite/zt-357qqm9b5-PbZRVu3Yt2rJIa6ofrwWNg"&gt; &lt;img src="https://img.shields.io/badge/Chat%20with%20Us-Slack-4A154B?logo=slack&amp;amp;logoColor=white" /&gt; &lt;/a&gt; 
 &lt;!-- Optional: replace with your scheduling link (Cal.com/Calendly) --&gt; 
 &lt;!-- &lt;a href="https://cal.com/keploy/demo"&gt;&lt;img src="https://img.shields.io/badge/Book%20via%20Calendar-Cal.com-111111" /&gt;&lt;/a&gt; --&gt; &lt;/p&gt; 
&lt;p&gt;Prefer a calendar invite? Mention your availability in the email‚Äîwe‚Äôll send a &lt;strong&gt;calendar invite&lt;/strong&gt; right away.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Documentation &amp;amp; Community&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üìò &lt;a href="https://keploy.io/docs/"&gt;Documentation&lt;/a&gt; ‚Äî Explore the full docs&lt;/li&gt; 
 &lt;li&gt;üí¨ &lt;a href="https://join.slack.com/t/keploy/shared_invite/zt-357qqm9b5-PbZRVu3Yt2rJIa6ofrwWNg"&gt;Slack Community&lt;/a&gt; ‚Äî Join the conversation&lt;/li&gt; 
 &lt;li&gt;üìú &lt;a href="https://keploy.io/docs/keploy-explained/contribution-guide/"&gt;Contribution Guidelines&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;‚ù§Ô∏è &lt;a href="https://github.com/keploy/keploy/raw/main/CODE_OF_CONDUCT.md"&gt;Code of Conduct&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üì¢ &lt;a href="https://keploy.io/blog/"&gt;Blog&lt;/a&gt; ‚Äî Read articles and updates&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Contribute &amp;amp; Collaborate&lt;/h2&gt; 
&lt;p&gt;Whether you're new or experienced, your input matters. Help us improve Keploy by contributing code, reporting issues, or sharing feedback.&lt;/p&gt; 
&lt;p&gt;Together, let's build better testing tools for modern applications.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>googleapis/genai-toolbox</title>
      <link>https://github.com/googleapis/genai-toolbox</link>
      <description>&lt;p&gt;MCP Toolbox for Databases is an open source MCP server for databases.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/logo.png" alt="logo" /&gt;&lt;/p&gt; 
&lt;h1&gt;MCP Toolbox for Databases&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://googleapis.github.io/genai-toolbox/"&gt;&lt;img src="https://img.shields.io/badge/docs-MCP_Toolbox-blue" alt="Docs" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/Dmm69peqjh"&gt;&lt;img src="https://img.shields.io/badge/Discord-%235865F2.svg?style=flat&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://medium.com/@mcp_toolbox"&gt;&lt;img src="https://img.shields.io/badge/Medium-12100E?style=flat&amp;amp;logo=medium&amp;amp;logoColor=white" alt="Medium" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/googleapis/genai-toolbox"&gt;&lt;img src="https://goreportcard.com/badge/github.com/googleapis/genai-toolbox" alt="Go Report Card" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] MCP Toolbox for Databases is currently in beta, and may see breaking changes until the first stable release (v1.0).&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;MCP Toolbox for Databases is an open source MCP server for databases. It enables you to develop tools easier, faster, and more securely by handling the complexities such as connection pooling, authentication, and more.&lt;/p&gt; 
&lt;p&gt;This README provides a brief overview. For comprehensive details, see the &lt;a href="https://googleapis.github.io/genai-toolbox/"&gt;full documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] This solution was originally named ‚ÄúGen AI Toolbox for Databases‚Äù as its initial development predated MCP, but was renamed to align with recently added MCP compatibility.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;!-- TOC ignore:true --&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;!-- TOC --&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#why-toolbox"&gt;Why Toolbox?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#general-architecture"&gt;General Architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#getting-started"&gt;Getting Started&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#installing-the-server"&gt;Installing the server&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#running-the-server"&gt;Running the server&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#integrating-your-application"&gt;Integrating your application&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#using-toolbox-with-gemini-cli-extensions"&gt;Using Toolbox with Gemini CLI Extensions&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#configuration"&gt;Configuration&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#sources"&gt;Sources&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#tools"&gt;Tools&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#toolsets"&gt;Toolsets&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#prompts"&gt;Prompts&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#versioning"&gt;Versioning&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#pre-100-versioning"&gt;Pre-1.0.0 Versioning&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#post-100-versioning"&gt;Post-1.0.0 Versioning&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#community"&gt;Community&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- /TOC --&gt; 
&lt;h2&gt;Why Toolbox?&lt;/h2&gt; 
&lt;p&gt;Toolbox helps you build Gen AI tools that let your agents access data in your database. Toolbox provides:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Simplified development&lt;/strong&gt;: Integrate tools to your agent in less than 10 lines of code, reuse tools between multiple agents or frameworks, and deploy new versions of tools more easily.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Better performance&lt;/strong&gt;: Best practices such as connection pooling, authentication, and more.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enhanced security&lt;/strong&gt;: Integrated auth for more secure access to your data&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;End-to-end observability&lt;/strong&gt;: Out of the box metrics and tracing with built-in support for OpenTelemetry.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;‚ö° Supercharge Your Workflow with an AI Database Assistant ‚ö°&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Stop context-switching and let your AI assistant become a true co-developer. By &lt;a href="https://googleapis.github.io/genai-toolbox/how-to/connect-ide/"&gt;connecting your IDE to your databases with MCP Toolbox&lt;/a&gt;, you can delegate complex and time-consuming database tasks, allowing you to build faster and focus on what matters. This isn't just about code completion; it's about giving your AI the context it needs to handle the entire development lifecycle.&lt;/p&gt; 
&lt;p&gt;Here‚Äôs how it will save you time:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Query in Plain English&lt;/strong&gt;: Interact with your data using natural language right from your IDE. Ask complex questions like, &lt;em&gt;"How many orders were delivered in 2024, and what items were in them?"&lt;/em&gt; without writing any SQL.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Automate Database Management&lt;/strong&gt;: Simply describe your data needs, and let the AI assistant manage your database for you. It can handle generating queries, creating tables, adding indexes, and more.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Generate Context-Aware Code&lt;/strong&gt;: Empower your AI assistant to generate application code and tests with a deep understanding of your real-time database schema. This accelerates the development cycle by ensuring the generated code is directly usable.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Slash Development Overhead&lt;/strong&gt;: Radically reduce the time spent on manual setup and boilerplate. MCP Toolbox helps streamline lengthy database configurations, repetitive code, and error-prone schema migrations.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Learn &lt;a href="https://googleapis.github.io/genai-toolbox/how-to/connect-ide/"&gt;how to connect your AI tools (IDEs) to Toolbox using MCP&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;General Architecture&lt;/h2&gt; 
&lt;p&gt;Toolbox sits between your application's orchestration framework and your database, providing a control plane that is used to modify, distribute, or invoke tools. It simplifies the management of your tools by providing you with a centralized location to store and update tools, allowing you to share tools between agents and applications and update those tools without necessarily redeploying your application.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/docs/en/getting-started/introduction/architecture.png" alt="architecture" width="50%" /&gt; &lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;h3&gt;(Non-production) Running Toolbox&lt;/h3&gt; 
&lt;p&gt;You can run Toolbox directly with a &lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#configuration"&gt;configuration file&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;npx @toolbox-sdk/server --tools-file tools.yaml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This runs the latest version of the toolbox server with your configuration file.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] This method should only be used for non-production use cases such as experimentation. For any production use-cases, please consider &lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#installing-the-server"&gt;Installing the server&lt;/a&gt; and then &lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#running-the-server"&gt;running it&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Installing the server&lt;/h3&gt; 
&lt;p&gt;For the latest version, check the &lt;a href="https://github.com/googleapis/genai-toolbox/releases"&gt;releases page&lt;/a&gt; and use the following instructions for your OS and CPU architecture.&lt;/p&gt; 
&lt;details open&gt; 
 &lt;summary&gt;Binary&lt;/summary&gt; 
 &lt;p&gt;To install Toolbox as a binary:&lt;/p&gt; 
 &lt;!-- {x-release-please-start-version} --&gt; 
 &lt;blockquote&gt; 
  &lt;details&gt; 
   &lt;summary&gt;Linux (AMD64)&lt;/summary&gt; 
   &lt;p&gt;To install Toolbox as a binary on Linux (AMD64):&lt;/p&gt; 
   &lt;pre&gt;&lt;code class="language-sh"&gt;# see releases page for other versions
export VERSION=0.25.0
curl -L -o toolbox https://storage.googleapis.com/genai-toolbox/v$VERSION/linux/amd64/toolbox
chmod +x toolbox
&lt;/code&gt;&lt;/pre&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt;macOS (Apple Silicon)&lt;/summary&gt; 
   &lt;p&gt;To install Toolbox as a binary on macOS (Apple Silicon):&lt;/p&gt; 
   &lt;pre&gt;&lt;code class="language-sh"&gt;# see releases page for other versions
export VERSION=0.25.0
curl -L -o toolbox https://storage.googleapis.com/genai-toolbox/v$VERSION/darwin/arm64/toolbox
chmod +x toolbox
&lt;/code&gt;&lt;/pre&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt;macOS (Intel)&lt;/summary&gt; 
   &lt;p&gt;To install Toolbox as a binary on macOS (Intel):&lt;/p&gt; 
   &lt;pre&gt;&lt;code class="language-sh"&gt;# see releases page for other versions
export VERSION=0.25.0
curl -L -o toolbox https://storage.googleapis.com/genai-toolbox/v$VERSION/darwin/amd64/toolbox
chmod +x toolbox
&lt;/code&gt;&lt;/pre&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt;Windows (Command Prompt)&lt;/summary&gt; 
   &lt;p&gt;To install Toolbox as a binary on Windows (Command Prompt):&lt;/p&gt; 
   &lt;pre&gt;&lt;code class="language-cmd"&gt;:: see releases page for other versions
set VERSION=0.25.0
curl -o toolbox.exe "https://storage.googleapis.com/genai-toolbox/v%VERSION%/windows/amd64/toolbox.exe"
&lt;/code&gt;&lt;/pre&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt;Windows (PowerShell)&lt;/summary&gt; 
   &lt;p&gt;To install Toolbox as a binary on Windows (PowerShell):&lt;/p&gt; 
   &lt;pre&gt;&lt;code class="language-powershell"&gt;# see releases page for other versions
$VERSION = "0.25.0"
curl.exe -o toolbox.exe "https://storage.googleapis.com/genai-toolbox/v$VERSION/windows/amd64/toolbox.exe"
&lt;/code&gt;&lt;/pre&gt; 
  &lt;/details&gt; 
 &lt;/blockquote&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Container image&lt;/summary&gt; You can also install Toolbox as a container: 
 &lt;pre&gt;&lt;code class="language-sh"&gt;# see releases page for other versions
export VERSION=0.25.0
docker pull us-central1-docker.pkg.dev/database-toolbox/toolbox/toolbox:$VERSION
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Homebrew&lt;/summary&gt; 
 &lt;p&gt;To install Toolbox using Homebrew on macOS or Linux:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-sh"&gt;brew install mcp-toolbox
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Compile from source&lt;/summary&gt; 
 &lt;p&gt;To install from source, ensure you have the latest version of &lt;a href="https://go.dev/doc/install"&gt;Go installed&lt;/a&gt;, and then run the following command:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-sh"&gt;go install github.com/googleapis/genai-toolbox@v0.25.0
&lt;/code&gt;&lt;/pre&gt; 
 &lt;!-- {x-release-please-end} --&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Gemini CLI Extensions&lt;/summary&gt; 
 &lt;p&gt;To install Gemini CLI Extensions for MCP Toolbox, run the following command:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-sh"&gt;gemini extensions install https://github.com/gemini-cli-extensions/mcp-toolbox
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;Running the server&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#configuration"&gt;Configure&lt;/a&gt; a &lt;code&gt;tools.yaml&lt;/code&gt; to define your tools, and then execute &lt;code&gt;toolbox&lt;/code&gt; to start the server:&lt;/p&gt; 
&lt;details open&gt; 
 &lt;summary&gt;Binary&lt;/summary&gt; 
 &lt;p&gt;To run Toolbox from binary:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-sh"&gt;./toolbox --tools-file "tools.yaml"
&lt;/code&gt;&lt;/pre&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;‚ìò Note&lt;br /&gt; Toolbox enables dynamic reloading by default. To disable, use the &lt;code&gt;--disable-reload&lt;/code&gt; flag.&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Container image&lt;/summary&gt; 
 &lt;p&gt;To run the server after pulling the &lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/#installing-the-server"&gt;container image&lt;/a&gt;:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-sh"&gt;export VERSION=0.24.0 # Use the version you pulled
docker run -p 5000:5000 \
-v $(pwd)/tools.yaml:/app/tools.yaml \
us-central1-docker.pkg.dev/database-toolbox/toolbox/toolbox:$VERSION \
--tools-file "/app/tools.yaml"
&lt;/code&gt;&lt;/pre&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;‚ìò Note&lt;br /&gt; The &lt;code&gt;-v&lt;/code&gt; flag mounts your local &lt;code&gt;tools.yaml&lt;/code&gt; into the container, and &lt;code&gt;-p&lt;/code&gt; maps the container's port &lt;code&gt;5000&lt;/code&gt; to your host's port &lt;code&gt;5000&lt;/code&gt;.&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Source&lt;/summary&gt; 
 &lt;p&gt;To run the server directly from source, navigate to the project root directory and run:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-sh"&gt;go run .
&lt;/code&gt;&lt;/pre&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;‚ìò Note&lt;br /&gt; This command runs the project from source, and is more suitable for development and testing. It does &lt;strong&gt;not&lt;/strong&gt; compile a binary into your &lt;code&gt;$GOPATH&lt;/code&gt;. If you want to compile a binary instead, refer the &lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/DEVELOPER.md#building-the-binary"&gt;Developer Documentation&lt;/a&gt;.&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Homebrew&lt;/summary&gt; 
 &lt;p&gt;If you installed Toolbox using &lt;a href="https://brew.sh/"&gt;Homebrew&lt;/a&gt;, the &lt;code&gt;toolbox&lt;/code&gt; binary is available in your system path. You can start the server with the same command:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-sh"&gt;toolbox --tools-file "tools.yaml"
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;NPM&lt;/summary&gt; 
 &lt;p&gt;To run Toolbox directly without manually downloading the binary (requires Node.js):&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-sh"&gt;npx @toolbox-sdk/server --tools-file tools.yaml
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Gemini CLI&lt;/summary&gt; 
 &lt;p&gt;Interact with your custom tools using natural language. Check &lt;a href="https://github.com/gemini-cli-extensions/mcp-toolbox"&gt;gemini-cli-extensions/mcp-toolbox&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;/details&gt; 
&lt;p&gt;You can use &lt;code&gt;toolbox help&lt;/code&gt; for a full list of flags! To stop the server, send a terminate signal (&lt;code&gt;ctrl+c&lt;/code&gt; on most platforms).&lt;/p&gt; 
&lt;p&gt;For more detailed documentation on deploying to different environments, check out the resources in the &lt;a href="https://googleapis.github.io/genai-toolbox/how-to/"&gt;How-to section&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Integrating your application&lt;/h3&gt; 
&lt;p&gt;Once your server is up and running, you can load the tools into your application. See below the list of Client SDKs for using various frameworks:&lt;/p&gt; 
&lt;details open&gt; 
 &lt;summary&gt;Python (&lt;a href="https://github.com/googleapis/mcp-toolbox-sdk-python"&gt;Github&lt;/a&gt;)&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;blockquote&gt; 
  &lt;details open&gt; 
   &lt;summary&gt;Core&lt;/summary&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;Install &lt;a href="https://pypi.org/project/toolbox-core/"&gt;Toolbox Core SDK&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pip install toolbox-core
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;Load tools:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;from toolbox_core import ToolboxClient

# update the url to point to your server
async with ToolboxClient("http://127.0.0.1:5000") as client:

    # these tools can be passed to your application!
    tools = await client.load_toolset("toolset_name")
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;p&gt;For more detailed instructions on using the Toolbox Core SDK, see the &lt;a href="https://github.com/googleapis/mcp-toolbox-sdk-python/tree/main/packages/toolbox-core/README.md"&gt;project's README&lt;/a&gt;.&lt;/p&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt;LangChain / LangGraph&lt;/summary&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;Install &lt;a href="https://pypi.org/project/toolbox-langchain/"&gt;Toolbox LangChain SDK&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pip install toolbox-langchain
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;Load tools:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;from toolbox_langchain import ToolboxClient

# update the url to point to your server
async with ToolboxClient("http://127.0.0.1:5000") as client:

    # these tools can be passed to your application!
    tools = client.load_toolset()
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;For more detailed instructions on using the Toolbox LangChain SDK, see the &lt;a href="https://github.com/googleapis/mcp-toolbox-sdk-python/raw/main/packages/toolbox-langchain/README.md"&gt;project's README&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt;LlamaIndex&lt;/summary&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;Install &lt;a href="https://pypi.org/project/toolbox-llamaindex/"&gt;Toolbox Llamaindex SDK&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pip install toolbox-llamaindex
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;Load tools:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;from toolbox_llamaindex import ToolboxClient

# update the url to point to your server
async with ToolboxClient("http://127.0.0.1:5000") as client:

    # these tools can be passed to your application!
    tools = client.load_toolset()
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;For more detailed instructions on using the Toolbox Llamaindex SDK, see the &lt;a href="https://github.com/googleapis/genai-toolbox-llamaindex-python/raw/main/README.md"&gt;project's README&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
  &lt;/details&gt; 
 &lt;/blockquote&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;Javascript/Typescript (&lt;a href="https://github.com/googleapis/mcp-toolbox-sdk-js"&gt;Github&lt;/a&gt;)&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;blockquote&gt; 
  &lt;details open&gt; 
   &lt;summary&gt;Core&lt;/summary&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;Install &lt;a href="https://www.npmjs.com/package/@toolbox-sdk/core"&gt;Toolbox Core SDK&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;npm install @toolbox-sdk/core
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;Load tools:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-javascript"&gt;import { ToolboxClient } from '@toolbox-sdk/core';

// update the url to point to your server
const URL = 'http://127.0.0.1:5000';
let client = new ToolboxClient(URL);

// these tools can be passed to your application!
const tools = await client.loadToolset('toolsetName');
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;For more detailed instructions on using the Toolbox Core SDK, see the &lt;a href="https://github.com/googleapis/mcp-toolbox-sdk-js/raw/main/packages/toolbox-core/README.md"&gt;project's README&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt;LangChain / LangGraph&lt;/summary&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;Install &lt;a href="https://www.npmjs.com/package/@toolbox-sdk/core"&gt;Toolbox Core SDK&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;npm install @toolbox-sdk/core
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;Load tools:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-javascript"&gt;import { ToolboxClient } from '@toolbox-sdk/core';

// update the url to point to your server
const URL = 'http://127.0.0.1:5000';
let client = new ToolboxClient(URL);

// these tools can be passed to your application!
const toolboxTools = await client.loadToolset('toolsetName');

// Define the basics of the tool: name, description, schema and core logic
const getTool = (toolboxTool) =&amp;gt; tool(currTool, {
    name: toolboxTool.getName(),
    description: toolboxTool.getDescription(),
    schema: toolboxTool.getParamSchema()
});

// Use these tools in your Langchain/Langraph applications
const tools = toolboxTools.map(getTool);
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt;Genkit&lt;/summary&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;Install &lt;a href="https://www.npmjs.com/package/@toolbox-sdk/core"&gt;Toolbox Core SDK&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;npm install @toolbox-sdk/core
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;Load tools:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-javascript"&gt;import { ToolboxClient } from '@toolbox-sdk/core';
import { genkit } from 'genkit';

// Initialise genkit
const ai = genkit({
    plugins: [
        googleAI({
            apiKey: process.env.GEMINI_API_KEY || process.env.GOOGLE_API_KEY
        })
    ],
    model: googleAI.model('gemini-2.0-flash'),
});

// update the url to point to your server
const URL = 'http://127.0.0.1:5000';
let client = new ToolboxClient(URL);

// these tools can be passed to your application!
const toolboxTools = await client.loadToolset('toolsetName');

// Define the basics of the tool: name, description, schema and core logic
const getTool = (toolboxTool) =&amp;gt; ai.defineTool({
    name: toolboxTool.getName(),
    description: toolboxTool.getDescription(),
    schema: toolboxTool.getParamSchema()
}, toolboxTool)

// Use these tools in your Genkit applications
const tools = toolboxTools.map(getTool);
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt;ADK&lt;/summary&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;Install &lt;a href="https://www.npmjs.com/package/@toolbox-sdk/adk"&gt;Toolbox ADK SDK&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;npm install @toolbox-sdk/adk
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;Load tools:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-javascript"&gt;import { ToolboxClient } from '@toolbox-sdk/adk';

// update the url to point to your server
const URL = 'http://127.0.0.1:5000';
let client = new ToolboxClient(URL);

// these tools can be passed to your application!
const tools = await client.loadToolset('toolsetName');
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;For more detailed instructions on using the Toolbox ADK SDK, see the &lt;a href="https://github.com/googleapis/mcp-toolbox-sdk-js/raw/main/packages/toolbox-adk/README.md"&gt;project's README&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
  &lt;/details&gt; 
 &lt;/blockquote&gt;
&lt;/details&gt;  
&lt;details&gt; 
 &lt;summary&gt;Go (&lt;a href="https://github.com/googleapis/mcp-toolbox-sdk-go"&gt;Github&lt;/a&gt;)&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;blockquote&gt; 
  &lt;details&gt; 
   &lt;summary&gt;Core&lt;/summary&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;Install &lt;a href="https://pkg.go.dev/github.com/googleapis/mcp-toolbox-sdk-go/core"&gt;Toolbox Go SDK&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;go get github.com/googleapis/mcp-toolbox-sdk-go
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;Load tools:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-go"&gt;package main

import (
  "github.com/googleapis/mcp-toolbox-sdk-go/core"
  "context"
)

func main() {
  // Make sure to add the error checks
  // update the url to point to your server
  URL := "http://127.0.0.1:5000";
  ctx := context.Background()

  client, err := core.NewToolboxClient(URL)

  // Framework agnostic tools
  tools, err := client.LoadToolset("toolsetName", ctx)
}
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;For more detailed instructions on using the Toolbox Go SDK, see the &lt;a href="https://github.com/googleapis/mcp-toolbox-sdk-go/raw/main/core/README.md"&gt;project's README&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt;LangChain Go&lt;/summary&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;Install &lt;a href="https://pkg.go.dev/github.com/googleapis/mcp-toolbox-sdk-go/core"&gt;Toolbox Go SDK&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;go get github.com/googleapis/mcp-toolbox-sdk-go
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;Load tools:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-go"&gt;package main

import (
  "context"
  "encoding/json"

  "github.com/googleapis/mcp-toolbox-sdk-go/core"
  "github.com/tmc/langchaingo/llms"
)

func main() {
  // Make sure to add the error checks
  // update the url to point to your server
  URL := "http://127.0.0.1:5000"
  ctx := context.Background()

  client, err := core.NewToolboxClient(URL)

  // Framework agnostic tool
  tool, err := client.LoadTool("toolName", ctx)

  // Fetch the tool's input schema
  inputschema, err := tool.InputSchema()

  var paramsSchema map[string]any
  _ = json.Unmarshal(inputschema, &amp;amp;paramsSchema)

  // Use this tool with LangChainGo
  langChainTool := llms.Tool{
    Type: "function",
    Function: &amp;amp;llms.FunctionDefinition{
      Name:        tool.Name(),
      Description: tool.Description(),
      Parameters:  paramsSchema,
    },
  }
}

&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt;Genkit&lt;/summary&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;Install &lt;a href="https://pkg.go.dev/github.com/googleapis/mcp-toolbox-sdk-go/core"&gt;Toolbox Go SDK&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;go get github.com/googleapis/mcp-toolbox-sdk-go
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;Load tools:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-go"&gt;package main
import (
  "context"
  "log"

  "github.com/firebase/genkit/go/genkit"
  "github.com/googleapis/mcp-toolbox-sdk-go/core"
  "github.com/googleapis/mcp-toolbox-sdk-go/tbgenkit"
)

func main() {
  // Make sure to add the error checks
  // Update the url to point to your server
  URL := "http://127.0.0.1:5000"
  ctx := context.Background()
  g := genkit.Init(ctx)

  client, err := core.NewToolboxClient(URL)

  // Framework agnostic tool
  tool, err := client.LoadTool("toolName", ctx)

  // Convert the tool using the tbgenkit package
  // Use this tool with Genkit Go
  genkitTool, err := tbgenkit.ToGenkitTool(tool, g)
  if err != nil {
    log.Fatalf("Failed to convert tool: %v\n", err)
  }
  log.Printf("Successfully converted tool: %s", genkitTool.Name())
}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt;Go GenAI&lt;/summary&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;Install &lt;a href="https://pkg.go.dev/github.com/googleapis/mcp-toolbox-sdk-go/core"&gt;Toolbox Go SDK&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;go get github.com/googleapis/mcp-toolbox-sdk-go
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;Load tools:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-go"&gt;package main

import (
  "context"
  "encoding/json"

  "github.com/googleapis/mcp-toolbox-sdk-go/core"
  "google.golang.org/genai"
)

func main() {
  // Make sure to add the error checks
  // Update the url to point to your server
  URL := "http://127.0.0.1:5000"
  ctx := context.Background()

  client, err := core.NewToolboxClient(URL)

  // Framework agnostic tool
  tool, err := client.LoadTool("toolName", ctx)

  // Fetch the tool's input schema
  inputschema, err := tool.InputSchema()

  var schema *genai.Schema
  _ = json.Unmarshal(inputschema, &amp;amp;schema)

  funcDeclaration := &amp;amp;genai.FunctionDeclaration{
    Name:        tool.Name(),
    Description: tool.Description(),
    Parameters:  schema,
  }

  // Use this tool with Go GenAI
  genAITool := &amp;amp;genai.Tool{
    FunctionDeclarations: []*genai.FunctionDeclaration{funcDeclaration},
  }
}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt;OpenAI Go&lt;/summary&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;Install &lt;a href="https://pkg.go.dev/github.com/googleapis/mcp-toolbox-sdk-go/core"&gt;Toolbox Go SDK&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;go get github.com/googleapis/mcp-toolbox-sdk-go
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;Load tools:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-go"&gt;package main

import (
  "context"
  "encoding/json"

  "github.com/googleapis/mcp-toolbox-sdk-go/core"
  openai "github.com/openai/openai-go"
)

func main() {
  // Make sure to add the error checks
  // Update the url to point to your server
  URL := "http://127.0.0.1:5000"
  ctx := context.Background()

  client, err := core.NewToolboxClient(URL)

  // Framework agnostic tool
  tool, err := client.LoadTool("toolName", ctx)

  // Fetch the tool's input schema
  inputschema, err := tool.InputSchema()

  var paramsSchema openai.FunctionParameters
  _ = json.Unmarshal(inputschema, &amp;amp;paramsSchema)

  // Use this tool with OpenAI Go
  openAITool := openai.ChatCompletionToolParam{
    Function: openai.FunctionDefinitionParam{
      Name:        tool.Name(),
      Description: openai.String(tool.Description()),
      Parameters:  paramsSchema,
    },
  }

}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
  &lt;/details&gt; 
  &lt;details open&gt; 
   &lt;summary&gt;ADK Go&lt;/summary&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;Install &lt;a href="https://pkg.go.dev/github.com/googleapis/mcp-toolbox-sdk-go/core"&gt;Toolbox Go SDK&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;go get github.com/googleapis/mcp-toolbox-sdk-go
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;Load tools:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-go"&gt;package main

import (
  "github.com/googleapis/mcp-toolbox-sdk-go/tbadk"
  "context"
)

func main() {
  // Make sure to add the error checks
  // Update the url to point to your server
  URL := "http://127.0.0.1:5000"
  ctx := context.Background()
  client, err := tbadk.NewToolboxClient(URL)
  if err != nil {
    return fmt.Sprintln("Could not start Toolbox Client", err)
  }

  // Use this tool with ADK Go
  tool, err := client.LoadTool("toolName", ctx)
  if err != nil {
    return fmt.Sprintln("Could not load Toolbox Tool", err)
  }
}
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;For more detailed instructions on using the Toolbox Go SDK, see the &lt;a href="https://github.com/googleapis/mcp-toolbox-sdk-go/raw/main/core/README.md"&gt;project's README&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
  &lt;/details&gt; 
 &lt;/blockquote&gt;
&lt;/details&gt;   
&lt;h3&gt;Using Toolbox with Gemini CLI Extensions&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/google-gemini/gemini-cli/raw/main/docs/extensions/index.md"&gt;Gemini CLI extensions&lt;/a&gt; provide tools to interact directly with your data sources from command line. Below is a list of Gemini CLI extensions that are built on top of &lt;strong&gt;Toolbox&lt;/strong&gt;. They allow you to interact with your data sources through pre-defined or custom tools with natural language. Click into the link to see detailed instructions on their usage.&lt;/p&gt; 
&lt;p&gt;To use &lt;strong&gt;custom&lt;/strong&gt; tools with Gemini CLI:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gemini-cli-extensions/mcp-toolbox"&gt;MCP Toolbox&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To use &lt;a href="https://googleapis.github.io/genai-toolbox/reference/prebuilt-tools/"&gt;prebuilt tools&lt;/a&gt; with Gemini CLI:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gemini-cli-extensions/alloydb"&gt;AlloyDB for PostgreSQL&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gemini-cli-extensions/alloydb-observability"&gt;AlloyDB for PostgreSQL Observability&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gemini-cli-extensions/bigquery-data-analytics"&gt;BigQuery Data Analytics&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gemini-cli-extensions/bigquery-conversational-analytics"&gt;BigQuery Conversational Analytics&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gemini-cli-extensions/cloud-sql-mysql"&gt;Cloud SQL for MySQL&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gemini-cli-extensions/cloud-sql-mysql-observability"&gt;Cloud SQL for MySQL Observability&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gemini-cli-extensions/cloud-sql-postgresql"&gt;Cloud SQL for PostgreSQL&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gemini-cli-extensions/cloud-sql-postgresql-observability"&gt;Cloud SQL for PostgreSQL Observability&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gemini-cli-extensions/cloud-sql-sqlserver"&gt;Cloud SQL for SQL Server&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gemini-cli-extensions/cloud-sql-sqlserver-observability"&gt;Cloud SQL for SQL Server Observability&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gemini-cli-extensions/looker"&gt;Looker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gemini-cli-extensions/dataplex"&gt;Dataplex&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gemini-cli-extensions/mysql"&gt;MySQL&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gemini-cli-extensions/postgres"&gt;PostgreSQL&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gemini-cli-extensions/spanner"&gt;Spanner&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gemini-cli-extensions/firestore-native"&gt;Firestore&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gemini-cli-extensions/sql-server"&gt;SQL Server&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Configuration&lt;/h2&gt; 
&lt;p&gt;The primary way to configure Toolbox is through the &lt;code&gt;tools.yaml&lt;/code&gt; file. If you have multiple files, you can tell toolbox which to load with the &lt;code&gt;--tools-file tools.yaml&lt;/code&gt; flag.&lt;/p&gt; 
&lt;p&gt;You can find more detailed reference documentation to all resource types in the &lt;a href="https://googleapis.github.io/genai-toolbox/resources/"&gt;Resources&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Sources&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;sources&lt;/code&gt; section of your &lt;code&gt;tools.yaml&lt;/code&gt; defines what data sources your Toolbox should have access to. Most tools will have at least one source to execute against.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;sources:
  my-pg-source:
    kind: postgres
    host: 127.0.0.1
    port: 5432
    database: toolbox_db
    user: toolbox_user
    password: my-password
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more details on configuring different types of sources, see the &lt;a href="https://googleapis.github.io/genai-toolbox/resources/sources"&gt;Sources&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Tools&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;tools&lt;/code&gt; section of a &lt;code&gt;tools.yaml&lt;/code&gt; define the actions an agent can take: what kind of tool it is, which source(s) it affects, what parameters it uses, etc.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;tools:
  search-hotels-by-name:
    kind: postgres-sql
    source: my-pg-source
    description: Search for hotels based on name.
    parameters:
      - name: name
        type: string
        description: The name of the hotel.
    statement: SELECT * FROM hotels WHERE name ILIKE '%' || $1 || '%';
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more details on configuring different types of tools, see the &lt;a href="https://googleapis.github.io/genai-toolbox/resources/tools"&gt;Tools&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Toolsets&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;toolsets&lt;/code&gt; section of your &lt;code&gt;tools.yaml&lt;/code&gt; allows you to define groups of tools that you want to be able to load together. This can be useful for defining different groups based on agent or application.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;toolsets:
    my_first_toolset:
        - my_first_tool
        - my_second_tool
    my_second_toolset:
        - my_second_tool
        - my_third_tool
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can load toolsets by name:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# This will load all tools
all_tools = client.load_toolset()

# This will only load the tools listed in 'my_second_toolset'
my_second_toolset = client.load_toolset("my_second_toolset")
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Prompts&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;prompts&lt;/code&gt; section of a &lt;code&gt;tools.yaml&lt;/code&gt; defines prompts that can be used for interactions with LLMs.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;prompts:
  code_review:
    description: "Asks the LLM to analyze code quality and suggest improvements."
    messages:
      - content: "Please review the following code for quality, correctness, and potential improvements: \n\n{{.code}}"
    arguments:
      - name: "code"
        description: "The code to review"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more details on configuring prompts, see the &lt;a href="https://googleapis.github.io/genai-toolbox/resources/prompts"&gt;Prompts&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Versioning&lt;/h2&gt; 
&lt;p&gt;This project uses &lt;a href="https://semver.org/"&gt;semantic versioning&lt;/a&gt; (&lt;code&gt;MAJOR.MINOR.PATCH&lt;/code&gt;). Since the project is in a pre-release stage (version &lt;code&gt;0.x.y&lt;/code&gt;), we follow the standard conventions for initial development:&lt;/p&gt; 
&lt;h3&gt;Pre-1.0.0 Versioning&lt;/h3&gt; 
&lt;p&gt;While the major version is &lt;code&gt;0&lt;/code&gt;, the public API should be considered unstable. The version will be incremented as follows:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;0.MINOR.PATCH&lt;/code&gt;&lt;/strong&gt;: The &lt;strong&gt;MINOR&lt;/strong&gt; version is incremented when we add new functionality or make breaking, incompatible API changes.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;0.MINOR.PATCH&lt;/code&gt;&lt;/strong&gt;: The &lt;strong&gt;PATCH&lt;/strong&gt; version is incremented for backward-compatible bug fixes.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Post-1.0.0 Versioning&lt;/h3&gt; 
&lt;p&gt;Once the project reaches a stable &lt;code&gt;1.0.0&lt;/code&gt; release, the version number &lt;strong&gt;&lt;code&gt;MAJOR.MINOR.PATCH&lt;/code&gt;&lt;/strong&gt; will follow the more common convention:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;MAJOR&lt;/code&gt;&lt;/strong&gt;: Incremented for incompatible API changes.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;MINOR&lt;/code&gt;&lt;/strong&gt;: Incremented for new, backward-compatible functionality.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;PATCH&lt;/code&gt;&lt;/strong&gt;: Incremented for backward-compatible bug fixes.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The public API that this applies to is the CLI associated with Toolbox, the interactions with official SDKs, and the definitions in the &lt;code&gt;tools.yaml&lt;/code&gt; file.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Contributions are welcome. Please, see the &lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/CONTRIBUTING.md"&gt;CONTRIBUTING&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;p&gt;Please note that this project is released with a Contributor Code of Conduct. By participating in this project you agree to abide by its terms. See &lt;a href="https://raw.githubusercontent.com/googleapis/genai-toolbox/main/CODE_OF_CONDUCT.md"&gt;Contributor Code of Conduct&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;Join our &lt;a href="https://discord.gg/GQrFB3Ec3W"&gt;discord community&lt;/a&gt; to connect with our developers!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>knadh/listmonk</title>
      <link>https://github.com/knadh/listmonk</link>
      <description>&lt;p&gt;High performance, self-hosted, newsletter and mailing list manager with a modern dashboard. Single binary app.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://zerodha.tech"&gt;&lt;img src="https://zerodha.tech/static/images/github-badge.svg?sanitize=true" align="right" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://listmonk.app"&gt;&lt;img src="https://user-images.githubusercontent.com/547147/231084896-835dba66-2dfe-497c-ba0f-787564c0819e.png" alt="listmonk-logo" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;listmonk is a standalone, self-hosted, newsletter and mailing list manager. It is fast, feature-rich, and packed into a single binary. It uses a PostgreSQL database as its data store.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://listmonk.app"&gt;&lt;img src="https://github.com/user-attachments/assets/689b5fbb-dd25-4956-a36f-e3226a65f9c4" alt="listmonk-dashboard" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Visit &lt;a href="https://listmonk.app"&gt;listmonk.app&lt;/a&gt; for more info. Check out the &lt;a href="https://demo.listmonk.app"&gt;&lt;strong&gt;live demo&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;Docker&lt;/h3&gt; 
&lt;p&gt;The latest image is available on DockerHub at &lt;a href="https://hub.docker.com/r/listmonk/listmonk/tags?page=1&amp;amp;ordering=last_updated&amp;amp;name=latest"&gt;&lt;code&gt;listmonk/listmonk:latest&lt;/code&gt;&lt;/a&gt;. Download and use the sample &lt;a href="https://github.com/knadh/listmonk/raw/master/docker-compose.yml"&gt;docker-compose.yml&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# Download the compose file to the current directory.
curl -LO https://github.com/knadh/listmonk/raw/master/docker-compose.yml

# Run the services in the background.
docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Visit &lt;code&gt;http://localhost:9000&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://listmonk.app/docs/installation"&gt;installation docs&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Binary&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Download the &lt;a href="https://github.com/knadh/listmonk/releases"&gt;latest release&lt;/a&gt; and extract the listmonk binary.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;./listmonk --new-config&lt;/code&gt; to generate config.toml. Edit it.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;./listmonk --install&lt;/code&gt; to setup the Postgres DB (or &lt;code&gt;--upgrade&lt;/code&gt; to upgrade an existing DB. Upgrades are idempotent and running them multiple times have no side effects).&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;./listmonk&lt;/code&gt; and visit &lt;code&gt;http://localhost:9000&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See &lt;a href="https://listmonk.app/docs/installation"&gt;installation docs&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Developers&lt;/h2&gt; 
&lt;p&gt;listmonk is free and open source software licensed under AGPLv3. If you are interested in contributing, refer to the &lt;a href="https://listmonk.app/docs/developer-setup"&gt;developer setup&lt;/a&gt;. The backend is written in Go and the frontend is Vue with Buefy for UI.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;listmonk is licensed under the AGPL v3 license.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>sysadminsmedia/homebox</title>
      <link>https://github.com/sysadminsmedia/homebox</link>
      <description>&lt;p&gt;A continuation of HomeBox the inventory and organization system built for the Home User&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/sysadminsmedia/homebox/main/docs/public/lilbox.svg?sanitize=true" height="200" /&gt; 
&lt;/div&gt; 
&lt;h1 align="center" style="margin-top: -10px;"&gt; HomeBox &lt;/h1&gt; 
&lt;p align="center" style="width: 100%;"&gt; &lt;a href="https://homebox.software/en/"&gt;Docs&lt;/a&gt; | &lt;a href="https://demo.homebox.software"&gt;Demo&lt;/a&gt; | &lt;a href="https://discord.gg/aY4DCkpNA9"&gt;Discord&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center" style="width: 100%;"&gt; &lt;img src="https://img.shields.io/github/check-runs/sysadminsmedia/homebox/main" alt="Github Checks" /&gt; &lt;img src="https://img.shields.io/github/license/sysadminsmedia/homebox" /&gt; &lt;img src="https://img.shields.io/github/v/release/sysadminsmedia/homebox?sort=semver&amp;amp;display_name=release" /&gt; &lt;img src="https://img.shields.io/weblate/progress/homebox?server=https%3A%2F%2Ftranslate.sysadminsmedia.com" /&gt; &lt;/p&gt; 
&lt;p align="center" style="width: 100%;"&gt; &lt;img src="https://img.shields.io/reddit/subreddit-subscribers/homebox" /&gt; &lt;img src="https://img.shields.io/mastodon/follow/110749314839831923?domain=infosec.exchange" /&gt; &lt;img src="https://img.shields.io/lemmy/homebox%40lemmy.world?label=lemmy" /&gt; &lt;/p&gt; 
&lt;p align="center" style="width: 100%;"&gt; &lt;a href="https://www.pikapods.com/pods?run=homebox"&gt;&lt;img src="https://www.pikapods.com/static/run-button.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;What is HomeBox&lt;/h2&gt; 
&lt;p&gt;HomeBox is the inventory and organization system built for the Home User! With a focus on simplicity and ease of use, Homebox is the perfect solution for your home inventory, organization, and management needs. While developing this project, We've tried to keep the following principles in mind:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üßò &lt;em&gt;Simple but Expandable&lt;/em&gt; - Homebox is designed to be simple and easy to use. No complicated setup or configuration required. But expandable to whatever level of infrastructure you want to put into it.&lt;/li&gt; 
 &lt;li&gt;üöÄ &lt;em&gt;Blazingly Fast&lt;/em&gt; - Homebox is written in Go, which makes it extremely fast and requires minimal resources to deploy. In general, idle memory usage is less than 50MB for the whole container.&lt;/li&gt; 
 &lt;li&gt;üì¶ &lt;em&gt;Portable&lt;/em&gt; - Homebox is designed to be portable and run on anywhere. We use SQLite and an embedded Web UI to make it easy to deploy, use, and backup.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Key Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üìá Rich Organization - Organize your items into categories, locations, and tags. You can also create custom fields to store additional information about your items.&lt;/li&gt; 
 &lt;li&gt;üîç Powerful Search - Quickly find items in your inventory using the powerful search feature.&lt;/li&gt; 
 &lt;li&gt;üì∏ Image Upload - Upload images of your items to make it easy to identify them.&lt;/li&gt; 
 &lt;li&gt;üìÑ Document and Warranty Tracking - Keep track of important documents and warranties for your items.&lt;/li&gt; 
 &lt;li&gt;üí∞ Purchase &amp;amp; Maintenance Tracking - Track purchase dates, prices, and maintenance schedules for your items.&lt;/li&gt; 
 &lt;li&gt;üì± Responsive Design - Homebox is designed to work on any device, including desktops, tablets, and smartphones.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Screenshots&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/sysadminsmedia/homebox/main/.github/screenshots/1.png" alt="Login Screen" /&gt; &lt;img src="https://raw.githubusercontent.com/sysadminsmedia/homebox/main/.github/screenshots/2.png" alt="Dashboard" /&gt; &lt;img src="https://raw.githubusercontent.com/sysadminsmedia/homebox/main/.github/screenshots/3.png" alt="Item View" /&gt; &lt;img src="https://raw.githubusercontent.com/sysadminsmedia/homebox/main/.github/screenshots/9.png" alt="Create Item" /&gt; &lt;img src="https://raw.githubusercontent.com/sysadminsmedia/homebox/main/.github/screenshots/8.png" alt="Search" /&gt;&lt;/p&gt; 
&lt;p&gt;You can also try the demo instances of Homebox:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://demo.homebox.software"&gt;Demo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://nightly.homebox.software"&gt;Nightly&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://homebox.software/en/quick-start.html"&gt;Configuration &amp;amp; Docker Compose&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# If using the rootless or hardened image, ensure data 
# folder has correct permissions
mkdir -p /path/to/data/folder
chown 65532:65532 -R /path/to/data/folder
docker run -d \
  --name homebox \
  --restart unless-stopped \
  --publish 3100:7745 \
  --env TZ=Europe/Bucharest \
  --volume /path/to/data/folder/:/data \
  ghcr.io/sysadminsmedia/homebox:latest
# ghcr.io/sysadminsmedia/homebox:latest-rootless
# ghcr.io/sysadminsmedia/homebox:latest-hardened
&lt;/code&gt;&lt;/pre&gt; 
&lt;!-- CONTRIBUTING --&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Contributions are what make the open source community such an amazing place to learn, inspire, and create. Any contributions you make are &lt;strong&gt;greatly appreciated&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;To get started with code based contributions, please see our &lt;a href="https://homebox.software/en/contribute/get-started.html"&gt;contributing guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you are not a coder and can't help translate, you can still contribute financially. Financial contributions help us maintain the project and keep demos running.&lt;/p&gt; 
&lt;h2&gt;Help us Translate&lt;/h2&gt; 
&lt;p&gt;We want to make sure that Homebox is available in as many languages as possible. If you are interested in helping us translate Homebox, please help us via our &lt;a href="https://translate.sysadminsmedia.com/projects/homebox/"&gt;Weblate instance&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://translate.sysadminsmedia.com/engage/homebox/"&gt;&lt;img src="https://translate.sysadminsmedia.com/widget/homebox/multi-auto.svg?sanitize=true" alt="Translation status" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Credits&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Original project by &lt;a href="https://github.com/hay-kot"&gt;@hay-kot&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Logo by &lt;a href="https://github.com/lakotelman"&gt;@lakotelman&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Contributors&lt;/h3&gt; 
&lt;a href="https://github.com/sysadminsmedia/homebox/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=sysadminsmedia/homebox" /&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>autobrr/qui</title>
      <link>https://github.com/autobrr/qui</link>
      <description>&lt;p&gt;A fast, single-binary qBittorrent web UI: manage multiple instances, automate torrent workflows, and cross-seed across trackers.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;qui&lt;/h1&gt; 
&lt;p&gt;A fast, modern web interface for qBittorrent. Supports managing multiple qBittorrent instances from a single, lightweight application.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/autobrr/qui/develop/.github/assets/qui.png" alt="qui" width="100%" /&gt; 
&lt;/div&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;Full documentation available at &lt;strong&gt;&lt;a href="https://getqui.com"&gt;getqui.com&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;h3&gt;Linux x86_64&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Download and extract the latest release
wget $(curl -s https://api.github.com/repos/autobrr/qui/releases/latest | grep browser_download_url | grep linux_x86_64 | cut -d\" -f4)
tar -C /usr/local/bin -xzf qui*.tar.gz

# Run
./qui serve
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The web interface will be available at &lt;a href="http://localhost:7476"&gt;http://localhost:7476&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Docker&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d \
  -p 7476:7476 \
  -v $(pwd)/config:/config \
  ghcr.io/autobrr/qui:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Single Binary&lt;/strong&gt;: No dependencies, just download and run&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-Instance Support&lt;/strong&gt;: Manage all your qBittorrent instances from one place&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Fast &amp;amp; Responsive&lt;/strong&gt;: Optimized for performance with large torrent collections&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cross-Seed&lt;/strong&gt;: Automatically find and add matching torrents across trackers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Automations&lt;/strong&gt;: Rule-based torrent management with conditions and actions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Backups &amp;amp; Restore&lt;/strong&gt;: Scheduled snapshots with multiple restore modes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Reverse Proxy&lt;/strong&gt;: Transparent qBittorrent proxy for external apps&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;Join our community on &lt;a href="https://discord.autobrr.com/qui"&gt;Discord&lt;/a&gt;!&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/autobrr/qui/discussions/new/choose"&gt;GitHub Discussions&lt;/a&gt; - Feature requests and bug reports&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/autobrr/qui/issues"&gt;GitHub Issues&lt;/a&gt; - Work in progress&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Support Development&lt;/h2&gt; 
&lt;p&gt;qui is developed and maintained by volunteers. Your support helps us continue improving the project.&lt;/p&gt; 
&lt;h3&gt;License Key&lt;/h3&gt; 
&lt;p&gt;Donate what you want (minimum $4.99) to unlock premium themes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Use any donation method below&lt;/li&gt; 
 &lt;li&gt;After donating, DM soup or ze0s on Discord (whoever you donated to) 
  &lt;ul&gt; 
   &lt;li&gt;For crypto, include the transaction hash/link&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;You'll receive a 100% discount code&lt;/li&gt; 
 &lt;li&gt;Redeem the code on &lt;a href="https://buy.polar.sh/polar_cl_yyXJesVM9pFVfAPIplspbfCukgVgXzXjXIc2N0I8WcL"&gt;Polar&lt;/a&gt; (free order) to receive your license key&lt;/li&gt; 
 &lt;li&gt;Enter the license key in Settings ‚Üí Themes in your qui instance&lt;/li&gt; 
 &lt;li&gt;License is lifetime&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Donation Methods&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;soup&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/sponsors/s0up4200"&gt;GitHub Sponsors&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://buymeacoffee.com/s0up4200"&gt;Buy Me a Coffee&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;zze0s&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/sponsors/zze0s"&gt;GitHub Sponsors&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://buymeacoffee.com/ze0s"&gt;Buy Me a Coffee&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Cryptocurrency&lt;/h4&gt; 
&lt;h4&gt;Bitcoin (BTC)&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;soup: &lt;code&gt;bc1qfe093kmhvsa436v4ksz0udfcggg3vtnm2tjgem&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;zze0s: &lt;code&gt;bc1q2nvdd83hrzelqn4vyjm8tvjwmsuuxsdlg4ws7x&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Ethereum (ETH)&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;soup: &lt;code&gt;0xD8f517c395a68FEa8d19832398d4dA7b45cbc38F&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;zze0s: &lt;code&gt;0xBF7d749574aabF17fC35b27232892d3F0ff4D423&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Litecoin (LTC)&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;soup: &lt;code&gt;ltc1q86nx64mu2j22psj378amm58ghvy4c9dw80z88h&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;zze0s: &lt;code&gt;ltc1qza9ffjr5y43uk8nj9ndjx9hkj0ph3rhur6wudn&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Monero (XMR)&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;soup: &lt;code&gt;8AMPTPgjmLG9armLBvRA8NMZqPWuNT4US3kQoZrxDDVSU21kpYpFr1UCWmmtcBKGsvDCFA3KTphGXExWb3aHEu67JkcjAvC&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;zze0s: &lt;code&gt;44AvbWXzFN3bnv2oj92AmEaR26PQf5Ys4W155zw3frvEJf2s4g325bk4tRBgH7umSVMhk88vkU3gw9cDvuCSHgpRPsuWVJp&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;p&gt;All methods unlock premium themes ‚Äî use whichever works best for you. For other currencies or donation methods, &lt;a href="https://discord.autobrr.com/qui"&gt;reach out on Discord&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Thank you for your support ‚ù§Ô∏è&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Contributions are welcome! Please feel free to submit a Pull Request.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;GPL-2.0-or-later&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>simulot/immich-go</title>
      <link>https://github.com/simulot/immich-go</link>
      <description>&lt;p&gt;An alternative to the immich-CLI command that doesn't depend on nodejs installation. It tries its best for importing google photos takeout archives.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Immich-Go: Upload Your Photos to Your Immich Server&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;Immich-Go&lt;/strong&gt; is an open-source tool designed to streamline uploading large photo collections to your self-hosted Immich server.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;‚ö†Ô∏è This is an early version, not yet extensively tested&lt;br /&gt; ‚ö†Ô∏è Keep a backup copy of your files for safety&lt;br /&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;üåü Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Simple Installation&lt;/strong&gt;: No NodeJS or Docker required&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multiple Sources&lt;/strong&gt;: Upload from Google Photos Takeouts, iCloud, local folders, ZIP archives, and other Immich servers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Large Collections&lt;/strong&gt;: Successfully handles 100,000+ photos&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Smart Management&lt;/strong&gt;: Duplicate detection, burst photo stacking, RAW+JPEG handling&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cross-Platform&lt;/strong&gt;: Available for Windows, macOS, Linux, and FreeBSD&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üöÄ Quick Start&lt;/h2&gt; 
&lt;h3&gt;1. Install Immich-Go&lt;/h3&gt; 
&lt;p&gt;Download the pre-built binary for your system from the &lt;a href="https://github.com/simulot/immich-go/releases"&gt;GitHub releases page&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;2. Basic Usage&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Upload photos from a local folder
immich-go upload from-folder --server=http://your-ip:2283 --api-key=your-api-key /path/to/your/photos

# Upload Google Photos takeout
immich-go upload from-google-photos --server=http://your-ip:2283 --api-key=your-api-key /path/to/takeout-*.zip

# Archive photos from Immich server
immich-go archive from-immich --server=http://your-ip:2283 --api-key=your-api-key --write-to-folder=/path/to/archive
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;3. Requirements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;A running Immich server with API access&lt;/li&gt; 
 &lt;li&gt;API key with appropriate permissions (&lt;a href="https://raw.githubusercontent.com/simulot/immich-go/main/docs/installation.md#api-permissions"&gt;see full list&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;‚ö†Ô∏è &lt;strong&gt;Breaking Change&lt;/strong&gt;: API keys must now include the &lt;code&gt;asset.copy&lt;/code&gt; and &lt;code&gt;asset.delete&lt;/code&gt; permissions in addition to previously required permissions. Please update your API keys accordingly.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;üôà Skip System Files&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Use &lt;code&gt;--ban-file&lt;/code&gt; to exclude junk artifacts. Patterns ending with &lt;code&gt;/&lt;/code&gt; apply to directories (for example, &lt;code&gt;--ban-file .Spotlight-V100/&lt;/code&gt;), while patterns without the trailing slash apply to individual files (for example, &lt;code&gt;--ban-file .DS_Store&lt;/code&gt;).&lt;/li&gt; 
 &lt;li&gt;Immich-Go ships with sensible defaults that already skip common clutter such as &lt;code&gt;@eaDir/&lt;/code&gt;, &lt;code&gt;@__thumb/&lt;/code&gt;, &lt;code&gt;SYNOFILE_THUMB_*.*&lt;/code&gt;, &lt;code&gt;Lightroom Catalog/&lt;/code&gt;, &lt;code&gt;thumbnails/&lt;/code&gt;, &lt;code&gt;.DS_Store&lt;/code&gt;, &lt;code&gt;/._*&lt;/code&gt;, &lt;code&gt;.Spotlight-V100/&lt;/code&gt;, &lt;code&gt;.photostructure/&lt;/code&gt;, and &lt;code&gt;Recently Deleted/&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Add additional patterns as needed to keep uploads focused on real photos. See the &lt;a href="https://raw.githubusercontent.com/simulot/immich-go/main/docs/technical.md#banned-files"&gt;banned files reference&lt;/a&gt; for details.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìö Documentation&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Topic&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/simulot/immich-go/main/docs/installation.md"&gt;Installation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Detailed installation instructions for all platforms&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/simulot/immich-go/main/docs/commands/"&gt;Commands&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Complete command reference and options&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/simulot/immich-go/main/docs/configuration.md"&gt;Configuration&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Configuration options and environment variables&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/simulot/immich-go/main/docs/examples.md"&gt;Examples&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Common use cases and practical examples&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/simulot/immich-go/main/docs/best-practices.md"&gt;Best Practices&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Tips for optimal performance and reliability&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/simulot/immich-go/main/docs/technical.md"&gt;Technical Details&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;File processing, metadata handling, and advanced features&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/simulot/immich-go/main/docs/upload-commands-overview.md"&gt;Upload Commands Overview&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;How &lt;code&gt;immich-go&lt;/code&gt; processes files from different sources&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/simulot/immich-go/main/docs/releases/"&gt;Release Notes&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Version history and release notes&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;‚ú® How immich-go Works&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;immich-go&lt;/code&gt; offers a versatile set of commands to handle your photo and video uploads. Whether you're uploading from a simple folder, migrating from a Google Photos Takeout, or transferring assets between Immich servers, the tool provides intelligent features to preserve your metadata and organization.&lt;/p&gt; 
&lt;p&gt;Here's a brief overview of the main upload commands:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;from-folder&lt;/code&gt;&lt;/strong&gt;: The basic command for uploading from any local folder. It can create albums from your directory structure and read XMP sidecar files.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;from-google-photos&lt;/code&gt;&lt;/strong&gt;: A powerful command to migrate from a Google Photos Takeout. It intelligently matches photos with their JSON metadata to preserve albums, descriptions, and locations.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;from-immich&lt;/code&gt;&lt;/strong&gt;: A server-to-server migration tool that allows you to copy assets between two Immich instances with fine-grained filtering.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;from-picasa&lt;/code&gt;&lt;/strong&gt;: A specialized version of &lt;code&gt;from-folder&lt;/code&gt; that automatically reads &lt;code&gt;.picasa.ini&lt;/code&gt; files to restore your Picasa album organization.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;from-icloud&lt;/code&gt;&lt;/strong&gt;: Another specialized command that handles the complexity of an iCloud Photos takeout, correctly identifying creation dates and album structures from the included CSV files.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Leveraging Immich's Features&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;immich-go&lt;/code&gt; is more than just an uploader; it intelligently interacts with the Immich server to preserve your library's structure:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Albums and Tags&lt;/strong&gt;: Automatically creates albums and tags on the server to match your source organization.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Stacking&lt;/strong&gt;: Groups related images, like RAW+JPEG pairs or photo bursts, into stacks.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Duplicate Detection&lt;/strong&gt;: Avoids re-uploading files that already exist on the server.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Efficient Uploads&lt;/strong&gt;: Can pause Immich's background jobs (like thumbnailing) during an upload for better performance.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For a detailed explanation of how each upload command works, please see the &lt;a href="https://raw.githubusercontent.com/simulot/immich-go/main/docs/upload-commands-overview.md"&gt;Upload Commands Overview&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üéØ Popular Use Cases&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Google Photos Migration&lt;/strong&gt;: &lt;a href="https://raw.githubusercontent.com/simulot/immich-go/main/docs/best-practices.md#google-photos-migration"&gt;Complete guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;iCloud Import&lt;/strong&gt;: &lt;a href="https://raw.githubusercontent.com/simulot/immich-go/main/docs/examples.md#icloud-import"&gt;Step-by-step instructions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Server Migration&lt;/strong&gt;: &lt;a href="https://raw.githubusercontent.com/simulot/immich-go/main/docs/examples.md#server-migration"&gt;Transfer between Immich instances&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Bulk Organization&lt;/strong&gt;: &lt;a href="https://raw.githubusercontent.com/simulot/immich-go/main/docs/best-practices.md#organization-strategies"&gt;Stacking and tagging strategies&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üí° Support the Project&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sponsors/simulot"&gt;GitHub Sponsor&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.paypal.com/donate/?hosted_button_id=VGU2SQE88T2T4"&gt;PayPal Donation&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; 
&lt;p&gt;Contributions are welcome! Please see our &lt;a href="https://raw.githubusercontent.com/simulot/immich-go/main/CONTRIBUTING.md"&gt;contributing guidelines&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the terms specified in the &lt;a href="https://raw.githubusercontent.com/simulot/immich-go/main/LICENSE"&gt;LICENSE&lt;/a&gt; file.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;Need help?&lt;/strong&gt; Check our &lt;a href="https://raw.githubusercontent.com/simulot/immich-go/main/docs/"&gt;documentation&lt;/a&gt; or open an issue on GitHub.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>schollz/croc</title>
      <link>https://github.com/schollz/croc</link>
      <description>&lt;p&gt;Easily and securely send things from one computer to another üêä üì¶&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://user-images.githubusercontent.com/6550035/46709024-9b23ad00-cbf6-11e8-9fb2-ca8b20b7dbec.jpg" width="408px" border="0" alt="croc" /&gt; &lt;br /&gt; &lt;a href="https://github.com/schollz/croc/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/schollz/croc" alt="Version" /&gt;&lt;/a&gt; &lt;a href="https://github.com/schollz/croc/actions/workflows/ci.yml"&gt;&lt;img src="https://github.com/schollz/croc/actions/workflows/ci.yml/badge.svg?sanitize=true" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://github.com/sponsors/schollz"&gt;&lt;img alt="GitHub Sponsors" src="https://img.shields.io/github/sponsors/schollz" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;strong&gt;This project‚Äôs future depends on community support. &lt;a href="https://github.com/sponsors/schollz"&gt;Become a sponsor today&lt;/a&gt;.&lt;/strong&gt; &lt;/p&gt; 
&lt;h2&gt;About&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;croc&lt;/code&gt; is a tool that allows any two computers to simply and securely transfer files and folders. AFAIK, &lt;em&gt;croc&lt;/em&gt; is the only CLI file-transfer tool that does &lt;strong&gt;all&lt;/strong&gt; of the following:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Allows &lt;strong&gt;any two computers&lt;/strong&gt; to transfer data (using a relay)&lt;/li&gt; 
 &lt;li&gt;Provides &lt;strong&gt;end-to-end encryption&lt;/strong&gt; (using PAKE)&lt;/li&gt; 
 &lt;li&gt;Enables easy &lt;strong&gt;cross-platform&lt;/strong&gt; transfers (Windows, Linux, Mac)&lt;/li&gt; 
 &lt;li&gt;Allows &lt;strong&gt;multiple file&lt;/strong&gt; transfers&lt;/li&gt; 
 &lt;li&gt;Allows &lt;strong&gt;resuming transfers&lt;/strong&gt; that are interrupted&lt;/li&gt; 
 &lt;li&gt;No need for local server or port-forwarding&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;IPv6-first&lt;/strong&gt; with IPv4 fallback&lt;/li&gt; 
 &lt;li&gt;Can &lt;strong&gt;use a proxy&lt;/strong&gt;, like Tor&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about &lt;code&gt;croc&lt;/code&gt;, see &lt;a href="https://schollz.com/tinker/croc6/"&gt;my blog post&lt;/a&gt; or read a &lt;a href="https://console.substack.com/p/console-91"&gt;recent interview I did&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/schollz/croc/main/src/install/customization.gif" alt="Example" /&gt;&lt;/p&gt; 
&lt;h2&gt;Install&lt;/h2&gt; 
&lt;p&gt;You can download &lt;a href="https://github.com/schollz/croc/releases/latest"&gt;the latest release for your system&lt;/a&gt;, or install a release from the command-line:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl https://getcroc.schollz.com | bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;On macOS&lt;/h3&gt; 
&lt;p&gt;Using &lt;a href="https://brew.sh/"&gt;Homebrew&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;brew install croc
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Using &lt;a href="https://www.macports.org/"&gt;MacPorts&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;sudo port selfupdate
sudo port install croc
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;On Windows&lt;/h3&gt; 
&lt;p&gt;You can install the latest release with &lt;a href="https://scoop.sh/"&gt;Scoop&lt;/a&gt;, &lt;a href="https://chocolatey.org/"&gt;Chocolatey&lt;/a&gt;, or &lt;a href="https://learn.microsoft.com/windows/package-manager/"&gt;Winget&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;scoop install croc
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;choco install croc
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;winget install schollz.croc
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Using nix-env&lt;/h3&gt; 
&lt;p&gt;You can install the latest release with &lt;a href="https://nixos.org/"&gt;Nix&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;nix-env -i croc
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;On NixOS&lt;/h3&gt; 
&lt;p&gt;You can add this to your &lt;a href="https://nixos.org/manual/nixos/stable/#ch-configuration"&gt;configuration.nix&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-nix"&gt;environment.systemPackages = [
  pkgs.croc
];
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;On Alpine Linux&lt;/h3&gt; 
&lt;p&gt;First, install dependencies:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;apk add bash coreutils
wget -qO- https://getcroc.schollz.com | bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;On Arch Linux&lt;/h3&gt; 
&lt;p&gt;Install with &lt;code&gt;pacman&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pacman -S croc
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;On Fedora&lt;/h3&gt; 
&lt;p&gt;Install with &lt;code&gt;dnf&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;dnf install croc
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;On Gentoo&lt;/h3&gt; 
&lt;p&gt;Install with &lt;code&gt;portage&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;emerge net-misc/croc
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;On Termux&lt;/h3&gt; 
&lt;p&gt;Install with &lt;code&gt;pkg&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pkg install croc
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;On FreeBSD&lt;/h3&gt; 
&lt;p&gt;Install with &lt;code&gt;pkg&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pkg install croc
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;On Linux, macOS, and Windows via Conda&lt;/h3&gt; 
&lt;p&gt;You can install from &lt;a href="https://github.com/conda-forge/croc-feedstock"&gt;conda-forge&lt;/a&gt; globally with &lt;a href="https://pixi.sh/"&gt;&lt;code&gt;pixi&lt;/code&gt;&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pixi global install croc
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or install into a particular environment with &lt;a href="https://docs.conda.io/projects/conda/"&gt;&lt;code&gt;conda&lt;/code&gt;&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;conda install --channel conda-forge croc
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;On Linux, macOS via Docker&lt;/h3&gt; 
&lt;p&gt;Add the following one-liner function to your ~/.profile (works with any POSIX-compliant shell):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;croc() { [ $# -eq 0 ] &amp;amp;&amp;amp; set -- ""; mkdir -p "$HOME/.config/croc"; docker run --rm -it --user "$(id -u):$(id -g)" -v "$(pwd):/c" -v "$HOME/.config/croc:/.config/croc" -w /c -e CROC_SECRET docker.io/schollz/croc "$@"; }
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also just paste it in the terminal for current session. On first run Docker will pull the image. &lt;code&gt;croc&lt;/code&gt; via Docker will only work within the current directory and its subdirectories.&lt;/p&gt; 
&lt;h3&gt;Build from Source&lt;/h3&gt; 
&lt;p&gt;If you prefer, you can &lt;a href="https://go.dev/dl/"&gt;install Go&lt;/a&gt; and build from source (requires Go 1.22+):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;go install github.com/schollz/croc/v10@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;On Android&lt;/h3&gt; 
&lt;p&gt;There is a 3rd-party F-Droid app &lt;a href="https://f-droid.org/packages/com.github.howeyc.crocgui/"&gt;available to download&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;To send a file, simply do:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ croc send [file(s)-or-folder]
Sending 'file-or-folder' (X MB)
Code is: code-phrase
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then, to receive the file (or folder) on another computer, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;croc code-phrase
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The code phrase is used to establish password-authenticated key agreement (&lt;a href="https://en.wikipedia.org/wiki/Password-authenticated_key_agreement"&gt;PAKE&lt;/a&gt;) which generates a secret key for the sender and recipient to use for end-to-end encryption.&lt;/p&gt; 
&lt;h3&gt;Customizations &amp;amp; Options&lt;/h3&gt; 
&lt;h4&gt;Using &lt;code&gt;croc&lt;/code&gt; on Linux or macOS&lt;/h4&gt; 
&lt;p&gt;On Linux and macOS, the sending and receiving process is slightly different to avoid &lt;a href="https://nvd.nist.gov/vuln/detail/CVE-2023-43621"&gt;leaking the secret via the process name&lt;/a&gt;. You will need to run &lt;code&gt;croc&lt;/code&gt; with the secret as an environment variable. For example, to receive with the secret &lt;code&gt;***&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;CROC_SECRET=*** croc
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For single-user systems, the default behavior can be permanently enabled by running:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;croc --classic
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Custom Code Phrase&lt;/h4&gt; 
&lt;p&gt;You can send with your own code phrase (must be more than 6 characters):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;croc send --code [code-phrase] [file(s)-or-folder]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Allow Overwriting Without Prompt&lt;/h4&gt; 
&lt;p&gt;To automatically overwrite files without prompting, use the &lt;code&gt;--overwrite&lt;/code&gt; flag:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;croc --yes --overwrite &amp;lt;code&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Excluding Folders&lt;/h4&gt; 
&lt;p&gt;To exclude folders from being sent, use the &lt;code&gt;--exclude&lt;/code&gt; flag with comma-delimited exclusions:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;croc send --exclude "node_modules,.venv" [folder]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Use Pipes - stdin and stdout&lt;/h4&gt; 
&lt;p&gt;You can pipe to &lt;code&gt;croc&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cat [filename] | croc send
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To receive the file to &lt;code&gt;stdout&lt;/code&gt;, you can use:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;croc --yes [code-phrase] &amp;gt; out
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Send Text&lt;/h4&gt; 
&lt;p&gt;To send URLs or short text, use:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;croc send --text "hello world"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Send Multiple Files&lt;/h4&gt; 
&lt;p&gt;You can send multiple files directly by listing the files and/or folders:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;croc send [file1] [file2] [file3] [folder1] [folder2]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Show QR Code&lt;/h4&gt; 
&lt;p&gt;To show QR code (for mobile devices), use:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;croc send --qr [file(s)-or-folder]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Use a Proxy&lt;/h4&gt; 
&lt;p&gt;You can send files via a proxy by adding &lt;code&gt;--socks5&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;croc --socks5 "127.0.0.1:9050" send SOMEFILE
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Change Encryption Curve&lt;/h4&gt; 
&lt;p&gt;To choose a different elliptic curve for encryption, use the &lt;code&gt;--curve&lt;/code&gt; flag:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;croc --curve p521 &amp;lt;codephrase&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Change Hash Algorithm&lt;/h4&gt; 
&lt;p&gt;For faster hashing, use the &lt;code&gt;imohash&lt;/code&gt; algorithm:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;croc send --hash imohash SOMEFILE
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Clipboard Options&lt;/h4&gt; 
&lt;p&gt;By default, the code phrase is copied to your clipboard. To disable this:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;croc --disable-clipboard send [filename]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To copy the full command with the secret as an environment variable (useful on Linux/macOS):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;croc --extended-clipboard send [filename]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This copies the full command like &lt;code&gt;CROC_SECRET="code-phrase" croc&lt;/code&gt; (including any relay/pass flags).&lt;/p&gt; 
&lt;h4&gt;Quiet Mode&lt;/h4&gt; 
&lt;p&gt;To suppress all output (useful for scripts and automation):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;croc --quiet send [filename]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Self-host Relay&lt;/h4&gt; 
&lt;p&gt;You can run your own relay:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;croc relay
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;By default, it uses TCP ports 9009-9013. You can customize the ports (e.g., &lt;code&gt;croc relay --ports 1111,1112&lt;/code&gt;), but at least &lt;strong&gt;2&lt;/strong&gt; ports are required.&lt;/p&gt; 
&lt;p&gt;To send files using your relay:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;croc --relay "myrelay.example.com:9009" send [filename]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Self-host Relay with Docker&lt;/h4&gt; 
&lt;p&gt;You can also run a relay with Docker:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d -p 9009-9013:9009-9013 -e CROC_PASS='YOURPASSWORD' docker.io/schollz/croc
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To send files using your custom relay:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;croc --pass YOURPASSWORD --relay "myreal.example.com:9009" send [filename]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;croc&lt;/code&gt; has evolved through many iterations, and I am thankful for the contributions! Special thanks to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/warner"&gt;@warner&lt;/a&gt; for the &lt;a href="https://github.com/magic-wormhole/magic-wormhole"&gt;idea&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tscholl2"&gt;@tscholl2&lt;/a&gt; for the &lt;a href="https://gist.github.com/tscholl2/dc7dc15dc132ea70a98e8542fefffa28"&gt;encryption gists&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/skorokithakis"&gt;@skorokithakis&lt;/a&gt; for &lt;a href="https://www.stavros.io/posts/proxying-two-connections-go/"&gt;proxying two connections&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;And many more!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>usememos/memos</title>
      <link>https://github.com/usememos/memos</link>
      <description>&lt;p&gt;An open-source, self-hosted note-taking service. Your thoughts, your data, your control ‚Äî no tracking, no ads, no subscription fees.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Memos&lt;/h1&gt; 
&lt;img align="right" height="96px" src="https://raw.githubusercontent.com/usememos/.github/refs/heads/main/assets/logo-rounded.png" alt="Memos" /&gt; 
&lt;p&gt;An open-source, self-hosted note-taking service. Your thoughts, your data, your control ‚Äî no tracking, no ads, no subscription fees.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://usememos.com"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%8F%A0-usememos.com-blue?style=flat-square" alt="Home" /&gt;&lt;/a&gt; &lt;a href="https://demo.usememos.com/"&gt;&lt;img src="https://img.shields.io/badge/%E2%9C%A8-Try%20Demo-orange?style=flat-square" alt="Live Demo" /&gt;&lt;/a&gt; &lt;a href="https://usememos.com/docs"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%93%9A-Documentation-green?style=flat-square" alt="Docs" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/tfPJa4UmAv"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%92%AC-Discord-5865f2?style=flat-square&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/neosmemo/memos"&gt;&lt;img src="https://img.shields.io/docker/pulls/neosmemo/memos?style=flat-square&amp;amp;logo=docker" alt="Docker Pulls" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/usememos/.github/refs/heads/main/assets/demo.png" alt="Memos Demo Screenshot" height="512" /&gt; 
&lt;h3&gt;üíé Featured Sponsors&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://go.warp.dev/memos"&gt;&lt;strong&gt;Warp&lt;/strong&gt; ‚Äî The AI-powered terminal built for speed and collaboration&lt;/a&gt;&lt;/p&gt; 
&lt;a href="https://go.warp.dev/memos" target="_blank" rel="noopener"&gt; &lt;img src="https://raw.githubusercontent.com/warpdotdev/brand-assets/main/Github/Sponsor/Warp-Github-LG-02.png" alt="Warp - The AI-powered terminal built for speed and collaboration" width="512" /&gt; &lt;/a&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;a href="https://www.lambdatest.com/?utm_source=memos&amp;amp;utm_medium=sponsor"&gt;&lt;strong&gt;LambdaTest&lt;/strong&gt; - Cross-browser testing cloud&lt;/a&gt;&lt;/p&gt; 
&lt;a href="https://www.lambdatest.com/?utm_source=memos&amp;amp;utm_medium=sponsor" target="_blank" rel="noopener"&gt; &lt;img src="https://www.lambdatest.com/blue-logo.png" alt="LambdaTest - Cross-browser testing cloud" height="50" /&gt; &lt;/a&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;Memos is a privacy-first, self-hosted knowledge base that works seamlessly for personal notes, team wikis, and knowledge management. Built with Go and React, it offers lightning-fast performance without compromising on features or usability.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Why choose Memos over cloud services?&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Feature&lt;/th&gt; 
   &lt;th&gt;Memos&lt;/th&gt; 
   &lt;th&gt;Cloud Services&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Privacy&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ Self-hosted, zero telemetry&lt;/td&gt; 
   &lt;td&gt;‚ùå Your data on their servers&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Cost&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ Free forever, MIT license&lt;/td&gt; 
   &lt;td&gt;‚ùå Subscription fees&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Performance&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ Instant load, no latency&lt;/td&gt; 
   &lt;td&gt;‚ö†Ô∏è Depends on internet&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Ownership&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ Full control &amp;amp; export&lt;/td&gt; 
   &lt;td&gt;‚ùå Vendor lock-in&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;API Access&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ Full REST + gRPC APIs&lt;/td&gt; 
   &lt;td&gt;‚ö†Ô∏è Limited or paid&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Customization&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ Open source, forkable&lt;/td&gt; 
   &lt;td&gt;‚ùå Closed ecosystem&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üîí Privacy-First Architecture&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Self-hosted on your infrastructure with zero telemetry&lt;/li&gt; 
   &lt;li&gt;Complete data ownership and export capabilities&lt;/li&gt; 
   &lt;li&gt;No tracking, no ads, no vendor lock-in&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üìù Markdown Native&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Full markdown support&lt;/li&gt; 
   &lt;li&gt;Plain text storage ‚Äî take your data anywhere&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;‚ö° Blazing Fast&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Built with Go backend and React frontend&lt;/li&gt; 
   &lt;li&gt;Optimized for performance at any scale&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üê≥ Simple Deployment&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;One-line Docker installation&lt;/li&gt; 
   &lt;li&gt;Supports SQLite, MySQL, and PostgreSQL&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üîó Developer-Friendly&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Full REST and gRPC APIs&lt;/li&gt; 
   &lt;li&gt;Easy integration with existing workflows&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üé® Beautiful Interface&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Clean, minimal design and dark mode support&lt;/li&gt; 
   &lt;li&gt;Mobile-responsive layout&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;h3&gt;Docker (Recommended)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d \
  --name memos \
  -p 5230:5230 \
  -v ~/.memos:/var/opt/memos \
  neosmemo/memos:stable
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Open &lt;code&gt;http://localhost:5230&lt;/code&gt; and start writing!&lt;/p&gt; 
&lt;h3&gt;Try the Live Demo&lt;/h3&gt; 
&lt;p&gt;Don't want to install yet? Try our &lt;a href="https://demo.usememos.com/"&gt;live demo&lt;/a&gt; first!&lt;/p&gt; 
&lt;h3&gt;Other Installation Methods&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Docker Compose&lt;/strong&gt; - Recommended for production deployments&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Pre-built Binaries&lt;/strong&gt; - Available for Linux, macOS, and Windows&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Kubernetes&lt;/strong&gt; - Helm charts and manifests available&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Build from Source&lt;/strong&gt; - For development and customization&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See our &lt;a href="https://usememos.com/docs/installation"&gt;installation guide&lt;/a&gt; for detailed instructions.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions of all kinds! Whether you're fixing bugs, adding features, improving documentation, or helping with translations ‚Äî every contribution matters.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Ways to contribute:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üêõ &lt;a href="https://github.com/usememos/memos/issues/new?template=bug_report.md"&gt;Report bugs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üí° &lt;a href="https://github.com/usememos/memos/issues/new?template=feature_request.md"&gt;Suggest features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üîß &lt;a href="https://github.com/usememos/memos/pulls"&gt;Submit pull requests&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üìñ &lt;a href="https://github.com/usememos/memos/tree/main/docs"&gt;Improve documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üåç &lt;a href="https://github.com/usememos/memos/tree/main/web/src/locales"&gt;Help with translations&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;p&gt;Love Memos? &lt;a href="https://github.com/sponsors/usememos"&gt;Sponsor us on GitHub&lt;/a&gt; to help keep the project growing!&lt;/p&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#usememos/memos&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=usememos/memos&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Memos is open-source software licensed under the &lt;a href="https://raw.githubusercontent.com/usememos/memos/main/LICENSE"&gt;MIT License&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Privacy Policy&lt;/h2&gt; 
&lt;p&gt;Memos is built with privacy as a core principle. As a self-hosted application, all your data stays on your infrastructure. There is no telemetry, no tracking, and no data collection. See our &lt;a href="https://usememos.com/privacy"&gt;Privacy Policy&lt;/a&gt; for details.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://usememos.com"&gt;Website&lt;/a&gt;&lt;/strong&gt; ‚Ä¢ &lt;strong&gt;&lt;a href="https://usememos.com/docs"&gt;Documentation&lt;/a&gt;&lt;/strong&gt; ‚Ä¢ &lt;strong&gt;&lt;a href="https://demo.usememos.com/"&gt;Demo&lt;/a&gt;&lt;/strong&gt; ‚Ä¢ &lt;strong&gt;&lt;a href="https://discord.gg/tfPJa4UmAv"&gt;Discord&lt;/a&gt;&lt;/strong&gt; ‚Ä¢ &lt;strong&gt;&lt;a href="https://x.com/usememos"&gt;X/Twitter&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;a href="https://vercel.com/oss"&gt; &lt;img alt="Vercel OSS Program" src="https://vercel.com/oss/program-badge.svg?sanitize=true" /&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>Tencent/WeKnora</title>
      <link>https://github.com/Tencent/WeKnora</link>
      <description>&lt;p&gt;LLM-powered framework for deep document understanding, semantic retrieval, and context-aware answers using RAG paradigm.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/logo.png" alt="WeKnora Logo" height="120" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;a href="https://trendshift.io/repositories/15289" target="_blank"&gt; &lt;img src="https://trendshift.io/api/badge/repositories/15289" alt="Tencent%2FWeKnora | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt; &lt;/a&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://weknora.weixin.qq.com" target="_blank"&gt; &lt;img alt="ÂÆòÊñπÁΩëÁ´ô" src="https://img.shields.io/badge/ÂÆòÊñπÁΩëÁ´ô-WeKnora-4e6b99" /&gt; &lt;/a&gt; &lt;a href="https://chatbot.weixin.qq.com" target="_blank"&gt; &lt;img alt="ÂæÆ‰ø°ÂØπËØùÂºÄÊîæÂπ≥Âè∞" src="https://img.shields.io/badge/ÂæÆ‰ø°ÂØπËØùÂºÄÊîæÂπ≥Âè∞-5ac725" /&gt; &lt;/a&gt; &lt;a href="https://github.com/Tencent/WeKnora/raw/main/LICENSE"&gt; &lt;img src="https://img.shields.io/badge/License-MIT-ffffff?labelColor=d4eaf7&amp;amp;color=2e6cc4" alt="License" /&gt; &lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/CHANGELOG.md"&gt; &lt;img alt="Version" src="https://img.shields.io/badge/version-0.2.6-2e6cc4?labelColor=d4eaf7" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; | &lt;b&gt;English&lt;/b&gt; | &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/README_CN.md"&gt;&lt;b&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/b&gt;&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/README_JA.md"&gt;&lt;b&gt;Êó•Êú¨Ë™û&lt;/b&gt;&lt;/a&gt; | &lt;/p&gt; 
&lt;p align="center"&gt; &lt;/p&gt;
&lt;h4 align="center"&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-overview"&gt;Overview&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-architecture"&gt;Architecture&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-key-features"&gt;Key Features&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-getting-started"&gt;Getting Started&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-api-reference"&gt;API Reference&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-developer-guide"&gt;Developer Guide&lt;/a&gt;&lt;/p&gt; &lt;/h4&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;h1&gt;üí° WeKnora - LLM-Powered Document Understanding &amp;amp; Retrieval Framework&lt;/h1&gt; 
&lt;h2&gt;üìå Overview&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://weknora.weixin.qq.com"&gt;&lt;strong&gt;WeKnora&lt;/strong&gt;&lt;/a&gt; is an LLM-powered framework designed for deep document understanding and semantic retrieval, especially for handling complex, heterogeneous documents.&lt;/p&gt; 
&lt;p&gt;It adopts a modular architecture that combines multimodal preprocessing, semantic vector indexing, intelligent retrieval, and large language model inference. At its core, WeKnora follows the &lt;strong&gt;RAG (Retrieval-Augmented Generation)&lt;/strong&gt; paradigm, enabling high-quality, context-aware answers by combining relevant document chunks with model reasoning.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Website:&lt;/strong&gt; &lt;a href="https://weknora.weixin.qq.com"&gt;https://weknora.weixin.qq.com&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;‚ú® Latest Updates&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;v0.2.0 Highlights:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ü§ñ &lt;strong&gt;Agent Mode&lt;/strong&gt;: New ReACT Agent mode that can call built-in tools, MCP tools, and web search, providing comprehensive summary reports through multiple iterations and reflection&lt;/li&gt; 
 &lt;li&gt;üìö &lt;strong&gt;Multi-Type Knowledge Bases&lt;/strong&gt;: Support for FAQ and document knowledge base types, with new features including folder import, URL import, tag management, and online entry&lt;/li&gt; 
 &lt;li&gt;‚öôÔ∏è &lt;strong&gt;Conversation Strategy&lt;/strong&gt;: Support for configuring Agent models, normal mode models, retrieval thresholds, and Prompts, with precise control over multi-turn conversation behavior&lt;/li&gt; 
 &lt;li&gt;üåê &lt;strong&gt;Web Search&lt;/strong&gt;: Support for extensible web search engines with built-in DuckDuckGo search engine&lt;/li&gt; 
 &lt;li&gt;üîå &lt;strong&gt;MCP Tool Integration&lt;/strong&gt;: Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting multiple transport methods&lt;/li&gt; 
 &lt;li&gt;üé® &lt;strong&gt;New UI&lt;/strong&gt;: Optimized conversation interface with Agent mode/normal mode switching, tool call process display, and comprehensive knowledge base management interface upgrade&lt;/li&gt; 
 &lt;li&gt;‚ö° &lt;strong&gt;Infrastructure Upgrade&lt;/strong&gt;: Introduced MQ async task management, support for automatic database migration, and fast development mode&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üîí Security Notice&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt; Starting from v0.1.3, WeKnora includes login authentication functionality to enhance system security. For production deployments, we strongly recommend:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Deploy WeKnora services in internal/private network environments rather than public internet&lt;/li&gt; 
 &lt;li&gt;Avoid exposing the service directly to public networks to prevent potential information leakage&lt;/li&gt; 
 &lt;li&gt;Configure proper firewall rules and access controls for your deployment environment&lt;/li&gt; 
 &lt;li&gt;Regularly update to the latest version for security patches and improvements&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üèóÔ∏è Architecture&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/architecture.png" alt="weknora-architecture.png" /&gt;&lt;/p&gt; 
&lt;p&gt;WeKnora employs a modern modular design to build a complete document understanding and retrieval pipeline. The system primarily includes document parsing, vector processing, retrieval engine, and large model inference as core modules, with each component being flexibly configurable and extendable.&lt;/p&gt; 
&lt;h2&gt;üéØ Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ü§ñ Agent Mode&lt;/strong&gt;: Support for ReACT Agent mode that can use built-in tools to retrieve knowledge bases, MCP tools, and web search tools to access external services, providing comprehensive summary reports through multiple iterations and reflection&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîç Precise Understanding&lt;/strong&gt;: Structured content extraction from PDFs, Word documents, images and more into unified semantic views&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üß† Intelligent Reasoning&lt;/strong&gt;: Leverages LLMs to understand document context and user intent for accurate Q&amp;amp;A and multi-turn conversations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üìö Multi-Type Knowledge Bases&lt;/strong&gt;: Support for FAQ and document knowledge base types, with folder import, URL import, tag management, and online entry capabilities&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîß Flexible Extension&lt;/strong&gt;: All components from parsing and embedding to retrieval and generation are decoupled for easy customization&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;‚ö° Efficient Retrieval&lt;/strong&gt;: Hybrid retrieval strategies combining keywords, vectors, and knowledge graphs, with cross-knowledge base retrieval support&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üåê Web Search&lt;/strong&gt;: Support for extensible web search engines with built-in DuckDuckGo search engine&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîå MCP Tool Integration&lt;/strong&gt;: Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting multiple transport methods&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;‚öôÔ∏è Conversation Strategy&lt;/strong&gt;: Support for configuring Agent models, normal mode models, retrieval thresholds, and Prompts, with precise control over multi-turn conversation behavior&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üéØ User-Friendly&lt;/strong&gt;: Intuitive web interface and standardized APIs for zero technical barriers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîí Secure &amp;amp; Controlled&lt;/strong&gt;: Support for local deployment and private cloud, ensuring complete data sovereignty&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìä Application Scenarios&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Scenario&lt;/th&gt; 
   &lt;th&gt;Applications&lt;/th&gt; 
   &lt;th&gt;Core Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Enterprise Knowledge Management&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Internal document retrieval, policy Q&amp;amp;A, operation manual search&lt;/td&gt; 
   &lt;td&gt;Improve knowledge discovery efficiency, reduce training costs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Academic Research Analysis&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Paper retrieval, research report analysis, scholarly material organization&lt;/td&gt; 
   &lt;td&gt;Accelerate literature review, assist research decisions&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Product Technical Support&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Product manual Q&amp;amp;A, technical documentation search, troubleshooting&lt;/td&gt; 
   &lt;td&gt;Enhance customer service quality, reduce support burden&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Legal &amp;amp; Compliance Review&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Contract clause retrieval, regulatory policy search, case analysis&lt;/td&gt; 
   &lt;td&gt;Improve compliance efficiency, reduce legal risks&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Medical Knowledge Assistance&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Medical literature retrieval, treatment guideline search, case analysis&lt;/td&gt; 
   &lt;td&gt;Support clinical decisions, improve diagnosis quality&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üß© Feature Matrix&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Module&lt;/th&gt; 
   &lt;th&gt;Support&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Agent Mode&lt;/td&gt; 
   &lt;td&gt;‚úÖ ReACT Agent Mode&lt;/td&gt; 
   &lt;td&gt;Support for using built-in tools to retrieve knowledge bases, MCP tools, and web search, with cross-knowledge base retrieval and multiple iterations&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Knowledge Base Types&lt;/td&gt; 
   &lt;td&gt;‚úÖ FAQ / Document&lt;/td&gt; 
   &lt;td&gt;Support for creating FAQ and document knowledge base types, with folder import, URL import, tag management, and online entry&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Document Formats&lt;/td&gt; 
   &lt;td&gt;‚úÖ PDF / Word / Txt / Markdown / Images (with OCR / Caption)&lt;/td&gt; 
   &lt;td&gt;Support for structured and unstructured documents with text extraction from images&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Model Management&lt;/td&gt; 
   &lt;td&gt;‚úÖ Centralized configuration, built-in model sharing&lt;/td&gt; 
   &lt;td&gt;Centralized model configuration with model selection in knowledge base settings, support for multi-tenant shared built-in models&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Embedding Models&lt;/td&gt; 
   &lt;td&gt;‚úÖ Local models, BGE / GTE APIs, etc.&lt;/td&gt; 
   &lt;td&gt;Customizable embedding models, compatible with local deployment and cloud vector generation APIs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Vector DB Integration&lt;/td&gt; 
   &lt;td&gt;‚úÖ PostgreSQL (pgvector), Elasticsearch&lt;/td&gt; 
   &lt;td&gt;Support for mainstream vector index backends, flexible switching for different retrieval scenarios&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Retrieval Strategies&lt;/td&gt; 
   &lt;td&gt;‚úÖ BM25 / Dense Retrieval / GraphRAG&lt;/td&gt; 
   &lt;td&gt;Support for sparse/dense recall and knowledge graph-enhanced retrieval with customizable retrieve-rerank-generate pipelines&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;LLM Integration&lt;/td&gt; 
   &lt;td&gt;‚úÖ Support for Qwen, DeepSeek, etc., with thinking/non-thinking mode switching&lt;/td&gt; 
   &lt;td&gt;Compatible with local models (e.g., via Ollama) or external API services with flexible inference configuration&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Conversation Strategy&lt;/td&gt; 
   &lt;td&gt;‚úÖ Agent models, normal mode models, retrieval thresholds, Prompt configuration&lt;/td&gt; 
   &lt;td&gt;Support for configuring Agent models, normal mode models, retrieval thresholds, online Prompt configuration, precise control over multi-turn conversation behavior&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Web Search&lt;/td&gt; 
   &lt;td&gt;‚úÖ Extensible search engines, DuckDuckGo / Google&lt;/td&gt; 
   &lt;td&gt;Support for extensible web search engines with built-in DuckDuckGo search engine&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MCP Tools&lt;/td&gt; 
   &lt;td&gt;‚úÖ uvx, npx launchers, Stdio/HTTP Streamable/SSE&lt;/td&gt; 
   &lt;td&gt;Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting three transport methods&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;QA Capabilities&lt;/td&gt; 
   &lt;td&gt;‚úÖ Context-aware, multi-turn dialogue, prompt templates&lt;/td&gt; 
   &lt;td&gt;Support for complex semantic modeling, instruction control and chain-of-thought Q&amp;amp;A with configurable prompts and context windows&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;E2E Testing&lt;/td&gt; 
   &lt;td&gt;‚úÖ Retrieval+generation process visualization and metric evaluation&lt;/td&gt; 
   &lt;td&gt;End-to-end testing tools for evaluating recall hit rates, answer coverage, BLEU/ROUGE and other metrics&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Deployment Modes&lt;/td&gt; 
   &lt;td&gt;‚úÖ Support for local deployment / Docker images&lt;/td&gt; 
   &lt;td&gt;Meets private, offline deployment and flexible operation requirements, with fast development mode support&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;User Interfaces&lt;/td&gt; 
   &lt;td&gt;‚úÖ Web UI + RESTful API&lt;/td&gt; 
   &lt;td&gt;Interactive interface and standard API endpoints, with Agent mode/normal mode switching and tool call process display&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Task Management&lt;/td&gt; 
   &lt;td&gt;‚úÖ MQ async tasks, automatic database migration&lt;/td&gt; 
   &lt;td&gt;MQ-based async task state maintenance, support for automatic database schema and data migration during version upgrades&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üöÄ Getting Started&lt;/h2&gt; 
&lt;h3&gt;üõ† Prerequisites&lt;/h3&gt; 
&lt;p&gt;Make sure the following tools are installed on your system:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.docker.com/compose/"&gt;Docker Compose&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://git-scm.com/"&gt;Git&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üì¶ Installation&lt;/h3&gt; 
&lt;h4&gt;‚ë† Clone the repository&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone the main repository
git clone https://github.com/Tencent/WeKnora.git
cd WeKnora
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;‚ë° Configure environment variables&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Copy example env file
cp .env.example .env

# Edit .env and set required values
# All variables are documented in the .env.example comments
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;‚ë¢ Start the services (include Ollama)&lt;/h4&gt; 
&lt;p&gt;Check the images that need to be started in the .env file.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/start_all.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make start-all
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;‚ë¢.0 Start ollama services (Optional)&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;ollama serve &amp;gt; /dev/null 2&amp;gt;&amp;amp;1 &amp;amp;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;‚ë¢.1 Activate different combinations of features&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Minimum core services&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;All features enabled&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose --profile full up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Tracing logs required&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose --profile jaeger up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Neo4j knowledge graph required&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose --profile neo4j up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Minio file storage service required&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose --profile minio up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Multiple options combination&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose --profile neo4j --profile minio up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;‚ë£ Stop the services&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/start_all.sh --stop
# Or
make stop-all
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;üåê Access Services&lt;/h3&gt; 
&lt;p&gt;Once started, services will be available at:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Web UI: &lt;code&gt;http://localhost&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Backend API: &lt;code&gt;http://localhost:8080&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Jaeger Tracing: &lt;code&gt;http://localhost:16686&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üîå Using WeChat Dialog Open Platform&lt;/h3&gt; 
&lt;p&gt;WeKnora serves as the core technology framework for the &lt;a href="https://chatbot.weixin.qq.com"&gt;WeChat Dialog Open Platform&lt;/a&gt;, providing a more convenient usage approach:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Zero-code Deployment&lt;/strong&gt;: Simply upload knowledge to quickly deploy intelligent Q&amp;amp;A services within the WeChat ecosystem, achieving an "ask and answer" experience&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Efficient Question Management&lt;/strong&gt;: Support for categorized management of high-frequency questions, with rich data tools to ensure accurate, reliable, and easily maintainable answers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;WeChat Ecosystem Integration&lt;/strong&gt;: Through the WeChat Dialog Open Platform, WeKnora's intelligent Q&amp;amp;A capabilities can be seamlessly integrated into WeChat Official Accounts, Mini Programs, and other WeChat scenarios, enhancing user interaction experiences&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üîó Access WeKnora via MCP Server&lt;/h3&gt; 
&lt;h4&gt;1Ô∏è‚É£ Clone the repository&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/Tencent/WeKnora
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2Ô∏è‚É£ Configure MCP Server&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;It is recommended to directly refer to the &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/mcp-server/MCP_CONFIG.md"&gt;MCP Configuration Guide&lt;/a&gt; for configuration.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Configure the MCP client to connect to the server:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "weknora": {
      "args": [
        "path/to/WeKnora/mcp-server/run_server.py"
      ],
      "command": "python",
      "env":{
        "WEKNORA_API_KEY":"Enter your WeKnora instance, open developer tools, check the request header x-api-key starting with sk",
        "WEKNORA_BASE_URL":"http(s)://your-weknora-address/api/v1"
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run directly using stdio command:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pip install weknora-mcp-server
python -m weknora-mcp-server
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üîß Initialization Configuration Guide&lt;/h2&gt; 
&lt;p&gt;To help users quickly configure various models and reduce trial-and-error costs, we've improved the original configuration file initialization method by adding a Web UI interface for model configuration. Before using, please ensure the code is updated to the latest version. The specific steps are as follows: If this is your first time using this project, you can skip steps ‚ë†‚ë° and go directly to steps ‚ë¢‚ë£.&lt;/p&gt; 
&lt;h3&gt;‚ë† Stop the services&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/start_all.sh --stop
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;‚ë° Clear existing data tables (recommended when no important data exists)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make clean-db
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;‚ë¢ Compile and start services&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/start_all.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;‚ë£ Access Web UI&lt;/h3&gt; 
&lt;p&gt;&lt;a href="http://localhost"&gt;http://localhost&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;On your first visit, you will be automatically redirected to the registration/login page. After completing registration, please create a new knowledge base and finish the relevant settings on its configuration page.&lt;/p&gt; 
&lt;h2&gt;üì± Interface Showcase&lt;/h2&gt; 
&lt;h3&gt;Web UI Interface&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt;&lt;b&gt;Knowledge Base Management&lt;/b&gt;&lt;br /&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/knowledgebases.png" alt="Knowledge Base Management" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;b&gt;Conversation Settings&lt;/b&gt;&lt;br /&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/settings.png" alt="Conversation Settings" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td colspan="2"&gt;&lt;b&gt;Agent Mode Tool Call Process&lt;/b&gt;&lt;br /&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/agent-qa.png" alt="Agent Mode Tool Call Process" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Knowledge Base Management:&lt;/strong&gt; Support for creating FAQ and document knowledge base types, with multiple import methods including drag-and-drop, folder import, and URL import. Automatically identifies document structures and extracts core knowledge to establish indexes. Supports tag management and online entry. The system clearly displays processing progress and document status, achieving efficient knowledge base management.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Agent Mode:&lt;/strong&gt; Support for ReACT Agent mode that can use built-in tools to retrieve knowledge bases, call user-configured MCP tools and web search tools to access external services, providing comprehensive summary reports through multiple iterations and reflection. Supports cross-knowledge base retrieval, allowing selection of multiple knowledge bases for simultaneous retrieval.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Conversation Strategy:&lt;/strong&gt; Support for configuring Agent models, normal mode models, retrieval thresholds, and online Prompt configuration, with precise control over multi-turn conversation behavior and retrieval execution methods. The conversation input box supports Agent mode/normal mode switching, enabling/disabling web search, and selecting conversation models.&lt;/p&gt; 
&lt;h3&gt;Document Knowledge Graph&lt;/h3&gt; 
&lt;p&gt;WeKnora supports transforming documents into knowledge graphs, displaying the relationships between different sections of the documents. Once the knowledge graph feature is enabled, the system analyzes and constructs an internal semantic association network that not only helps users understand document content but also provides structured support for indexing and retrieval, enhancing the relevance and breadth of search results.&lt;/p&gt; 
&lt;p&gt;For detailed configuration, please refer to the &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/KnowledgeGraph.md"&gt;Knowledge Graph Configuration Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;MCP Server&lt;/h3&gt; 
&lt;p&gt;Please refer to the &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/mcp-server/MCP_CONFIG.md"&gt;MCP Configuration Guide&lt;/a&gt; for the necessary setup.&lt;/p&gt; 
&lt;h2&gt;üìò API Reference&lt;/h2&gt; 
&lt;p&gt;Troubleshooting FAQ: &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/QA.md"&gt;Troubleshooting FAQ&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Detailed API documentation is available at: &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/api/README.md"&gt;API Docs&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üß≠ Developer Guide&lt;/h2&gt; 
&lt;h3&gt;‚ö° Fast Development Mode (Recommended)&lt;/h3&gt; 
&lt;p&gt;If you need to frequently modify code, &lt;strong&gt;you don't need to rebuild Docker images every time&lt;/strong&gt;! Use fast development mode:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Method 1: Using Make commands (Recommended)
make dev-start      # Start infrastructure
make dev-app        # Start backend (new terminal)
make dev-frontend   # Start frontend (new terminal)

# Method 2: One-click start
./scripts/quick-dev.sh

# Method 3: Using scripts
./scripts/dev.sh start     # Start infrastructure
./scripts/dev.sh app       # Start backend (new terminal)
./scripts/dev.sh frontend  # Start frontend (new terminal)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Development Advantages:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚úÖ Frontend modifications auto hot-reload (no restart needed)&lt;/li&gt; 
 &lt;li&gt;‚úÖ Backend modifications quick restart (5-10 seconds, supports Air hot-reload)&lt;/li&gt; 
 &lt;li&gt;‚úÖ No need to rebuild Docker images&lt;/li&gt; 
 &lt;li&gt;‚úÖ Support IDE breakpoint debugging&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Detailed Documentation:&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97.md"&gt;Development Environment Quick Start&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;üìÅ Directory Structure&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;WeKnora/
‚îú‚îÄ‚îÄ client/      # go client
‚îú‚îÄ‚îÄ cmd/         # Main entry point
‚îú‚îÄ‚îÄ config/      # Configuration files
‚îú‚îÄ‚îÄ docker/      # docker images files
‚îú‚îÄ‚îÄ docreader/   # Document parsing app
‚îú‚îÄ‚îÄ docs/        # Project documentation
‚îú‚îÄ‚îÄ frontend/    # Frontend app
‚îú‚îÄ‚îÄ internal/    # Core business logic
‚îú‚îÄ‚îÄ mcp-server/  # MCP server
‚îú‚îÄ‚îÄ migrations/  # DB migration scripts
‚îî‚îÄ‚îÄ scripts/     # Shell scripts
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome community contributions! For suggestions, bugs, or feature requests, please submit an &lt;a href="https://github.com/Tencent/WeKnora/issues"&gt;Issue&lt;/a&gt; or directly create a Pull Request.&lt;/p&gt; 
&lt;h3&gt;üéØ How to Contribute&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üêõ &lt;strong&gt;Bug Fixes&lt;/strong&gt;: Discover and fix system defects&lt;/li&gt; 
 &lt;li&gt;‚ú® &lt;strong&gt;New Features&lt;/strong&gt;: Propose and implement new capabilities&lt;/li&gt; 
 &lt;li&gt;üìö &lt;strong&gt;Documentation&lt;/strong&gt;: Improve project documentation&lt;/li&gt; 
 &lt;li&gt;üß™ &lt;strong&gt;Test Cases&lt;/strong&gt;: Write unit and integration tests&lt;/li&gt; 
 &lt;li&gt;üé® &lt;strong&gt;UI/UX Enhancements&lt;/strong&gt;: Improve user interface and experience&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üìã Contribution Process&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Fork the project&lt;/strong&gt; to your GitHub account&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Create a feature branch&lt;/strong&gt; &lt;code&gt;git checkout -b feature/amazing-feature&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Commit changes&lt;/strong&gt; &lt;code&gt;git commit -m 'Add amazing feature'&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Push branch&lt;/strong&gt; &lt;code&gt;git push origin feature/amazing-feature&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Create a Pull Request&lt;/strong&gt; with detailed description of changes&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;üé® Code Standards&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Follow &lt;a href="https://github.com/golang/go/wiki/CodeReviewComments"&gt;Go Code Review Comments&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Format code using &lt;code&gt;gofmt&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Add necessary unit tests&lt;/li&gt; 
 &lt;li&gt;Update relevant documentation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üìù Commit Guidelines&lt;/h3&gt; 
&lt;p&gt;Use &lt;a href="https://www.conventionalcommits.org/"&gt;Conventional Commits&lt;/a&gt; standard:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;feat: Add document batch upload functionality
fix: Resolve vector retrieval precision issue
docs: Update API documentation
test: Add retrieval engine test cases
refactor: Restructure document parsing module
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üë• Contributors&lt;/h2&gt; 
&lt;p&gt;Thanks to these excellent contributors:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Tencent/WeKnora/graphs/contributors"&gt;&lt;img src="https://contrib.rocks/image?repo=Tencent/WeKnora" alt="Contributors" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/LICENSE"&gt;MIT License&lt;/a&gt;. You are free to use, modify, and distribute the code with proper attribution.&lt;/p&gt; 
&lt;h2&gt;üìà Project Statistics&lt;/h2&gt; 
&lt;a href="https://www.star-history.com/#Tencent/WeKnora&amp;amp;type=date&amp;amp;legend=top-left"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=Tencent/WeKnora&amp;amp;type=date&amp;amp;theme=dark&amp;amp;legend=top-left" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=Tencent/WeKnora&amp;amp;type=date&amp;amp;legend=top-left" /&gt; 
  &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=Tencent/WeKnora&amp;amp;type=date&amp;amp;legend=top-left" /&gt; 
 &lt;/picture&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>netbirdio/netbird</title>
      <link>https://github.com/netbirdio/netbird</link>
      <description>&lt;p&gt;Connect your devices into a secure WireGuard¬Æ-based overlay network with SSO, MFA and granular access controls.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;br /&gt; 
 &lt;br /&gt; 
 &lt;p align="center"&gt; &lt;img width="234" src="https://raw.githubusercontent.com/netbirdio/netbird/main/docs/media/logo-full.png" /&gt; &lt;/p&gt; 
 &lt;p&gt; &lt;a href="https://img.shields.io/badge/license-BSD--3-blue)"&gt; &lt;img src="https://sonarcloud.io/api/project_badges/measure?project=netbirdio_netbird&amp;amp;metric=alert_status" /&gt; &lt;/a&gt; &lt;a href="https://github.com/netbirdio/netbird/raw/main/LICENSE"&gt; &lt;img src="https://img.shields.io/badge/license-BSD--3-blue" /&gt; &lt;/a&gt; &lt;br /&gt; &lt;a href="https://docs.netbird.io/slack-url"&gt; &lt;img src="https://img.shields.io/badge/slack-@netbird-red.svg?logo=slack" /&gt; &lt;/a&gt; &lt;a href="https://forum.netbird.io"&gt; &lt;img src="https://img.shields.io/badge/community forum-@netbird-red.svg?logo=discourse" /&gt; &lt;/a&gt; &lt;br /&gt; &lt;a href="https://gurubase.io/g/netbird"&gt; &lt;img src="https://img.shields.io/badge/Gurubase-Ask%20NetBird%20Guru-006BFF" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt; &lt;strong&gt; Start using NetBird at &lt;a href="https://netbird.io/pricing"&gt;netbird.io&lt;/a&gt; &lt;br /&gt; See &lt;a href="https://netbird.io/docs/"&gt;Documentation&lt;/a&gt; &lt;br /&gt; Join our &lt;a href="https://docs.netbird.io/slack-url"&gt;Slack channel&lt;/a&gt; or our &lt;a href="https://forum.netbird.io"&gt;Community forum&lt;/a&gt; &lt;br /&gt; &lt;/strong&gt; &lt;br /&gt; &lt;strong&gt; üöÄ &lt;a href="https://careers.netbird.io"&gt;We are hiring! Join us at careers.netbird.io&lt;/a&gt; &lt;/strong&gt; &lt;br /&gt; &lt;br /&gt; &lt;a href="https://registry.terraform.io/providers/netbirdio/netbird/latest"&gt; New: NetBird terraform provider &lt;/a&gt; &lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;strong&gt;NetBird combines a configuration-free peer-to-peer private network and a centralized access control system in a single platform, making it easy to create secure private networks for your organization or home.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Connect.&lt;/strong&gt; NetBird creates a WireGuard-based overlay network that automatically connects your machines over an encrypted tunnel, leaving behind the hassle of opening ports, complex firewall rules, VPN gateways, and so forth.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Secure.&lt;/strong&gt; NetBird enables secure remote access by applying granular access policies while allowing you to manage them intuitively from a single place. Works universally on any infrastructure.&lt;/p&gt; 
&lt;h3&gt;Open Source Network Security in a Single Platform&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/10cec749-bb56-4ab3-97af-4e38850108d2"&gt;https://github.com/user-attachments/assets/10cec749-bb56-4ab3-97af-4e38850108d2&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;NetBird on Lawrence Systems (Video)&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=Kwrff6h0rEw"&gt;&lt;img src="https://img.youtube.com/vi/Kwrff6h0rEw/0.jpg" alt="Watch the video" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Key features&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Connectivity&lt;/th&gt; 
   &lt;th&gt;Management&lt;/th&gt; 
   &lt;th&gt;Security&lt;/th&gt; 
   &lt;th&gt;Automation&lt;/th&gt; 
   &lt;th&gt;Platforms&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Kernel WireGuard&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://github.com/netbirdio/dashboard"&gt;Admin Web UI&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/installation#running-net-bird-with-sso-login"&gt;SSO &amp;amp; MFA support&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/api"&gt;Public API&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Linux&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Peer-to-peer connections&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Auto peer discovery and configuration&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/manage-network-access"&gt;Access control - groups &amp;amp; rules&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/register-machines-using-setup-keys"&gt;Setup keys for bulk network provisioning&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Mac&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Connection relay fallback&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/selfhosted/identity-providers"&gt;IdP integrations&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/audit-events-logging"&gt;Activity logging&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/selfhosted/selfhosted-quickstart"&gt;Self-hosting quickstart script&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Windows&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/routing-traffic-to-private-networks"&gt;Routes to external networks&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/manage-dns-in-your-network"&gt;Private DNS&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/manage-posture-checks"&gt;Device posture checks&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] IdP groups sync with JWT&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Android&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] NAT traversal with BPF&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/add-users-to-your-network"&gt;Multiuser support&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Peer-to-peer encryption&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] iOS&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://netbird.io/knowledge-hub/the-first-quantum-resistant-mesh-vpn"&gt;Quantum-resistance with Rosenpass&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] OpenWRT&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/enforce-periodic-user-authentication"&gt;Periodic re-authentication&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] &lt;a href="https://docs.netbird.io/how-to/netbird-on-faas"&gt;Serverless&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;
    &lt;ul&gt;
     &lt;li&gt;- [x] Docker&lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Quickstart with NetBird Cloud&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Download and install NetBird at &lt;a href="https://app.netbird.io/install"&gt;https://app.netbird.io/install&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Follow the steps to sign-up with Google, Microsoft, GitHub or your email address.&lt;/li&gt; 
 &lt;li&gt;Check NetBird &lt;a href="https://app.netbird.io/"&gt;admin UI&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Add more machines.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Quickstart with self-hosted NetBird&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;This is the quickest way to try self-hosted NetBird. It should take around 5 minutes to get started if you already have a public domain and a VM. Follow the &lt;a href="https://docs.netbird.io/selfhosted/selfhosted-guide#advanced-guide-with-a-custom-identity-provider"&gt;Advanced guide with a custom identity provider&lt;/a&gt; for installations with different IDPs.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Infrastructure requirements:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;A Linux VM with at least &lt;strong&gt;1CPU&lt;/strong&gt; and &lt;strong&gt;2GB&lt;/strong&gt; of memory.&lt;/li&gt; 
 &lt;li&gt;The VM should be publicly accessible on TCP ports &lt;strong&gt;80&lt;/strong&gt; and &lt;strong&gt;443&lt;/strong&gt; and UDP port: &lt;strong&gt;3478&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Public domain&lt;/strong&gt; name pointing to the VM.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Software requirements:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Docker installed on the VM with the docker-compose plugin (&lt;a href="https://docs.docker.com/engine/install/"&gt;Docker installation guide&lt;/a&gt;) or docker with docker-compose in version 2 or higher.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://jqlang.github.io/jq/"&gt;jq&lt;/a&gt; installed. In most distributions Usually available in the official repositories and can be installed with &lt;code&gt;sudo apt install jq&lt;/code&gt; or &lt;code&gt;sudo yum install jq&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://curl.se/"&gt;curl&lt;/a&gt; installed. Usually available in the official repositories and can be installed with &lt;code&gt;sudo apt install curl&lt;/code&gt; or &lt;code&gt;sudo yum install curl&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Steps&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Download and run the installation script:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export NETBIRD_DOMAIN=netbird.example.com; curl -fsSL https://github.com/netbirdio/netbird/releases/latest/download/getting-started.sh | bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Once finished, you can manage the resources via &lt;code&gt;docker-compose&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;A bit on NetBird internals&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Every machine in the network runs &lt;a href="https://raw.githubusercontent.com/netbirdio/netbird/main/client/"&gt;NetBird Agent (or Client)&lt;/a&gt; that manages WireGuard.&lt;/li&gt; 
 &lt;li&gt;Every agent connects to &lt;a href="https://raw.githubusercontent.com/netbirdio/netbird/main/management/"&gt;Management Service&lt;/a&gt; that holds network state, manages peer IPs, and distributes network updates to agents (peers).&lt;/li&gt; 
 &lt;li&gt;NetBird agent uses WebRTC ICE implemented in &lt;a href="https://github.com/pion/ice"&gt;pion/ice library&lt;/a&gt; to discover connection candidates when establishing a peer-to-peer connection between machines.&lt;/li&gt; 
 &lt;li&gt;Connection candidates are discovered with the help of &lt;a href="https://en.wikipedia.org/wiki/STUN"&gt;STUN&lt;/a&gt; servers.&lt;/li&gt; 
 &lt;li&gt;Agents negotiate a connection through &lt;a href="https://raw.githubusercontent.com/netbirdio/netbird/main/signal/"&gt;Signal Service&lt;/a&gt; passing p2p encrypted messages with candidates.&lt;/li&gt; 
 &lt;li&gt;Sometimes the NAT traversal is unsuccessful due to strict NATs (e.g. mobile carrier-grade NAT) and a p2p connection isn't possible. When this occurs the system falls back to a relay server called &lt;a href="https://en.wikipedia.org/wiki/Traversal_Using_Relays_around_NAT"&gt;TURN&lt;/a&gt;, and a secure WireGuard tunnel is established via the TURN server.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://github.com/coturn/coturn"&gt;Coturn&lt;/a&gt; is the one that has been successfully used for STUN and TURN in NetBird setups.&lt;/p&gt; 
&lt;p float="left" align="middle"&gt; &lt;img src="https://docs.netbird.io/docs-static/img/about-netbird/high-level-dia.png" width="700" /&gt; &lt;/p&gt; 
&lt;p&gt;See a complete &lt;a href="https://docs.netbird.io/about-netbird/how-netbird-works#architecture"&gt;architecture overview&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h3&gt;Community projects&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/physk/netbird-installer"&gt;NetBird installer script&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://galaxy.ansible.com/ui/repo/published/dominion_solutions/netbird/"&gt;NetBird ansible collection by Dominion Solutions&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The &lt;code&gt;main&lt;/code&gt; branch may be in an &lt;em&gt;unstable or even broken state&lt;/em&gt; during development. For stable versions, see &lt;a href="https://github.com/netbirdio/netbird/releases"&gt;releases&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Support acknowledgement&lt;/h3&gt; 
&lt;p&gt;In November 2022, NetBird joined the &lt;a href="https://www.forschung-it-sicherheit-kommunikationssysteme.de/foerderung/bekanntmachungen/startup-secure"&gt;StartUpSecure program&lt;/a&gt; sponsored by The Federal Ministry of Education and Research of The Federal Republic of Germany. Together with &lt;a href="https://cispa.de/en"&gt;CISPA Helmholtz Center for Information Security&lt;/a&gt; NetBird brings the security best practices and simplicity to private networking.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/700848/203091324-c6d311a0-22b5-4b05-a288-91cbc6cdcc46.png" alt="CISPA_Logo_BLACK_EN_RZ_RGB (1)" /&gt;&lt;/p&gt; 
&lt;h3&gt;Testimonials&lt;/h3&gt; 
&lt;p&gt;We use open-source technologies like &lt;a href="https://www.wireguard.com/"&gt;WireGuard¬Æ&lt;/a&gt;, &lt;a href="https://github.com/pion/ice"&gt;Pion ICE (WebRTC)&lt;/a&gt;, &lt;a href="https://github.com/coturn/coturn"&gt;Coturn&lt;/a&gt;, and &lt;a href="https://rosenpass.eu"&gt;Rosenpass&lt;/a&gt;. We very much appreciate the work these guys are doing and we'd greatly appreciate if you could support them in any way (e.g., by giving a star or a contribution).&lt;/p&gt; 
&lt;h3&gt;Legal&lt;/h3&gt; 
&lt;p&gt;This repository is licensed under BSD-3-Clause license that applies to all parts of the repository except for the directories management/, signal/ and relay/. Those directories are licensed under the GNU Affero General Public License version 3.0 (AGPLv3). See the respective LICENSE files inside each directory.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;WireGuard&lt;/em&gt; and the &lt;em&gt;WireGuard&lt;/em&gt; logo are &lt;a href="https://www.wireguard.com/trademark-policy/"&gt;registered trademarks&lt;/a&gt; of Jason A. Donenfeld.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>NexaAI/nexa-sdk</title>
      <link>https://github.com/NexaAI/nexa-sdk</link>
      <description>&lt;p&gt;Run frontier LLMs and VLMs with day-0 model support across GPU, NPU, and CPU, with comprehensive runtime coverage for PC (Python/C++), mobile (Android &amp; iOS), and Linux/IoT (Arm64 &amp; x86 Docker). Supporting OpenAI GPT-OSS, IBM Granite-4, Qwen-3-VL, Gemma-3n, Ministral-3, and more.&lt;/p&gt;&lt;hr&gt;&lt;div align="center" style="text-decoration: none;"&gt; 
 &lt;img width="100%" src="https://raw.githubusercontent.com/NexaAI/nexa-sdk/main/assets/banner1.png" alt="Nexa AI Banner" /&gt; 
 &lt;p style="font-size: 1.3em; font-weight: 600; margin-bottom: 20px;"&gt; &lt;a href="https://raw.githubusercontent.com/NexaAI/nexa-sdk/main/README_zh.md"&gt; ÁÆÄ‰Ωì‰∏≠Êñá &lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/NexaAI/nexa-sdk/main/README.md"&gt; English &lt;/a&gt; &lt;/p&gt; 
 &lt;p style="font-size: 1.3em; font-weight: 600; margin-bottom: 20px;"&gt;ü§ù Supported chipmakers &lt;/p&gt; 
 &lt;picture&gt; 
  &lt;source srcset="assets/chipmakers-dark.png" media="(prefers-color-scheme: dark)" /&gt; 
  &lt;source srcset="assets/chipmakers.png" media="(prefers-color-scheme: light)" /&gt; 
  &lt;img src="https://raw.githubusercontent.com/NexaAI/nexa-sdk/main/assets/chipmakers.png" style="max-height:30px; height:auto; width:auto;" /&gt; 
 &lt;/picture&gt; 
 &lt;p&gt;&lt;/p&gt; 
 &lt;p&gt; &lt;a href="https://www.producthunt.com/products/nexasdk-for-mobile?embed=true&amp;amp;utm_source=badge-top-post-badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=badge-nexasdk-for-mobile" target="_blank" rel="noopener noreferrer"&gt; &lt;img alt="NexaSDK for Mobile - #1 Product of the Day" width="180" height="39" src="https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?post_id=1049998&amp;amp;theme=dark&amp;amp;period=daily&amp;amp;t=1765991451976" /&gt; &lt;/a&gt; &lt;a href="https://trendshift.io/repositories/12239" target="_blank" rel="noopener noreferrer"&gt; &lt;img alt="NexaAI/nexa-sdk - #1 Repository of the Day" height="39" src="https://trendshift.io/api/badge/repositories/12239" /&gt; &lt;/a&gt; &lt;/p&gt; 
 &lt;p&gt; &lt;a href="https://docs.nexa.ai"&gt; &lt;img src="https://img.shields.io/badge/docs-website-brightgreen?logo=readthedocs" alt="Documentation" /&gt; &lt;/a&gt; &lt;a href="https://sdk.nexa.ai/wishlist"&gt; &lt;img src="https://img.shields.io/badge/üéØ_Vote_for-Next_Models-ff69b4?style=flat-square" alt="Vote for Next Models" /&gt; &lt;/a&gt; &lt;a href="https://x.com/nexa_ai"&gt;&lt;img alt="X account" src="https://img.shields.io/twitter/url/https/twitter.com/diffuserslib.svg?style=social&amp;amp;label=Follow%20%40Nexa_AI" /&gt;&lt;/a&gt; &lt;a href="https://discord.com/invite/nexa-ai"&gt; &lt;img src="https://img.shields.io/discord/1192186167391682711?color=5865F2&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;style=flat-square" alt="Join us on Discord" /&gt; &lt;/a&gt; &lt;a href="https://join.slack.com/t/nexa-ai-community/shared_invite/zt-3837k9xpe-LEty0disTTUnTUQ4O3uuNw"&gt; &lt;img src="https://img.shields.io/badge/slack-join%20chat-4A154B?logo=slack&amp;amp;logoColor=white" alt="Join us on Slack" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;h1&gt;NexaSDK&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;NexaSDK lets you build the smartest and fastest on-device AI with minimum energy.&lt;/strong&gt; It is a highly performant local inference framework that runs the latest multimodal AI models locally on NPU, GPU, and CPU - across Android, Windows, Linux, macOS, and iOS devices with a few lines of code.&lt;/p&gt; 
&lt;p&gt;NexaSDK supports latest models &lt;strong&gt;weeks or months before anyone else&lt;/strong&gt; ‚Äî Qwen3-VL, DeepSeek-OCR, Gemma3n (Vision), and more.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;‚≠ê &lt;strong&gt;Star this repo&lt;/strong&gt; to keep up with exciting updates and new releases about latest on-device AI capabilities.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;üèÜ Recognized Milestones&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Qualcomm&lt;/strong&gt; featured us &lt;strong&gt;3 times&lt;/strong&gt; in official blogs. 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://www.qualcomm.com/developer/blog/2025/09/omnineural-4b-nexaml-qualcomm-hexagon-npu"&gt;Innovating Multimodal AI on Qualcomm Hexagon NPU&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.qualcomm.com/developer/blog/2025/10/granite-4-0-to-the-edge-on-device-ai-for-real-world-performance"&gt;First-ever Day-0 model support on Qualcomm Hexagon NPU for compute and mobile platforms, Auto and IoT&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.qualcomm.com/developer/blog/2025/11/nexa-ai-for-android-simple-way-to-bring-on-device-ai-to-smartphones-with-snapdragon"&gt;A simple way to bring on-device AI to smartphones with Snapdragon&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Qwen&lt;/strong&gt; featured us for &lt;a href="https://x.com/Alibaba_Qwen/status/1978154384098754943"&gt;Day-0 Qwen3-VL support on NPU, GPU, and CPU&lt;/a&gt;. We were 3 weeks ahead of Ollama and llama.cpp on GGUF support, and no one else supports it on NPU to date.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;IBM&lt;/strong&gt; featured our NexaML inference engine alongside vLLM, llama.cpp, and MLX in &lt;a href="https://www.ibm.com/new/announcements/ibm-granite-4-0-hyper-efficient-high-performance-hybrid-models"&gt;official IBM blog&lt;/a&gt; and also for Day-0 Granite 4.0 support.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Google&lt;/strong&gt; featured us for &lt;a href="https://x.com/googleaidevs/status/1969188152049889511"&gt;EmbeddingGemma Day-0 NPU support&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;AMD&lt;/strong&gt; featured us for &lt;a href="https://www.amd.com/en/developer/resources/technical-articles/2025/advancing-ai-with-nexa-ai--image-generation-on-amd-npu-with-sdxl.html"&gt;enabling SDXL-turbo image generation on AMD NPU&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;NVIDIA&lt;/strong&gt; featured Hyperlink, a viral local AI app powered by NexaSDK, in their &lt;a href="https://blogs.nvidia.com/blog/rtx-ai-garage-nexa-hyperlink-local-agent/"&gt;official blog&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Microsoft&lt;/strong&gt; presented us on stage at Microsoft Ignite 2025 as &lt;a href="https://www.linkedin.com/posts/mixen_excited-to-celebrate-our-developer-partnerships-activity-7396601602327007232-AmCR?utm_source=share&amp;amp;utm_medium=member_desktop&amp;amp;rcm=ACoAAChXnS8B4gqbBLUlWfwt-ck0XAv472NzT4k"&gt;official partner&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Intel&lt;/strong&gt; featured us for &lt;a href="https://www.linkedin.com/posts/intel-software_ai-ondeviceai-nexasdk-activity-7376337062087667712-xw7i?utm_source=share&amp;amp;utm_medium=member_desktop&amp;amp;rcm=ACoAAChXnS8B4gqbBLUlWfwt-ck0XAv472NzT4k"&gt;Intel NPU support in NexaSDK&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üöÄ Quick Start&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Platform&lt;/th&gt; 
   &lt;th&gt;Links&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;üñ•Ô∏è CLI&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/NexaAI/nexa-sdk/main/#-cli"&gt;Quick Start&lt;/a&gt; ÔΩú &lt;a href="https://docs.nexa.ai/en/nexa-sdk-go/NexaCLI"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;üêç Python&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/NexaAI/nexa-sdk/main/#-python-sdk"&gt;Quick Start&lt;/a&gt; ÔΩú &lt;a href="https://docs.nexa.ai/en/nexa-sdk-python/overview"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ü§ñ Android&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/NexaAI/nexa-sdk/main/#-android-sdk"&gt;Quick Start&lt;/a&gt; ÔΩú &lt;a href="https://docs.nexa.ai/en/nexa-sdk-android/overview"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;üê≥ Linux Docker&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/NexaAI/nexa-sdk/main/#-linux-docker"&gt;Quick Start&lt;/a&gt; ÔΩú &lt;a href="https://docs.nexa.ai/en/nexa-sdk-docker/overview"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;üçé iOS&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/NexaAI/nexa-sdk/main/#-ios-sdk"&gt;Quick Start&lt;/a&gt; ÔΩú &lt;a href="https://docs.nexa.ai/en/nexa-sdk-ios/overview"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h3&gt;üñ•Ô∏è CLI&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Download:&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Windows&lt;/th&gt; 
   &lt;th&gt;macOS&lt;/th&gt; 
   &lt;th&gt;Linux&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://public-storage.nexa4ai.com/nexa_sdk/downloads/nexa-cli_windows_arm64.exe"&gt;arm64 (Qualcomm NPU)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://public-storage.nexa4ai.com/nexa_sdk/downloads/nexa-cli_macos_arm64.pkg"&gt;arm64 (Apple Silicon)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/NexaAI/nexa-sdk/releases/latest/download/nexa-cli_linux_arm64.sh"&gt;arm64&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://public-storage.nexa4ai.com/nexa_sdk/downloads/nexa-cli_windows_x86_64.exe"&gt;x64 (Intel/AMD NPU)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://public-storage.nexa4ai.com/nexa_sdk/downloads/nexa-cli_macos_x86_64.pkg"&gt;x64&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/NexaAI/nexa-sdk/releases/latest/download/nexa-cli_linux_x86_64.sh"&gt;x64&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Run your first model:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Chat with Qwen3
nexa infer ggml-org/Qwen3-1.7B-GGUF

# Multimodal: drag images into the CLI
nexa infer NexaAI/Qwen3-VL-4B-Instruct-GGUF

# NPU (Windows arm64 with Snapdragon X Elite)
nexa infer NexaAI/OmniNeural-4B
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Models:&lt;/strong&gt; LLM, Multimodal, ASR, OCR, Rerank, Object Detection, Image Generation, Embedding&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Formats:&lt;/strong&gt; GGUF, MLX, NEXA&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;NPU Models:&lt;/strong&gt; &lt;a href="https://sdk.nexa.ai/model"&gt;Model Hub&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üìñ &lt;a href="https://docs.nexa.ai/en/nexa-sdk-go/NexaCLI"&gt;CLI Reference Docs&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h3&gt;üêç Python SDK&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install nexaai
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from nexaai import LLM, GenerationConfig, ModelConfig, LlmChatMessage

llm = LLM.from_(model="NexaAI/Qwen3-0.6B-GGUF", config=ModelConfig())

conversation = [
    LlmChatMessage(role="user", content="Hello, tell me a joke")
]
prompt = llm.apply_chat_template(conversation)
for token in llm.generate_stream(prompt, GenerationConfig(max_tokens=100)):
    print(token, end="", flush=True)
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Models:&lt;/strong&gt; LLM, Multimodal, ASR, OCR, Rerank, Object Detection, Image Generation, Embedding&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Formats:&lt;/strong&gt; GGUF, MLX, NEXA&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;NPU Models:&lt;/strong&gt; &lt;a href="https://sdk.nexa.ai/model"&gt;Model Hub&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üìñ &lt;a href="https://docs.nexa.ai/en/nexa-sdk-python/quickstart"&gt;Python SDK Docs&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h3&gt;ü§ñ Android SDK&lt;/h3&gt; 
&lt;p&gt;Add to your &lt;code&gt;app/AndroidManifest.xml&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-xml"&gt;&amp;lt;application android:extractNativeLibs="true"&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Add to your &lt;code&gt;build.gradle.kts&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-kotlin"&gt;dependencies {
    implementation("ai.nexa:core:0.0.15")
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-kotlin"&gt;// Initialize SDK
NexaSdk.getInstance().init(this)

// Load and run model
VlmWrapper.builder()
    .vlmCreateInput(VlmCreateInput(
        model_name = "omni-neural",
        model_path = "/data/data/your.app/files/models/OmniNeural-4B/files-1-1.nexa",
        plugin_id = "npu",
        config = ModelConfig()
    ))
    .build()
    .onSuccess { vlm -&amp;gt;
        vlm.generateStreamFlow("Hello!", GenerationConfig()).collect { print(it) }
    }
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Requirements:&lt;/strong&gt; Android minSdk 27, Qualcomm Snapdragon 8 Gen 4 Chip&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Models:&lt;/strong&gt; LLM, Multimodal, ASR, OCR, Rerank, Embedding&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;NPU Models:&lt;/strong&gt; &lt;a href="https://docs.nexa.ai/en/nexa-sdk-android/overview#supported-models"&gt;Supported Models&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üìñ &lt;a href="https://docs.nexa.ai/en/nexa-sdk-android/quickstart"&gt;Android SDK Docs&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h3&gt;üê≥ Linux Docker&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker pull nexa4ai/nexasdk:latest

export NEXA_TOKEN="your_token_here"
docker run --rm -it --privileged \
  -e NEXA_TOKEN \
  nexa4ai/nexasdk:latest infer NexaAI/Granite-4.0-h-350M-NPU
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Requirements:&lt;/strong&gt; Qualcomm Dragonwing IQ9, ARM64 systems&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Models:&lt;/strong&gt; LLM, VLM, ASR, CV, Rerank, Embedding&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;NPU Models:&lt;/strong&gt; &lt;a href="https://docs.nexa.ai/en/nexa-sdk-docker/overview#supported-models"&gt;Supported Models&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üìñ &lt;a href="https://docs.nexa.ai/en/nexa-sdk-docker/quickstart"&gt;Linux Docker Docs&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h3&gt;üçé iOS SDK&lt;/h3&gt; 
&lt;p&gt;Download &lt;a href="https://nexa-model-hub-bucket.s3.us-west-1.amazonaws.com/public/ios/latest/NexaSdk.xcframework.zip"&gt;NexaSdk.xcframework&lt;/a&gt; and add to your Xcode project.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-swift"&gt;import NexaSdk

// Example: Speech Recognition
let asr = try Asr(plugin: .ane)
try await asr.load(from: modelURL)

let result = try await asr.transcribe(options: .init(audioPath: "audio.wav"))
print(result.asrResult.transcript)
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Requirements:&lt;/strong&gt; iOS 17.0+ / macOS 15.0+, Swift 5.9+&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Models:&lt;/strong&gt; LLM, ASR, OCR, Rerank, Embedding&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ANE Models:&lt;/strong&gt; &lt;a href="https://huggingface.co/collections/NexaAI/apple-neural-engine"&gt;Apple Neural Engine Models&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üìñ &lt;a href="https://docs.nexa.ai/en/nexa-sdk-ios/quickstart"&gt;iOS SDK Docs&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;‚öôÔ∏è Features &amp;amp; Comparisons&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Features&lt;/th&gt; 
    &lt;th&gt;&lt;strong&gt;NexaSDK&lt;/strong&gt;&lt;/th&gt; 
    &lt;th&gt;&lt;strong&gt;Ollama&lt;/strong&gt;&lt;/th&gt; 
    &lt;th&gt;&lt;strong&gt;llama.cpp&lt;/strong&gt;&lt;/th&gt; 
    &lt;th&gt;&lt;strong&gt;LM Studio&lt;/strong&gt;&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;NPU support&lt;/td&gt; 
    &lt;td&gt;‚úÖ NPU-first&lt;/td&gt; 
    &lt;td&gt;‚ùå&lt;/td&gt; 
    &lt;td&gt;‚ùå&lt;/td&gt; 
    &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Android/iOS SDK support&lt;/td&gt; 
    &lt;td&gt;‚úÖ NPU/GPU/CPU support&lt;/td&gt; 
    &lt;td&gt;‚ö†Ô∏è&lt;/td&gt; 
    &lt;td&gt;‚ö†Ô∏è&lt;/td&gt; 
    &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Linux support (Docker image)&lt;/td&gt; 
    &lt;td&gt;‚úÖ&lt;/td&gt; 
    &lt;td&gt;‚úÖ&lt;/td&gt; 
    &lt;td&gt;‚úÖ&lt;/td&gt; 
    &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Day-0 model support in GGUF, MLX, NEXA&lt;/td&gt; 
    &lt;td&gt;‚úÖ&lt;/td&gt; 
    &lt;td&gt;‚ùå&lt;/td&gt; 
    &lt;td&gt;‚ö†Ô∏è&lt;/td&gt; 
    &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Full multimodality support&lt;/td&gt; 
    &lt;td&gt;‚úÖ Image, Audio, Text, Embedding, Rerank, ASR, TTS&lt;/td&gt; 
    &lt;td&gt;‚ö†Ô∏è&lt;/td&gt; 
    &lt;td&gt;‚ö†Ô∏è&lt;/td&gt; 
    &lt;td&gt;‚ö†Ô∏è&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Cross-platform support&lt;/td&gt; 
    &lt;td&gt;‚úÖ Desktop, Mobile (Android, iOS), Automotive, IoT (Linux)&lt;/td&gt; 
    &lt;td&gt;‚ö†Ô∏è&lt;/td&gt; 
    &lt;td&gt;‚ö†Ô∏è&lt;/td&gt; 
    &lt;td&gt;‚ö†Ô∏è&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;One line of code to run&lt;/td&gt; 
    &lt;td&gt;‚úÖ&lt;/td&gt; 
    &lt;td&gt;‚úÖ&lt;/td&gt; 
    &lt;td&gt;‚ö†Ô∏è&lt;/td&gt; 
    &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;OpenAI-compatible API + Function calling&lt;/td&gt; 
    &lt;td&gt;‚úÖ&lt;/td&gt; 
    &lt;td&gt;‚úÖ&lt;/td&gt; 
    &lt;td&gt;‚úÖ&lt;/td&gt; 
    &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;p align="center" style="margin-top:14px"&gt; &lt;i&gt; &lt;b&gt;Legend:&lt;/b&gt; &lt;span title="Full support"&gt;‚úÖ Supported&lt;/span&gt; &amp;nbsp; | &amp;nbsp; &lt;span title="Partial or limited support"&gt;‚ö†Ô∏è Partial or limited support &lt;/span&gt; &amp;nbsp; | &amp;nbsp; &lt;span title="Not Supported"&gt;‚ùå No&lt;/span&gt; &lt;/i&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;üéØ You Decide What Model We Support Next&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://sdk.nexa.ai/wishlist"&gt;Nexa Wishlist&lt;/a&gt;&lt;/strong&gt; ‚Äî Request and vote for the models you want to run on-device.&lt;/p&gt; 
&lt;p&gt;Drop a Hugging Face repo ID, pick your preferred backend (GGUF, MLX, or Nexa format for Qualcomm + Apple NPUs), and watch the community's top requests go live in NexaSDK.&lt;/p&gt; 
&lt;p&gt;üëâ &lt;strong&gt;&lt;a href="https://sdk.nexa.ai/wishlist"&gt;Vote now at sdk.nexa.ai/wishlist&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;üí∞ Join Builder Bounty Program&lt;/h2&gt; 
&lt;p&gt;Earn up to 1,500 USD for building with NexaSDK.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/NexaAI/nexa-sdk/main/assets/developer_bounty.png" alt="Developer Bounty" /&gt;&lt;/p&gt; 
&lt;p&gt;Learn more in our &lt;a href="https://docs.nexa.ai/en/community/builder-bounty#builder-bounty-program"&gt;Participant Details&lt;/a&gt;).&lt;/p&gt; 
&lt;h2&gt;üôè Acknowledgements&lt;/h2&gt; 
&lt;p&gt;We would like to thank the following projects:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ggml-org/ggml"&gt;ggml&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ml-explore/mlx-lm"&gt;mlx-lm&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Blaizzy/mlx-vlm"&gt;mlx-vlm&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Blaizzy/mlx-audio"&gt;mlx-audio&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;NexaSDK uses a dual licensing model:&lt;/p&gt; 
&lt;h3&gt;CPU/GPU Components&lt;/h3&gt; 
&lt;p&gt;Licensed under &lt;a href="https://raw.githubusercontent.com/NexaAI/nexa-sdk/main/LICENSE"&gt;Apache License 2.0&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;NPU Components&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Personal Use&lt;/strong&gt;: Free license key available from &lt;a href="https://sdk.nexa.ai/model"&gt;Nexa AI Model Hub&lt;/a&gt;. Each key activates 1 device for NPU usage.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Commercial Use&lt;/strong&gt;: Contact &lt;a href="mailto:hello@nexa.ai"&gt;hello@nexa.ai&lt;/a&gt; for licensing.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ü§ù Contact &amp;amp; Community Support&lt;/h2&gt; 
&lt;h3&gt;Business Inquiries&lt;/h3&gt; 
&lt;p&gt;For model launching partner, business inquiries, or any other questions, please schedule a call with us &lt;a href="https://nexa.ai/book-a-call"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Community &amp;amp; Support&lt;/h3&gt; 
&lt;p&gt;Want more model support, backend support, device support or other features? We'd love to hear from you!&lt;/p&gt; 
&lt;p&gt;Feel free to &lt;a href="https://github.com/NexaAI/nexa-sdk/issues"&gt;submit an issue&lt;/a&gt; on our GitHub repository with your requests, suggestions, or feedback. Your input helps us prioritize what to build next.&lt;/p&gt; 
&lt;p&gt;Join our community:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/thRu2HaK4D"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://join.slack.com/t/nexaai/shared_invite/zt-30a8yfv8k-1JqAXv~OjKJKLqvbKqHJxA"&gt;Slack&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>charmbracelet/crush</title>
      <link>https://github.com/charmbracelet/crush</link>
      <description>&lt;p&gt;The glamourous AI coding agent for your favourite terminal üíò&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Crush&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;a href="https://stuff.charm.sh/crush/charm-crush.png"&gt;&lt;img width="450" alt="Charm Crush Logo" src="https://github.com/user-attachments/assets/adc1a6f4-b284-4603-836c-59038caa2e8b" /&gt;&lt;/a&gt;&lt;br /&gt; &lt;a href="https://github.com/charmbracelet/crush/releases"&gt;&lt;img src="https://img.shields.io/github/release/charmbracelet/crush" alt="Latest Release" /&gt;&lt;/a&gt; &lt;a href="https://github.com/charmbracelet/crush/actions"&gt;&lt;img src="https://github.com/charmbracelet/crush/actions/workflows/build.yml/badge.svg?sanitize=true" alt="Build Status" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt;Your new coding bestie, now available in your favourite terminal.&lt;br /&gt;Your tools, your code, and your workflows, wired into your LLM of choice.&lt;/p&gt; 
&lt;p align="center"&gt;‰Ω†ÁöÑÊñ∞ÁºñÁ®ã‰ºô‰º¥ÔºåÁé∞Âú®Â∞±Âú®‰Ω†ÊúÄÁà±ÁöÑÁªàÁ´Ø‰∏≠„ÄÇ&lt;br /&gt;‰Ω†ÁöÑÂ∑•ÂÖ∑„ÄÅ‰ª£Á†ÅÂíåÂ∑•‰ΩúÊµÅÔºåÈÉΩ‰∏éÊÇ®ÈÄâÊã©ÁöÑ LLM Ê®°ÂûãÁ¥ßÂØÜÁõ∏Ëøû„ÄÇ&lt;/p&gt; 
&lt;p align="center"&gt;&lt;img width="800" alt="Crush Demo" src="https://github.com/user-attachments/assets/58280caf-851b-470a-b6f7-d5c4ea8a1968" /&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-Model:&lt;/strong&gt; choose from a wide range of LLMs or add your own via OpenAI- or Anthropic-compatible APIs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexible:&lt;/strong&gt; switch LLMs mid-session while preserving context&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Session-Based:&lt;/strong&gt; maintain multiple work sessions and contexts per project&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;LSP-Enhanced:&lt;/strong&gt; Crush uses LSPs for additional context, just like you do&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Extensible:&lt;/strong&gt; add capabilities via MCPs (&lt;code&gt;http&lt;/code&gt;, &lt;code&gt;stdio&lt;/code&gt;, and &lt;code&gt;sse&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Works Everywhere:&lt;/strong&gt; first-class support in every terminal on macOS, Linux, Windows (PowerShell and WSL), FreeBSD, OpenBSD, and NetBSD&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Use a package manager:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Homebrew
brew install charmbracelet/tap/crush

# NPM
npm install -g @charmland/crush

# Arch Linux (btw)
yay -S crush-bin

# Nix
nix run github:numtide/nix-ai-tools#crush

# FreeBSD
pkg install crush
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Windows users:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Winget
winget install charmbracelet.crush

# Scoop
scoop bucket add charm https://github.com/charmbracelet/scoop-bucket.git
scoop install crush
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Nix (NUR)&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;Crush is available via the official Charm &lt;a href="https://github.com/nix-community/NUR"&gt;NUR&lt;/a&gt; in &lt;code&gt;nur.repos.charmbracelet.crush&lt;/code&gt;, which is the most up-to-date way to get Crush in Nix.&lt;/p&gt; 
 &lt;p&gt;You can also try out Crush via the NUR with &lt;code&gt;nix-shell&lt;/code&gt;:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Add the NUR channel.
nix-channel --add https://github.com/nix-community/NUR/archive/main.tar.gz nur
nix-channel --update

# Get Crush in a Nix shell.
nix-shell -p '(import &amp;lt;nur&amp;gt; { pkgs = import &amp;lt;nixpkgs&amp;gt; {}; }).repos.charmbracelet.crush'
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;NixOS &amp;amp; Home Manager Module Usage via NUR&lt;/h3&gt; 
 &lt;p&gt;Crush provides NixOS and Home Manager modules via NUR. You can use these modules directly in your flake by importing them from NUR. Since it auto detects whether its a home manager or nixos context you can use the import the exact same way :)&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-nix"&gt;{
  inputs = {
    nixpkgs.url = "github:NixOS/nixpkgs/nixos-unstable";
    nur.url = "github:nix-community/NUR";
  };

  outputs = { self, nixpkgs, nur, ... }: {
    nixosConfigurations.your-hostname = nixpkgs.lib.nixosSystem {
      system = "x86_64-linux";
      modules = [
        nur.modules.nixos.default
        nur.repos.charmbracelet.modules.crush
        {
          programs.crush = {
            enable = true;
            settings = {
              providers = {
                openai = {
                  id = "openai";
                  name = "OpenAI";
                  base_url = "https://api.openai.com/v1";
                  type = "openai";
                  api_key = "sk-fake123456789abcdef...";
                  models = [
                    {
                      id = "gpt-4";
                      name = "GPT-4";
                    }
                  ];
                };
              };
              lsp = {
                go = { command = "gopls"; enabled = true; };
                nix = { command = "nil"; enabled = true; };
              };
              options = {
                context_paths = [ "/etc/nixos/configuration.nix" ];
                tui = { compact_mode = true; };
                debug = false;
              };
            };
          };
        }
      ];
    };
  };
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Debian/Ubuntu&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;sudo mkdir -p /etc/apt/keyrings
curl -fsSL https://repo.charm.sh/apt/gpg.key | sudo gpg --dearmor -o /etc/apt/keyrings/charm.gpg
echo "deb [signed-by=/etc/apt/keyrings/charm.gpg] https://repo.charm.sh/apt/ * *" | sudo tee /etc/apt/sources.list.d/charm.list
sudo apt update &amp;amp;&amp;amp; sudo apt install crush
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Fedora/RHEL&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;echo '[charm]
name=Charm
baseurl=https://repo.charm.sh/yum/
enabled=1
gpgcheck=1
gpgkey=https://repo.charm.sh/yum/gpg.key' | sudo tee /etc/yum.repos.d/charm.repo
sudo yum install crush
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;p&gt;Or, download it:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/charmbracelet/crush/releases"&gt;Packages&lt;/a&gt; are available in Debian and RPM formats&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/charmbracelet/crush/releases"&gt;Binaries&lt;/a&gt; are available for Linux, macOS, Windows, FreeBSD, OpenBSD, and NetBSD&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Or just install it with Go:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;go install github.com/charmbracelet/crush@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] Productivity may increase when using Crush and you may find yourself nerd sniped when first using the application. If the symptoms persist, join the &lt;a href="https://charm.land/discord"&gt;Discord&lt;/a&gt; and nerd snipe the rest of us.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;The quickest way to get started is to grab an API key for your preferred provider such as Anthropic, OpenAI, Groq, or OpenRouter and just start Crush. You'll be prompted to enter your API key.&lt;/p&gt; 
&lt;p&gt;That said, you can also set environment variables for preferred providers.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Environment Variable&lt;/th&gt; 
   &lt;th&gt;Provider&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ANTHROPIC_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Anthropic&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OpenAI&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENROUTER_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OpenRouter&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;GEMINI_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Google Gemini&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;CEREBRAS_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Cerebras&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;HF_TOKEN&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Huggingface Inference&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;VERTEXAI_PROJECT&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Google Cloud VertexAI (Gemini)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;VERTEXAI_LOCATION&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Google Cloud VertexAI (Gemini)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;GROQ_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Groq&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AWS_ACCESS_KEY_ID&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Amazon Bedrock (Claude)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AWS_SECRET_ACCESS_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Amazon Bedrock (Claude)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AWS_REGION&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Amazon Bedrock (Claude)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AWS_PROFILE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Amazon Bedrock (Custom Profile)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AWS_BEARER_TOKEN_BEDROCK&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Amazon Bedrock&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AZURE_OPENAI_API_ENDPOINT&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Azure OpenAI models&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AZURE_OPENAI_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Azure OpenAI models (optional when using Entra ID)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AZURE_OPENAI_API_VERSION&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Azure OpenAI models&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;By the Way&lt;/h3&gt; 
&lt;p&gt;Is there a provider you‚Äôd like to see in Crush? Is there an existing model that needs an update?&lt;/p&gt; 
&lt;p&gt;Crush‚Äôs default model listing is managed in &lt;a href="https://github.com/charmbracelet/catwalk"&gt;Catwalk&lt;/a&gt;, a community-supported, open source repository of Crush-compatible models, and you‚Äôre welcome to contribute.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/charmbracelet/catwalk"&gt;&lt;img width="174" height="174" alt="Catwalk Badge" src="https://github.com/user-attachments/assets/95b49515-fe82-4409-b10d-5beb0873787d" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Configuration&lt;/h2&gt; 
&lt;p&gt;Crush runs great with no configuration. That said, if you do need or want to customize Crush, configuration can be added either local to the project itself, or globally, with the following priority:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;code&gt;.crush.json&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;crush.json&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;$HOME/.config/crush/crush.json&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Configuration itself is stored as a JSON object:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "this-setting": { "this": "that" },
  "that-setting": ["ceci", "cela"]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;As an additional note, Crush also stores ephemeral data, such as application state, in one additional location:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Unix
$HOME/.local/share/crush/crush.json

# Windows
%LOCALAPPDATA%\crush\crush.json
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] You can override the user and data config locations by setting:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;CRUSH_GLOBAL_CONFIG&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;CRUSH_GLOBAL_DATA&lt;/code&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;LSPs&lt;/h3&gt; 
&lt;p&gt;Crush can use LSPs for additional context to help inform its decisions, just like you would. LSPs can be added manually like so:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "$schema": "https://charm.land/crush.json",
  "lsp": {
    "go": {
      "command": "gopls",
      "env": {
        "GOTOOLCHAIN": "go1.24.5"
      }
    },
    "typescript": {
      "command": "typescript-language-server",
      "args": ["--stdio"]
    },
    "nix": {
      "command": "nil"
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;MCPs&lt;/h3&gt; 
&lt;p&gt;Crush also supports Model Context Protocol (MCP) servers through three transport types: &lt;code&gt;stdio&lt;/code&gt; for command-line servers, &lt;code&gt;http&lt;/code&gt; for HTTP endpoints, and &lt;code&gt;sse&lt;/code&gt; for Server-Sent Events. Environment variable expansion is supported using &lt;code&gt;$(echo $VAR)&lt;/code&gt; syntax.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "$schema": "https://charm.land/crush.json",
  "mcp": {
    "filesystem": {
      "type": "stdio",
      "command": "node",
      "args": ["/path/to/mcp-server.js"],
      "timeout": 120,
      "disabled": false,
      "disabled_tools": ["some-tool-name"],
      "env": {
        "NODE_ENV": "production"
      }
    },
    "github": {
      "type": "http",
      "url": "https://api.githubcopilot.com/mcp/",
      "timeout": 120,
      "disabled": false,
      "disabled_tools": ["create_issue", "create_pull_request"],
      "headers": {
        "Authorization": "Bearer $GH_PAT"
      }
    },
    "streaming-service": {
      "type": "sse",
      "url": "https://example.com/mcp/sse",
      "timeout": 120,
      "disabled": false,
      "headers": {
        "API-Key": "$(echo $API_KEY)"
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Ignoring Files&lt;/h3&gt; 
&lt;p&gt;Crush respects &lt;code&gt;.gitignore&lt;/code&gt; files by default, but you can also create a &lt;code&gt;.crushignore&lt;/code&gt; file to specify additional files and directories that Crush should ignore. This is useful for excluding files that you want in version control but don't want Crush to consider when providing context.&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;.crushignore&lt;/code&gt; file uses the same syntax as &lt;code&gt;.gitignore&lt;/code&gt; and can be placed in the root of your project or in subdirectories.&lt;/p&gt; 
&lt;h3&gt;Allowing Tools&lt;/h3&gt; 
&lt;p&gt;By default, Crush will ask you for permission before running tool calls. If you'd like, you can allow tools to be executed without prompting you for permissions. Use this with care.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "$schema": "https://charm.land/crush.json",
  "permissions": {
    "allowed_tools": [
      "view",
      "ls",
      "grep",
      "edit",
      "mcp_context7_get-library-doc"
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also skip all permission prompts entirely by running Crush with the &lt;code&gt;--yolo&lt;/code&gt; flag. Be very, very careful with this feature.&lt;/p&gt; 
&lt;h3&gt;Disabling Built-In Tools&lt;/h3&gt; 
&lt;p&gt;If you'd like to prevent Crush from using certain built-in tools entirely, you can disable them via the &lt;code&gt;options.disabled_tools&lt;/code&gt; list. Disabled tools are completely hidden from the agent.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "$schema": "https://charm.land/crush.json",
  "options": {
    "disabled_tools": [
      "bash",
      "sourcegraph"
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To disable tools from MCP servers, see the &lt;a href="https://raw.githubusercontent.com/charmbracelet/crush/main/#mcps"&gt;MCP config section&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Agent Skills&lt;/h3&gt; 
&lt;p&gt;Crush supports the &lt;a href="https://agentskills.io"&gt;Agent Skills&lt;/a&gt; open standard for extending agent capabilities with reusable skill packages. Skills are folders containing a &lt;code&gt;SKILL.md&lt;/code&gt; file with instructions that Crush can discover and activate on demand.&lt;/p&gt; 
&lt;p&gt;Skills are discovered from:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;~/.config/crush/skills/&lt;/code&gt; on Unix (default, can be overridden with &lt;code&gt;CRUSH_SKILLS_DIR&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;%LOCALAPPDATA%\crush\skills\&lt;/code&gt; on Windows (default, can be overridden with &lt;code&gt;CRUSH_SKILLS_DIR&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Additional paths configured via &lt;code&gt;options.skills_paths&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-jsonc"&gt;{
  "$schema": "https://charm.land/crush.json",
  "options": {
    "skills_paths": [
      "~/.config/crush/skills", // Windows: "%LOCALAPPDATA%\\crush\\skills",
      "./project-skills"
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can get started with example skills from &lt;a href="https://github.com/anthropics/skills"&gt;anthropics/skills&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Unix
mkdir -p ~/.config/crush/skills
cd ~/.config/crush/skills
git clone https://github.com/anthropics/skills.git _temp
mv _temp/skills/* . &amp;amp;&amp;amp; rm -rf _temp
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;# Windows (PowerShell)
mkdir -Force "$env:LOCALAPPDATA\crush\skills"
cd "$env:LOCALAPPDATA\crush\skills"
git clone https://github.com/anthropics/skills.git _temp
mv _temp/skills/* . ; rm -r -force _temp
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Initialization&lt;/h3&gt; 
&lt;p&gt;When you initialize a project, Crush analyzes your codebase and creates a context file that helps it work more effectively in future sessions. By default, this file is named &lt;code&gt;AGENTS.md&lt;/code&gt;, but you can customize the name and location with the &lt;code&gt;initialize_as&lt;/code&gt; option:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "$schema": "https://charm.land/crush.json",
  "options": {
    "initialize_as": "AGENTS.md"
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This is useful if you prefer a different naming convention or want to place the file in a specific directory (e.g., &lt;code&gt;CRUSH.md&lt;/code&gt; or &lt;code&gt;docs/LLMs.md&lt;/code&gt;). Crush will fill the file with project-specific context like build commands, code patterns, and conventions it discovered during initialization.&lt;/p&gt; 
&lt;h3&gt;Attribution Settings&lt;/h3&gt; 
&lt;p&gt;By default, Crush adds attribution information to Git commits and pull requests it creates. You can customize this behavior with the &lt;code&gt;attribution&lt;/code&gt; option:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "$schema": "https://charm.land/crush.json",
  "options": {
    "attribution": {
      "trailer_style": "co-authored-by",
      "generated_with": true
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;trailer_style&lt;/code&gt;: Controls the attribution trailer added to commit messages (default: &lt;code&gt;assisted-by&lt;/code&gt;) 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;assisted-by&lt;/code&gt;: Adds &lt;code&gt;Assisted-by: [Model Name] via Crush &amp;lt;crush@charm.land&amp;gt;&lt;/code&gt; (includes the model name)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;co-authored-by&lt;/code&gt;: Adds &lt;code&gt;Co-Authored-By: Crush &amp;lt;crush@charm.land&amp;gt;&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;none&lt;/code&gt;: No attribution trailer&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;generated_with&lt;/code&gt;: When true (default), adds &lt;code&gt;üíò Generated with Crush&lt;/code&gt; line to commit messages and PR descriptions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Custom Providers&lt;/h3&gt; 
&lt;p&gt;Crush supports custom provider configurations for both OpenAI-compatible and Anthropic-compatible APIs.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Note that we support two "types" for OpenAI. Make sure to choose the right one to ensure the best experience!&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;openai&lt;/code&gt; should be used when proxying or routing requests through OpenAI.&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;openai-compat&lt;/code&gt; should be used when using non-OpenAI providers that have OpenAI-compatible APIs.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;OpenAI-Compatible APIs&lt;/h4&gt; 
&lt;p&gt;Here‚Äôs an example configuration for Deepseek, which uses an OpenAI-compatible API. Don't forget to set &lt;code&gt;DEEPSEEK_API_KEY&lt;/code&gt; in your environment.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "$schema": "https://charm.land/crush.json",
  "providers": {
    "deepseek": {
      "type": "openai-compat",
      "base_url": "https://api.deepseek.com/v1",
      "api_key": "$DEEPSEEK_API_KEY",
      "models": [
        {
          "id": "deepseek-chat",
          "name": "Deepseek V3",
          "cost_per_1m_in": 0.27,
          "cost_per_1m_out": 1.1,
          "cost_per_1m_in_cached": 0.07,
          "cost_per_1m_out_cached": 1.1,
          "context_window": 64000,
          "default_max_tokens": 5000
        }
      ]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Anthropic-Compatible APIs&lt;/h4&gt; 
&lt;p&gt;Custom Anthropic-compatible providers follow this format:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "$schema": "https://charm.land/crush.json",
  "providers": {
    "custom-anthropic": {
      "type": "anthropic",
      "base_url": "https://api.anthropic.com/v1",
      "api_key": "$ANTHROPIC_API_KEY",
      "extra_headers": {
        "anthropic-version": "2023-06-01"
      },
      "models": [
        {
          "id": "claude-sonnet-4-20250514",
          "name": "Claude Sonnet 4",
          "cost_per_1m_in": 3,
          "cost_per_1m_out": 15,
          "cost_per_1m_in_cached": 3.75,
          "cost_per_1m_out_cached": 0.3,
          "context_window": 200000,
          "default_max_tokens": 50000,
          "can_reason": true,
          "supports_attachments": true
        }
      ]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Amazon Bedrock&lt;/h3&gt; 
&lt;p&gt;Crush currently supports running Anthropic models through Bedrock, with caching disabled.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;A Bedrock provider will appear once you have AWS configured, i.e. &lt;code&gt;aws configure&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Crush also expects the &lt;code&gt;AWS_REGION&lt;/code&gt; or &lt;code&gt;AWS_DEFAULT_REGION&lt;/code&gt; to be set&lt;/li&gt; 
 &lt;li&gt;To use a specific AWS profile set &lt;code&gt;AWS_PROFILE&lt;/code&gt; in your environment, i.e. &lt;code&gt;AWS_PROFILE=myprofile crush&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Alternatively to &lt;code&gt;aws configure&lt;/code&gt;, you can also just set &lt;code&gt;AWS_BEARER_TOKEN_BEDROCK&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Vertex AI Platform&lt;/h3&gt; 
&lt;p&gt;Vertex AI will appear in the list of available providers when &lt;code&gt;VERTEXAI_PROJECT&lt;/code&gt; and &lt;code&gt;VERTEXAI_LOCATION&lt;/code&gt; are set. You will also need to be authenticated:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;gcloud auth application-default login
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To add specific models to the configuration, configure as such:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "$schema": "https://charm.land/crush.json",
  "providers": {
    "vertexai": {
      "models": [
        {
          "id": "claude-sonnet-4@20250514",
          "name": "VertexAI Sonnet 4",
          "cost_per_1m_in": 3,
          "cost_per_1m_out": 15,
          "cost_per_1m_in_cached": 3.75,
          "cost_per_1m_out_cached": 0.3,
          "context_window": 200000,
          "default_max_tokens": 50000,
          "can_reason": true,
          "supports_attachments": true
        }
      ]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Local Models&lt;/h3&gt; 
&lt;p&gt;Local models can also be configured via OpenAI-compatible API. Here are two common examples:&lt;/p&gt; 
&lt;h4&gt;Ollama&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "providers": {
    "ollama": {
      "name": "Ollama",
      "base_url": "http://localhost:11434/v1/",
      "type": "openai-compat",
      "models": [
        {
          "name": "Qwen 3 30B",
          "id": "qwen3:30b",
          "context_window": 256000,
          "default_max_tokens": 20000
        }
      ]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;LM Studio&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "providers": {
    "lmstudio": {
      "name": "LM Studio",
      "base_url": "http://localhost:1234/v1/",
      "type": "openai-compat",
      "models": [
        {
          "name": "Qwen 3 30B",
          "id": "qwen/qwen3-30b-a3b-2507",
          "context_window": 256000,
          "default_max_tokens": 20000
        }
      ]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Logging&lt;/h2&gt; 
&lt;p&gt;Sometimes you need to look at logs. Luckily, Crush logs all sorts of stuff. Logs are stored in &lt;code&gt;./.crush/logs/crush.log&lt;/code&gt; relative to the project.&lt;/p&gt; 
&lt;p&gt;The CLI also contains some helper commands to make perusing recent logs easier:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Print the last 1000 lines
crush logs

# Print the last 500 lines
crush logs --tail 500

# Follow logs in real time
crush logs --follow
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Want more logging? Run &lt;code&gt;crush&lt;/code&gt; with the &lt;code&gt;--debug&lt;/code&gt; flag, or enable it in the config:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "$schema": "https://charm.land/crush.json",
  "options": {
    "debug": true,
    "debug_lsp": true
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Provider Auto-Updates&lt;/h2&gt; 
&lt;p&gt;By default, Crush automatically checks for the latest and greatest list of providers and models from &lt;a href="https://github.com/charmbracelet/catwalk"&gt;Catwalk&lt;/a&gt;, the open source Crush provider database. This means that when new providers and models are available, or when model metadata changes, Crush automatically updates your local configuration.&lt;/p&gt; 
&lt;h3&gt;Disabling automatic provider updates&lt;/h3&gt; 
&lt;p&gt;For those with restricted internet access, or those who prefer to work in air-gapped environments, this might not be want you want, and this feature can be disabled.&lt;/p&gt; 
&lt;p&gt;To disable automatic provider updates, set &lt;code&gt;disable_provider_auto_update&lt;/code&gt; into your &lt;code&gt;crush.json&lt;/code&gt; config:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "$schema": "https://charm.land/crush.json",
  "options": {
    "disable_provider_auto_update": true
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or set the &lt;code&gt;CRUSH_DISABLE_PROVIDER_AUTO_UPDATE&lt;/code&gt; environment variable:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export CRUSH_DISABLE_PROVIDER_AUTO_UPDATE=1
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Manually updating providers&lt;/h3&gt; 
&lt;p&gt;Manually updating providers is possible with the &lt;code&gt;crush update-providers&lt;/code&gt; command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Update providers remotely from Catwalk.
crush update-providers

# Update providers from a custom Catwalk base URL.
crush update-providers https://example.com/

# Update providers from a local file.
crush update-providers /path/to/local-providers.json

# Reset providers to the embedded version, embedded at crush at build time.
crush update-providers embedded

# For more info:
crush update-providers --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Metrics&lt;/h2&gt; 
&lt;p&gt;Crush records pseudonymous usage metrics (tied to a device-specific hash), which maintainers rely on to inform development and support priorities. The metrics include solely usage metadata; prompts and responses are NEVER collected.&lt;/p&gt; 
&lt;p&gt;Details on exactly what‚Äôs collected are in the source code (&lt;a href="https://github.com/charmbracelet/crush/tree/main/internal/event"&gt;here&lt;/a&gt; and &lt;a href="https://github.com/charmbracelet/crush/raw/main/internal/llm/agent/event.go"&gt;here&lt;/a&gt;).&lt;/p&gt; 
&lt;p&gt;You can opt out of metrics collection at any time by setting the environment variable by setting the following in your environment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export CRUSH_DISABLE_METRICS=1
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or by setting the following in your config:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "options": {
    "disable_metrics": true
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Crush also respects the &lt;a href="https://consoledonottrack.com"&gt;&lt;code&gt;DO_NOT_TRACK&lt;/code&gt;&lt;/a&gt; convention which can be enabled via &lt;code&gt;export DO_NOT_TRACK=1&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/charmbracelet/crush?tab=contributing-ov-file#contributing"&gt;contributing guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Whatcha think?&lt;/h2&gt; 
&lt;p&gt;We‚Äôd love to hear your thoughts on this project. Need help? We gotchu. You can find us on:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/charmcli"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://charm.land/slack"&gt;Slack&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://charm.land/discord"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mastodon.social/@charmcli"&gt;The Fediverse&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://bsky.app/profile/charm.land"&gt;Bluesky&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/charmbracelet/crush/raw/main/LICENSE.md"&gt;FSL-1.1-MIT&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;Part of &lt;a href="https://charm.land"&gt;Charm&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://charm.land/"&gt;&lt;img alt="The Charm logo" width="400" src="https://stuff.charm.sh/charm-banner-next.jpg" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!--prettier-ignore--&gt; 
&lt;p&gt;CharmÁÉ≠Áà±ÂºÄÊ∫ê ‚Ä¢ Charm loves open source&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>vllm-project/semantic-router</title>
      <link>https://github.com/vllm-project/semantic-router</link>
      <description>&lt;p&gt;System Level Intelligent Router for Mixture-of-Models at Cloud, Data Center and Edge&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/vllm-project/semantic-router/main/website/static/img/code.png" alt="vLLM Semantic Router" width="100%" /&gt; 
 &lt;p&gt;&lt;a href="https://vllm-semantic-router.com"&gt;&lt;img src="https://img.shields.io/badge/docs-read%20the%20docs-blue" alt="Documentation" /&gt;&lt;/a&gt; &lt;a href="https://huggingface.co/LLM-Semantic-Router"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Community-yellow" alt="Hugging Face" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/vllm-project/semantic-router/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-Apache%202.0-blue.svg?sanitize=true" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://crates.io/crates/candle-semantic-router"&gt;&lt;img src="https://img.shields.io/crates/v/candle-semantic-router.svg?sanitize=true" alt="Crates.io" /&gt;&lt;/a&gt; &lt;img src="https://github.com/vllm-project/semantic-router/workflows/Test%20And%20Build/badge.svg?sanitize=true" alt="Test And Build" /&gt; &lt;a href="https://deepwiki.com/vllm-project/semantic-router"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;üìö &lt;a href="https://vllm-semantic-router.com"&gt;Complete Documentation&lt;/a&gt; | üöÄ &lt;a href="https://vllm-semantic-router.com/docs/installation"&gt;Quick Start&lt;/a&gt; | üì£ &lt;a href="https://vllm-semantic-router.com/blog/"&gt;Blog&lt;/a&gt; | üìñ &lt;a href="https://vllm-semantic-router.com/publications/"&gt;Publications&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;em&gt;Latest News&lt;/em&gt; üî•&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;[2026/01/05] Iris v0.1 is Released: &lt;a href="https://blog.vllm.ai/2026/01/05/vllm-sr-iris.html"&gt;vLLM Semantic Router v0.1 Iris: The First Major Release&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[2025/12/16] Collaboration: &lt;a href="https://blog.vllm.ai/2025/12/16/vllm-sr-amd.html"&gt;AMD √ó vLLM Semantic Router: Building the System Intelligence Together&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[2025/12/15] New Blog: &lt;a href="https://blog.vllm.ai/2025/12/14/halugate.html"&gt;Token-Level Truth: Real-Time Hallucination Detection for Production LLMs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[2025/11/19] New Blog: &lt;a href="https://blog.vllm.ai/2025/11/19/signal-decision.html"&gt;Signal-Decision Driven Architecture: Reshaping Semantic Routing at Scale&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[2025/11/03] Our paper &lt;a href="https://arxiv.org/abs/2510.26835"&gt;Category-Aware Semantic Caching for Heterogeneous LLM Workloads&lt;/a&gt; published&lt;/li&gt; 
 &lt;li&gt;[2025/10/27] New Blog: &lt;a href="https://blog.vllm.ai/2025/10/27/semantic-router-modular.html"&gt;Scaling Semantic Routing with Extensible LoRA&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;[2025/10/12] Our paper &lt;a href="https://arxiv.org/abs/2510.08731"&gt;When to Reason: Semantic Router for vLLM&lt;/a&gt; accepted by NeurIPS 2025 MLForSys.&lt;/li&gt; 
 &lt;li&gt;[2025/10/08] Collaboration: vLLM Semantic Router with &lt;a href="https://github.com/vllm-project/production-stack"&gt;vLLM Production Stack&lt;/a&gt; Team.&lt;/li&gt; 
 &lt;li&gt;[2025/09/01] Released the project: &lt;a href="https://blog.vllm.ai/2025/09/11/semantic-router.html"&gt;vLLM Semantic Router: Next Phase in LLM inference&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Goals&lt;/h2&gt; 
&lt;p&gt;We are building the &lt;strong&gt;System Level Intelligence&lt;/strong&gt; for Mixture-of-Models (MoM), bringing the &lt;strong&gt;Collective Intelligence&lt;/strong&gt; into &lt;strong&gt;LLM systems&lt;/strong&gt;, answering the following questions:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;How to capture the missing signals in request, response and context?&lt;/li&gt; 
 &lt;li&gt;How to combine the signals to make better decisions?&lt;/li&gt; 
 &lt;li&gt;How to collaborate more efficiently between different models?&lt;/li&gt; 
 &lt;li&gt;How to secure the real world and LLM system from jailbreaks, pii leaks, hallucinations?&lt;/li&gt; 
 &lt;li&gt;How to collect the valuable signals and build a self-learning system?&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/vllm-project/semantic-router/main/website/static/img/banner.png" alt="vLLM Semantic Router Banner" /&gt;&lt;/p&gt; 
&lt;h3&gt;Where it lives&lt;/h3&gt; 
&lt;p&gt;It lives between the real world and models:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/vllm-project/semantic-router/main/website/static/img/level.png" alt="level" /&gt;&lt;/p&gt; 
&lt;h3&gt;Architecture&lt;/h3&gt; 
&lt;p&gt;A quick overview of the current architecture:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/vllm-project/semantic-router/main/website/static/img/architecture.png" alt="architecture" /&gt;&lt;/p&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] We recommend that you setup a Python virtual environment to manage dependencies.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ python -m venv vsr
$ source vsr/bin/activate
$ pip install vllm-sr
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Installed successfully if you see the following help message:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ vllm-sr

       _ _     __  __       ____  ____
__   _| | |_ _|  \/  |     / ___||  _ \
\ \ / / | | | | |\/| |_____\___ \| |_) |
 \ V /| | | |_| | |  |_____|___) |  _ &amp;lt;
  \_/ |_|_|\__,_|_|  |     |____/|_| \_\

vLLM Semantic Router - Intelligent routing for vLLM

Usage: vllm-sr [OPTIONS] COMMAND [ARGS]...

  vLLM Semantic Router CLI - Intelligent routing and caching for vLLM
  endpoints.

Options:
  --version  Show version and exit.
  --help     Show this message and exit.

Commands:
  config  Print generated configuration.
  init    Initialize vLLM Semantic Router configuration.
  dashboard  Launch the vLLM Semantic Router dashboard.
  logs    Show logs from vLLM Semantic Router service.
  serve   Start vLLM Semantic Router.
  status  Show status of vLLM Semantic Router services.
  stop    Stop vLLM Semantic Router.
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] You can specify the HF_ENDPOINT, HF_TOKEN, and HF_HOME environment variables to configure the Hugging Face credentials.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Set environment variables (optional)
export HF_ENDPOINT=https://huggingface.co  # Or use mirror: https://hf-mirror.com
export HF_TOKEN=your_token_here  # Only for gated models
export HF_HOME=/path/to/cache  # Optional: custom cache directory

# Start the service - models download automatically
# Environment variables are automatically passed to the container
vllm-sr serve
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Configuration&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;File Descriptor Limits&lt;/strong&gt;: The CLI automatically sets file descriptor limits to 65,536 for Envoy proxy. For custom limits:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export VLLM_SR_NOFILE_LIMIT=100000  # Optional: custom limit (min: 8192)
vllm-sr serve
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/vllm-project/semantic-router/main/src/vllm-sr/README.md#configuration"&gt;vllm-sr README&lt;/a&gt; for detailed configuration options and troubleshooting.&lt;/p&gt; 
&lt;h2&gt;Documentation üìñ&lt;/h2&gt; 
&lt;p&gt;For comprehensive documentation including detailed setup instructions, architecture guides, and API references, visit:&lt;/p&gt; 
&lt;p&gt;Complete Documentation at Read the &lt;strong&gt;&lt;a href="https://vllm-semantic-router.com/"&gt;Docs&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;The documentation includes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://vllm-semantic-router.com/docs/installation/"&gt;Installation Guide&lt;/a&gt;&lt;/strong&gt; - Complete setup instructions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://vllm-semantic-router.com/docs/overview/architecture/system-architecture/"&gt;System Architecture&lt;/a&gt;&lt;/strong&gt; - Technical deep dive&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://vllm-semantic-router.com/docs/training/training-overview/"&gt;Model Training&lt;/a&gt;&lt;/strong&gt; - How classification models work&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://vllm-semantic-router.com/docs/api/router/"&gt;API Reference&lt;/a&gt;&lt;/strong&gt; - Complete API documentation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Community üëã&lt;/h2&gt; 
&lt;p&gt;For questions, feedback, or to contribute, please join &lt;code&gt;#semantic-router&lt;/code&gt; channel in vLLM Slack.&lt;/p&gt; 
&lt;h3&gt;Community Meetings üìÖ&lt;/h3&gt; 
&lt;p&gt;We host bi-weekly community meetings to sync up with contributors across different time zones:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;First Tuesday of the month&lt;/strong&gt;: 9:00-10:00 AM EST (accommodates US EST, EU, and Asia Pacific contributors) 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://us05web.zoom.us/j/84122485631?pwd=BB88v03mMNLVHn60YzVk4PihuqBV9d.1"&gt;Zoom Link&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://us05web.zoom.us/meeting/tZAsdeuspj4sGdVraOOR4UaXSstrH2jjPYFq/calendar/google/add?meetingMasterEventId=4jjzUKSLSLiBHtIKZpGc3g"&gt;Google Calendar Invite&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://drive.google.com/file/d/15wO8cg0ZjNxdr8OtGiZyAgkSS8_Wry0J/view?usp=sharing"&gt;ics file&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Third Tuesday of the month&lt;/strong&gt;: 1:00-2:00 PM EST (accommodates US EST and California contributors) 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://us06web.zoom.us/j/86871492845?pwd=LcTtXm9gtGu23JeWqXxbnLLCCvbumB.1"&gt;Zoom Link&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://us05web.zoom.us/meeting/tZIlcOispzkiHtH2dlkWlLym68bEqvuf3MU5/calendar/google/add?meetingMasterEventId=PqWz2vk7TOCszPXqconGAA"&gt;Google Calendar Invite&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://drive.google.com/file/d/1T54mwYpXXoV9QfR76I56BFBPNbykSsTw/view?usp=sharing"&gt;ics file&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Meeting Recordings: &lt;a href="https://www.youtube.com/@vLLMSemanticRouter/videos"&gt;YouTube&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Join us to discuss the latest developments, share ideas, and collaborate on the project!&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you find Semantic Router helpful in your research or projects, please consider citing it:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@misc{semanticrouter2025,
  title={vLLM Semantic Router},
  author={vLLM Semantic Router Team},
  year={2025},
  howpublished={\url{https://github.com/vllm-project/semantic-router}},
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Star History üî•&lt;/h2&gt; 
&lt;p&gt;We opened the project at Aug 31, 2025. We love open source and collaboration ‚ù§Ô∏è&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#vllm-project/semantic-router&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=vllm-project/semantic-router&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Sponsors üëã&lt;/h2&gt; 
&lt;p&gt;We are grateful to our sponsors who support us:&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;a href="https://www.amd.com"&gt;&lt;strong&gt;AMD&lt;/strong&gt;&lt;/a&gt; provides us with GPU resources and &lt;a href="https://www.amd.com/en/products/software/rocm.html"&gt;ROCm‚Ñ¢&lt;/a&gt; Software for training and researching the frontier router models, enhancing e2e testing, and building online models playground.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://www.amd.com"&gt; &lt;img src="https://raw.githubusercontent.com/vllm-project/semantic-router/main/website/static/img/amd-logo.svg?sanitize=true" alt="AMD" width="40%" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;hr /&gt;</description>
    </item>
    
    <item>
      <title>AlexxIT/go2rtc</title>
      <link>https://github.com/AlexxIT/go2rtc</link>
      <description>&lt;p&gt;Ultimate camera streaming application with support RTSP, RTMP, HTTP-FLV, WebRTC, MSE, HLS, MP4, MJPEG, HomeKit, FFmpeg, etc.&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/assets/logo.gif" alt="go2rtc" /&gt; &lt;br /&gt; &lt;a href="https://github.com/AlexxIT/go2rtc/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/AlexxIT/go2rtc?style=flat-square&amp;amp;logo=github" alt="stars" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/alexxit/go2rtc"&gt;&lt;img src="https://img.shields.io/docker/pulls/alexxit/go2rtc?style=flat-square&amp;amp;logo=docker&amp;amp;logoColor=white&amp;amp;label=pulls" alt="docker pulls" /&gt;&lt;/a&gt; &lt;a href="https://github.com/AlexxIT/go2rtc/releases"&gt;&lt;img src="https://img.shields.io/github/downloads/AlexxIT/go2rtc/total?color=blue&amp;amp;style=flat-square&amp;amp;logo=github" alt="releases" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/AlexxIT/go2rtc"&gt;&lt;img src="https://goreportcard.com/badge/github.com/AlexxIT/go2rtc" alt="goreport" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;/h1&gt; 
&lt;p&gt;Ultimate camera streaming application with support for RTSP, WebRTC, HomeKit, FFmpeg, RTMP, etc.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/assets/go2rtc.png" alt="" /&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;zero-dependency and zero-config &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#go2rtc-binary"&gt;small app&lt;/a&gt; for all OS (Windows, macOS, Linux, ARM)&lt;/li&gt; 
 &lt;li&gt;zero-delay for many supported protocols (lowest possible streaming latency)&lt;/li&gt; 
 &lt;li&gt;streaming from &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-rtsp"&gt;RTSP&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-rtmp"&gt;RTMP&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-dvrip"&gt;DVRIP&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-http"&gt;HTTP&lt;/a&gt; (FLV/MJPEG/JPEG/TS), &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-ffmpeg-device"&gt;USB Cameras&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-streams"&gt;other sources&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;streaming from any sources, supported by &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-ffmpeg"&gt;FFmpeg&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;streaming to &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-rtsp"&gt;RTSP&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-webrtc"&gt;WebRTC&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-mp4"&gt;MSE/MP4&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-homekit"&gt;HomeKit&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-hls"&gt;HLS&lt;/a&gt; or &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-mjpeg"&gt;MJPEG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#publish-stream"&gt;publish&lt;/a&gt; any source to popular streaming services (YouTube, Telegram, etc.)&lt;/li&gt; 
 &lt;li&gt;first project in the World with support streaming from &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-homekit"&gt;HomeKit Cameras&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;on-the-fly transcoding for unsupported codecs via &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-ffmpeg"&gt;FFmpeg&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;play audio files and live streams on some cameras with &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#stream-to-camera"&gt;speaker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;multi-source two-way &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#codecs-negotiation"&gt;codecs negotiation&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;mixing tracks from different sources to single stream&lt;/li&gt; 
   &lt;li&gt;auto-match client-supported codecs&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#two-way-audio"&gt;two-way audio&lt;/a&gt; for some cameras&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;can be &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-api"&gt;integrated to&lt;/a&gt; any smart home platform or be used as &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#go2rtc-binary"&gt;standalone app&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Supported Formats&lt;/strong&gt; - describes the communication API: authorization, encryption, command set, structure of media packets&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;devices: &lt;code&gt;alsa&lt;/code&gt; (Linux audio), &lt;code&gt;v4l2&lt;/code&gt; (Linux video)&lt;/li&gt; 
 &lt;li&gt;files: &lt;code&gt;adts&lt;/code&gt;, &lt;code&gt;flv&lt;/code&gt;, &lt;code&gt;h264&lt;/code&gt;, &lt;code&gt;hevc&lt;/code&gt;, &lt;code&gt;hls&lt;/code&gt;, &lt;code&gt;mjpeg&lt;/code&gt;, &lt;code&gt;mpegts&lt;/code&gt;, &lt;code&gt;mp4&lt;/code&gt;, &lt;code&gt;wav&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;network (public and well known): &lt;code&gt;mpjpeg&lt;/code&gt;, &lt;code&gt;onvif&lt;/code&gt;, &lt;code&gt;rtmp&lt;/code&gt;, &lt;code&gt;rtp&lt;/code&gt;, &lt;code&gt;rtsp&lt;/code&gt;, &lt;code&gt;webrtc&lt;/code&gt;, &lt;code&gt;y2m&lt;/code&gt; (yuv4mpegpipe)&lt;/li&gt; 
 &lt;li&gt;network (private and exclusive): &lt;code&gt;bubble&lt;/code&gt;, &lt;code&gt;doorbird&lt;/code&gt;, &lt;code&gt;dvrip&lt;/code&gt;, &lt;code&gt;eseecloud&lt;/code&gt;, &lt;code&gt;gopro&lt;/code&gt;, &lt;code&gt;hass&lt;/code&gt; (Home Assistant), &lt;code&gt;homekit&lt;/code&gt; (Apple), &lt;code&gt;isapi&lt;/code&gt; (Hikvision), &lt;code&gt;kasa&lt;/code&gt; (TP-Link), &lt;code&gt;nest&lt;/code&gt; (Google), &lt;code&gt;ring&lt;/code&gt;, &lt;code&gt;roborock&lt;/code&gt;, &lt;code&gt;tapo&lt;/code&gt; and &lt;code&gt;vigi&lt;/code&gt; (TP-Link), &lt;code&gt;tuya&lt;/code&gt;, &lt;code&gt;webtorrent&lt;/code&gt;, &lt;code&gt;xiaomi&lt;/code&gt; (Mi Home)&lt;/li&gt; 
 &lt;li&gt;webrtc related: &lt;code&gt;creality&lt;/code&gt;, &lt;code&gt;kinesis&lt;/code&gt; (Amazon), &lt;code&gt;openipc&lt;/code&gt;, &lt;code&gt;switchbot&lt;/code&gt;, &lt;code&gt;whep&lt;/code&gt;, &lt;code&gt;whip&lt;/code&gt;, &lt;code&gt;wyze&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;other: &lt;code&gt;ascii&lt;/code&gt;, &lt;code&gt;echo&lt;/code&gt;, &lt;code&gt;exec&lt;/code&gt;, &lt;code&gt;expr&lt;/code&gt;, &lt;code&gt;ffmpeg&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Supported Protocols&lt;/strong&gt; - describes the transport for data transmission&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;public: &lt;code&gt;http&lt;/code&gt;, &lt;code&gt;pipe&lt;/code&gt;, &lt;code&gt;rtmp&lt;/code&gt;, &lt;code&gt;rtsp&lt;/code&gt;, &lt;code&gt;tcp&lt;/code&gt;, &lt;code&gt;udp&lt;/code&gt;, &lt;code&gt;webrtc&lt;/code&gt;, &lt;code&gt;ws&lt;/code&gt; (WebSocket)&lt;/li&gt; 
 &lt;li&gt;private: &lt;code&gt;cs2&lt;/code&gt; (PPPP), &lt;code&gt;hap&lt;/code&gt; and &lt;code&gt;hds&lt;/code&gt; (HomeKit), &lt;code&gt;tutk&lt;/code&gt; (P2P)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Inspired by:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;series of streaming projects from &lt;a href="https://github.com/deepch"&gt;@deepch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pion/webrtc"&gt;webrtc&lt;/a&gt; go library and whole &lt;a href="https://github.com/pion"&gt;@pion&lt;/a&gt; team&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aler9/rtsp-simple-server"&gt;rtsp-simple-server&lt;/a&gt; idea from &lt;a href="https://github.com/aler9"&gt;@aler9&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gstreamer.freedesktop.org/"&gt;GStreamer&lt;/a&gt; framework pipeline idea&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mediasoup.org/"&gt;MediaSoup&lt;/a&gt; framework routing idea&lt;/li&gt; 
 &lt;li&gt;HomeKit Accessory Protocol from &lt;a href="https://github.com/brutella/hap"&gt;@brutella&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;creator of the project's logo &lt;a href="https://www.instagram.com/v_novoseltsev"&gt;@v_novoseltsev&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!CAUTION] The official website of the project is this GitHub repository and go2rtc.org (hosted on GitHub Pages). The website go2rtc[.]com is in no way associated with the authors of this project.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr /&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#fast-start"&gt;Fast start&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#go2rtc-binary"&gt;go2rtc: Binary&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#go2rtc-docker"&gt;go2rtc: Docker&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#go2rtc-home-assistant-add-on"&gt;go2rtc: Home Assistant Add-on&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#go2rtc-home-assistant-integration"&gt;go2rtc: Home Assistant Integration&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#go2rtc-dev-version"&gt;go2rtc: Dev version&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#configuration"&gt;Configuration&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-streams"&gt;Module: Streams&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#two-way-audio"&gt;Two way audio&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-rtsp"&gt;Source: RTSP&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-rtmp"&gt;Source: RTMP&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-http"&gt;Source: HTTP&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-onvif"&gt;Source: ONVIF&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-ffmpeg"&gt;Source: FFmpeg&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-ffmpeg-device"&gt;Source: FFmpeg Device&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-exec"&gt;Source: Exec&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-echo"&gt;Source: Echo&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-expr"&gt;Source: Expr&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-homekit"&gt;Source: HomeKit&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-bubble"&gt;Source: Bubble&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-dvrip"&gt;Source: DVRIP&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-tapo"&gt;Source: Tapo&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-kasa"&gt;Source: Kasa&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-tuya"&gt;Source: Tuya&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-xiaomi"&gt;Source: Xiaomi&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-gopro"&gt;Source: GoPro&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-ivideon"&gt;Source: Ivideon&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-hass"&gt;Source: Hass&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-isapi"&gt;Source: ISAPI&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-nest"&gt;Source: Nest&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-ring"&gt;Source: Ring&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-roborock"&gt;Source: Roborock&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-doorbird"&gt;Source: Doorbird&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-webrtc"&gt;Source: WebRTC&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-webtorrent"&gt;Source: WebTorrent&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#incoming-sources"&gt;Incoming sources&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#stream-to-camera"&gt;Stream to camera&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#publish-stream"&gt;Publish stream&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#preload-stream"&gt;Preload stream&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-api"&gt;Module: API&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-rtsp"&gt;Module: RTSP&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-rtmp"&gt;Module: RTMP&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-webrtc"&gt;Module: WebRTC&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-homekit"&gt;Module: HomeKit&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-webtorrent"&gt;Module: WebTorrent&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-ngrok"&gt;Module: ngrok&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-hass"&gt;Module: Hass&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-mp4"&gt;Module: MP4&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-hls"&gt;Module: HLS&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-mjpeg"&gt;Module: MJPEG&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-log"&gt;Module: Log&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#security"&gt;Security&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#codecs-filters"&gt;Codecs filters&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#codecs-madness"&gt;Codecs madness&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#codecs-negotiation"&gt;Codecs negotiation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#projects-using-go2rtc"&gt;Projects using go2rtc&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#cameras-experience"&gt;Camera experience&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#tips"&gt;TIPS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#faq"&gt;FAQ&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Fast start&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Download &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#go2rtc-binary"&gt;binary&lt;/a&gt; or use &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#go2rtc-docker"&gt;Docker&lt;/a&gt; or Home Assistant &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#go2rtc-home-assistant-add-on"&gt;Add-on&lt;/a&gt; or &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#go2rtc-home-assistant-integration"&gt;Integration&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Open web interface: &lt;code&gt;http://localhost:1984/&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Optionally:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;add your &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-streams"&gt;streams&lt;/a&gt; to &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#configuration"&gt;config&lt;/a&gt; file&lt;/li&gt; 
 &lt;li&gt;setup &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-webrtc"&gt;external access&lt;/a&gt; to webrtc&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Developers:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;write your own &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-api"&gt;web interface&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;integrate &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-api"&gt;web api&lt;/a&gt; into your smart home platform&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;go2rtc: Binary&lt;/h3&gt; 
&lt;p&gt;Download binary for your OS from &lt;a href="https://github.com/AlexxIT/go2rtc/releases/"&gt;latest release&lt;/a&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;go2rtc_win64.zip&lt;/code&gt; - Windows 10+ 64-bit&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;go2rtc_win32.zip&lt;/code&gt; - Windows 10+ 32-bit&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;go2rtc_win_arm64.zip&lt;/code&gt; - Windows ARM 64-bit&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;go2rtc_linux_amd64&lt;/code&gt; - Linux 64-bit&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;go2rtc_linux_i386&lt;/code&gt; - Linux 32-bit&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;go2rtc_linux_arm64&lt;/code&gt; - Linux ARM 64-bit (ex. Raspberry 64-bit OS)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;go2rtc_linux_arm&lt;/code&gt; - Linux ARM 32-bit (ex. Raspberry 32-bit OS)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;go2rtc_linux_armv6&lt;/code&gt; - Linux ARMv6 (for old Raspberry 1 and Zero)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;go2rtc_linux_mipsel&lt;/code&gt; - Linux MIPS (ex. &lt;a href="https://github.com/AlexxIT/XiaomiGateway3"&gt;Xiaomi Gateway 3&lt;/a&gt;, &lt;a href="https://github.com/gtxaspec/wz_mini_hacks"&gt;Wyze cameras&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;go2rtc_mac_amd64.zip&lt;/code&gt; - macOS 11+ Intel 64-bit&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;go2rtc_mac_arm64.zip&lt;/code&gt; - macOS ARM 64-bit&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;go2rtc_freebsd_amd64.zip&lt;/code&gt; - FreeBSD 64-bit&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;go2rtc_freebsd_arm64.zip&lt;/code&gt; - FreeBSD ARM 64-bit&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Don't forget to fix the rights &lt;code&gt;chmod +x go2rtc_xxx_xxx&lt;/code&gt; on Linux and Mac.&lt;/p&gt; 
&lt;p&gt;PS. The application is compiled with the latest versions of the Go language for maximum speed and security. Therefore, the &lt;a href="https://go.dev/wiki/MinimumRequirements"&gt;minimum OS versions&lt;/a&gt; depend on the Go language.&lt;/p&gt; 
&lt;h3&gt;go2rtc: Docker&lt;/h3&gt; 
&lt;p&gt;The Docker container &lt;a href="https://hub.docker.com/r/alexxit/go2rtc"&gt;&lt;code&gt;alexxit/go2rtc&lt;/code&gt;&lt;/a&gt; supports multiple architectures including &lt;code&gt;amd64&lt;/code&gt;, &lt;code&gt;386&lt;/code&gt;, &lt;code&gt;arm64&lt;/code&gt;, and &lt;code&gt;arm&lt;/code&gt;. This container offers the same functionality as the &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#go2rtc-home-assistant-add-on"&gt;Home Assistant Add-on&lt;/a&gt; but is designed to operate independently of Home Assistant. It comes preinstalled with &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-ffmpeg"&gt;FFmpeg&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-echo"&gt;Python&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;go2rtc: Home Assistant Add-on&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://my.home-assistant.io/redirect/supervisor_addon/?addon=a889bffc_go2rtc&amp;amp;repository_url=https%3A%2F%2Fgithub.com%2FAlexxIT%2Fhassio-addons"&gt;&lt;img src="https://my.home-assistant.io/badges/supervisor_addon.svg?sanitize=true" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install Add-On: 
  &lt;ul&gt; 
   &lt;li&gt;Settings &amp;gt; Add-ons &amp;gt; Plus &amp;gt; Repositories &amp;gt; Add &lt;code&gt;https://github.com/AlexxIT/hassio-addons&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;go2rtc &amp;gt; Install &amp;gt; Start&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Setup &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-hass"&gt;Integration&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;go2rtc: Home Assistant Integration&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/AlexxIT/WebRTC"&gt;WebRTC Camera&lt;/a&gt; custom component can be used on any &lt;a href="https://www.home-assistant.io/installation/"&gt;Home Assistant installation&lt;/a&gt;, including &lt;a href="https://github.com/AlexxIT/HassWP"&gt;HassWP&lt;/a&gt; on Windows. It can automatically download and use the latest version of go2rtc. Or it can connect to an existing version of go2rtc. Addon installation in this case is optional.&lt;/p&gt; 
&lt;h3&gt;go2rtc: Dev version&lt;/h3&gt; 
&lt;p&gt;Latest, but maybe unstable version:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Binary: &lt;a href="https://nightly.link/AlexxIT/go2rtc/workflows/build/master"&gt;latest nightly release&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Docker: &lt;code&gt;alexxit/go2rtc:master&lt;/code&gt; or &lt;code&gt;alexxit/go2rtc:master-hardware&lt;/code&gt; versions&lt;/li&gt; 
 &lt;li&gt;Hass Add-on: &lt;code&gt;go2rtc master&lt;/code&gt; or &lt;code&gt;go2rtc master hardware&lt;/code&gt; versions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Configuration&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;by default go2rtc will search &lt;code&gt;go2rtc.yaml&lt;/code&gt; in the current work directory&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;api&lt;/code&gt; server will start on default &lt;strong&gt;1984 port&lt;/strong&gt; (TCP)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;rtsp&lt;/code&gt; server will start on default &lt;strong&gt;8554 port&lt;/strong&gt; (TCP)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;webrtc&lt;/code&gt; will use port &lt;strong&gt;8555&lt;/strong&gt; (TCP/UDP) for connections&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ffmpeg&lt;/code&gt; will use default transcoding options&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Configuration options and a complete list of settings can be found in &lt;a href="https://github.com/AlexxIT/go2rtc/wiki/Configuration"&gt;the wiki&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Available modules:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-streams"&gt;streams&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-api"&gt;api&lt;/a&gt; - HTTP API (important for WebRTC support)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-rtsp"&gt;rtsp&lt;/a&gt; - RTSP Server (important for FFmpeg support)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-webrtc"&gt;webrtc&lt;/a&gt; - WebRTC Server&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-mp4"&gt;mp4&lt;/a&gt; - MSE, MP4 stream and MP4 snapshot Server&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-hls"&gt;hls&lt;/a&gt; - HLS TS or fMP4 stream Server&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-mjpeg"&gt;mjpeg&lt;/a&gt; - MJPEG Server&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-ffmpeg"&gt;ffmpeg&lt;/a&gt; - FFmpeg integration&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-ngrok"&gt;ngrok&lt;/a&gt; - ngrok integration (external access for private network)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-hass"&gt;hass&lt;/a&gt; - Home Assistant integration&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-log"&gt;log&lt;/a&gt; - logs config&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Module: Streams&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;go2rtc&lt;/strong&gt; supports different stream source types. You can config one or multiple links of any type as a stream source.&lt;/p&gt; 
&lt;p&gt;Available source types:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-rtsp"&gt;rtsp&lt;/a&gt; - &lt;code&gt;RTSP&lt;/code&gt; and &lt;code&gt;RTSPS&lt;/code&gt; cameras with &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#two-way-audio"&gt;two-way audio&lt;/a&gt; support&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-rtmp"&gt;rtmp&lt;/a&gt; - &lt;code&gt;RTMP&lt;/code&gt; streams&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-http"&gt;http&lt;/a&gt; - &lt;code&gt;HTTP-FLV&lt;/code&gt;, &lt;code&gt;MPEG-TS&lt;/code&gt;, &lt;code&gt;JPEG&lt;/code&gt; (snapshots), &lt;code&gt;MJPEG&lt;/code&gt; streams&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-onvif"&gt;onvif&lt;/a&gt; - get camera &lt;code&gt;RTSP&lt;/code&gt; link and snapshot link using &lt;code&gt;ONVIF&lt;/code&gt; protocol&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-ffmpeg"&gt;ffmpeg&lt;/a&gt; - FFmpeg integration (&lt;code&gt;HLS&lt;/code&gt;, &lt;code&gt;files&lt;/code&gt; and many others)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-ffmpeg-device"&gt;ffmpeg:device&lt;/a&gt; - local USB Camera or Webcam&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-exec"&gt;exec&lt;/a&gt; - get media from external app output&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-echo"&gt;echo&lt;/a&gt; - get stream link from bash or python&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-expr"&gt;expr&lt;/a&gt; - get stream link via built-in expression language&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-homekit"&gt;homekit&lt;/a&gt; - streaming from HomeKit Camera&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-bubble"&gt;bubble&lt;/a&gt; - streaming from ESeeCloud/dvr163 NVR&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-dvrip"&gt;dvrip&lt;/a&gt; - streaming from DVR-IP NVR&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-eseecloud"&gt;eseecloud&lt;/a&gt; - streaming from ESeeCloud/dvr163 NVR&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-tapo"&gt;tapo&lt;/a&gt; - TP-Link Tapo cameras with &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#two-way-audio"&gt;two way audio&lt;/a&gt; support&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-ring"&gt;ring&lt;/a&gt; - Ring cameras with &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#two-way-audio"&gt;two way audio&lt;/a&gt; support&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-tuya"&gt;tuya&lt;/a&gt; - Tuya cameras with &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#two-way-audio"&gt;two way audio&lt;/a&gt; support&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-xiaomi"&gt;xiaomi&lt;/a&gt; - Xiaomi cameras with &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#two-way-audio"&gt;two way audio&lt;/a&gt; support&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-tapo"&gt;kasa&lt;/a&gt; - TP-Link Kasa cameras&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-gopro"&gt;gopro&lt;/a&gt; - GoPro cameras&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-ivideon"&gt;ivideon&lt;/a&gt; - public cameras from &lt;a href="https://tv.ivideon.com/"&gt;Ivideon&lt;/a&gt; service&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-hass"&gt;hass&lt;/a&gt; - Home Assistant integration&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-isapi"&gt;isapi&lt;/a&gt; - two-way audio for Hikvision (ISAPI) cameras&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-roborock"&gt;roborock&lt;/a&gt; - Roborock vacuums with cameras&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-doorbird"&gt;doorbird&lt;/a&gt; - Doorbird cameras with &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#two-way-audio"&gt;two way audio&lt;/a&gt; support&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-webrtc"&gt;webrtc&lt;/a&gt; - WebRTC/WHEP sources&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-webtorrent"&gt;webtorrent&lt;/a&gt; - WebTorrent source from another go2rtc&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Read more about &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#incoming-sources"&gt;incoming sources&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;Two-way audio&lt;/h4&gt; 
&lt;p&gt;Supported sources:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-rtsp"&gt;RTSP cameras&lt;/a&gt; with &lt;a href="https://www.onvif.org/specs/stream/ONVIF-Streaming-Spec.pdf"&gt;ONVIF Profile T&lt;/a&gt; (back channel connection)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-dvrip"&gt;DVRIP&lt;/a&gt; cameras&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-tapo"&gt;TP-Link Tapo&lt;/a&gt; cameras&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-isapi"&gt;Hikvision ISAPI&lt;/a&gt; cameras&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-roborock"&gt;Roborock vacuums&lt;/a&gt; models with cameras&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-doorbird"&gt;Doorbird&lt;/a&gt; cameras&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-exec"&gt;Exec&lt;/a&gt; audio on server&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-ring"&gt;Ring&lt;/a&gt; cameras&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-tuya"&gt;Tuya&lt;/a&gt; cameras&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-xiaomi"&gt;Xiaomi&lt;/a&gt; cameras&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#incoming-browser"&gt;Any Browser&lt;/a&gt; as IP-camera&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Two-way audio can be used in browser with &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-webrtc"&gt;WebRTC&lt;/a&gt; technology. The browser will give access to the microphone only for HTTPS sites (&lt;a href="https://stackoverflow.com/questions/52759992/how-to-access-camera-and-microphone-in-chrome-without-https"&gt;read more&lt;/a&gt;).&lt;/p&gt; 
&lt;p&gt;go2rtc also supports &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#stream-to-camera"&gt;play audio&lt;/a&gt; files and live streams on this cameras.&lt;/p&gt; 
&lt;h4&gt;Source: RTSP&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;streams:
  sonoff_camera: rtsp://rtsp:12345678@192.168.1.123/av_stream/ch0
  dahua_camera:
    - rtsp://admin:password@192.168.1.123/cam/realmonitor?channel=1&amp;amp;subtype=0&amp;amp;unicast=true&amp;amp;proto=Onvif
    - rtsp://admin:password@192.168.1.123/cam/realmonitor?channel=1&amp;amp;subtype=1#backchannel=0
  amcrest_doorbell:
    - rtsp://username:password@192.168.1.123:554/cam/realmonitor?channel=1&amp;amp;subtype=0#backchannel=0
  unifi_camera: rtspx://192.168.1.123:7441/fD6ouM72bWoFijxK
  glichy_camera: ffmpeg:rtsp://username:password@192.168.1.123/live/ch00_1 
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Recommendations&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Amcrest Doorbell&lt;/strong&gt; users may want to disable two-way audio, because with an active stream, you won't have a working call button. You need to add &lt;code&gt;#backchannel=0&lt;/code&gt; to the end of your RTSP link in YAML config file&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dahua Doorbell&lt;/strong&gt; users may want to change &lt;a href="https://github.com/AlexxIT/go2rtc/issues/49#issuecomment-2127107379"&gt;audio codec&lt;/a&gt; for proper 2-way audio. Make sure not to request backchannel multiple times by adding &lt;code&gt;#backchannel=0&lt;/code&gt; to other stream sources of the same doorbell. The &lt;code&gt;unicast=true&amp;amp;proto=Onvif&lt;/code&gt; is preferred for 2-way audio as this makes the doorbell accept multiple codecs for the incoming audio&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Reolink&lt;/strong&gt; users may want NOT to use RTSP protocol at all, some camera models have a very awful, unusable stream implementation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ubiquiti UniFi&lt;/strong&gt; users may want to disable HTTPS verification. Use &lt;code&gt;rtspx://&lt;/code&gt; prefix instead of &lt;code&gt;rtsps://&lt;/code&gt;. And don't use &lt;code&gt;?enableSrtp&lt;/code&gt; &lt;a href="https://github.com/AlexxIT/go2rtc/issues/81"&gt;suffix&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;TP-Link Tapo&lt;/strong&gt; users may skip login and password, because go2rtc support login &lt;a href="https://drmnsamoliu.github.io/video.html"&gt;without them&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;If your camera has two RTSP links, you can add both as sources. This is useful when streams have different codecs, for example AAC audio with main stream and PCMU/PCMA audio with second stream&lt;/li&gt; 
 &lt;li&gt;If the stream from your camera is glitchy, try using &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-ffmpeg"&gt;ffmpeg source&lt;/a&gt;. It will not add CPU load if you don't use transcoding&lt;/li&gt; 
 &lt;li&gt;If the stream from your camera is very glitchy, try to use transcoding with &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-ffmpeg"&gt;ffmpeg source&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Other options&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Format: &lt;code&gt;rtsp...#{param1}#{param2}#{param3}&lt;/code&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Add custom timeout &lt;code&gt;#timeout=30&lt;/code&gt; (in seconds)&lt;/li&gt; 
 &lt;li&gt;Ignore audio - &lt;code&gt;#media=video&lt;/code&gt; or ignore video - &lt;code&gt;#media=audio&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Ignore two-way audio API &lt;code&gt;#backchannel=0&lt;/code&gt; - important for some glitchy cameras&lt;/li&gt; 
 &lt;li&gt;Use WebSocket transport &lt;code&gt;#transport=ws...&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;RTSP over WebSocket&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;streams:
  # WebSocket with authorization, RTSP - without
  axis-rtsp-ws:  rtsp://192.168.1.123:4567/axis-media/media.amp?overview=0&amp;amp;camera=1&amp;amp;resolution=1280x720&amp;amp;videoframeskipmode=empty&amp;amp;Axis-Orig-Sw=true#transport=ws://user:pass@192.168.1.123:4567/rtsp-over-websocket
  # WebSocket without authorization, RTSP - with
  dahua-rtsp-ws: rtsp://user:pass@192.168.1.123/cam/realmonitor?channel=1&amp;amp;subtype=1&amp;amp;proto=Private3#transport=ws://192.168.1.123/rtspoverwebsocket
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Source: RTMP&lt;/h4&gt; 
&lt;p&gt;You can get a stream from an RTMP server, for example &lt;a href="https://github.com/arut/nginx-rtmp-module"&gt;Nginx with nginx-rtmp-module&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;streams:
  rtmp_stream: rtmp://192.168.1.123/live/camera1
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Source: HTTP&lt;/h4&gt; 
&lt;p&gt;Support Content-Type:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;HTTP-FLV&lt;/strong&gt; (&lt;code&gt;video/x-flv&lt;/code&gt;) - same as RTMP, but over HTTP&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;HTTP-JPEG&lt;/strong&gt; (&lt;code&gt;image/jpeg&lt;/code&gt;) - camera snapshot link, can be converted by go2rtc to MJPEG stream&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;HTTP-MJPEG&lt;/strong&gt; (&lt;code&gt;multipart/x&lt;/code&gt;) - simple MJPEG stream over HTTP&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MPEG-TS&lt;/strong&gt; (&lt;code&gt;video/mpeg&lt;/code&gt;) - legacy &lt;a href="https://en.wikipedia.org/wiki/MPEG_transport_stream"&gt;streaming format&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Source also supports HTTP and TCP streams with autodetection for different formats: &lt;strong&gt;MJPEG&lt;/strong&gt;, &lt;strong&gt;H.264/H.265 bitstream&lt;/strong&gt;, &lt;strong&gt;MPEG-TS&lt;/strong&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;streams:
  # [HTTP-FLV] stream in video/x-flv format
  http_flv: http://192.168.1.123:20880/api/camera/stream/780900131155/657617
  
  # [JPEG] snapshots from Dahua camera, will be converted to MJPEG stream
  dahua_snap: http://admin:password@192.168.1.123/cgi-bin/snapshot.cgi?channel=1

  # [MJPEG] stream will be proxied without modification
  http_mjpeg: https://mjpeg.sanford.io/count.mjpeg

  # [MJPEG or H.264/H.265 bitstream or MPEG-TS]
  tcp_magic: tcp://192.168.1.123:12345

  # Add custom header
  custom_header: "https://mjpeg.sanford.io/count.mjpeg#header=Authorization: Bearer XXX"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;PS.&lt;/strong&gt; Dahua camera has a bug: if you select MJPEG codec for RTSP second stream, snapshot won't work.&lt;/p&gt; 
&lt;h4&gt;Source: ONVIF&lt;/h4&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href="https://github.com/AlexxIT/go2rtc/releases/tag/v1.5.0"&gt;New in v1.5.0&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;The source is not very useful if you already know RTSP and snapshot links for your camera. But it can be useful if you don't.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;WebUI &amp;gt; Add&lt;/strong&gt; webpage support ONVIF autodiscovery. Your server must be on the same subnet as the camera. If you use Docker, you must use "network host".&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;streams:
  dahua1: onvif://admin:password@192.168.1.123
  reolink1: onvif://admin:password@192.168.1.123:8000
  tapo1: onvif://admin:password@192.168.1.123:2020
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Source: FFmpeg&lt;/h4&gt; 
&lt;p&gt;You can get any stream, file or device via FFmpeg and push it to go2rtc. The app will automatically start FFmpeg with the proper arguments when someone starts watching the stream.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;FFmpeg preistalled for &lt;strong&gt;Docker&lt;/strong&gt; and &lt;strong&gt;Hass Add-on&lt;/strong&gt; users&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Hass Add-on&lt;/strong&gt; users can target files from &lt;a href="https://www.home-assistant.io/more-info/local-media/setup-media/"&gt;/media&lt;/a&gt; folder&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Format: &lt;code&gt;ffmpeg:{input}#{param1}#{param2}#{param3}&lt;/code&gt;. Examples:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;streams:
  # [FILE] all tracks will be copied without transcoding codecs
  file1: ffmpeg:/media/BigBuckBunny.mp4

  # [FILE] video will be transcoded to H264, audio will be skipped
  file2: ffmpeg:/media/BigBuckBunny.mp4#video=h264

  # [FILE] video will be copied, audio will be transcoded to PCMU
  file3: ffmpeg:/media/BigBuckBunny.mp4#video=copy#audio=pcmu

  # [HLS] video will be copied, audio will be skipped
  hls: ffmpeg:https://devstreaming-cdn.apple.com/videos/streaming/examples/bipbop_16x9/gear5/prog_index.m3u8#video=copy

  # [MJPEG] video will be transcoded to H264
  mjpeg: ffmpeg:http://185.97.122.128/cgi-bin/faststream.jpg#video=h264

  # [RTSP] video with rotation, should be transcoded, so select H264
  rotate: ffmpeg:rtsp://12345678@192.168.1.123/av_stream/ch0#video=h264#rotate=90
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;All transcoding formats have &lt;a href="https://github.com/AlexxIT/go2rtc/raw/master/internal/ffmpeg/ffmpeg.go"&gt;built-in templates&lt;/a&gt;: &lt;code&gt;h264&lt;/code&gt;, &lt;code&gt;h265&lt;/code&gt;, &lt;code&gt;opus&lt;/code&gt;, &lt;code&gt;pcmu&lt;/code&gt;, &lt;code&gt;pcmu/16000&lt;/code&gt;, &lt;code&gt;pcmu/48000&lt;/code&gt;, &lt;code&gt;pcma&lt;/code&gt;, &lt;code&gt;pcma/16000&lt;/code&gt;, &lt;code&gt;pcma/48000&lt;/code&gt;, &lt;code&gt;aac&lt;/code&gt;, &lt;code&gt;aac/16000&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;But you can override them via YAML config. You can also add your own formats to the config and use them with source params.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;ffmpeg:
  bin: ffmpeg  # path to ffmpeg binary
  global: "-hide_banner"
  timeout: 5  # default timeout in seconds for rtsp inputs
  h264: "-codec:v libx264 -g:v 30 -preset:v superfast -tune:v zerolatency -profile:v main -level:v 4.1"
  mycodec: "-any args that supported by ffmpeg..."
  myinput: "-fflags nobuffer -flags low_delay -timeout {timeout} -i {input}"
  myraw: "-ss 00:00:20"
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;You can use go2rtc stream name as ffmpeg input (ex. &lt;code&gt;ffmpeg:camera1#video=h264&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;You can use &lt;code&gt;video&lt;/code&gt; and &lt;code&gt;audio&lt;/code&gt; params multiple times (ex. &lt;code&gt;#video=copy#audio=copy#audio=pcmu&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;You can use &lt;code&gt;rotate&lt;/code&gt; param with &lt;code&gt;90&lt;/code&gt;, &lt;code&gt;180&lt;/code&gt;, &lt;code&gt;270&lt;/code&gt; or &lt;code&gt;-90&lt;/code&gt; values, important with transcoding (ex. &lt;code&gt;#video=h264#rotate=90&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;You can use &lt;code&gt;width&lt;/code&gt; and/or &lt;code&gt;height&lt;/code&gt; params, important with transcoding (ex. &lt;code&gt;#video=h264#width=1280&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;You can use &lt;code&gt;drawtext&lt;/code&gt; to add a timestamp (ex. &lt;code&gt;drawtext=x=2:y=2:fontsize=12:fontcolor=white:box=1:boxcolor=black&lt;/code&gt;) 
  &lt;ul&gt; 
   &lt;li&gt;This will greatly increase the CPU of the server, even with hardware acceleration&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;You can use &lt;code&gt;timeout&lt;/code&gt; param to set RTSP input timeout in seconds (ex. &lt;code&gt;#timeout=10&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;You can use &lt;code&gt;raw&lt;/code&gt; param for any additional FFmpeg arguments (ex. &lt;code&gt;#raw=-vf transpose=1&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;You can use &lt;code&gt;input&lt;/code&gt; param to override default input template (ex. &lt;code&gt;#input=rtsp/udp&lt;/code&gt; will change RTSP transport from TCP to UDP+TCP) 
  &lt;ul&gt; 
   &lt;li&gt;You can use raw input value (ex. &lt;code&gt;#input=-timeout {timeout} -i {input}&lt;/code&gt;)&lt;/li&gt; 
   &lt;li&gt;You can add your own input templates&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Read more about &lt;a href="https://github.com/AlexxIT/go2rtc/wiki/Hardware-acceleration"&gt;hardware acceleration&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;PS.&lt;/strong&gt; It is recommended to check the available hardware in the WebUI add page.&lt;/p&gt; 
&lt;h4&gt;Source: FFmpeg Device&lt;/h4&gt; 
&lt;p&gt;You can get video from any USB camera or Webcam as RTSP or WebRTC stream. This is part of FFmpeg integration.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;check available devices in web interface&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;video_size&lt;/code&gt; and &lt;code&gt;framerate&lt;/code&gt; must be supported by your camera!&lt;/li&gt; 
 &lt;li&gt;for Linux supported only video for now&lt;/li&gt; 
 &lt;li&gt;for macOS you can stream FaceTime camera or whole desktop!&lt;/li&gt; 
 &lt;li&gt;for macOS important to set right framerate&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Format: &lt;code&gt;ffmpeg:device?{input-params}#{param1}#{param2}#{param3}&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;streams:
  linux_usbcam:   ffmpeg:device?video=0&amp;amp;video_size=1280x720#video=h264
  windows_webcam: ffmpeg:device?video=0#video=h264
  macos_facetime: ffmpeg:device?video=0&amp;amp;audio=1&amp;amp;video_size=1280x720&amp;amp;framerate=30#video=h264#audio=pcma
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;PS.&lt;/strong&gt; It is recommended to check the available devices in the WebUI add page.&lt;/p&gt; 
&lt;h4&gt;Source: Exec&lt;/h4&gt; 
&lt;p&gt;Exec source can run any external application and expect data from it. Two transports are supported - &lt;strong&gt;pipe&lt;/strong&gt; (&lt;em&gt;from &lt;a href="https://github.com/AlexxIT/go2rtc/releases/tag/v1.5.0"&gt;v1.5.0&lt;/a&gt;&lt;/em&gt;) and &lt;strong&gt;RTSP&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;If you want to use &lt;strong&gt;RTSP&lt;/strong&gt; transport, the command must contain the &lt;code&gt;{output}&lt;/code&gt; argument in any place. On launch, it will be replaced by the local address of the RTSP server.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;pipe&lt;/strong&gt; reads data from app stdout in different formats: &lt;strong&gt;MJPEG&lt;/strong&gt;, &lt;strong&gt;H.264/H.265 bitstream&lt;/strong&gt;, &lt;strong&gt;MPEG-TS&lt;/strong&gt;. Also pipe can write data to app stdin in two formats: &lt;strong&gt;PCMA&lt;/strong&gt; and &lt;strong&gt;PCM/48000&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;The source can be used with:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://ffmpeg.org/"&gt;FFmpeg&lt;/a&gt; - go2rtc ffmpeg source just a shortcut to exec source&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ffmpeg.org/ffplay.html"&gt;FFplay&lt;/a&gt; - play audio on your server&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gstreamer.freedesktop.org/"&gt;GStreamer&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.raspberrypi.com/documentation/computers/camera_software.html"&gt;Raspberry Pi Cameras&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;any of your own software&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Pipe commands support parameters (format: &lt;code&gt;exec:{command}#{param1}#{param2}&lt;/code&gt;):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;killsignal&lt;/code&gt; - signal which will be sent to stop the process (numeric form)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;killtimeout&lt;/code&gt; - time in seconds for forced termination with sigkill&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;backchannel&lt;/code&gt; - enable backchannel for two-way audio&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;streams:
  stream: exec:ffmpeg -re -i /media/BigBuckBunny.mp4 -c copy -rtsp_transport tcp -f rtsp {output}
  picam_h264: exec:libcamera-vid -t 0 --inline -o -
  picam_mjpeg: exec:libcamera-vid -t 0 --codec mjpeg -o -
  pi5cam_h264: exec:libcamera-vid -t 0 --libav-format h264 -o -
  canon: exec:gphoto2 --capture-movie --stdout#killsignal=2#killtimeout=5
  play_pcma: exec:ffplay -fflags nobuffer -f alaw -ar 8000 -i -#backchannel=1
  play_pcm48k: exec:ffplay -fflags nobuffer -f s16be -ar 48000 -i -#backchannel=1
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Source: Echo&lt;/h4&gt; 
&lt;p&gt;Some sources may have a dynamic link. And you will need to get it using a Bash or Python script. Your script should echo a link to the source. RTSP, FFmpeg or any of the &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-streams"&gt;supported sources&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Docker&lt;/strong&gt; and &lt;strong&gt;Hass Add-on&lt;/strong&gt; users has preinstalled &lt;code&gt;python3&lt;/code&gt;, &lt;code&gt;curl&lt;/code&gt;, &lt;code&gt;jq&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Check examples in &lt;a href="https://github.com/AlexxIT/go2rtc/wiki/Source-Echo-examples"&gt;wiki&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;streams:
  apple_hls: echo:python3 hls.py https://developer.apple.com/streaming/examples/basic-stream-osx-ios5.html
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Source: Expr&lt;/h4&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href="https://github.com/AlexxIT/go2rtc/releases/tag/v1.8.2"&gt;New in v1.8.2&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;Like &lt;code&gt;echo&lt;/code&gt; source, but uses the built-in &lt;a href="https://github.com/antonmedv/expr"&gt;expr&lt;/a&gt; expression language (&lt;a href="https://github.com/AlexxIT/go2rtc/raw/master/internal/expr/README.md"&gt;read more&lt;/a&gt;).&lt;/p&gt; 
&lt;h4&gt;Source: HomeKit&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You can use HomeKit Cameras &lt;strong&gt;without Apple devices&lt;/strong&gt; (iPhone, iPad, etc.), it's just a yet another protocol&lt;/li&gt; 
 &lt;li&gt;HomeKit device can be paired with only one ecosystem. So, if you have paired it to an iPhone (Apple Home), you can't pair it with Home Assistant or go2rtc. Or if you have paired it to go2rtc, you can't pair it with an iPhone&lt;/li&gt; 
 &lt;li&gt;HomeKit device should be on the same network with working &lt;a href="https://en.wikipedia.org/wiki/Multicast_DNS"&gt;mDNS&lt;/a&gt; between the device and go2rtc&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;go2rtc supports importing paired HomeKit devices from &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-hass"&gt;Home Assistant&lt;/a&gt;. So you can use HomeKit camera with Hass and go2rtc simultaneously. If you are using Hass, I recommend pairing devices with it; it will give you more options.&lt;/p&gt; 
&lt;p&gt;You can pair device with go2rtc on the HomeKit page. If you can't see your devices, reload the page. Also, try rebooting your HomeKit device (power off). If you still can't see it, you have a problem with mDNS.&lt;/p&gt; 
&lt;p&gt;If you see a device but it does not have a pairing button, it is paired to some ecosystem (Apple Home, Home Assistant, HomeBridge etc). You need to delete the device from that ecosystem, and it will be available for pairing. If you cannot unpair the device, you will have to reset it.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;HomeKit audio uses very non-standard &lt;strong&gt;AAC-ELD&lt;/strong&gt; codec with very non-standard params and specification violations&lt;/li&gt; 
 &lt;li&gt;Audio can't be played in &lt;code&gt;VLC&lt;/code&gt; and probably any other player&lt;/li&gt; 
 &lt;li&gt;Audio should be transcoded for use with MSE, WebRTC, etc.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Recommended settings for using HomeKit Camera with WebRTC, MSE, MP4, RTSP:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;streams:
  aqara_g3:
    - hass:Camera-Hub-G3-AB12
    - ffmpeg:aqara_g3#audio=aac#audio=opus
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;RTSP link with "normal" audio for any player: &lt;code&gt;rtsp://192.168.1.123:8554/aqara_g3?video&amp;amp;audio=aac&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;This source is in active development!&lt;/strong&gt; Tested only with &lt;a href="https://www.aqara.com/eu/product/camera-hub-g3"&gt;Aqara Camera Hub G3&lt;/a&gt; (both EU and CN versions).&lt;/p&gt; 
&lt;h4&gt;Source: Bubble&lt;/h4&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href="https://github.com/AlexxIT/go2rtc/releases/tag/v1.6.1"&gt;New in v1.6.1&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;Other names: &lt;a href="http://www.eseecloud.com/"&gt;ESeeCloud&lt;/a&gt;, &lt;a href="http://help.dvr163.com/"&gt;dvr163&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;you can skip &lt;code&gt;username&lt;/code&gt;, &lt;code&gt;password&lt;/code&gt;, &lt;code&gt;port&lt;/code&gt;, &lt;code&gt;ch&lt;/code&gt; and &lt;code&gt;stream&lt;/code&gt; if they are default&lt;/li&gt; 
 &lt;li&gt;set up separate streams for different channels and streams&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;streams:
  camera1: bubble://username:password@192.168.1.123:34567/bubble/live?ch=0&amp;amp;stream=0
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Source: DVRIP&lt;/h4&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href="https://github.com/AlexxIT/go2rtc/releases/tag/v1.2.0"&gt;New in v1.2.0&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;Other names: DVR-IP, NetSurveillance, Sofia protocol (NETsurveillance ActiveX plugin XMeye SDK).&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;you can skip &lt;code&gt;username&lt;/code&gt;, &lt;code&gt;password&lt;/code&gt;, &lt;code&gt;port&lt;/code&gt;, &lt;code&gt;channel&lt;/code&gt; and &lt;code&gt;subtype&lt;/code&gt; if they are default&lt;/li&gt; 
 &lt;li&gt;set up separate streams for different channels&lt;/li&gt; 
 &lt;li&gt;use &lt;code&gt;subtype=0&lt;/code&gt; for Main stream, and &lt;code&gt;subtype=1&lt;/code&gt; for Extra1 stream&lt;/li&gt; 
 &lt;li&gt;only the TCP protocol is supported&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;streams:
  only_stream: dvrip://username:password@192.168.1.123:34567?channel=0&amp;amp;subtype=0
  only_tts: dvrip://username:password@192.168.1.123:34567?backchannel=1
  two_way_audio:
    - dvrip://username:password@192.168.1.123:34567?channel=0&amp;amp;subtype=0
    - dvrip://username:password@192.168.1.123:34567?backchannel=1
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Source: EseeCloud&lt;/h4&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href="https://github.com/AlexxIT/go2rtc/releases/tag/v1.9.10"&gt;New in v1.9.10&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;streams:
  camera1: eseecloud://user:pass@192.168.1.123:80/livestream/12
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Source: Tapo&lt;/h4&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href="https://github.com/AlexxIT/go2rtc/releases/tag/v1.2.0"&gt;New in v1.2.0&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.tapo.com/"&gt;TP-Link Tapo&lt;/a&gt; proprietary camera protocol with &lt;strong&gt;two way audio&lt;/strong&gt; support.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;stream quality is the same as &lt;a href="https://www.tapo.com/en/faq/34/"&gt;RTSP protocol&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;use the &lt;strong&gt;cloud password&lt;/strong&gt;, this is not the RTSP password! you do not need to add a login!&lt;/li&gt; 
 &lt;li&gt;you can also use &lt;strong&gt;UPPERCASE&lt;/strong&gt; MD5 hash from your cloud password with &lt;code&gt;admin&lt;/code&gt; username&lt;/li&gt; 
 &lt;li&gt;some new camera firmwares require SHA256 instead of MD5&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;streams:
  # cloud password without username
  camera1: tapo://cloud-password@192.168.1.123
  # admin username and UPPERCASE MD5 cloud-password hash
  camera2: tapo://admin:UPPERCASE-MD5@192.168.1.123
  # admin username and UPPERCASE SHA256 cloud-password hash
  camera3: tapo://admin:UPPERCASE-SHA256@192.168.1.123
  # VGA stream (the so called substream, the lower resolution one)
  camera4: tapo://cloud-password@192.168.1.123?subtype=1 
  # HD stream (default)
  camera5: tapo://cloud-password@192.168.1.123?subtype=0 
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;echo -n "cloud password" | md5 | awk '{print toupper($0)}'
echo -n "cloud password" | shasum -a 256 | awk '{print toupper($0)}'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Source: Kasa&lt;/h4&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href="https://github.com/AlexxIT/go2rtc/releases/tag/v1.7.0"&gt;New in v1.7.0&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.kasasmart.com/"&gt;TP-Link Kasa&lt;/a&gt; non-standard protocol &lt;a href="https://medium.com/@hu3vjeen/reverse-engineering-tp-link-kc100-bac4641bf1cd"&gt;more info&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;username&lt;/code&gt; - urlsafe email, &lt;code&gt;alex@gmail.com&lt;/code&gt; -&amp;gt; &lt;code&gt;alex%40gmail.com&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;password&lt;/code&gt; - base64password, &lt;code&gt;secret1&lt;/code&gt; -&amp;gt; &lt;code&gt;c2VjcmV0MQ==&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;streams:
  kc401: kasa://username:password@192.168.1.123:19443/https/stream/mixed
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Tested: KD110, KC200, KC401, KC420WS, EC71.&lt;/p&gt; 
&lt;h4&gt;Source: Tuya&lt;/h4&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href="https://github.com/AlexxIT/go2rtc/releases/tag/v1.9.13"&gt;New in v1.9.13&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.tuya.com/"&gt;Tuya&lt;/a&gt; proprietary camera protocol with &lt;strong&gt;two way audio&lt;/strong&gt; support. Go2rtc supports &lt;code&gt;Tuya Smart API&lt;/code&gt; and &lt;code&gt;Tuya Cloud API&lt;/code&gt;. &lt;a href="https://github.com/AlexxIT/go2rtc/raw/master/internal/tuya/README.md"&gt;Read more&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Source: Xiaomi&lt;/h4&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href="https://github.com/AlexxIT/go2rtc/releases/tag/v1.9.13"&gt;New in v1.9.13&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;This source allows you to view cameras from the &lt;a href="https://home.mi.com/"&gt;Xiaomi Mi Home&lt;/a&gt; ecosystem. &lt;a href="https://github.com/AlexxIT/go2rtc/raw/master/internal/xiaomi/README.md"&gt;Read more&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Source: GoPro&lt;/h4&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href="https://github.com/AlexxIT/go2rtc/releases/tag/v1.8.3"&gt;New in v1.8.3&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;Support streaming from &lt;a href="https://gopro.com/"&gt;GoPro&lt;/a&gt; cameras, connected via USB or Wi-Fi to Linux, Mac, Windows. &lt;a href="https://github.com/AlexxIT/go2rtc/tree/master/internal/gopro"&gt;Read more&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Source: Ivideon&lt;/h4&gt; 
&lt;p&gt;Support public cameras from the service &lt;a href="https://tv.ivideon.com/"&gt;Ivideon&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;streams:
  quailcam: ivideon:100-tu5dkUPct39cTp9oNEN2B6/0
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Source: Hass&lt;/h4&gt; 
&lt;p&gt;Support import camera links from &lt;a href="https://www.home-assistant.io/"&gt;Home Assistant&lt;/a&gt; config files:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.home-assistant.io/integrations/generic/"&gt;Generic Camera&lt;/a&gt;, setup via GUI&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.home-assistant.io/integrations/homekit_controller/"&gt;HomeKit Camera&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.home-assistant.io/integrations/onvif/"&gt;ONVIF&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/humbertogontijo/homeassistant-roborock"&gt;Roborock&lt;/a&gt; vacuums with camera&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;hass:
  config: "/config"  # skip this setting if you Hass add-on user

streams:
  generic_camera: hass:Camera1  # Settings &amp;gt; Integrations &amp;gt; Integration Name
  aqara_g3: hass:Camera-Hub-G3-AB12
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;WebRTC Cameras&lt;/strong&gt; (&lt;em&gt;from &lt;a href="https://github.com/AlexxIT/go2rtc/releases/tag/v1.6.0"&gt;v1.6.0&lt;/a&gt;&lt;/em&gt;)&lt;/p&gt; 
&lt;p&gt;Any cameras in WebRTC format are supported. But at the moment Home Assistant only supports some &lt;a href="https://www.home-assistant.io/integrations/nest/"&gt;Nest&lt;/a&gt; cameras in this format.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Important.&lt;/strong&gt; The Nest API only allows you to get a link to a stream for 5 minutes. Do not use this with Frigate! If the stream expires, Frigate will consume all available RAM on your machine within seconds. It's recommended to use &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-nest"&gt;Nest source&lt;/a&gt; - it supports extending the stream.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;streams:
  # link to Home Assistant Supervised
  hass-webrtc1: hass://supervisor?entity_id=camera.nest_doorbell
  # link to external Hass with Long-Lived Access Tokens
  hass-webrtc2: hass://192.168.1.123:8123?entity_id=camera.nest_doorbell&amp;amp;token=eyXYZ...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;RTSP Cameras&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;By default, the Home Assistant API does not allow you to get a dynamic RTSP link to a camera stream. So more cameras, like &lt;a href="https://www.home-assistant.io/integrations/tuya/"&gt;Tuya&lt;/a&gt;, and possibly others, can also be imported using &lt;a href="https://github.com/felipecrs/hass-expose-camera-stream-source#importing-home-assistant-cameras-to-go2rtc-andor-frigate"&gt;this method&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Source: ISAPI&lt;/h4&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href="https://github.com/AlexxIT/go2rtc/releases/tag/v1.3.0"&gt;New in v1.3.0&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;This source type supports only backchannel audio for the Hikvision ISAPI protocol. So it should be used as a second source in addition to the RTSP protocol.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;streams:
  hikvision1:
    - rtsp://admin:password@192.168.1.123:554/Streaming/Channels/101
    - isapi://admin:password@192.168.1.123:80/
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Source: Nest&lt;/h4&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href="https://github.com/AlexxIT/go2rtc/releases/tag/v1.6.0"&gt;New in v1.6.0&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;Currently, only WebRTC cameras are supported.&lt;/p&gt; 
&lt;p&gt;For simplicity, it is recommended to connect the Nest/WebRTC camera to the &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-hass"&gt;Home Assistant&lt;/a&gt;. But if you can somehow get the below parameters, Nest/WebRTC source will work without Hass.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;streams:
  nest-doorbell: nest:?client_id=***&amp;amp;client_secret=***&amp;amp;refresh_token=***&amp;amp;project_id=***&amp;amp;device_id=***
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Source: Ring&lt;/h4&gt; 
&lt;p&gt;This source type support Ring cameras with &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#two-way-audio"&gt;two way audio&lt;/a&gt; support. If you have a &lt;code&gt;refresh_token&lt;/code&gt; and &lt;code&gt;device_id&lt;/code&gt; - you can use it in &lt;code&gt;go2rtc.yaml&lt;/code&gt; config file. Otherwise, you can use the go2rtc interface and add your ring account (WebUI &amp;gt; Add &amp;gt; Ring). Once added, it will list all your Ring cameras.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;streams:
  ring: ring:?device_id=XXX&amp;amp;refresh_token=XXX
  ring_snapshot: ring:?device_id=XXX&amp;amp;refresh_token=XXX&amp;amp;snapshot
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Source: Roborock&lt;/h4&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href="https://github.com/AlexxIT/go2rtc/releases/tag/v1.3.0"&gt;New in v1.3.0&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;This source type supports Roborock vacuums with cameras. Known working models:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Roborock S6 MaxV - only video (the vacuum has no microphone)&lt;/li&gt; 
 &lt;li&gt;Roborock S7 MaxV - video and two-way audio&lt;/li&gt; 
 &lt;li&gt;Roborock Qrevo MaxV - video and two-way audio&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Source supports loading Roborock credentials from Home Assistant &lt;a href="https://github.com/humbertogontijo/homeassistant-roborock"&gt;custom integration&lt;/a&gt; or the &lt;a href="https://www.home-assistant.io/integrations/roborock"&gt;core integration&lt;/a&gt;. Otherwise, you need to log in to your Roborock account (MiHome account is not supported). Go to: go2rtc WebUI &amp;gt; Add webpage. Copy &lt;code&gt;roborock://...&lt;/code&gt; source for your vacuum and paste it to &lt;code&gt;go2rtc.yaml&lt;/code&gt; config.&lt;/p&gt; 
&lt;p&gt;If you have a graphic PIN for your vacuum, add it as a numeric PIN (lines: 123, 456, 789) to the end of the &lt;code&gt;roborock&lt;/code&gt; link.&lt;/p&gt; 
&lt;h4&gt;Source: Doorbird&lt;/h4&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href="https://github.com/AlexxIT/go2rtc/releases/tag/v1.9.11"&gt;New in v1.9.11&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;This source type supports Doorbird devices including MJPEG stream, audio stream as well as two-way audio.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;streams:
  doorbird1:
    - rtsp://admin:password@192.168.1.123:8557/mpeg/720p/media.amp  # RTSP stream
    - doorbird://admin:password@192.168.1.123?media=video           # MJPEG stream
    - doorbird://admin:password@192.168.1.123?media=audio           # audio stream
    - doorbird://admin:password@192.168.1.123                       # two-way audio
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Source: WebRTC&lt;/h4&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href="https://github.com/AlexxIT/go2rtc/releases/tag/v1.3.0"&gt;New in v1.3.0&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;This source type supports four connection formats.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;whep&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://datatracker.ietf.org/doc/draft-murillo-whep/"&gt;WebRTC/WHEP&lt;/a&gt; is replaced by &lt;a href="https://datatracker.ietf.org/doc/charter-ietf-wish/02/"&gt;WebRTC/WISH&lt;/a&gt; standard for WebRTC video/audio viewers. But it may already be supported in some third-party software. It is supported in go2rtc.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;go2rtc&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;This format is only supported in go2rtc. Unlike WHEP, it supports asynchronous WebRTC connections and two-way audio.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;openipc&lt;/strong&gt; (&lt;em&gt;from &lt;a href="https://github.com/AlexxIT/go2rtc/releases/tag/v1.7.0"&gt;v1.7.0&lt;/a&gt;&lt;/em&gt;)&lt;/p&gt; 
&lt;p&gt;Support connection to &lt;a href="https://openipc.org/"&gt;OpenIPC&lt;/a&gt; cameras.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;wyze&lt;/strong&gt; (&lt;em&gt;from &lt;a href="https://github.com/AlexxIT/go2rtc/releases/tag/v1.6.1"&gt;v1.6.1&lt;/a&gt;&lt;/em&gt;)&lt;/p&gt; 
&lt;p&gt;Supports connection to &lt;a href="https://www.wyze.com/"&gt;Wyze&lt;/a&gt; cameras, using WebRTC protocol. You can use the &lt;a href="https://github.com/mrlt8/docker-wyze-bridge"&gt;docker-wyze-bridge&lt;/a&gt; project to get connection credentials.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;kinesis&lt;/strong&gt; (&lt;em&gt;from &lt;a href="https://github.com/AlexxIT/go2rtc/releases/tag/v1.6.1"&gt;v1.6.1&lt;/a&gt;&lt;/em&gt;)&lt;/p&gt; 
&lt;p&gt;Supports &lt;a href="https://aws.amazon.com/kinesis/video-streams/"&gt;Amazon Kinesis Video Streams&lt;/a&gt;, using WebRTC protocol. You need to specify the signalling WebSocket URL with all credentials in query params, &lt;code&gt;client_id&lt;/code&gt; and &lt;code&gt;ice_servers&lt;/code&gt; list in &lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/RTCIceServer"&gt;JSON format&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;switchbot&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Support connection to &lt;a href="https://us.switch-bot.com/"&gt;SwitchBot&lt;/a&gt; cameras that are based on Kinesis Video Streams. Specifically, this includes &lt;a href="https://us.switch-bot.com/pages/switchbot-pan-tilt-cam-plus-2k"&gt;Pan/Tilt Cam Plus 2K&lt;/a&gt; and &lt;a href="https://us.switch-bot.com/pages/switchbot-pan-tilt-cam-plus-3k"&gt;Pan/Tilt Cam Plus 3K&lt;/a&gt; and &lt;a href="https://www.switchbot.jp/products/switchbot-smart-video-doorbell"&gt;Smart Video Doorbell&lt;/a&gt;. &lt;code&gt;Outdoor Spotlight Cam 1080P&lt;/code&gt;, &lt;code&gt;Outdoor Spotlight Cam 2K&lt;/code&gt;, &lt;code&gt;Pan/Tilt Cam&lt;/code&gt;, &lt;code&gt;Pan/Tilt Cam 2K&lt;/code&gt;, &lt;code&gt;Indoor Cam&lt;/code&gt; are based on Tuya, so this feature is not available.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;streams:
  webrtc-whep:      webrtc:http://192.168.1.123:1984/api/webrtc?src=camera1
  webrtc-go2rtc:    webrtc:ws://192.168.1.123:1984/api/ws?src=camera1
  webrtc-openipc:   webrtc:ws://192.168.1.123/webrtc_ws#format=openipc#ice_servers=[{"urls":"stun:stun.kinesisvideo.eu-north-1.amazonaws.com:443"}]
  webrtc-wyze:      webrtc:http://192.168.1.123:5000/signaling/camera1?kvs#format=wyze
  webrtc-kinesis:   webrtc:wss://...amazonaws.com/?...#format=kinesis#client_id=...#ice_servers=[{...},{...}]
  webrtc-switchbot: webrtc:wss://...amazonaws.com/?...#format=switchbot#resolution=hd#play_type=0#client_id=...#ice_servers=[{...},{...}]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;PS.&lt;/strong&gt; For &lt;code&gt;kinesis&lt;/code&gt; sources, you can use &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-echo"&gt;echo&lt;/a&gt; to get connection params using &lt;code&gt;bash&lt;/code&gt;, &lt;code&gt;python&lt;/code&gt; or any other script language.&lt;/p&gt; 
&lt;h4&gt;Source: WebTorrent&lt;/h4&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href="https://github.com/AlexxIT/go2rtc/releases/tag/v1.3.0"&gt;New in v1.3.0&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;This source can get a stream from another go2rtc via &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-webtorrent"&gt;WebTorrent&lt;/a&gt; protocol.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;streams:
  webtorrent1: webtorrent:?share=huofssuxaty00izc&amp;amp;pwd=k3l2j9djeg8v8r7e
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Incoming sources&lt;/h4&gt; 
&lt;p&gt;By default, go2rtc establishes a connection to the source when any client requests it. Go2rtc drops the connection to the source when it has no clients left.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Go2rtc also can accepts incoming sources in &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-rtsp"&gt;RTSP&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-rtmp"&gt;RTMP&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-http"&gt;HTTP&lt;/a&gt; and &lt;strong&gt;WebRTC/WHIP&lt;/strong&gt; formats&lt;/li&gt; 
 &lt;li&gt;Go2rtc won't stop such a source if it has no clients&lt;/li&gt; 
 &lt;li&gt;You can push data only to an existing stream (create a stream with empty source in config)&lt;/li&gt; 
 &lt;li&gt;You can push multiple incoming sources to the same stream&lt;/li&gt; 
 &lt;li&gt;You can push data to a non-empty stream, so it will have additional codecs inside&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Examples&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;RTSP with any codec &lt;pre&gt;&lt;code class="language-yaml"&gt;ffmpeg -re -i BigBuckBunny.mp4 -c copy -rtsp_transport tcp -f rtsp rtsp://localhost:8554/camera1
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;HTTP-MJPEG with MJPEG codec &lt;pre&gt;&lt;code class="language-yaml"&gt;ffmpeg -re -i BigBuckBunny.mp4 -c mjpeg -f mpjpeg http://localhost:1984/api/stream.mjpeg?dst=camera1
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;HTTP-FLV with H264, AAC codecs &lt;pre&gt;&lt;code class="language-yaml"&gt;ffmpeg -re -i BigBuckBunny.mp4 -c copy -f flv http://localhost:1984/api/stream.flv?dst=camera1
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;MPEG-TS with H264 codec &lt;pre&gt;&lt;code class="language-yaml"&gt;ffmpeg -re -i BigBuckBunny.mp4 -c copy -f mpegts http://localhost:1984/api/stream.ts?dst=camera1
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Incoming: Browser&lt;/h4&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href="https://github.com/AlexxIT/go2rtc/releases/tag/v1.3.0"&gt;New in v1.3.0&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;You can turn the browser of any PC or mobile into an IP camera with support for video and two-way audio. Or even broadcast your PC screen:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Create empty stream in the &lt;code&gt;go2rtc.yaml&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Go to go2rtc WebUI&lt;/li&gt; 
 &lt;li&gt;Open &lt;code&gt;links&lt;/code&gt; page for your stream&lt;/li&gt; 
 &lt;li&gt;Select &lt;code&gt;camera+microphone&lt;/code&gt; or &lt;code&gt;display+speaker&lt;/code&gt; option&lt;/li&gt; 
 &lt;li&gt;Open &lt;code&gt;webrtc&lt;/code&gt; local page (your go2rtc &lt;strong&gt;should work over HTTPS!&lt;/strong&gt;) or &lt;code&gt;share link&lt;/code&gt; via &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-webtorrent"&gt;WebTorrent&lt;/a&gt; technology (work over HTTPS by default)&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Incoming: WebRTC/WHIP&lt;/h4&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href="https://github.com/AlexxIT/go2rtc/releases/tag/v1.3.0"&gt;New in v1.3.0&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;You can use &lt;strong&gt;OBS Studio&lt;/strong&gt; or any other broadcast software with &lt;a href="https://www.ietf.org/archive/id/draft-ietf-wish-whip-01.html"&gt;WHIP&lt;/a&gt; protocol support. This standard has not yet been approved. But you can download OBS Studio &lt;a href="https://github.com/obsproject/obs-studio/actions/runs/3969201209"&gt;dev version&lt;/a&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Settings &amp;gt; Stream &amp;gt; Service: WHIP &amp;gt; &lt;a href="http://192.168.1.123:1984/api/webrtc?dst=camera1"&gt;http://192.168.1.123:1984/api/webrtc?dst=camera1&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Stream to camera&lt;/h4&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href="https://github.com/AlexxIT/go2rtc/releases/tag/v1.3.0"&gt;New in v1.3.0&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;go2rtc supports playing audio files (ex. music or &lt;a href="https://www.home-assistant.io/integrations/#text-to-speech"&gt;TTS&lt;/a&gt;) and live streams (ex. radio) on cameras with &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#two-way-audio"&gt;two-way audio&lt;/a&gt; support (RTSP/ONVIF cameras, TP-Link Tapo, Hikvision ISAPI, Roborock vacuums, any Browser).&lt;/p&gt; 
&lt;p&gt;API example:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;POST http://localhost:1984/api/streams?dst=camera1&amp;amp;src=ffmpeg:http://example.com/song.mp3#audio=pcma#input=file
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;you can stream: local files, web files, live streams or any format, supported by FFmpeg&lt;/li&gt; 
 &lt;li&gt;you should use &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-ffmpeg"&gt;ffmpeg source&lt;/a&gt; for transcoding audio to codec, that your camera supports&lt;/li&gt; 
 &lt;li&gt;you can check camera codecs on the go2rtc WebUI info page when the stream is active&lt;/li&gt; 
 &lt;li&gt;some cameras support only low quality &lt;code&gt;PCMA/8000&lt;/code&gt; codec (ex. &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-tapo"&gt;Tapo&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;it is recommended to choose higher quality formats if your camera supports them (ex. &lt;code&gt;PCMA/48000&lt;/code&gt; for some Dahua cameras)&lt;/li&gt; 
 &lt;li&gt;if you play files over &lt;code&gt;http&lt;/code&gt; link, you need to add &lt;code&gt;#input=file&lt;/code&gt; params for transcoding, so the file will be transcoded and played in real time&lt;/li&gt; 
 &lt;li&gt;if you play live streams, you should skip &lt;code&gt;#input&lt;/code&gt; param, because it is already in real time&lt;/li&gt; 
 &lt;li&gt;you can stop active playback by calling the API with the empty &lt;code&gt;src&lt;/code&gt; parameter&lt;/li&gt; 
 &lt;li&gt;you will see one active producer and one active consumer in go2rtc WebUI info page during streaming&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Publish stream&lt;/h3&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href="https://github.com/AlexxIT/go2rtc/releases/tag/v1.8.0"&gt;New in v1.8.0&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;You can publish any stream to streaming services (YouTube, Telegram, etc.) via RTMP/RTMPS. Important:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Supported codecs: H264 for video and AAC for audio&lt;/li&gt; 
 &lt;li&gt;AAC audio is required for YouTube; videos without audio will not work&lt;/li&gt; 
 &lt;li&gt;You don't need to enable &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-rtmp"&gt;RTMP module&lt;/a&gt; listening for this task&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You can use the API:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;POST http://localhost:1984/api/streams?src=camera1&amp;amp;dst=rtmps://...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or config file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;publish:
  # publish stream "video_audio_transcode" to Telegram
  video_audio_transcode:
    - rtmps://xxx-x.rtmp.t.me/s/xxxxxxxxxx:xxxxxxxxxxxxxxxxxxxxxx
  # publish stream "audio_transcode" to Telegram and YouTube
  audio_transcode:
    - rtmps://xxx-x.rtmp.t.me/s/xxxxxxxxxx:xxxxxxxxxxxxxxxxxxxxxx
    - rtmp://xxx.rtmp.youtube.com/live2/xxxx-xxxx-xxxx-xxxx-xxxx

streams:
  video_audio_transcode:
    - ffmpeg:rtsp://user:pass@192.168.1.123/stream1#video=h264#hardware#audio=aac
  audio_transcode:
    - ffmpeg:rtsp://user:pass@192.168.1.123/stream1#video=copy#audio=aac
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Telegram Desktop App&lt;/strong&gt; &amp;gt; Any public or private channel or group (where you admin) &amp;gt; Live stream &amp;gt; Start with... &amp;gt; Start streaming.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;YouTube&lt;/strong&gt; &amp;gt; Create &amp;gt; Go live &amp;gt; Stream latency: Ultra low-latency &amp;gt; Copy: Stream URL + Stream key.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Preload stream&lt;/h3&gt; 
&lt;p&gt;You can preload any stream on go2rtc start. This is useful for cameras that take a long time to start up.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;preload:
  camera1:                                     # default: video&amp;amp;audio = ANY
  camera2: "video"                             # preload only video track
  camera3: "video=h264&amp;amp;audio=opus"             # preload H264 video and OPUS audio

streams:
  camera1: 
    - rtsp://192.168.1.100/stream
  camera2: 
    - rtsp://192.168.1.101/stream  
  camera3: 
    - rtsp://192.168.1.102/h265stream
    - ffmpeg:camera3#video=h264#audio=opus#hardware
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Module: API&lt;/h3&gt; 
&lt;p&gt;The HTTP API is the main part for interacting with the application. Default address: &lt;code&gt;http://localhost:1984/&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Important!&lt;/strong&gt; go2rtc passes requests from localhost and from Unix sockets without HTTP authorisation, even if you have it configured! It is your responsibility to set up secure external access to the API. If not properly configured, an attacker can gain access to your cameras and even your server.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/AlexxIT/go2rtc/tree/master/api"&gt;API description&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Module config&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;you can disable HTTP API with &lt;code&gt;listen: ""&lt;/code&gt; and use, for example, only RTSP client/server protocol&lt;/li&gt; 
 &lt;li&gt;you can enable HTTP API only on localhost with &lt;code&gt;listen: "127.0.0.1:1984"&lt;/code&gt; setting&lt;/li&gt; 
 &lt;li&gt;you can change the API &lt;code&gt;base_path&lt;/code&gt; and host go2rtc on your main app webserver suburl&lt;/li&gt; 
 &lt;li&gt;all files from &lt;code&gt;static_dir&lt;/code&gt; hosted on root path: &lt;code&gt;/&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;you can use raw TLS cert/key content or path to files&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;api:
  listen: ":1984"    # default ":1984", HTTP API port ("" - disabled)
  username: "admin"  # default "", Basic auth for WebUI
  password: "pass"   # default "", Basic auth for WebUI
  local_auth: true   # default false, Enable auth check for localhost requests
  base_path: "/rtc"  # default "", API prefix for serving on suburl (/api =&amp;gt; /rtc/api)
  static_dir: "www"  # default "", folder for static files (custom web interface)
  origin: "*"        # default "", allow CORS requests (only * supported)
  tls_listen: ":443" # default "", enable HTTPS server
  tls_cert: |        # default "", PEM-encoded fullchain certificate for HTTPS
    -----BEGIN CERTIFICATE-----
    ...
    -----END CERTIFICATE-----
  tls_key: |         # default "", PEM-encoded private key for HTTPS
    -----BEGIN PRIVATE KEY-----
    ...
    -----END PRIVATE KEY-----
  unix_listen: "/tmp/go2rtc.sock"  # default "", unix socket listener for API
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;PS:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;MJPEG over WebSocket plays better than native MJPEG because Chrome &lt;a href="https://bugs.chromium.org/p/chromium/issues/detail?id=527446"&gt;bug&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;MP4 over WebSocket was created only for Apple iOS because it doesn't support MSE and native MP4&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Module: RTSP&lt;/h3&gt; 
&lt;p&gt;You can get any stream as RTSP-stream: &lt;code&gt;rtsp://192.168.1.123:8554/{stream_name}&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;You can enable external password protection for your RTSP streams. Password protection is always disabled for localhost calls (ex. FFmpeg or Hass on the same server).&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;rtsp:
  listen: ":8554"    # RTSP Server TCP port, default - 8554
  username: "admin"  # optional, default - disabled
  password: "pass"   # optional, default - disabled
  default_query: "video&amp;amp;audio"  # optional, default codecs filters 
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;By default go2rtc provide RTSP-stream with only one first video and only one first audio. You can change it with the &lt;code&gt;default_query&lt;/code&gt; setting:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;default_query: "mp4"&lt;/code&gt; - MP4 compatible codecs (H264, H265, AAC)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;default_query: "video=all&amp;amp;audio=all"&lt;/code&gt; - all tracks from all source (not all players can handle this)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;default_query: "video=h264,h265"&lt;/code&gt; - only one video track (H264 or H265)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;default_query: "video&amp;amp;audio=all"&lt;/code&gt; - only one first any video and all audio as separate tracks&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Read more about &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#codecs-filters"&gt;codecs filters&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Module: RTMP&lt;/h3&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href="https://github.com/AlexxIT/go2rtc/releases/tag/v1.8.0"&gt;New in v1.8.0&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;You can get any stream as RTMP-stream: &lt;code&gt;rtmp://192.168.1.123/{stream_name}&lt;/code&gt;. Only H264/AAC codecs supported right now.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#incoming-sources"&gt;Incoming stream&lt;/a&gt; in RTMP format tested only with &lt;a href="https://obsproject.com/"&gt;OBS Studio&lt;/a&gt; and a Dahua camera. Different FFmpeg versions have different problems with this format.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;rtmp:
  listen: ":1935"  # by default - disabled!
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Module: WebRTC&lt;/h3&gt; 
&lt;p&gt;In most cases, &lt;a href="https://en.wikipedia.org/wiki/WebRTC"&gt;WebRTC&lt;/a&gt; uses a direct peer-to-peer connection from your browser to go2rtc and sends media data via UDP. It &lt;strong&gt;can't pass&lt;/strong&gt; media data through your Nginx or Cloudflare or &lt;a href="https://www.nabucasa.com/"&gt;Nabu Casa&lt;/a&gt; HTTP TCP connection! It can automatically detect your external IP via a public &lt;a href="https://en.wikipedia.org/wiki/STUN"&gt;STUN&lt;/a&gt; server. It can establish an external direct connection via &lt;a href="https://en.wikipedia.org/wiki/UDP_hole_punching"&gt;UDP hole punching&lt;/a&gt; technology even if you do not open your server to the World.&lt;/p&gt; 
&lt;p&gt;But about 10-20% of users may need to configure additional settings for external access if &lt;strong&gt;mobile phone&lt;/strong&gt; or &lt;strong&gt;go2rtc server&lt;/strong&gt; is behind &lt;a href="https://tomchen.github.io/symmetric-nat-test/"&gt;Symmetric NAT&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;by default, WebRTC uses both TCP and UDP on port 8555 for connections&lt;/li&gt; 
 &lt;li&gt;you can use this port for external access&lt;/li&gt; 
 &lt;li&gt;you can change the port in YAML config:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;webrtc:
  listen: ":8555"  # address of your local server and port (TCP/UDP)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Static public IP&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;forward the port 8555 on your router (you can use the same 8555 port or any other as external port)&lt;/li&gt; 
 &lt;li&gt;add your external IP address and external port to the YAML config&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;webrtc:
  candidates:
    - 216.58.210.174:8555  # if you have a static public IP address
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Dynamic public IP&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;forward the port 8555 on your router (you can use the same 8555 port or any other as the external port)&lt;/li&gt; 
 &lt;li&gt;add &lt;code&gt;stun&lt;/code&gt; word and external port to YAML config 
  &lt;ul&gt; 
   &lt;li&gt;go2rtc automatically detects your external address with STUN server&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;webrtc:
  candidates:
    - stun:8555  # if you have a dynamic public IP address
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Hard tech way 1. Own TCP-tunnel&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;If you have a personal &lt;a href="https://en.wikipedia.org/wiki/Virtual_private_server"&gt;VPS&lt;/a&gt;, you can create a TCP tunnel and setup in the same way as "Static public IP". But use your VPS IP address in the YAML config.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Hard tech way 2. Using TURN-server&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;If you have personal &lt;a href="https://en.wikipedia.org/wiki/Virtual_private_server"&gt;VPS&lt;/a&gt;, you can install TURN server (e.g. &lt;a href="https://github.com/coturn/coturn"&gt;coturn&lt;/a&gt;, config &lt;a href="https://github.com/AlexxIT/WebRTC/wiki/Coturn-Example"&gt;example&lt;/a&gt;).&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;webrtc:
  ice_servers:
    - urls: [stun:stun.l.google.com:19302]
    - urls: [turn:123.123.123.123:3478]
      username: your_user
      credential: your_pass
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Module: HomeKit&lt;/h3&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href="https://github.com/AlexxIT/go2rtc/releases/tag/v1.7.0"&gt;New in v1.7.0&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;HomeKit module can work in two modes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;export any H264 camera to Apple HomeKit&lt;/li&gt; 
 &lt;li&gt;transparent proxy any Apple HomeKit camera (Aqara, Eve, Eufy, etc.) back to Apple HomeKit, so you will have all camera features in Apple Home and also will have RTSP/WebRTC/MP4/etc. from your HomeKit camera&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;HomeKit cameras support only H264 video and OPUS audio&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Minimal config&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;streams:
  dahua1: rtsp://admin:password@192.168.1.123/cam/realmonitor?channel=1&amp;amp;subtype=0
homekit:
  dahua1:  # same stream ID from streams list, default PIN - 19550224
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Full config&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;streams:
  dahua1:
    - rtsp://admin:password@192.168.1.123/cam/realmonitor?channel=1&amp;amp;subtype=0
    - ffmpeg:dahua1#video=h264#hardware  # if your camera doesn't support H264, important for HomeKit
    - ffmpeg:dahua1#audio=opus           # only OPUS audio supported by HomeKit

homekit:
  dahua1:                   # same stream ID from streams list
    pin: 12345678           # custom PIN, default: 19550224
    name: Dahua camera      # custom camera name, default: generated from stream ID
    device_id: dahua1       # custom ID, default: generated from stream ID
    device_private: dahua1  # custom key, default: generated from stream ID
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Proxy HomeKit camera&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Video stream from HomeKit camera to Apple device (iPhone, AppleTV) will be transmitted directly&lt;/li&gt; 
 &lt;li&gt;Video stream from HomeKit camera to RTSP/WebRTC/MP4/etc. will be transmitted via go2rtc&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;streams:
  aqara1:
    - homekit://...
    - ffmpeg:aqara1#audio=aac#audio=opus  # optional audio transcoding

homekit:
  aqara1:  # same stream ID from streams list
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Module: WebTorrent&lt;/h3&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href="https://github.com/AlexxIT/go2rtc/releases/tag/v1.3.0"&gt;New in v1.3.0&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;This module supports:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Share any local stream via &lt;a href="https://webtorrent.io/"&gt;WebTorrent&lt;/a&gt; technology&lt;/li&gt; 
 &lt;li&gt;Get any &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#incoming-browser"&gt;incoming stream&lt;/a&gt; from PC or mobile via &lt;a href="https://webtorrent.io/"&gt;WebTorrent&lt;/a&gt; technology&lt;/li&gt; 
 &lt;li&gt;Get any remote &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-webtorrent"&gt;go2rtc source&lt;/a&gt; via &lt;a href="https://webtorrent.io/"&gt;WebTorrent&lt;/a&gt; technology&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Securely and freely. You do not need to open a public access to the go2rtc server. But in some cases (Symmetric NAT), you may need to set up external access to &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-webrtc"&gt;WebRTC module&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To generate a sharing link or incoming link, go to the go2rtc WebUI (stream links page). This link is &lt;strong&gt;temporary&lt;/strong&gt; and will stop working after go2rtc is restarted!&lt;/p&gt; 
&lt;p&gt;You can create permanent external links in the go2rtc config:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;webtorrent:
  shares:
    super-secret-share:  # share name, should be unique among all go2rtc users!
      pwd: super-secret-password
      src: rtsp-dahua1   # stream name from streams section
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Link example: &lt;a href="https://go2rtc.org/webtorrent/#share=02SNtgjKXY&amp;amp;pwd=wznEQqznxW&amp;amp;media=video+audio"&gt;https://go2rtc.org/webtorrent/#share=02SNtgjKXY&amp;amp;pwd=wznEQqznxW&amp;amp;media=video+audio&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Module: ngrok&lt;/h3&gt; 
&lt;p&gt;With &lt;a href="https://ngrok.com/"&gt;ngrok&lt;/a&gt; integration, you can get external access to your streams in situations when you have Internet with a private IP address (&lt;a href="https://github.com/AlexxIT/go2rtc/raw/master/internal/ngrok/README.md"&gt;read more&lt;/a&gt;).&lt;/p&gt; 
&lt;h3&gt;Module: Hass&lt;/h3&gt; 
&lt;p&gt;The best and easiest way to use go2rtc inside Home Assistant is to install the custom integration &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#go2rtc-home-assistant-integration"&gt;WebRTC Camera&lt;/a&gt; and custom Lovelace card.&lt;/p&gt; 
&lt;p&gt;But go2rtc is also compatible and can be used with the &lt;a href="https://www.home-assistant.io/integrations/rtsp_to_webrtc/"&gt;RTSPtoWebRTC&lt;/a&gt; built-in integration.&lt;/p&gt; 
&lt;p&gt;You have several options on how to add a camera to Home Assistant:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Camera RTSP source =&amp;gt; &lt;a href="https://www.home-assistant.io/integrations/generic/"&gt;Generic Camera&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Camera &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-streams"&gt;any source&lt;/a&gt; =&amp;gt; &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#configuration"&gt;go2rtc config&lt;/a&gt; =&amp;gt; &lt;a href="https://www.home-assistant.io/integrations/generic/"&gt;Generic Camera&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Install any &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#fast-start"&gt;go2rtc&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Add your stream to &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#configuration"&gt;go2rtc config&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Hass &amp;gt; Settings &amp;gt; Integrations &amp;gt; Add Integration &amp;gt; &lt;a href="https://my.home-assistant.io/redirect/config_flow_start/?domain=onvif"&gt;ONVIF&lt;/a&gt; &amp;gt; Host: &lt;code&gt;127.0.0.1&lt;/code&gt;, Port: &lt;code&gt;1984&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Hass &amp;gt; Settings &amp;gt; Integrations &amp;gt; Add Integration &amp;gt; &lt;a href="https://my.home-assistant.io/redirect/config_flow_start/?domain=generic"&gt;Generic Camera&lt;/a&gt; &amp;gt; Stream Source URL: &lt;code&gt;rtsp://127.0.0.1:8554/camera1&lt;/code&gt; (change to your stream name, leave everything else as is)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;You have several options on how to watch the stream from the cameras in Home Assistant:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;code&gt;Camera Entity&lt;/code&gt; =&amp;gt; &lt;code&gt;Picture Entity Card&lt;/code&gt; =&amp;gt; Technology &lt;code&gt;HLS&lt;/code&gt;, codecs: &lt;code&gt;H264/H265/AAC&lt;/code&gt;, poor latency.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;Camera Entity&lt;/code&gt; =&amp;gt; &lt;a href="https://www.home-assistant.io/integrations/rtsp_to_webrtc/"&gt;RTSPtoWebRTC&lt;/a&gt; =&amp;gt; &lt;code&gt;Picture Entity Card&lt;/code&gt; =&amp;gt; Technology &lt;code&gt;WebRTC&lt;/code&gt;, codecs: &lt;code&gt;H264/PCMU/PCMA/OPUS&lt;/code&gt;, best latency. 
  &lt;ul&gt; 
   &lt;li&gt;Install any &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#fast-start"&gt;go2rtc&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Hass &amp;gt; Settings &amp;gt; Integrations &amp;gt; Add Integration &amp;gt; &lt;a href="https://my.home-assistant.io/redirect/config_flow_start/?domain=rtsp_to_webrtc"&gt;RTSPtoWebRTC&lt;/a&gt; &amp;gt; &lt;code&gt;http://127.0.0.1:1984/&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;RTSPtoWebRTC &amp;gt; Configure &amp;gt; STUN server: &lt;code&gt;stun.l.google.com:19302&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Use Picture Entity or Picture Glance Lovelace card&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;Camera Entity&lt;/code&gt; or &lt;code&gt;Camera URL&lt;/code&gt; =&amp;gt; &lt;a href="https://github.com/AlexxIT/WebRTC"&gt;WebRTC Camera&lt;/a&gt; =&amp;gt; Technology: &lt;code&gt;WebRTC/MSE/MP4/MJPEG&lt;/code&gt;, codecs: &lt;code&gt;H264/H265/AAC/PCMU/PCMA/OPUS&lt;/code&gt;, best latency, best compatibility. 
  &lt;ul&gt; 
   &lt;li&gt;Install and add &lt;a href="https://github.com/AlexxIT/WebRTC"&gt;WebRTC Camera&lt;/a&gt; custom integration&lt;/li&gt; 
   &lt;li&gt;Use WebRTC Camera custom Lovelace card&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;You can add camera &lt;code&gt;entity_id&lt;/code&gt; to &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#configuration"&gt;go2rtc config&lt;/a&gt; if you need transcoding:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;streams:
  "camera.hall": ffmpeg:{input}#video=copy#audio=opus
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;PS.&lt;/strong&gt; Default Home Assistant lovelace cards don't support two-way audio. You can use 2-way audio from &lt;a href="https://my.home-assistant.io/redirect/supervisor_addon/?addon=a889bffc_go2rtc&amp;amp;repository_url=https%3A%2F%2Fgithub.com%2FAlexxIT%2Fhassio-addons"&gt;Add-on Web UI&lt;/a&gt;, but you need to use HTTPS to access the microphone. This is a browser restriction and cannot be avoided.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;PS.&lt;/strong&gt; There is also another nice card with go2rtc support - &lt;a href="https://github.com/dermotduffy/frigate-hass-card"&gt;Frigate Lovelace Card&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Module: MP4&lt;/h3&gt; 
&lt;p&gt;Provides several features:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;MSE stream (fMP4 over WebSocket)&lt;/li&gt; 
 &lt;li&gt;Camera snapshots in MP4 format (single frame), can be sent to &lt;a href="https://github.com/AlexxIT/go2rtc/wiki/Snapshot-to-Telegram"&gt;Telegram&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;HTTP progressive streaming (MP4 file stream) - bad format for streaming because of high start delay. This format doesn't work in all Safari browsers, but go2rtc will automatically redirect it to HLS/fMP4 in this case.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;API examples:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;MP4 snapshot: &lt;code&gt;http://192.168.1.123:1984/api/frame.mp4?src=camera1&lt;/code&gt; (H264, H265)&lt;/li&gt; 
 &lt;li&gt;MP4 stream: &lt;code&gt;http://192.168.1.123:1984/api/stream.mp4?src=camera1&lt;/code&gt; (H264, H265, AAC)&lt;/li&gt; 
 &lt;li&gt;MP4 file: &lt;code&gt;http://192.168.1.123:1984/api/stream.mp4?src=camera1&lt;/code&gt; (H264, H265*, AAC, OPUS, MP3, PCMA, PCMU, PCM) 
  &lt;ul&gt; 
   &lt;li&gt;You can use &lt;code&gt;mp4&lt;/code&gt;, &lt;code&gt;mp4=flac&lt;/code&gt; and &lt;code&gt;mp4=all&lt;/code&gt; param for codec filters&lt;/li&gt; 
   &lt;li&gt;You can use &lt;code&gt;duration&lt;/code&gt; param in seconds (ex. &lt;code&gt;duration=15&lt;/code&gt;)&lt;/li&gt; 
   &lt;li&gt;You can use &lt;code&gt;filename&lt;/code&gt; param (ex. &lt;code&gt;filename=record.mp4&lt;/code&gt;)&lt;/li&gt; 
   &lt;li&gt;You can use &lt;code&gt;rotate&lt;/code&gt; param with &lt;code&gt;90&lt;/code&gt;, &lt;code&gt;180&lt;/code&gt; or &lt;code&gt;270&lt;/code&gt; values&lt;/li&gt; 
   &lt;li&gt;You can use &lt;code&gt;scale&lt;/code&gt; param with positive integer values (ex. &lt;code&gt;scale=4:3&lt;/code&gt;)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Read more about &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#codecs-filters"&gt;codecs filters&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;PS.&lt;/strong&gt; Rotate and scale params don't use transcoding and change video using metadata.&lt;/p&gt; 
&lt;h3&gt;Module: HLS&lt;/h3&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href="https://github.com/AlexxIT/go2rtc/releases/tag/v1.1.0"&gt;New in v1.1.0&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/HTTP_Live_Streaming"&gt;HLS&lt;/a&gt; is the worst technology for real-time streaming. It can only be useful on devices that do not support more modern technology, like &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-webrtc"&gt;WebRTC&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-mp4"&gt;MSE/MP4&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The go2rtc implementation differs from the standards and may not work with all players.&lt;/p&gt; 
&lt;p&gt;API examples:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;HLS/TS stream: &lt;code&gt;http://192.168.1.123:1984/api/stream.m3u8?src=camera1&lt;/code&gt; (H264)&lt;/li&gt; 
 &lt;li&gt;HLS/fMP4 stream: &lt;code&gt;http://192.168.1.123:1984/api/stream.m3u8?src=camera1&amp;amp;mp4&lt;/code&gt; (H264, H265, AAC)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Read more about &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#codecs-filters"&gt;codecs filters&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Module: MJPEG&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Important.&lt;/strong&gt; For stream in MJPEG format, your source MUST contain the MJPEG codec. If your stream has an MJPEG codec, you can receive &lt;strong&gt;MJPEG stream&lt;/strong&gt; or &lt;strong&gt;JPEG snapshots&lt;/strong&gt; via API.&lt;/p&gt; 
&lt;p&gt;You can receive an MJPEG stream in several ways:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;some cameras support MJPEG codec inside &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-rtsp"&gt;RTSP stream&lt;/a&gt; (ex. second stream for Dahua cameras)&lt;/li&gt; 
 &lt;li&gt;some cameras have an HTTP link with &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-http"&gt;MJPEG stream&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;some cameras have an HTTP link with snapshots - go2rtc can convert them to &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-http"&gt;MJPEG stream&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;you can convert H264/H265 stream from your camera via &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-ffmpeg"&gt;FFmpeg integraion&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;With this example, your stream will have both H264 and MJPEG codecs:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;streams:
  camera1:
    - rtsp://rtsp:12345678@192.168.1.123/av_stream/ch0
    - ffmpeg:camera1#video=mjpeg
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;API examples:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;MJPEG stream: &lt;code&gt;http://192.168.1.123:1984/api/stream.mjpeg?src=camera1&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;JPEG snapshots: &lt;code&gt;http://192.168.1.123:1984/api/frame.jpeg?src=camera1&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;You can use &lt;code&gt;width&lt;/code&gt;/&lt;code&gt;w&lt;/code&gt; and/or &lt;code&gt;height&lt;/code&gt;/&lt;code&gt;h&lt;/code&gt; params&lt;/li&gt; 
   &lt;li&gt;You can use &lt;code&gt;rotate&lt;/code&gt; param with &lt;code&gt;90&lt;/code&gt;, &lt;code&gt;180&lt;/code&gt;, &lt;code&gt;270&lt;/code&gt; or &lt;code&gt;-90&lt;/code&gt; values&lt;/li&gt; 
   &lt;li&gt;You can use &lt;code&gt;hardware&lt;/code&gt;/&lt;code&gt;hw&lt;/code&gt; param &lt;a href="https://github.com/AlexxIT/go2rtc/wiki/Hardware-acceleration"&gt;read more&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;PS.&lt;/strong&gt; This module also supports streaming to the server console (terminal) in the &lt;strong&gt;animated ASCII art&lt;/strong&gt; format (&lt;a href="https://github.com/AlexxIT/go2rtc/raw/master/internal/mjpeg/README.md"&gt;read more&lt;/a&gt;):&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=sHj_3h_sX7M"&gt;&lt;img src="https://img.youtube.com/vi/sHj_3h_sX7M/mqdefault.jpg" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Module: Log&lt;/h3&gt; 
&lt;p&gt;You can set different log levels for different modules.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;log:
  level: info  # default level
  api: trace
  exec: debug
  rtsp: warn
  streams: error
  webrtc: fatal
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] If an attacker gains access to the API, you are in danger. Through the API, an attacker can use insecure sources such as echo and exec. And get full access to your server.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;For maximum (paranoid) security, go2rtc has special settings:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;app:
  # use only allowed modules
  modules: [api, rtsp, webrtc, exec, ffmpeg, mjpeg]

api:
  # use only allowed API paths
  allow_paths: [/api, /api/streams, /api/webrtc, /api/frame.jpeg]
  # enable auth for localhost (used together with username and password)
  local_auth: true

exec:
  # use only allowed exec paths
  allow_paths: [ffmpeg]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;By default, &lt;code&gt;go2rtc&lt;/code&gt; starts the Web interface on port &lt;code&gt;1984&lt;/code&gt; and RTSP on port &lt;code&gt;8554&lt;/code&gt;, as well as uses port &lt;code&gt;8555&lt;/code&gt; for WebRTC connections. The three ports are accessible from your local network. So anyone on your local network can watch video from your cameras without authorization. The same rule applies to the Home Assistant Add-on.&lt;/p&gt; 
&lt;p&gt;This is not a problem if you trust your local network as much as I do. But you can change this behaviour with a &lt;code&gt;go2rtc.yaml&lt;/code&gt; config:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;api:
  listen: "127.0.0.1:1984" # localhost

rtsp:
  listen: "127.0.0.1:8554" # localhost

webrtc:
  listen: ":8555" # external TCP/UDP port
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;local access to RTSP is not a problem for &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-ffmpeg"&gt;FFmpeg&lt;/a&gt; integration, because it runs locally on your server&lt;/li&gt; 
 &lt;li&gt;local access to API is not a problem for the &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#go2rtc-home-assistant-add-on"&gt;Home Assistant add-on&lt;/a&gt;, because Hass runs locally on the same server, and the add-on web UI is protected with Hass authorization (&lt;a href="https://www.home-assistant.io/blog/2019/04/15/hassio-ingress/"&gt;Ingress feature&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;external access to WebRTC TCP port is not a problem, because it is used only for transmitting encrypted media data 
  &lt;ul&gt; 
   &lt;li&gt;anyway you need to open this port to your local network and to the Internet for WebRTC to work&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you need web interface protection without the Home Assistant add-on, you need to use a reverse proxy, like &lt;a href="https://nginx.org/"&gt;Nginx&lt;/a&gt;, &lt;a href="https://caddyserver.com/"&gt;Caddy&lt;/a&gt;, etc.&lt;/p&gt; 
&lt;p&gt;PS. Additionally, WebRTC will try to use the 8555 UDP port to transmit encrypted media. It works without problems on the local network, and sometimes also works for external access, even if you haven't opened this port on your router (&lt;a href="https://en.wikipedia.org/wiki/UDP_hole_punching"&gt;read more&lt;/a&gt;). But for stable external WebRTC access, you need to open the 8555 port on your router for both TCP and UDP.&lt;/p&gt; 
&lt;h2&gt;Codecs filters&lt;/h2&gt; 
&lt;p&gt;go2rtc can automatically detect which codecs your device supports for &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-webrtc"&gt;WebRTC&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-mp4"&gt;MSE&lt;/a&gt; technologies.&lt;/p&gt; 
&lt;p&gt;But it cannot be done for &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-rtsp"&gt;RTSP&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-mp4"&gt;HTTP progressive streaming&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#module-hls"&gt;HLS&lt;/a&gt; technologies. You can manually add a codec filter when you create a link to a stream. The filters work the same for all three technologies. Filters do not create a new codec. They only select the suitable codec from existing sources. You can add new codecs to the stream using the &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-ffmpeg"&gt;FFmpeg transcoding&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Without filters:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;RTSP will provide only the first video and only the first audio (any codec)&lt;/li&gt; 
 &lt;li&gt;MP4 will include only compatible codecs (H264, H265, AAC)&lt;/li&gt; 
 &lt;li&gt;HLS will output in the legacy TS format (H264 without audio)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Some examples:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;rtsp://192.168.1.123:8554/camera1?mp4&lt;/code&gt; - useful for recording as MP4 files (e.g. Hass or Frigate)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;rtsp://192.168.1.123:8554/camera1?video=h264,h265&amp;amp;audio=aac&lt;/code&gt; - full version of the filter above&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;rtsp://192.168.1.123:8554/camera1?video=h264&amp;amp;audio=aac&amp;amp;audio=opus&lt;/code&gt; - H264 video codec and two separate audio tracks&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;rtsp://192.168.1.123:8554/camera1?video&amp;amp;audio=all&lt;/code&gt; - any video codec and all audio codecs as separate tracks&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;http://192.168.1.123:1984/api/stream.m3u8?src=camera1&amp;amp;mp4&lt;/code&gt; - HLS stream with MP4 compatible codecs (HLS/fMP4)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;http://192.168.1.123:1984/api/stream.m3u8?src=camera1&amp;amp;mp4=flac&lt;/code&gt; - HLS stream with PCMA/PCMU/PCM audio support (HLS/fMP4), won't work on old devices&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;http://192.168.1.123:1984/api/stream.mp4?src=camera1&amp;amp;mp4=flac&lt;/code&gt; - MP4 file with PCMA/PCMU/PCM audio support, won't work on old devices (ex. iOS 12)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;http://192.168.1.123:1984/api/stream.mp4?src=camera1&amp;amp;mp4=all&lt;/code&gt; - MP4 file with non-standard audio codecs, won't work on some players&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Codecs madness&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;AVC/H.264&lt;/code&gt; video can be played almost anywhere. But &lt;code&gt;HEVC/H.265&lt;/code&gt; has many limitations in supporting different devices and browsers.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Device&lt;/th&gt; 
   &lt;th&gt;WebRTC&lt;/th&gt; 
   &lt;th&gt;MSE&lt;/th&gt; 
   &lt;th&gt;HTTP*&lt;/th&gt; 
   &lt;th&gt;HLS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;em&gt;latency&lt;/em&gt;&lt;/td&gt; 
   &lt;td&gt;best&lt;/td&gt; 
   &lt;td&gt;medium&lt;/td&gt; 
   &lt;td&gt;bad&lt;/td&gt; 
   &lt;td&gt;bad&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Desktop Chrome 136+ &lt;br /&gt; Desktop Edge &lt;br /&gt; Android Chrome 136+&lt;/td&gt; 
   &lt;td&gt;H264, H265* &lt;br /&gt; PCMU, PCMA &lt;br /&gt; OPUS&lt;/td&gt; 
   &lt;td&gt;H264, H265* &lt;br /&gt; AAC, FLAC* &lt;br /&gt; OPUS&lt;/td&gt; 
   &lt;td&gt;H264, H265* &lt;br /&gt; AAC, FLAC* &lt;br /&gt; OPUS, MP3&lt;/td&gt; 
   &lt;td&gt;no&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Desktop Firefox&lt;/td&gt; 
   &lt;td&gt;H264 &lt;br /&gt; PCMU, PCMA &lt;br /&gt; OPUS&lt;/td&gt; 
   &lt;td&gt;H264 &lt;br /&gt; AAC, FLAC* &lt;br /&gt; OPUS&lt;/td&gt; 
   &lt;td&gt;H264 &lt;br /&gt; AAC, FLAC* &lt;br /&gt; OPUS&lt;/td&gt; 
   &lt;td&gt;no&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Desktop Safari 14+ &lt;br /&gt; iPad Safari 14+ &lt;br /&gt; iPhone Safari 17.1+&lt;/td&gt; 
   &lt;td&gt;H264, H265* &lt;br /&gt; PCMU, PCMA &lt;br /&gt; OPUS&lt;/td&gt; 
   &lt;td&gt;H264, H265 &lt;br /&gt; AAC, FLAC*&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;no!&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;H264, H265 &lt;br /&gt; AAC, FLAC*&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;iPhone Safari 14+&lt;/td&gt; 
   &lt;td&gt;H264, H265* &lt;br /&gt; PCMU, PCMA &lt;br /&gt; OPUS&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;no!&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;no!&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;H264, H265 &lt;br /&gt; AAC, FLAC*&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;macOS &lt;a href="https://apps.apple.com/app/home-assistant/id1099568401"&gt;Hass App&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;no&lt;/td&gt; 
   &lt;td&gt;no&lt;/td&gt; 
   &lt;td&gt;no&lt;/td&gt; 
   &lt;td&gt;H264, H265 &lt;br /&gt; AAC, FLAC*&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;HTTP*&lt;/code&gt; - HTTP Progressive Streaming, not related to &lt;a href="https://en.wikipedia.org/wiki/Progressive_download"&gt;progressive download&lt;/a&gt;, because the file has no size and no end&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;WebRTC H265&lt;/code&gt; - supported in &lt;a href="https://developer.chrome.com/release-notes/136"&gt;Chrome 136+&lt;/a&gt;, supported in &lt;a href="https://developer.apple.com/documentation/safari-release-notes/safari-18-release-notes"&gt;Safari 18+&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;MSE iPhone&lt;/code&gt; - supported in &lt;a href="https://webkit.org/blog/14735/webkit-features-in-safari-17-1/"&gt;iOS 17.1+&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Audio&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Go2rtc support &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#built-in-transcoding"&gt;automatic repack&lt;/a&gt; &lt;code&gt;PCMA/PCMU/PCM&lt;/code&gt; codecs to &lt;code&gt;FLAC&lt;/code&gt; for MSE/MP4/HLS so they will work almost anywhere&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;WebRTC&lt;/strong&gt; audio codecs: &lt;code&gt;PCMU/8000&lt;/code&gt;, &lt;code&gt;PCMA/8000&lt;/code&gt;, &lt;code&gt;OPUS/48000/2&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;OPUS&lt;/code&gt; and &lt;code&gt;MP3&lt;/code&gt; inside &lt;strong&gt;MP4&lt;/strong&gt; are part of the standard, but some players do not support them anyway (especially Apple)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Apple devices&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;all Apple devices don't support HTTP progressive streaming&lt;/li&gt; 
 &lt;li&gt;old iPhone firmwares don't support MSE technology because it competes with the HTTP Live Streaming (HLS) technology, invented by Apple&lt;/li&gt; 
 &lt;li&gt;HLS is the worst technology for &lt;strong&gt;live&lt;/strong&gt; streaming, it still exists only because of iPhones&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Codec names&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;H264 = H.264 = AVC (Advanced Video Coding)&lt;/li&gt; 
 &lt;li&gt;H265 = H.265 = HEVC (High Efficiency Video Coding)&lt;/li&gt; 
 &lt;li&gt;PCMA = G.711 PCM (A-law) = PCM A-law (&lt;code&gt;alaw&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;PCMU = G.711 PCM (¬µ-law) = PCM mu-law (&lt;code&gt;mulaw&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;PCM = L16 = PCM signed 16-bit big-endian (&lt;code&gt;s16be&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;AAC = MPEG4-GENERIC&lt;/li&gt; 
 &lt;li&gt;MP3 = MPEG-1 Audio Layer III or MPEG-2 Audio Layer III&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Built-in transcoding&lt;/h2&gt; 
&lt;p&gt;There are no plans to embed complex transcoding algorithms inside go2rtc. &lt;a href="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/#source-ffmpeg"&gt;FFmpeg source&lt;/a&gt; does a great job with this. Including &lt;a href="https://github.com/AlexxIT/go2rtc/wiki/Hardware-acceleration"&gt;hardware acceleration&lt;/a&gt; support.&lt;/p&gt; 
&lt;p&gt;But go2rtc has some simple algorithms. They are turned on automatically; you do not need to set them up additionally.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;PCM for MSE/MP4/HLS&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Go2rtc can pack &lt;code&gt;PCMA&lt;/code&gt;, &lt;code&gt;PCMU&lt;/code&gt; and &lt;code&gt;PCM&lt;/code&gt; codecs into an MP4 container so that they work in all browsers and all built-in players on modern devices. Including Apple QuickTime:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;PCMA/PCMU =&amp;gt; PCM =&amp;gt; FLAC =&amp;gt; MSE/MP4/HLS
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Resample PCMA/PCMU for WebRTC&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;By default WebRTC supports only &lt;code&gt;PCMA/8000&lt;/code&gt; and &lt;code&gt;PCMU/8000&lt;/code&gt;. But go2rtc can automatically resample PCMA and PCMU codecs with a different sample rate. Also, go2rtc can transcode &lt;code&gt;PCM&lt;/code&gt; codec to &lt;code&gt;PCMA/8000&lt;/code&gt;, so WebRTC can play it:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;PCM/xxx =&amp;gt; PCMA/8000 =&amp;gt; WebRTC
PCMA/xxx =&amp;gt; PCMA/8000 =&amp;gt; WebRTC
PCMU/xxx =&amp;gt; PCMU/8000 =&amp;gt; WebRTC
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;FLAC codec not supported in an RTSP stream. If you are using Frigate or Hass for recording MP4 files with PCMA/PCMU/PCM audio, you should set up transcoding to the AAC codec.&lt;/li&gt; 
 &lt;li&gt;PCMA and PCMU are VERY low-quality codecs. They support only 256! different sounds. Use them only when you have no other options.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Codecs negotiation&lt;/h2&gt; 
&lt;p&gt;For example, you want to watch RTSP-stream from &lt;a href="https://www.dahuasecurity.com/fr/products/All-Products/Network-Cameras/Wireless-Series/Wi-Fi-Series/4MP/IPC-K42"&gt;Dahua IPC-K42&lt;/a&gt; camera in your Chrome browser.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;this camera supports two-way audio standard &lt;strong&gt;ONVIF Profile T&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;this camera supports codecs &lt;strong&gt;H264, H265&lt;/strong&gt; for send video, and you select &lt;code&gt;H264&lt;/code&gt; in camera settings&lt;/li&gt; 
 &lt;li&gt;this camera supports codecs &lt;strong&gt;AAC, PCMU, PCMA&lt;/strong&gt; for sending audio (from mic), and you select &lt;code&gt;AAC/16000&lt;/code&gt; in camera settings&lt;/li&gt; 
 &lt;li&gt;this camera supports codecs &lt;strong&gt;AAC, PCMU, PCMA&lt;/strong&gt; for receiving audio (to speaker), you don't need to select them&lt;/li&gt; 
 &lt;li&gt;your browser supports codecs &lt;strong&gt;H264, VP8, VP9, AV1&lt;/strong&gt; for receiving video, you don't need to select them&lt;/li&gt; 
 &lt;li&gt;your browser supports codecs &lt;strong&gt;OPUS, PCMU, PCMA&lt;/strong&gt; for sending and receiving audio, you don't need to select them&lt;/li&gt; 
 &lt;li&gt;you can't get camera audio directly, because its audio codecs don't match with your browser codecs 
  &lt;ul&gt; 
   &lt;li&gt;so you decide to use transcoding via FFmpeg and add this setting to the config YAML file&lt;/li&gt; 
   &lt;li&gt;you have chosen &lt;code&gt;OPUS/48000/2&lt;/code&gt; codec, because it is higher quality than the &lt;code&gt;PCMU/8000&lt;/code&gt; or &lt;code&gt;PCMA/8000&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Now you have a stream with two sources - &lt;strong&gt;RTSP and FFmpeg&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;streams:
  dahua:
    - rtsp://admin:password@192.168.1.123/cam/realmonitor?channel=1&amp;amp;subtype=0&amp;amp;unicast=true&amp;amp;proto=Onvif
    - ffmpeg:rtsp://admin:password@192.168.1.123/cam/realmonitor?channel=1&amp;amp;subtype=0#audio=opus
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;go2rtc&lt;/strong&gt; automatically matches codecs for your browser and all your stream sources. This is called &lt;strong&gt;multi-source two-way codec negotiation&lt;/strong&gt;. And this is one of the main features of this app.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/AlexxIT/go2rtc/master/assets/codecs.svg?sanitize=true" alt="" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;PS.&lt;/strong&gt; You can select &lt;code&gt;PCMU&lt;/code&gt; or &lt;code&gt;PCMA&lt;/code&gt; codec in camera settings and not use transcoding at all. Or you can select &lt;code&gt;AAC&lt;/code&gt; codec for main stream and &lt;code&gt;PCMU&lt;/code&gt; codec for second stream and add both RTSP to YAML config, this also will work fine.&lt;/p&gt; 
&lt;h2&gt;Projects using go2rtc&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.home-assistant.io/"&gt;Home Assistant&lt;/a&gt; &lt;a href="https://www.home-assistant.io/integrations/go2rtc/"&gt;2024.11+&lt;/a&gt; - top open-source smart home project&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://frigate.video/"&gt;Frigate&lt;/a&gt; &lt;a href="https://docs.frigate.video/guides/configuring_go2rtc/"&gt;0.12+&lt;/a&gt; - open-source NVR built around real-time AI object detection&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dermotduffy/frigate-hass-card"&gt;Frigate Lovelace Card&lt;/a&gt; - custom card for Home Assistant&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/OpenIPC/firmware/tree/master/general/package/go2rtc"&gt;OpenIPC&lt;/a&gt; - alternative IP camera firmware from an open community&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gtxaspec/wz_mini_hacks"&gt;wz_mini_hacks&lt;/a&gt; - custom firmware for Wyze cameras&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/oischinger/eufyp2pstream"&gt;EufyP2PStream&lt;/a&gt; - a small project that provides a video/audio stream from Eufy cameras that don't directly support RTSP&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bropat/ioBroker.eusec"&gt;ioBroker.euSec&lt;/a&gt; - &lt;a href="https://www.iobroker.net/"&gt;ioBroker&lt;/a&gt; adapter for controlling Eufy security devices&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Anonym-tsk/MMM-go2rtc"&gt;MMM-go2rtc&lt;/a&gt; - MagicMirror¬≤ module&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tsightler/ring-mqtt"&gt;ring-mqtt&lt;/a&gt; - Ring-to-MQTT bridge&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/opensensor/lightNVR"&gt;lightNVR&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Distributions&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://pkgs.alpinelinux.org/packages?name=go2rtc"&gt;Alpine Linux&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://linux-packages.com/aur/package/go2rtc"&gt;Arch User Repository&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/inode64/inode64-overlay/tree/main/media-video/go2rtc"&gt;Gentoo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://search.nixos.org/packages?query=go2rtc"&gt;NixOS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/community-scripts/ProxmoxVE/"&gt;Proxmox Helper Scripts&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.myqnap.org/product/go2rtc/"&gt;QNAP&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://synocommunity.com/package/go2rtc"&gt;Synology NAS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://unraid.net/community/apps?q=go2rtc"&gt;Unraid&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Camera experience&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.dahuasecurity.com/"&gt;Dahua&lt;/a&gt; - reference implementation streaming protocols, a lot of settings, high stream quality, multiple streaming clients&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.ezviz.com/"&gt;EZVIZ&lt;/a&gt; - awful RTSP protocol implementation, many bugs in SDP&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.hikvision.com/"&gt;Hikvision&lt;/a&gt; - a lot of proprietary streaming technologies&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://reolink.com/"&gt;Reolink&lt;/a&gt; - some models have an awful, unusable RTSP implementation and not the best RTMP alternative (I recommend that you contact Reolink support for new firmware), few settings&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://sonoff.tech/"&gt;Sonoff&lt;/a&gt; - very low stream quality, no settings, not the best protocol implementation&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.tp-link.com/"&gt;TP-Link&lt;/a&gt; - few streaming clients, packet loss?&lt;/li&gt; 
 &lt;li&gt;Chinese cheap noname cameras, Wyze Cams, Xiaomi cameras with hacks (usually have &lt;code&gt;/live/ch00_1&lt;/code&gt; in RTSP URL) - awful but usable RTSP protocol implementation, low stream quality, few settings, packet loss?&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;TIPS&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Using apps for low RTSP delay&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;ffplay -fflags nobuffer -flags low_delay "rtsp://192.168.1.123:8554/camera1"&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;VLC &amp;gt; Preferences &amp;gt; Input / Codecs &amp;gt; Default Caching Level: Lowest Latency&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Snapshots to Telegram&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/AlexxIT/go2rtc/wiki/Snapshot-to-Telegram"&gt;read more&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>