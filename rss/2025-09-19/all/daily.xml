<rss version="2.0">
  <channel>
    <title>GitHub All Languages Daily Trending</title>
    <description>Daily Trending of All Languages in GitHub</description>
    <pubDate>Thu, 18 Sep 2025 01:30:42 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>virattt/ai-hedge-fund</title>
      <link>https://github.com/virattt/ai-hedge-fund</link>
      <description>&lt;p&gt;An AI Hedge Fund Team&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;AI Hedge Fund&lt;/h1&gt; 
&lt;p&gt;This is a proof of concept for an AI-powered hedge fund. The goal of this project is to explore the use of AI to make trading decisions. This project is for &lt;strong&gt;educational&lt;/strong&gt; purposes only and is not intended for real trading or investment.&lt;/p&gt; 
&lt;p&gt;This system employs several agents working together:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Aswath Damodaran Agent - The Dean of Valuation, focuses on story, numbers, and disciplined valuation&lt;/li&gt; 
 &lt;li&gt;Ben Graham Agent - The godfather of value investing, only buys hidden gems with a margin of safety&lt;/li&gt; 
 &lt;li&gt;Bill Ackman Agent - An activist investor, takes bold positions and pushes for change&lt;/li&gt; 
 &lt;li&gt;Cathie Wood Agent - The queen of growth investing, believes in the power of innovation and disruption&lt;/li&gt; 
 &lt;li&gt;Charlie Munger Agent - Warren Buffett's partner, only buys wonderful businesses at fair prices&lt;/li&gt; 
 &lt;li&gt;Michael Burry Agent - The Big Short contrarian who hunts for deep value&lt;/li&gt; 
 &lt;li&gt;Mohnish Pabrai Agent - The Dhandho investor, who looks for doubles at low risk&lt;/li&gt; 
 &lt;li&gt;Peter Lynch Agent - Practical investor who seeks "ten-baggers" in everyday businesses&lt;/li&gt; 
 &lt;li&gt;Phil Fisher Agent - Meticulous growth investor who uses deep "scuttlebutt" research&lt;/li&gt; 
 &lt;li&gt;Rakesh Jhunjhunwala Agent - The Big Bull of India&lt;/li&gt; 
 &lt;li&gt;Stanley Druckenmiller Agent - Macro legend who hunts for asymmetric opportunities with growth potential&lt;/li&gt; 
 &lt;li&gt;Warren Buffett Agent - The oracle of Omaha, seeks wonderful companies at a fair price&lt;/li&gt; 
 &lt;li&gt;Valuation Agent - Calculates the intrinsic value of a stock and generates trading signals&lt;/li&gt; 
 &lt;li&gt;Sentiment Agent - Analyzes market sentiment and generates trading signals&lt;/li&gt; 
 &lt;li&gt;Fundamentals Agent - Analyzes fundamental data and generates trading signals&lt;/li&gt; 
 &lt;li&gt;Technicals Agent - Analyzes technical indicators and generates trading signals&lt;/li&gt; 
 &lt;li&gt;Risk Manager - Calculates risk metrics and sets position limits&lt;/li&gt; 
 &lt;li&gt;Portfolio Manager - Makes final trading decisions and generates orders&lt;/li&gt; 
&lt;/ol&gt; 
&lt;img width="1042" alt="Screenshot 2025-03-22 at 6 19 07 PM" src="https://github.com/user-attachments/assets/cbae3dcf-b571-490d-b0ad-3f0f035ac0d4" /&gt; 
&lt;p&gt;Note: the system does not actually make any trades.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://twitter.com/virattt"&gt;&lt;img src="https://img.shields.io/twitter/follow/virattt?style=social" alt="Twitter Follow" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Disclaimer&lt;/h2&gt; 
&lt;p&gt;This project is for &lt;strong&gt;educational and research purposes only&lt;/strong&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Not intended for real trading or investment&lt;/li&gt; 
 &lt;li&gt;No investment advice or guarantees provided&lt;/li&gt; 
 &lt;li&gt;Creator assumes no liability for financial losses&lt;/li&gt; 
 &lt;li&gt;Consult a financial advisor for investment decisions&lt;/li&gt; 
 &lt;li&gt;Past performance does not indicate future results&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;By using this software, you agree to use it solely for learning purposes.&lt;/p&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/virattt/ai-hedge-fund/main/#how-to-install"&gt;How to Install&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/virattt/ai-hedge-fund/main/#how-to-run"&gt;How to Run&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/virattt/ai-hedge-fund/main/#%EF%B8%8F-command-line-interface"&gt;‚å®Ô∏è Command Line Interface&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/virattt/ai-hedge-fund/main/#%EF%B8%8F-web-application"&gt;üñ•Ô∏è Web Application&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/virattt/ai-hedge-fund/main/#how-to-contribute"&gt;How to Contribute&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/virattt/ai-hedge-fund/main/#feature-requests"&gt;Feature Requests&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/virattt/ai-hedge-fund/main/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;How to Install&lt;/h2&gt; 
&lt;p&gt;Before you can run the AI Hedge Fund, you'll need to install it and set up your API keys. These steps are common to both the full-stack web application and command line interface.&lt;/p&gt; 
&lt;h3&gt;1. Clone the Repository&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/virattt/ai-hedge-fund.git
cd ai-hedge-fund
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. Set up API keys&lt;/h3&gt; 
&lt;p&gt;Create a &lt;code&gt;.env&lt;/code&gt; file for your API keys:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Create .env file for your API keys (in the root directory)
cp .env.example .env
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Open and edit the &lt;code&gt;.env&lt;/code&gt; file to add your API keys:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# For running LLMs hosted by openai (gpt-4o, gpt-4o-mini, etc.)
OPENAI_API_KEY=your-openai-api-key

# For getting financial data to power the hedge fund
FINANCIAL_DATASETS_API_KEY=your-financial-datasets-api-key
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: You must set at least one LLM API key (e.g. &lt;code&gt;OPENAI_API_KEY&lt;/code&gt;, &lt;code&gt;GROQ_API_KEY&lt;/code&gt;, &lt;code&gt;ANTHROPIC_API_KEY&lt;/code&gt;, or &lt;code&gt;DEEPSEEK_API_KEY&lt;/code&gt;) for the hedge fund to work.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Financial Data&lt;/strong&gt;: Data for AAPL, GOOGL, MSFT, NVDA, and TSLA is free and does not require an API key. For any other ticker, you will need to set the &lt;code&gt;FINANCIAL_DATASETS_API_KEY&lt;/code&gt; in the .env file.&lt;/p&gt; 
&lt;h2&gt;How to Run&lt;/h2&gt; 
&lt;h3&gt;‚å®Ô∏è Command Line Interface&lt;/h3&gt; 
&lt;p&gt;You can run the AI Hedge Fund directly via terminal. This approach offers more granular control and is useful for automation, scripting, and integration purposes.&lt;/p&gt; 
&lt;img width="992" alt="Screenshot 2025-01-06 at 5 50 17 PM" src="https://github.com/user-attachments/assets/e8ca04bf-9989-4a7d-a8b4-34e04666663b" /&gt; 
&lt;h4&gt;Quick Start&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install Poetry (if not already installed):&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -sSL https://install.python-poetry.org | python3 -
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Install dependencies:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry install
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Run the AI Hedge Fund&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry run python src/main.py --ticker AAPL,MSFT,NVDA
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also specify a &lt;code&gt;--ollama&lt;/code&gt; flag to run the AI hedge fund using local LLMs.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry run python src/main.py --ticker AAPL,MSFT,NVDA --ollama
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can optionally specify the start and end dates to make decisions over a specific time period.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry run python src/main.py --ticker AAPL,MSFT,NVDA --start-date 2024-01-01 --end-date 2024-03-01
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Run the Backtester&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry run python src/backtester.py --ticker AAPL,MSFT,NVDA
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Example Output:&lt;/strong&gt; &lt;img width="941" alt="Screenshot 2025-01-06 at 5 47 52 PM" src="https://github.com/user-attachments/assets/00e794ea-8628-44e6-9a84-8f8a31ad3b47" /&gt;&lt;/p&gt; 
&lt;p&gt;Note: The &lt;code&gt;--ollama&lt;/code&gt;, &lt;code&gt;--start-date&lt;/code&gt;, and &lt;code&gt;--end-date&lt;/code&gt; flags work for the backtester, as well!&lt;/p&gt; 
&lt;h3&gt;üñ•Ô∏è Web Application&lt;/h3&gt; 
&lt;p&gt;The new way to run the AI Hedge Fund is through our web application that provides a user-friendly interface. This is recommended for users who prefer visual interfaces over command line tools.&lt;/p&gt; 
&lt;p&gt;Please see detailed instructions on how to install and run the web application &lt;a href="https://github.com/virattt/ai-hedge-fund/tree/main/app"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;img width="1721" alt="Screenshot 2025-06-28 at 6 41 03‚ÄØPM" src="https://github.com/user-attachments/assets/b95ab696-c9f4-416c-9ad1-51feb1f5374b" /&gt; 
&lt;h2&gt;How to Contribute&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Fork the repository&lt;/li&gt; 
 &lt;li&gt;Create a feature branch&lt;/li&gt; 
 &lt;li&gt;Commit your changes&lt;/li&gt; 
 &lt;li&gt;Push to the branch&lt;/li&gt; 
 &lt;li&gt;Create a Pull Request&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: Please keep your pull requests small and focused. This will make it easier to review and merge.&lt;/p&gt; 
&lt;h2&gt;Feature Requests&lt;/h2&gt; 
&lt;p&gt;If you have a feature request, please open an &lt;a href="https://github.com/virattt/ai-hedge-fund/issues"&gt;issue&lt;/a&gt; and make sure it is tagged with &lt;code&gt;enhancement&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the MIT License - see the LICENSE file for details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>google-research/timesfm</title>
      <link>https://github.com/google-research/timesfm</link>
      <description>&lt;p&gt;TimesFM (Time Series Foundation Model) is a pretrained time-series foundation model developed by Google Research for time-series forecasting.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;TimesFM&lt;/h1&gt; 
&lt;p&gt;TimesFM (Time Series Foundation Model) is a pretrained time-series foundation model developed by Google Research for time-series forecasting.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Paper: &lt;a href="https://arxiv.org/abs/2310.10688"&gt;A decoder-only foundation model for time-series forecasting&lt;/a&gt;, ICML 2024.&lt;/li&gt; 
 &lt;li&gt;All checkpoints: &lt;a href="https://huggingface.co/collections/google/timesfm-release-66e4be5fdb56e960c1e482a6"&gt;TimesFM Hugging Face Collection&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://research.google/blog/a-decoder-only-foundation-model-for-time-series-forecasting/"&gt;Google Research blog&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://cloud.google.com/bigquery/docs/timesfm-model"&gt;TimesFM in BigQuery&lt;/a&gt;: an official Google product.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This open version is not an officially supported Google product.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Latest Model Version:&lt;/strong&gt; TimesFM 2.5&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Archived Model Versions:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;1.0 and 2.0: relevant code archived in the sub directory &lt;code&gt;v1&lt;/code&gt;. You can &lt;code&gt;pip install timesfm==1.3.0&lt;/code&gt; to install an older version of this package to load them.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Update - Sept. 15, 2025&lt;/h2&gt; 
&lt;p&gt;TimesFM 2.5 is out!&lt;/p&gt; 
&lt;p&gt;Comparing to TimesFM 2.0, this new 2.5 model:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;uses 200M parameters, down from 500M.&lt;/li&gt; 
 &lt;li&gt;supports up to 16k context length, up from 2048.&lt;/li&gt; 
 &lt;li&gt;supports continuous quantile forecast up to 1k horizon via an optional 30M quantile head.&lt;/li&gt; 
 &lt;li&gt;gets rid of the &lt;code&gt;frequency&lt;/code&gt; indicator.&lt;/li&gt; 
 &lt;li&gt;has a couple of new forecasting flags.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Along with the model upgrade we have also upgraded the inference API. This repo will be under construction over the next few weeks to&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;add support for an upcoming Flax version of the model (faster inference).&lt;/li&gt; 
 &lt;li&gt;add back covariate support.&lt;/li&gt; 
 &lt;li&gt;populate more docstrings, docs and notebook.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Install&lt;/h3&gt; 
&lt;p&gt;TODO(siriuz42): Package timesfm==2.0.0 and upload to PyPI .&lt;/p&gt; 
&lt;p&gt;Run&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;git clone https://github.com/google-research/timesfm.git
cd timesfm
pip install -e .
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Code Example&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import numpy as np
import timesfm
model = timesfm.TimesFM_2p5_200M_torch()
model.load_checkpoint()
model.compile(
    timesfm.ForecastConfig(
        max_context=1024,
        max_horizon=256,
        normalize_inputs=True,
        use_continuous_quantile_head=True,
        force_flip_invariance=True,
        infer_is_positive=True,
        fix_quantile_crossing=True,
    )
)
point_forecast, quantile_forecast = model.forecast(
    horizon=12,
    inputs=[
        np.linspace(0, 1, 100),
        np.sin(np.linspace(0, 20, 67)),
    ],  # Two dummy inputs
)
point_forecast.shape  # (2, 12)
quantile_forecast.shape  # (2, 12, 10): mean, then 10th to 90th quantiles.
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>openai/codex</title>
      <link>https://github.com/openai/codex</link>
      <description>&lt;p&gt;Lightweight coding agent that runs in your terminal&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt;OpenAI Codex CLI&lt;/h1&gt; 
&lt;p align="center"&gt;&lt;code&gt;npm i -g @openai/codex&lt;/code&gt;&lt;br /&gt;or &lt;code&gt;brew install codex&lt;/code&gt;&lt;/p&gt; 
&lt;p align="center"&gt;&lt;strong&gt;Codex CLI&lt;/strong&gt; is a coding agent from OpenAI that runs locally on your computer. &lt;br /&gt; &lt;br /&gt;If you want Codex in your code editor (VS Code, Cursor, Windsurf), &lt;a href="https://developers.openai.com/codex/ide"&gt;install in your IDE&lt;/a&gt; &lt;br /&gt;If you are looking for the &lt;em&gt;cloud-based agent&lt;/em&gt; from OpenAI, &lt;strong&gt;Codex Web&lt;/strong&gt;, go to &lt;a href="https://chatgpt.com/codex"&gt;chatgpt.com/codex&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/openai/codex/main/.github/codex-cli-splash.png" alt="Codex CLI splash" width="80%" /&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;h3&gt;Installing and running Codex CLI&lt;/h3&gt; 
&lt;p&gt;Install globally with your preferred package manager. If you use npm:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;npm install -g @openai/codex
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively, if you use Homebrew:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;brew install codex
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then simply run &lt;code&gt;codex&lt;/code&gt; to get started:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;codex
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;You can also go to the &lt;a href="https://github.com/openai/codex/releases/latest"&gt;latest GitHub Release&lt;/a&gt; and download the appropriate binary for your platform.&lt;/summary&gt; 
 &lt;p&gt;Each GitHub Release contains many executables, but in practice, you likely want one of these:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;macOS 
   &lt;ul&gt; 
    &lt;li&gt;Apple Silicon/arm64: &lt;code&gt;codex-aarch64-apple-darwin.tar.gz&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;x86_64 (older Mac hardware): &lt;code&gt;codex-x86_64-apple-darwin.tar.gz&lt;/code&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Linux 
   &lt;ul&gt; 
    &lt;li&gt;x86_64: &lt;code&gt;codex-x86_64-unknown-linux-musl.tar.gz&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;arm64: &lt;code&gt;codex-aarch64-unknown-linux-musl.tar.gz&lt;/code&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;Each archive contains a single entry with the platform baked into the name (e.g., &lt;code&gt;codex-x86_64-unknown-linux-musl&lt;/code&gt;), so you likely want to rename it to &lt;code&gt;codex&lt;/code&gt; after extracting it.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h3&gt;Using Codex with your ChatGPT plan&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/openai/codex/main/.github/codex-cli-login.png" alt="Codex CLI login" width="80%" /&gt; &lt;/p&gt; 
&lt;p&gt;Run &lt;code&gt;codex&lt;/code&gt; and select &lt;strong&gt;Sign in with ChatGPT&lt;/strong&gt;. We recommend signing into your ChatGPT account to use Codex as part of your Plus, Pro, Team, Edu, or Enterprise plan. &lt;a href="https://help.openai.com/en/articles/11369540-codex-in-chatgpt"&gt;Learn more about what's included in your ChatGPT plan&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can also use Codex with an API key, but this requires &lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/authentication.md#usage-based-billing-alternative-use-an-openai-api-key"&gt;additional setup&lt;/a&gt;. If you previously used an API key for usage-based billing, see the &lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/authentication.md#migrating-from-usage-based-billing-api-key"&gt;migration steps&lt;/a&gt;. If you're having trouble with login, please comment on &lt;a href="https://github.com/openai/codex/issues/1243"&gt;this issue&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Model Context Protocol (MCP)&lt;/h3&gt; 
&lt;p&gt;Codex CLI supports &lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/advanced.md#model-context-protocol-mcp"&gt;MCP servers&lt;/a&gt;. Enable by adding an &lt;code&gt;mcp_servers&lt;/code&gt; section to your &lt;code&gt;~/.codex/config.toml&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Configuration&lt;/h3&gt; 
&lt;p&gt;Codex CLI supports a rich set of configuration options, with preferences stored in &lt;code&gt;~/.codex/config.toml&lt;/code&gt;. For full configuration options, see &lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/config.md"&gt;Configuration&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Docs &amp;amp; FAQ&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/getting-started.md"&gt;&lt;strong&gt;Getting started&lt;/strong&gt;&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/getting-started.md#cli-usage"&gt;CLI usage&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/getting-started.md#running-with-a-prompt-as-input"&gt;Running with a prompt as input&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/getting-started.md#example-prompts"&gt;Example prompts&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/getting-started.md#memory-with-agentsmd"&gt;Memory with AGENTS.md&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/config.md"&gt;Configuration&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/sandbox.md"&gt;&lt;strong&gt;Sandbox &amp;amp; approvals&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/authentication.md"&gt;&lt;strong&gt;Authentication&lt;/strong&gt;&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/authentication.md#forcing-a-specific-auth-method-advanced"&gt;Auth methods&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/authentication.md#connecting-on-a-headless-machine"&gt;Login on a "Headless" machine&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/advanced.md"&gt;&lt;strong&gt;Advanced&lt;/strong&gt;&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/advanced.md#non-interactive--ci-mode"&gt;Non-interactive / CI mode&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/advanced.md#tracing--verbose-logging"&gt;Tracing / verbose logging&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/advanced.md#model-context-protocol-mcp"&gt;Model Context Protocol (MCP)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/zdr.md"&gt;&lt;strong&gt;Zero data retention (ZDR)&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/contributing.md"&gt;&lt;strong&gt;Contributing&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/install.md"&gt;&lt;strong&gt;Install &amp;amp; build&lt;/strong&gt;&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/install.md#system-requirements"&gt;System Requirements&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/install.md#dotslash"&gt;DotSlash&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/install.md#build-from-source"&gt;Build from source&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/faq.md"&gt;&lt;strong&gt;FAQ&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/open-source-fund.md"&gt;&lt;strong&gt;Open source fund&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This repository is licensed under the &lt;a href="https://raw.githubusercontent.com/openai/codex/main/LICENSE"&gt;Apache-2.0 License&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ItzCrazyKns/Perplexica</title>
      <link>https://github.com/ItzCrazyKns/Perplexica</link>
      <description>&lt;p&gt;Perplexica is an AI-powered search engine. It is an Open source alternative to Perplexity AI&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;üöÄ Perplexica - An AI-powered search engine üîé 
 &lt;!-- omit in toc --&gt;&lt;/h1&gt; 
&lt;div align="center" markdown="1"&gt; 
 &lt;sup&gt;Special thanks to:&lt;/sup&gt; 
 &lt;br /&gt; 
 &lt;br /&gt; 
 &lt;a href="https://www.warp.dev/perplexica"&gt; &lt;img alt="Warp sponsorship" width="400" src="https://github.com/user-attachments/assets/775dd593-9b5f-40f1-bf48-479faff4c27b" /&gt; &lt;/a&gt; 
 &lt;h3&gt;&lt;a href="https://www.warp.dev/perplexica"&gt;Warp, the AI Devtool that lives in your terminal&lt;/a&gt;&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://www.warp.dev/perplexica"&gt;Available for MacOS, Linux, &amp;amp; Windows&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;a href="https://discord.gg/26aArMy8tT"&gt;&lt;img src="https://dcbadge.limes.pink/api/server/26aArMy8tT?style=flat" alt="Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ItzCrazyKns/Perplexica/master/.assets/perplexica-screenshot.png?" alt="preview" /&gt;&lt;/p&gt; 
&lt;h2&gt;Table of Contents 
 &lt;!-- omit in toc --&gt;&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ItzCrazyKns/Perplexica/master/#overview"&gt;Overview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ItzCrazyKns/Perplexica/master/#preview"&gt;Preview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ItzCrazyKns/Perplexica/master/#features"&gt;Features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ItzCrazyKns/Perplexica/master/#installation"&gt;Installation&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ItzCrazyKns/Perplexica/master/#getting-started-with-docker-recommended"&gt;Getting Started with Docker (Recommended)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ItzCrazyKns/Perplexica/master/#non-docker-installation"&gt;Non-Docker Installation&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ItzCrazyKns/Perplexica/master/#ollama-connection-errors"&gt;Ollama Connection Errors&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ItzCrazyKns/Perplexica/master/#using-as-a-search-engine"&gt;Using as a Search Engine&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ItzCrazyKns/Perplexica/master/#using-perplexicas-api"&gt;Using Perplexica's API&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ItzCrazyKns/Perplexica/master/#expose-perplexica-to-network"&gt;Expose Perplexica to a network&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ItzCrazyKns/Perplexica/master/#one-click-deployment"&gt;One-Click Deployment&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ItzCrazyKns/Perplexica/master/#upcoming-features"&gt;Upcoming Features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ItzCrazyKns/Perplexica/master/#support-us"&gt;Support Us&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ItzCrazyKns/Perplexica/master/#donations"&gt;Donations&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ItzCrazyKns/Perplexica/master/#contribution"&gt;Contribution&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ItzCrazyKns/Perplexica/master/#help-and-support"&gt;Help and Support&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;Perplexica is an open-source AI-powered searching tool or an AI-powered search engine that goes deep into the internet to find answers. Inspired by Perplexity AI, it's an open-source option that not just searches the web but understands your questions. It uses advanced machine learning algorithms like similarity searching and embeddings to refine results and provides clear answers with sources cited.&lt;/p&gt; 
&lt;p&gt;Using SearxNG to stay current and fully open source, Perplexica ensures you always get the most up-to-date information without compromising your privacy.&lt;/p&gt; 
&lt;p&gt;Want to know more about its architecture and how it works? You can read it &lt;a href="https://github.com/ItzCrazyKns/Perplexica/tree/master/docs/architecture/README.md"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Preview&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ItzCrazyKns/Perplexica/master/.assets/perplexica-preview.gif" alt="video-preview" /&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Local LLMs&lt;/strong&gt;: You can utilize local LLMs such as Qwen, DeepSeek, Llama, and Mistral.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Two Main Modes:&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Copilot Mode:&lt;/strong&gt; (In development) Boosts search by generating different queries to find more relevant internet sources. Like normal search instead of just using the context by SearxNG, it visits the top matches and tries to find relevant sources to the user's query directly from the page.&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Normal Mode:&lt;/strong&gt; Processes your query and performs a web search.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Focus Modes:&lt;/strong&gt; Special modes to better answer specific types of questions. Perplexica currently has 6 focus modes: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;All Mode:&lt;/strong&gt; Searches the entire web to find the best results.&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Writing Assistant Mode:&lt;/strong&gt; Helpful for writing tasks that do not require searching the web.&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Academic Search Mode:&lt;/strong&gt; Finds articles and papers, ideal for academic research.&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;YouTube Search Mode:&lt;/strong&gt; Finds YouTube videos based on the search query.&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Wolfram Alpha Search Mode:&lt;/strong&gt; Answers queries that need calculations or data analysis using Wolfram Alpha.&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Reddit Search Mode:&lt;/strong&gt; Searches Reddit for discussions and opinions related to the query.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Current Information:&lt;/strong&gt; Some search tools might give you outdated info because they use data from crawling bots and convert them into embeddings and store them in a index. Unlike them, Perplexica uses SearxNG, a metasearch engine to get the results and rerank and get the most relevant source out of it, ensuring you always get the latest information without the overhead of daily data updates.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;API&lt;/strong&gt;: Integrate Perplexica into your existing applications and make use of its capibilities.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;It has many more features like image and video search. Some of the planned features are mentioned in &lt;a href="https://raw.githubusercontent.com/ItzCrazyKns/Perplexica/master/#upcoming-features"&gt;upcoming features&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;There are mainly 2 ways of installing Perplexica - With Docker, Without Docker. Using Docker is highly recommended.&lt;/p&gt; 
&lt;h3&gt;Getting Started with Docker (Recommended)&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Ensure Docker is installed and running on your system.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Clone the Perplexica repository:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/ItzCrazyKns/Perplexica.git
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;After cloning, navigate to the directory containing the project files.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Rename the &lt;code&gt;sample.config.toml&lt;/code&gt; file to &lt;code&gt;config.toml&lt;/code&gt;. For Docker setups, you need only fill in the following fields:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;&lt;code&gt;OPENAI&lt;/code&gt;: Your OpenAI API key. &lt;strong&gt;You only need to fill this if you wish to use OpenAI's models&lt;/strong&gt;.&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;code&gt;CUSTOM_OPENAI&lt;/code&gt;: Your OpenAI-API-compliant local server URL, model name, and API key. You should run your local server with host set to &lt;code&gt;0.0.0.0&lt;/code&gt;, take note of which port number it is running on, and then use that port number to set &lt;code&gt;API_URL = http://host.docker.internal:PORT_NUMBER&lt;/code&gt;. You must specify the model name, such as &lt;code&gt;MODEL_NAME = "unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF:Q4_K_XL"&lt;/code&gt;. Finally, set &lt;code&gt;API_KEY&lt;/code&gt; to the appropriate value. If you have not defined an API key, just put anything you want in-between the quotation marks: &lt;code&gt;API_KEY = "whatever-you-want-but-not-blank"&lt;/code&gt; &lt;strong&gt;You only need to configure these settings if you want to use a local OpenAI-compliant server, such as Llama.cpp's &lt;a href="https://github.com/ggml-org/llama.cpp/raw/master/tools/server/README.md"&gt;&lt;code&gt;llama-server&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;code&gt;OLLAMA&lt;/code&gt;: Your Ollama API URL. You should enter it as &lt;code&gt;http://host.docker.internal:PORT_NUMBER&lt;/code&gt;. If you installed Ollama on port 11434, use &lt;code&gt;http://host.docker.internal:11434&lt;/code&gt;. For other ports, adjust accordingly. &lt;strong&gt;You need to fill this if you wish to use Ollama's models instead of OpenAI's&lt;/strong&gt;.&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;code&gt;GROQ&lt;/code&gt;: Your Groq API key. &lt;strong&gt;You only need to fill this if you wish to use Groq's hosted models&lt;/strong&gt;.&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;code&gt;ANTHROPIC&lt;/code&gt;: Your Anthropic API key. &lt;strong&gt;You only need to fill this if you wish to use Anthropic models&lt;/strong&gt;.&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;code&gt;Gemini&lt;/code&gt;: Your Gemini API key. &lt;strong&gt;You only need to fill this if you wish to use Google's models&lt;/strong&gt;.&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;code&gt;DEEPSEEK&lt;/code&gt;: Your Deepseek API key. &lt;strong&gt;Only needed if you want Deepseek models.&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;code&gt;AIMLAPI&lt;/code&gt;: Your AI/ML API key. &lt;strong&gt;Only needed if you want to use AI/ML API models and embeddings.&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: You can change these after starting Perplexica from the settings dialog.&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;code&gt;SIMILARITY_MEASURE&lt;/code&gt;: The similarity measure to use (This is filled by default; you can leave it as is if you are unsure about it.)&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Ensure you are in the directory containing the &lt;code&gt;docker-compose.yaml&lt;/code&gt; file and execute:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;docker compose up -d
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Wait a few minutes for the setup to complete. You can access Perplexica at &lt;a href="http://localhost:3000"&gt;http://localhost:3000&lt;/a&gt; in your web browser.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: After the containers are built, you can start Perplexica directly from Docker without having to open a terminal.&lt;/p&gt; 
&lt;h3&gt;Non-Docker Installation&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install SearXNG and allow &lt;code&gt;JSON&lt;/code&gt; format in the SearXNG settings.&lt;/li&gt; 
 &lt;li&gt;Clone the repository and rename the &lt;code&gt;sample.config.toml&lt;/code&gt; file to &lt;code&gt;config.toml&lt;/code&gt; in the root directory. Ensure you complete all required fields in this file.&lt;/li&gt; 
 &lt;li&gt;After populating the configuration run &lt;code&gt;npm i&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Install the dependencies and then execute &lt;code&gt;npm run build&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Finally, start the app by running &lt;code&gt;npm run start&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Using Docker is recommended as it simplifies the setup process, especially for managing environment variables and dependencies.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/ItzCrazyKns/Perplexica/tree/master/docs/installation"&gt;installation documentation&lt;/a&gt; for more information like updating, etc.&lt;/p&gt; 
&lt;h3&gt;Troubleshooting&lt;/h3&gt; 
&lt;h4&gt;Local OpenAI-API-Compliant Servers&lt;/h4&gt; 
&lt;p&gt;If Perplexica tells you that you haven't configured any chat model providers, ensure that:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Your server is running on &lt;code&gt;0.0.0.0&lt;/code&gt; (not &lt;code&gt;127.0.0.1&lt;/code&gt;) and on the same port you put in the API URL.&lt;/li&gt; 
 &lt;li&gt;You have specified the correct model name loaded by your local LLM server.&lt;/li&gt; 
 &lt;li&gt;You have specified the correct API key, or if one is not defined, you have put &lt;em&gt;something&lt;/em&gt; in the API key field and not left it empty.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Ollama Connection Errors&lt;/h4&gt; 
&lt;p&gt;If you're encountering an Ollama connection error, it is likely due to the backend being unable to connect to Ollama's API. To fix this issue you can:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Check your Ollama API URL:&lt;/strong&gt; Ensure that the API URL is correctly set in the settings menu.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Update API URL Based on OS:&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Windows:&lt;/strong&gt; Use &lt;code&gt;http://host.docker.internal:11434&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Mac:&lt;/strong&gt; Use &lt;code&gt;http://host.docker.internal:11434&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Linux:&lt;/strong&gt; Use &lt;code&gt;http://&amp;lt;private_ip_of_host&amp;gt;:11434&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;Adjust the port number if you're using a different one.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Linux Users - Expose Ollama to Network:&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;Inside &lt;code&gt;/etc/systemd/system/ollama.service&lt;/code&gt;, you need to add &lt;code&gt;Environment="OLLAMA_HOST=0.0.0.0:11434"&lt;/code&gt;. (Change the port number if you are using a different one.) Then reload the systemd manager configuration with &lt;code&gt;systemctl daemon-reload&lt;/code&gt;, and restart Ollama by &lt;code&gt;systemctl restart ollama&lt;/code&gt;. For more information see &lt;a href="https://github.com/ollama/ollama/raw/main/docs/faq.md#setting-environment-variables-on-linux"&gt;Ollama docs&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Ensure that the port (default is 11434) is not blocked by your firewall.&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Using as a Search Engine&lt;/h2&gt; 
&lt;p&gt;If you wish to use Perplexica as an alternative to traditional search engines like Google or Bing, or if you want to add a shortcut for quick access from your browser's search bar, follow these steps:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Open your browser's settings.&lt;/li&gt; 
 &lt;li&gt;Navigate to the 'Search Engines' section.&lt;/li&gt; 
 &lt;li&gt;Add a new site search with the following URL: &lt;code&gt;http://localhost:3000/?q=%s&lt;/code&gt;. Replace &lt;code&gt;localhost&lt;/code&gt; with your IP address or domain name, and &lt;code&gt;3000&lt;/code&gt; with the port number if Perplexica is not hosted locally.&lt;/li&gt; 
 &lt;li&gt;Click the add button. Now, you can use Perplexica directly from your browser's search bar.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Using Perplexica's API&lt;/h2&gt; 
&lt;p&gt;Perplexica also provides an API for developers looking to integrate its powerful search engine into their own applications. You can run searches, use multiple models and get answers to your queries.&lt;/p&gt; 
&lt;p&gt;For more details, check out the full documentation &lt;a href="https://github.com/ItzCrazyKns/Perplexica/tree/master/docs/API/SEARCH.md"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Expose Perplexica to network&lt;/h2&gt; 
&lt;p&gt;Perplexica runs on Next.js and handles all API requests. It works right away on the same network and stays accessible even with port forwarding.&lt;/p&gt; 
&lt;h2&gt;One-Click Deployment&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://usw.sealos.io/?openapp=system-template%3FtemplateName%3Dperplexica"&gt;&lt;img src="https://raw.githubusercontent.com/labring-actions/templates/main/Deploy-on-Sealos.svg?sanitize=true" alt="Deploy to Sealos" /&gt;&lt;/a&gt; &lt;a href="https://repocloud.io/details/?app_id=267"&gt;&lt;img src="https://d16t0pc4846x52.cloudfront.net/deploylobe.svg?sanitize=true" alt="Deploy to RepoCloud" /&gt;&lt;/a&gt; &lt;a href="https://template.run.claw.cloud/?referralCode=U11MRQ8U9RM4&amp;amp;openapp=system-fastdeploy%3FtemplateName%3Dperplexica"&gt;&lt;img src="https://raw.githubusercontent.com/ClawCloud/Run-Template/refs/heads/main/Run-on-ClawCloud.svg?sanitize=true" alt="Run on ClawCloud" /&gt;&lt;/a&gt; &lt;a href="https://www.hostinger.com/vps/docker-hosting?compose_url=https://raw.githubusercontent.com/ItzCrazyKns/Perplexica/refs/heads/master/docker-compose.yaml"&gt;&lt;img src="https://assets.hostinger.com/vps/deploy.svg?sanitize=true" alt="Deploy on Hostinger" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Upcoming Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Add settings page&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Adding support for local LLMs&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; History Saving features&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Introducing various Focus Modes&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Adding API support&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Adding Discover&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Finalizing Copilot Mode&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Support Us&lt;/h2&gt; 
&lt;p&gt;If you find Perplexica useful, consider giving us a star on GitHub. This helps more people discover Perplexica and supports the development of new features. Your support is greatly appreciated.&lt;/p&gt; 
&lt;h3&gt;Donations&lt;/h3&gt; 
&lt;p&gt;We also accept donations to help sustain our project. If you would like to contribute, you can use the following options to donate. Thank you for your support!&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Ethereum&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Address: &lt;code&gt;0xB025a84b2F269570Eb8D4b05DEdaA41D8525B6DD&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Contribution&lt;/h2&gt; 
&lt;p&gt;Perplexica is built on the idea that AI and large language models should be easy for everyone to use. If you find bugs or have ideas, please share them in via GitHub Issues. For more information on contributing to Perplexica you can read the &lt;a href="https://raw.githubusercontent.com/ItzCrazyKns/Perplexica/master/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; file to learn more about Perplexica and how you can contribute to it.&lt;/p&gt; 
&lt;h2&gt;Help and Support&lt;/h2&gt; 
&lt;p&gt;If you have any questions or feedback, please feel free to reach out to us. You can create an issue on GitHub or join our Discord server. There, you can connect with other users, share your experiences and reviews, and receive more personalized help. &lt;a href="https://discord.gg/EFwsmQDgAu"&gt;Click here&lt;/a&gt; to join the Discord server. To discuss matters outside of regular support, feel free to contact me on Discord at &lt;code&gt;itzcrazykns&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Thank you for exploring Perplexica, the AI-powered search engine designed to enhance your search experience. We are constantly working to improve Perplexica and expand its capabilities. We value your feedback and contributions which help us make Perplexica even better. Don't forget to check back for updates and new features!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>WebKit/WebKit</title>
      <link>https://github.com/WebKit/WebKit</link>
      <description>&lt;p&gt;Home of the WebKit project, the browser engine used by Safari, Mail, App Store and many other applications on macOS, iOS and Linux.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;WebKit&lt;/h1&gt; 
&lt;p&gt;WebKit is a cross-platform web browser engine. On iOS and macOS, it powers Safari, Mail, Apple Books, and many other applications. For more information about WebKit, see the &lt;a href="https://webkit.org/"&gt;WebKit project website&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Trying the Latest&lt;/h2&gt; 
&lt;p&gt;On macOS, &lt;a href="https://webkit.org/downloads/"&gt;download Safari Technology Preview&lt;/a&gt; to test the latest version of WebKit. On Linux, download &lt;a href="https://webkitgtk.org/epiphany-tech-preview"&gt;Epiphany Technology Preview&lt;/a&gt;. On Windows, you'll have to build it yourself.&lt;/p&gt; 
&lt;h2&gt;Reporting Bugs&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://bugs.webkit.org/query.cgi?format=specific&amp;amp;product=WebKit"&gt;Search WebKit Bugzilla&lt;/a&gt; to see if there is an existing report for the bug you've encountered.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://bugs.webkit.org/createaccount.cgi"&gt;Create a Bugzilla account&lt;/a&gt; to report bugs (and comment on them) if you haven't done so already.&lt;/li&gt; 
 &lt;li&gt;File a bug in accordance with &lt;a href="https://webkit.org/bug-report-guidelines/"&gt;our guidelines&lt;/a&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Once your bug is filed, you will receive email when it is updated at each stage in the &lt;a href="https://webkit.org/bug-life-cycle"&gt;bug life cycle&lt;/a&gt;. After the bug is considered fixed, you may be asked to download the &lt;a href="https://webkit.org/nightly"&gt;latest nightly&lt;/a&gt; and confirm that the fix works for you.&lt;/p&gt; 
&lt;h2&gt;Getting the Code&lt;/h2&gt; 
&lt;p&gt;Run the following command to clone WebKit's Git repository:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/WebKit/WebKit.git WebKit
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can enable &lt;a href="https://git-scm.com/docs/git-config#Documentation/git-config.txt-corefsmonitor"&gt;git fsmonitor&lt;/a&gt; to make many git commands faster (such as &lt;code&gt;git status&lt;/code&gt;) with &lt;code&gt;git config core.fsmonitor true&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;Building WebKit&lt;/h2&gt; 
&lt;h3&gt;Building for Apple platforms&lt;/h3&gt; 
&lt;p&gt;Install Xcode and its command line tools if you haven't done so already:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Install Xcode&lt;/strong&gt; Get Xcode from &lt;a href="https://developer.apple.com/downloads"&gt;https://developer.apple.com/downloads&lt;/a&gt;. To build WebKit for OS X, Xcode 5.1.1 or later is required. To build WebKit for iOS Simulator, Xcode 7 or later is required.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Install the Xcode Command Line Tools&lt;/strong&gt; In Terminal, run the command: &lt;code&gt;xcode-select --install&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Run the following command to build a macOS debug build with debugging symbols and assertions:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Tools/Scripts/build-webkit --debug
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For performance testing, and other purposes, use &lt;code&gt;--release&lt;/code&gt; instead. If you also need debug symbols (dSYMs), run:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Tools/Scripts/build-webkit --release DEBUG_INFORMATION_FORMAT=dwarf-with-dsym 
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Embedded Builds&lt;/h4&gt; 
&lt;p&gt;To build for an embedded platform like iOS, tvOS, or watchOS, pass a platform argument to &lt;code&gt;build-webkit&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;For example, to build a debug build with debugging symbols and assertions for embedded simulators:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Tools/Scripts/build-webkit --debug --&amp;lt;platform&amp;gt;-simulator
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or embedded devices:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Tools/Scripts/build-webkit --debug --&amp;lt;platform&amp;gt;-device
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;where &lt;code&gt;platform&lt;/code&gt; is &lt;code&gt;ios&lt;/code&gt;, &lt;code&gt;tvos&lt;/code&gt; or &lt;code&gt;watchos&lt;/code&gt;.&lt;/p&gt; 
&lt;h4&gt;Using Xcode&lt;/h4&gt; 
&lt;p&gt;You can open &lt;code&gt;WebKit.xcworkspace&lt;/code&gt; to build and debug WebKit within Xcode. Select the "Everything up to WebKit + Tools" scheme to build the entire project.&lt;/p&gt; 
&lt;p&gt;If you don't use a custom build location in Xcode preferences, you have to update the workspace settings to use &lt;code&gt;WebKitBuild&lt;/code&gt; directory. In menu bar, choose File &amp;gt; Workspace Settings, then click the Advanced button, select "Custom", "Relative to Workspace", and enter &lt;code&gt;WebKitBuild&lt;/code&gt; for both Products and Intermediates.&lt;/p&gt; 
&lt;h3&gt;Building the GTK Port&lt;/h3&gt; 
&lt;p&gt;For production builds:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;cmake -DPORT=GTK -DCMAKE_BUILD_TYPE=RelWithDebInfo -GNinja
ninja
sudo ninja install
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For development builds:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Tools/gtk/install-dependencies
Tools/Scripts/update-webkitgtk-libs
Tools/Scripts/build-webkit --gtk --debug
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more information on building WebKitGTK, see the &lt;a href="https://trac.webkit.org/wiki/BuildingGtk"&gt;wiki page&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Building the WPE Port&lt;/h3&gt; 
&lt;p&gt;For production builds:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;cmake -DPORT=WPE -DCMAKE_BUILD_TYPE=RelWithDebInfo -GNinja
ninja
sudo ninja install
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For development builds:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Tools/wpe/install-dependencies
Tools/Scripts/update-webkitwpe-libs
Tools/Scripts/build-webkit --wpe --debug
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Building Windows Port&lt;/h3&gt; 
&lt;p&gt;For building WebKit on Windows, see the &lt;a href="https://docs.webkit.org/Ports/WindowsPort.html"&gt;WebKit on Windows page&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Running WebKit&lt;/h2&gt; 
&lt;h3&gt;With Safari and Other macOS Applications&lt;/h3&gt; 
&lt;p&gt;Run the following command to launch Safari with your local build of WebKit:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Tools/Scripts/run-safari --debug
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;code&gt;run-safari&lt;/code&gt; script sets the &lt;code&gt;DYLD_FRAMEWORK_PATH&lt;/code&gt; environment variable to point to your build products, and then launches &lt;code&gt;/Applications/Safari.app&lt;/code&gt;. &lt;code&gt;DYLD_FRAMEWORK_PATH&lt;/code&gt; tells the system loader to prefer your build products over the frameworks installed in &lt;code&gt;/System/Library/Frameworks&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;To run other applications with your local build of WebKit, run the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Tools/Scripts/run-webkit-app &amp;lt;application-path&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;iOS Simulator&lt;/h3&gt; 
&lt;p&gt;Run the following command to launch iOS simulator with your local build of WebKit:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;run-safari --debug --ios-simulator
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In both cases, if you have built release builds instead, use &lt;code&gt;--release&lt;/code&gt; instead of &lt;code&gt;--debug&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;To run other applications, for example MobileMiniBrowser, with your local build of WebKit, run the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;Tools/Scripts/run-webkit-app --debug --iphone-simulator &amp;lt;application-path&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Using Xcode&lt;/h4&gt; 
&lt;p&gt;Open &lt;code&gt;WebKit.xcworkspace&lt;/code&gt;, select intended scheme such as MobileMiniBrowser and an iOS simulator as target, click run.&lt;/p&gt; 
&lt;h3&gt;Linux Ports&lt;/h3&gt; 
&lt;p&gt;If you have a development build, you can use the &lt;code&gt;run-minibrowser&lt;/code&gt; script, e.g.:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;run-minibrowser --debug --wpe
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Pass one of &lt;code&gt;--gtk&lt;/code&gt;, &lt;code&gt;--jsc-only&lt;/code&gt;, or &lt;code&gt;--wpe&lt;/code&gt; to indicate the port to use.&lt;/p&gt; 
&lt;h2&gt;Contribute&lt;/h2&gt; 
&lt;p&gt;Congratulations! You‚Äôre up and running. Now you can begin coding in WebKit and contribute your fixes and new features to the project. For details on submitting your code to the project, read &lt;a href="https://webkit.org/contributing-code/"&gt;Contributing Code&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>nocodb/nocodb</title>
      <link>https://github.com/nocodb/nocodb</link>
      <description>&lt;p&gt;üî• üî• üî• Open Source Airtable Alternative&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center" style="border-bottom: none"&gt; 
 &lt;div&gt; 
  &lt;a style="color:#36f" href="https://www.nocodb.com"&gt; &lt;img src="https://raw.githubusercontent.com/nocodb/nocodb/develop/packages/nc-gui/assets/img/brand/nocodb-full.png" height="80" /&gt; &lt;br /&gt; The Open Source Airtable Alternative &lt;/a&gt; 
  &lt;br /&gt; 
 &lt;/div&gt; &lt;/h1&gt; 
&lt;p align="center"&gt; NocoDB is the fastest and easiest way to build databases online. &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="http://www.nocodb.com"&gt;&lt;b&gt;Website&lt;/b&gt;&lt;/a&gt; ‚Ä¢ &lt;a href="https://discord.gg/5RgZmkW"&gt;&lt;b&gt;Discord&lt;/b&gt;&lt;/a&gt; ‚Ä¢ &lt;a href="https://community.nocodb.com/"&gt;&lt;b&gt;Community&lt;/b&gt;&lt;/a&gt; ‚Ä¢ &lt;a href="https://twitter.com/nocodb"&gt;&lt;b&gt;Twitter&lt;/b&gt;&lt;/a&gt; ‚Ä¢ &lt;a href="https://www.reddit.com/r/NocoDB/"&gt;&lt;b&gt;Reddit&lt;/b&gt;&lt;/a&gt; ‚Ä¢ &lt;a href="https://docs.nocodb.com/"&gt;&lt;b&gt;Documentation&lt;/b&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/nocodb/nocodb/assets/86527202/e2fad786-f211-4dcb-9bd3-aaece83a6783" alt="video avi" /&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/markdown/readme/languages/chinese.md"&gt;&lt;img height="38" src="https://user-images.githubusercontent.com/61551451/135263434-75fe793d-42af-49e4-b964-d70920e41655.png" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/markdown/readme/languages/french.md"&gt;&lt;img height="38" src="https://user-images.githubusercontent.com/61551451/135263474-787d71e7-3a87-42a8-92a8-be1d1f55413d.png" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/markdown/readme/languages/german.md"&gt;&lt;img height="38" src="https://user-images.githubusercontent.com/61551451/135263531-fae58600-6616-4b43-95a0-5891019dd35d.png" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/markdown/readme/languages/spanish.md"&gt;&lt;img height="38" src="https://user-images.githubusercontent.com/61551451/135263589-3dbeda9a-0d2e-4bbd-b1fc-691404bb74fb.png" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/markdown/readme/languages/portuguese.md"&gt;&lt;img height="38" src="https://user-images.githubusercontent.com/61551451/135263669-f567196a-d4e8-4143-a80a-93d3be32ba90.png" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/markdown/readme/languages/italian.md"&gt;&lt;img height="38" src="https://user-images.githubusercontent.com/61551451/135263707-ba4e04a4-268a-4626-91b8-048e572fd9f6.png" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/markdown/readme/languages/japanese.md"&gt;&lt;img height="38" src="https://user-images.githubusercontent.com/61551451/135263770-38e3e79d-11d4-472e-ac27-ae0f17cf65c4.png" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/markdown/readme/languages/korean.md"&gt;&lt;img height="38" src="https://user-images.githubusercontent.com/61551451/135263822-28fce9de-915a-44dc-962d-7a61d340e91d.png" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/markdown/readme/languages/russian.md"&gt;&lt;img height="38" src="https://user-images.githubusercontent.com/61551451/135263888-151d4ad1-7084-4943-97c9-56f28cd40b80.png" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt;&lt;a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/markdown/readme/languages/README.md"&gt;&lt;b&gt;See other languages ¬ª&lt;/b&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;img src="https://static.scarf.sh/a.png?x-pxid=c12a77cc-855e-4602-8a0f-614b2d0da56a" /&gt; 
&lt;h1&gt;Join Our Community&lt;/h1&gt; 
&lt;a href="https://discord.gg/5RgZmkW" target="_blank"&gt; &lt;img src="https://discordapp.com/api/guilds/661905455894888490/widget.png?style=banner3" alt="" /&gt; &lt;/a&gt; 
&lt;p&gt;&lt;a href="https://github.com/nocodb/nocodb/stargazers"&gt;&lt;img src="http://reporoster.com/stars/nocodb/nocodb" alt="Stargazers repo roster for @nocodb/nocodb" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Installation&lt;/h1&gt; 
&lt;h2&gt;Docker with SQLite&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d \
  --name noco \
  -v "$(pwd)"/nocodb:/usr/app/data/ \
  -p 8080:8080 \
  nocodb/nocodb:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Docker with PG&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d \
  --name noco \
  -v "$(pwd)"/nocodb:/usr/app/data/ \
  -p 8080:8080 \
  -e NC_DB="pg://host.docker.internal:5432?u=root&amp;amp;p=password&amp;amp;d=d1" \
  -e NC_AUTH_JWT_SECRET="569a1821-0a93-45e8-87ab-eb857f20a010" \
  nocodb/nocodb:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Auto-upstall&lt;/h2&gt; 
&lt;p&gt;Auto-upstall is a single command that sets up NocoDB on a server for production usage. Behind the scenes it auto-generates docker-compose for you.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;bash &amp;lt;(curl -sSL http://install.nocodb.com/noco.sh) &amp;lt;(mktemp)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Auto-upstall does the following: üïä&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üê≥ Automatically installs all pre-requisites like docker, docker-compose&lt;/li&gt; 
 &lt;li&gt;üöÄ Automatically installs NocoDB with PostgreSQL, Redis, Minio, Traefik gateway using Docker Compose. üêò üóÑÔ∏è üåê&lt;/li&gt; 
 &lt;li&gt;üîÑ Automatically upgrades NocoDB to the latest version when you run the command again.&lt;/li&gt; 
 &lt;li&gt;üîí Automatically setups SSL and also renews it. Needs a domain or subdomain as input while installation.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;install.nocodb.com/noco.sh script can be found &lt;a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/docker-compose/1_Auto_Upstall/noco.sh"&gt;here in our github&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Other Methods&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Binaries are only for quick testing locally.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Install Method&lt;/th&gt; 
   &lt;th&gt;Command to install&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;üçè MacOS arm64 &lt;br /&gt;(Binary)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;curl http://get.nocodb.com/macos-arm64 -o nocodb -L &amp;amp;&amp;amp; chmod +x nocodb &amp;amp;&amp;amp; ./nocodb&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;üçè MacOS x64 &lt;br /&gt;(Binary)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;curl http://get.nocodb.com/macos-x64 -o nocodb -L &amp;amp;&amp;amp; chmod +x nocodb &amp;amp;&amp;amp; ./nocodb&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;üêß Linux arm64 &lt;br /&gt;(Binary)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;curl http://get.nocodb.com/linux-arm64 -o nocodb -L &amp;amp;&amp;amp; chmod +x nocodb &amp;amp;&amp;amp; ./nocodb&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;üêß Linux x64 &lt;br /&gt;(Binary)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;curl http://get.nocodb.com/linux-x64 -o nocodb -L &amp;amp;&amp;amp; chmod +x nocodb &amp;amp;&amp;amp; ./nocodb&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ü™ü Windows arm64 &lt;br /&gt;(Binary)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;iwr http://get.nocodb.com/win-arm64.exe -OutFile Noco-win-arm64.exe &amp;amp;&amp;amp; .\Noco-win-arm64.exe&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ü™ü Windows x64 &lt;br /&gt;(Binary)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;iwr http://get.nocodb.com/win-x64.exe -OutFile Noco-win-x64.exe &amp;amp;&amp;amp; .\Noco-win-x64.exe&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;When running locally access nocodb by visiting: &lt;a href="http://localhost:8080/dashboard"&gt;http://localhost:8080/dashboard&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;For more installation methods, please refer to &lt;a href="https://docs.nocodb.com/category/installation"&gt;our docs&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Screenshots&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://github.com/nocodb/nocodb/assets/86527202/a127c05e-2121-4af2-a342-128e0e2d0291" alt="2" /&gt; &lt;img src="https://github.com/nocodb/nocodb/assets/86527202/674da952-8a06-4848-a0e8-a7b02d5f5c88" alt="3" /&gt; &lt;img src="https://github.com/nocodb/nocodb/assets/86527202/cbc5152a-9caf-4f77-a8f7-92a9d06d025b" alt="4" /&gt; &lt;img src="https://github.com/nocodb/nocodb/assets/86527202/dc75dfdc-c486-4f5a-a853-2a8f9e6b569a" alt="5" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/35857179/194844886-a17006e0-979d-493f-83c4-0e72f5a9b716.png" alt="5" /&gt; &lt;img src="https://github.com/nocodb/nocodb/assets/86527202/be64e619-7295-43e2-aa95-cace4462b17f" alt="7" /&gt; &lt;img src="https://github.com/nocodb/nocodb/assets/86527202/4538bf5a-371f-4ec1-a867-8197e5824286" alt="8" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/35857179/194844893-82d5e21b-ae61-41bd-9990-31ad659bf490.png" alt="8" /&gt; &lt;img src="https://user-images.githubusercontent.com/35857179/194844897-cfd79946-e413-4c97-b16d-eb4d7678bb79.png" alt="9" /&gt; &lt;img src="https://user-images.githubusercontent.com/35857179/194844902-c0122570-0dd5-41cf-a26f-6f8d71fefc99.png" alt="10" /&gt; &lt;img src="https://user-images.githubusercontent.com/35857179/194844903-c1e47f40-e782-4f5d-8dce-6449cc70b181.png" alt="11" /&gt; &lt;img src="https://user-images.githubusercontent.com/35857179/194844907-09277d3e-cbbf-465c-9165-6afc4161e279.png" alt="12" /&gt;&lt;/p&gt; 
&lt;h1&gt;Features&lt;/h1&gt; 
&lt;h3&gt;Rich Spreadsheet Interface&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚ö° &amp;nbsp;Basic Operations: Create, Read, Update and Delete Tables, Columns, and Rows&lt;/li&gt; 
 &lt;li&gt;‚ö° &amp;nbsp;Fields Operations: Sort, Filter, Group, Hide / Unhide Columns&lt;/li&gt; 
 &lt;li&gt;‚ö° &amp;nbsp;Multiple Views Types: Grid (By default), Gallery, Form, Kanban and Calendar View&lt;/li&gt; 
 &lt;li&gt;‚ö° &amp;nbsp;View Permissions Types: Collaborative Views, &amp;amp; Locked Views&lt;/li&gt; 
 &lt;li&gt;‚ö° &amp;nbsp;Share Bases / Views: either Public or Private (with Password Protected)&lt;/li&gt; 
 &lt;li&gt;‚ö° &amp;nbsp;Variant Cell Types: ID, Links, Lookup, Rollup, SingleLineText, Attachment, Currency, Formula, User, etc&lt;/li&gt; 
 &lt;li&gt;‚ö° &amp;nbsp;Access Control with Roles: Fine-grained Access Control at different levels&lt;/li&gt; 
 &lt;li&gt;‚ö° &amp;nbsp;and more ...&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;App Store for Workflow Automations&lt;/h3&gt; 
&lt;p&gt;We provide different integrations in three main categories. See &lt;a href="https://docs.nocodb.com/account-settings/oss-specific-details/#app-store" target="_blank"&gt;App Store&lt;/a&gt; for details.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚ö° &amp;nbsp;Chat: Slack, Discord, Mattermost, and etc&lt;/li&gt; 
 &lt;li&gt;‚ö° &amp;nbsp;Email: AWS SES, SMTP, MailerSend, and etc&lt;/li&gt; 
 &lt;li&gt;‚ö° &amp;nbsp;Storage: AWS S3, Google Cloud Storage, Minio, and etc&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Programmatic Access&lt;/h3&gt; 
&lt;p&gt;We provide the following ways to let users programmatically invoke actions. You can use a token (either JWT or Social Auth) to sign your requests for authorization to NocoDB.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚ö° &amp;nbsp;REST APIs&lt;/li&gt; 
 &lt;li&gt;‚ö° &amp;nbsp;NocoDB SDK&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Contributing&lt;/h1&gt; 
&lt;p&gt;Please refer to &lt;a href="https://github.com/nocodb/nocodb/raw/master/.github/CONTRIBUTING.md"&gt;Contribution Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Why are we building this?&lt;/h1&gt; 
&lt;p&gt;Most internet businesses equip themselves with either spreadsheet or a database to solve their business needs. Spreadsheets are used by Billion+ humans collaboratively every single day. However, we are way off working at similar speeds on databases which are way more powerful tools when it comes to computing. Attempts to solve this with SaaS offerings have meant horrible access controls, vendor lock-in, data lock-in, abrupt price changes &amp;amp; most importantly a glass ceiling on what's possible in the future.&lt;/p&gt; 
&lt;h1&gt;Our Mission&lt;/h1&gt; 
&lt;p&gt;Our mission is to provide the most powerful no-code interface for databases that is open source to every single internet business in the world. This would not only democratise access to a powerful computing tool but also bring forth a billion+ people who will have radical tinkering-and-building abilities on the internet.&lt;/p&gt; 
&lt;h1&gt;License&lt;/h1&gt; 
&lt;p&gt; This project is licensed under &lt;a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/LICENSE"&gt;AGPLv3&lt;/a&gt;. &lt;/p&gt; 
&lt;h1&gt;Contributors&lt;/h1&gt; 
&lt;p&gt;Thank you for your contributions! We appreciate all the contributions from the community.&lt;/p&gt; 
&lt;a href="https://github.com/nocodb/nocodb/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=nocodb/nocodb" /&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>category-labs/monad-bft</title>
      <link>https://github.com/category-labs/monad-bft</link>
      <description>&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Monad BFT&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://github.com/monad-crypto/monad-bft/actions/workflows/randomized.yml/badge.svg?branch=master" alt="Nightly Tests" /&gt;&lt;/p&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;This repository contains implementation for the Monad consensus client and JsonRpc server. Monad consensus collects transactions and produces blocks which are written to a ledger filestream. These blocks are consumed by Monad execution, which then updates the state of the blockchain. The &lt;a href="https://raw.githubusercontent.com/category-labs/monad-bft/master/monad-triedb/README.md"&gt;triedb&lt;/a&gt; is a database which stores block information and the blockchain state.&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;git submodule update --init --recursive
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Using Docker&lt;/h3&gt; 
&lt;p&gt;The most straightforward way to start a consensus client + an execution client + a JsonRpc server. Run the following:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;code&gt;cd docker/single-node&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;nets/run.sh&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Using Cargo&lt;/h3&gt; 
&lt;p&gt;To run a Monad consensus client, follow instructions &lt;a href="https://raw.githubusercontent.com/category-labs/monad-bft/master/monad-node/README.md"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To run a JsonRpc server, follow instructions &lt;a href="https://raw.githubusercontent.com/category-labs/monad-bft/master/monad-rpc/README.md"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Architecture&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-mermaid"&gt;sequenceDiagram
autonumber
    participant D as Driver
    box Purple Executor
    participant S as impl Stream
    participant E as impl Executor
    end
    participant State
    participant PersistenceLogger
    loop
    D -&amp;gt;&amp;gt;+ S: CALL next()
    Note over S: blocks until event ready
    S --&amp;gt;&amp;gt;- D: RETURN Event
    D -&amp;gt;&amp;gt; PersistenceLogger: CALL push(Event)
    D -&amp;gt;&amp;gt;+ State: CALL update(Event)
    Note over State: mutate state
    State --&amp;gt;&amp;gt;- D: RETURN Vec&amp;lt;Command&amp;gt;
    D -&amp;gt;&amp;gt; E: CALL exec(Vec&amp;lt;Command&amp;gt;)
    Note over E: apply side effects
    end
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>category-labs/monad</title>
      <link>https://github.com/category-labs/monad</link>
      <description>&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Monad Execution&lt;/h1&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;This repository contains the execution component of a Monad node. It handles the transaction processing for new blocks, and keeps track of the state of the blockchain. Consequently, this repository contains the source code for Category Labs' custom &lt;a href="https://docs.monad.xyz/monad-arch/execution/native-compilation"&gt;EVM implementation&lt;/a&gt;, its &lt;a href="https://docs.monad.xyz/monad-arch/execution/monaddb"&gt;database implementation&lt;/a&gt;, and the high-level &lt;a href="https://docs.monad.xyz/monad-arch/execution/parallel-execution"&gt;transaction scheduling&lt;/a&gt;. The other main repository is &lt;a href="https://github.com/category-labs/monad-bft"&gt;monad-bft&lt;/a&gt;, which contains the source code for the consensus component.&lt;/p&gt; 
&lt;h2&gt;Building the source code&lt;/h2&gt; 
&lt;h3&gt;Package requirements&lt;/h3&gt; 
&lt;p&gt;Execution has two kinds of dependencies on third-party libraries:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Self-managed&lt;/strong&gt;: execution's CMake build system will checkout most of its third-party dependencies as git submodules, and build them as part of its own build process, as CMake subprojects; this will happen automatically during the build, but you must run:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;git submodule update --init --recursive
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;after checking out this repository.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;System&lt;/strong&gt;: some dependencies are expected to already be part of the system in a default location, i.e., they are expected to come from the system's package manager. The primary development platform is Ubuntu, so the required packages use the Debian/Ubuntu package names; an up-to-date list of the required system dependencies can be found in the docker configuration file &lt;code&gt;docker/release.Dockerfile&lt;/code&gt; (you will need all the packages installed via the &lt;code&gt;apt install&lt;/code&gt; commands)&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Minimum development tool requirements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;gcc-15 or clang-19&lt;/li&gt; 
 &lt;li&gt;CMake 3.27&lt;/li&gt; 
 &lt;li&gt;Even when using clang, the only standard library supported is libstdc++; libc++ may work but it is not a tested platform&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;CPU compilation requirements&lt;/h3&gt; 
&lt;p&gt;As explained in the &lt;a href="https://docs.monad.xyz/monad-arch/hardware-requirements"&gt;hardware requirements&lt;/a&gt;, a Monad node requires a relatively recent CPU. Execution explicitly requires this to compile: it needs to emit machine code that is only supported on recent CPU models, for fast cryptographic operations.&lt;/p&gt; 
&lt;p&gt;The minimum ISA support corresponds to the &lt;a href="https://en.wikipedia.org/wiki/X86-64#Microarchitecture_levels"&gt;x86-64-v3&lt;/a&gt; feature level. Consequently, the minimum flag you must pass to the compiler is &lt;code&gt;-march=x86-64-v3&lt;/code&gt;, or alternatively &lt;code&gt;-march=haswell&lt;/code&gt; ("Haswell" was the codename of the first Intel CPU to support all of these features).&lt;/p&gt; 
&lt;p&gt;You may also pass any higher architecture level if you wish, although the compiled binary may not work on older CPUs. The execution docker files use &lt;code&gt;-march=haswell&lt;/code&gt; because it tries to maximize the number of systems the resulting binary can run on. If you are only running locally (i.e., the binary does not need to run anywhere else) use &lt;code&gt;-march=native&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Compiling the execution code&lt;/h3&gt; 
&lt;p&gt;First, change your working directory to the root directory of the execution git repository root and then run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;CC=gcc-15 CXX=g++-15 CFLAGS="-march=haswell" CXXFLAGS="-march=haswell" ASMFLAGS="-march=haswell" \
./scripts/configure.sh &amp;amp;&amp;amp; ./scripts/build.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The above command will do several things:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Use gcc-15 instead of the system's default compiler&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Emit machine code using Haswell-era CPU extensions&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run CMake, and generate a &lt;a href="https://ninja-build.org/"&gt;ninja&lt;/a&gt; build system in the &lt;code&gt;&amp;lt;path-to-execution-repo&amp;gt;/build&lt;/code&gt; directory with the &lt;a href="https://cmake.org/cmake/help/latest/variable/CMAKE_BUILD_TYPE.html"&gt;&lt;code&gt;CMAKE_BUILD_TYPE&lt;/code&gt;&lt;/a&gt; set to &lt;code&gt;RelWithDebInfo&lt;/code&gt; by default&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Build the CMake &lt;code&gt;all&lt;/code&gt; target, which builds everything&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The compiler and CPU options are injected via environment variables that are read by CMake. If you want debug binaries instead, you can also pass &lt;code&gt;CMAKE_BUILD_TYPE=Debug&lt;/code&gt; via the environment.&lt;/p&gt; 
&lt;p&gt;When finished, this will build all of the execution binaries. The main one is the execution daemon, &lt;code&gt;build/cmd/monad&lt;/code&gt;. This binary can provide block execution services for different EVM-compatible blockchains:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;When used as part of a Monad blockchain node, it behaves as the block execution service for the Category Labs consensus daemon (for details, see &lt;a href="https://raw.githubusercontent.com/category-labs/monad/main/docs/overview.md#how-is-execution-used"&gt;here&lt;/a&gt;); when running in this mode, Monad EVM extensions (e.g., Monad-style staking) are enabled&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;It can also replay the history of other EVM-compatible blockchains, by executing their historical blocks as inputs; a common developer workflow (and a good full system test) is to replay the history of the original Ethereum mainnet and verify that the computed Merkle roots match after each block&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You can also run the full test suite in parallel with:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;CTEST_PARALLEL_LEVEL=$(nproc) ctest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;A tour of execution&lt;/h2&gt; 
&lt;p&gt;To understand how the source code is organized, you should start by reading the execution &lt;a href="https://raw.githubusercontent.com/category-labs/monad/main/docs/overview.md"&gt;developer overview&lt;/a&gt;, which explains how execution and consensus fit together, and where in the source tree you can find different pieces of functionality.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>microsoft/markitdown</title>
      <link>https://github.com/microsoft/markitdown</link>
      <description>&lt;p&gt;Python tool for converting files and office documents to Markdown.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;MarkItDown&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://pypi.org/project/markitdown/"&gt;&lt;img src="https://img.shields.io/pypi/v/markitdown.svg?sanitize=true" alt="PyPI" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/pypi/dd/markitdown" alt="PyPI - Downloads" /&gt; &lt;a href="https://github.com/microsoft/autogen"&gt;&lt;img src="https://img.shields.io/badge/Built%20by-AutoGen%20Team-blue" alt="Built by AutoGen Team" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] MarkItDown now offers an MCP (Model Context Protocol) server for integration with LLM applications like Claude Desktop. See &lt;a href="https://github.com/microsoft/markitdown/tree/main/packages/markitdown-mcp"&gt;markitdown-mcp&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] Breaking changes between 0.0.1 to 0.1.0:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Dependencies are now organized into optional feature-groups (further details below). Use &lt;code&gt;pip install 'markitdown[all]'&lt;/code&gt; to have backward-compatible behavior.&lt;/li&gt; 
  &lt;li&gt;convert_stream() now requires a binary file-like object (e.g., a file opened in binary mode, or an io.BytesIO object). This is a breaking change from the previous version, where it previously also accepted text file-like objects, like io.StringIO.&lt;/li&gt; 
  &lt;li&gt;The DocumentConverter class interface has changed to read from file-like streams rather than file paths. &lt;em&gt;No temporary files are created anymore&lt;/em&gt;. If you are the maintainer of a plugin, or custom DocumentConverter, you likely need to update your code. Otherwise, if only using the MarkItDown class or CLI (as in these examples), you should not need to change anything.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;MarkItDown is a lightweight Python utility for converting various files to Markdown for use with LLMs and related text analysis pipelines. To this end, it is most comparable to &lt;a href="https://github.com/deanmalmgren/textract"&gt;textract&lt;/a&gt;, but with a focus on preserving important document structure and content as Markdown (including: headings, lists, tables, links, etc.) While the output is often reasonably presentable and human-friendly, it is meant to be consumed by text analysis tools -- and may not be the best option for high-fidelity document conversions for human consumption.&lt;/p&gt; 
&lt;p&gt;MarkItDown currently supports the conversion from:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;PDF&lt;/li&gt; 
 &lt;li&gt;PowerPoint&lt;/li&gt; 
 &lt;li&gt;Word&lt;/li&gt; 
 &lt;li&gt;Excel&lt;/li&gt; 
 &lt;li&gt;Images (EXIF metadata and OCR)&lt;/li&gt; 
 &lt;li&gt;Audio (EXIF metadata and speech transcription)&lt;/li&gt; 
 &lt;li&gt;HTML&lt;/li&gt; 
 &lt;li&gt;Text-based formats (CSV, JSON, XML)&lt;/li&gt; 
 &lt;li&gt;ZIP files (iterates over contents)&lt;/li&gt; 
 &lt;li&gt;Youtube URLs&lt;/li&gt; 
 &lt;li&gt;EPubs&lt;/li&gt; 
 &lt;li&gt;... and more!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Why Markdown?&lt;/h2&gt; 
&lt;p&gt;Markdown is extremely close to plain text, with minimal markup or formatting, but still provides a way to represent important document structure. Mainstream LLMs, such as OpenAI's GPT-4o, natively "&lt;em&gt;speak&lt;/em&gt;" Markdown, and often incorporate Markdown into their responses unprompted. This suggests that they have been trained on vast amounts of Markdown-formatted text, and understand it well. As a side benefit, Markdown conventions are also highly token-efficient.&lt;/p&gt; 
&lt;h2&gt;Prerequisites&lt;/h2&gt; 
&lt;p&gt;MarkItDown requires Python 3.10 or higher. It is recommended to use a virtual environment to avoid dependency conflicts.&lt;/p&gt; 
&lt;p&gt;With the standard Python installation, you can create and activate a virtual environment using the following commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python -m venv .venv
source .venv/bin/activate
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If using &lt;code&gt;uv&lt;/code&gt;, you can create a virtual environment with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv venv --python=3.12 .venv
source .venv/bin/activate
# NOTE: Be sure to use 'uv pip install' rather than just 'pip install' to install packages in this virtual environment
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you are using Anaconda, you can create a virtual environment with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;conda create -n markitdown python=3.12
conda activate markitdown
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;To install MarkItDown, use pip: &lt;code&gt;pip install 'markitdown[all]'&lt;/code&gt;. Alternatively, you can install it from the source:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone git@github.com:microsoft/markitdown.git
cd markitdown
pip install -e 'packages/markitdown[all]'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;h3&gt;Command-Line&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;markitdown path-to-file.pdf &amp;gt; document.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or use &lt;code&gt;-o&lt;/code&gt; to specify the output file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;markitdown path-to-file.pdf -o document.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also pipe content:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cat path-to-file.pdf | markitdown
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Optional Dependencies&lt;/h3&gt; 
&lt;p&gt;MarkItDown has optional dependencies for activating various file formats. Earlier in this document, we installed all optional dependencies with the &lt;code&gt;[all]&lt;/code&gt; option. However, you can also install them individually for more control. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install 'markitdown[pdf, docx, pptx]'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;will install only the dependencies for PDF, DOCX, and PPTX files.&lt;/p&gt; 
&lt;p&gt;At the moment, the following optional dependencies are available:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;[all]&lt;/code&gt; Installs all optional dependencies&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[pptx]&lt;/code&gt; Installs dependencies for PowerPoint files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[docx]&lt;/code&gt; Installs dependencies for Word files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[xlsx]&lt;/code&gt; Installs dependencies for Excel files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[xls]&lt;/code&gt; Installs dependencies for older Excel files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[pdf]&lt;/code&gt; Installs dependencies for PDF files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[outlook]&lt;/code&gt; Installs dependencies for Outlook messages&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[az-doc-intel]&lt;/code&gt; Installs dependencies for Azure Document Intelligence&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[audio-transcription]&lt;/code&gt; Installs dependencies for audio transcription of wav and mp3 files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[youtube-transcription]&lt;/code&gt; Installs dependencies for fetching YouTube video transcription&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Plugins&lt;/h3&gt; 
&lt;p&gt;MarkItDown also supports 3rd-party plugins. Plugins are disabled by default. To list installed plugins:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;markitdown --list-plugins
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To enable plugins use:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;markitdown --use-plugins path-to-file.pdf
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To find available plugins, search GitHub for the hashtag &lt;code&gt;#markitdown-plugin&lt;/code&gt;. To develop a plugin, see &lt;code&gt;packages/markitdown-sample-plugin&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Azure Document Intelligence&lt;/h3&gt; 
&lt;p&gt;To use Microsoft Document Intelligence for conversion:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;markitdown path-to-file.pdf -o document.md -d -e "&amp;lt;document_intelligence_endpoint&amp;gt;"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;More information about how to set up an Azure Document Intelligence Resource can be found &lt;a href="https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/how-to-guides/create-document-intelligence-resource?view=doc-intel-4.0.0"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Python API&lt;/h3&gt; 
&lt;p&gt;Basic usage in Python:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from markitdown import MarkItDown

md = MarkItDown(enable_plugins=False) # Set to True to enable plugins
result = md.convert("test.xlsx")
print(result.text_content)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Document Intelligence conversion in Python:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from markitdown import MarkItDown

md = MarkItDown(docintel_endpoint="&amp;lt;document_intelligence_endpoint&amp;gt;")
result = md.convert("test.pdf")
print(result.text_content)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To use Large Language Models for image descriptions (currently only for pptx and image files), provide &lt;code&gt;llm_client&lt;/code&gt; and &lt;code&gt;llm_model&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from markitdown import MarkItDown
from openai import OpenAI

client = OpenAI()
md = MarkItDown(llm_client=client, llm_model="gpt-4o", llm_prompt="optional custom prompt")
result = md.convert("example.jpg")
print(result.text_content)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Docker&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;docker build -t markitdown:latest .
docker run --rm -i markitdown:latest &amp;lt; ~/your-file.pdf &amp;gt; output.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit &lt;a href="https://cla.opensource.microsoft.com"&gt;https://cla.opensource.microsoft.com&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.&lt;/p&gt; 
&lt;p&gt;This project has adopted the &lt;a href="https://opensource.microsoft.com/codeofconduct/"&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;. For more information see the &lt;a href="https://opensource.microsoft.com/codeofconduct/faq/"&gt;Code of Conduct FAQ&lt;/a&gt; or contact &lt;a href="mailto:opencode@microsoft.com"&gt;opencode@microsoft.com&lt;/a&gt; with any additional questions or comments.&lt;/p&gt; 
&lt;h3&gt;How to Contribute&lt;/h3&gt; 
&lt;p&gt;You can help by looking at issues or helping review PRs. Any issue or PR is welcome, but we have also marked some as 'open for contribution' and 'open for reviewing' to help facilitate community contributions. These are of course just suggestions and you are welcome to contribute in any way you like.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;&lt;/th&gt; 
    &lt;th&gt;All&lt;/th&gt; 
    &lt;th&gt;Especially Needs Help from Community&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Issues&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://github.com/microsoft/markitdown/issues"&gt;All Issues&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://github.com/microsoft/markitdown/issues?q=is%3Aissue+is%3Aopen+label%3A%22open+for+contribution%22"&gt;Issues open for contribution&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;PRs&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://github.com/microsoft/markitdown/pulls"&gt;All PRs&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://github.com/microsoft/markitdown/pulls?q=is%3Apr+is%3Aopen+label%3A%22open+for+reviewing%22"&gt;PRs open for reviewing&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;h3&gt;Running Tests and Checks&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Navigate to the MarkItDown package:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;cd packages/markitdown
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Install &lt;code&gt;hatch&lt;/code&gt; in your environment and run tests:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;pip install hatch  # Other ways of installing hatch: https://hatch.pypa.io/dev/install/
hatch shell
hatch test
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;(Alternative) Use the Devcontainer which has all the dependencies installed:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;# Reopen the project in Devcontainer and run:
hatch test
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run pre-commit checks before submitting a PR: &lt;code&gt;pre-commit run --all-files&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Contributing 3rd-party Plugins&lt;/h3&gt; 
&lt;p&gt;You can also contribute by creating and sharing 3rd party plugins. See &lt;code&gt;packages/markitdown-sample-plugin&lt;/code&gt; for more details.&lt;/p&gt; 
&lt;h2&gt;Trademarks&lt;/h2&gt; 
&lt;p&gt;This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow &lt;a href="https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general"&gt;Microsoft's Trademark &amp;amp; Brand Guidelines&lt;/a&gt;. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party's policies.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>dataease/SQLBot</title>
      <link>https://github.com/dataease/SQLBot</link>
      <description>&lt;p&gt;Âü∫‰∫éÂ§ßÊ®°ÂûãÂíå RAG ÁöÑÊô∫ËÉΩÈóÆÊï∞Á≥ªÁªü„ÄÇText-to-SQL Generation via LLMs using RAG.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt;&lt;img src="https://resource-fit2cloud-com.oss-cn-hangzhou.aliyuncs.com/sqlbot/sqlbot.png" alt="SQLBot" width="300" /&gt;&lt;/p&gt; 
&lt;h3 align="center"&gt;Âü∫‰∫éÂ§ßÊ®°ÂûãÂíå RAG ÁöÑÊô∫ËÉΩÈóÆÊï∞Á≥ªÁªü&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/dataease/SQLBot/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/dataease/SQLBot" alt="Latest release" /&gt;&lt;/a&gt; &lt;a href="https://github.com/dataease/SQLBot"&gt;&lt;img src="https://img.shields.io/github/stars/dataease/SQLBot?color=%231890FF&amp;amp;style=flat-square" alt="Stars" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/dataease/SQLbot"&gt;&lt;img src="https://img.shields.io/docker/pulls/dataease/sqlbot?label=downloads" alt="Download" /&gt;&lt;/a&gt;&lt;br /&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;SQLBot ÊòØ‰∏ÄÊ¨æÂü∫‰∫éÂ§ßÊ®°ÂûãÂíå RAG ÁöÑÊô∫ËÉΩÈóÆÊï∞Á≥ªÁªü„ÄÇSQLBot ÁöÑ‰ºòÂäøÂåÖÊã¨Ôºö&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ÂºÄÁÆ±Âç≥Áî®&lt;/strong&gt;: Âè™ÈúÄÈÖçÁΩÆÂ§ßÊ®°ÂûãÂíåÊï∞ÊçÆÊ∫êÂç≥ÂèØÂºÄÂêØÈóÆÊï∞‰πãÊóÖÔºåÈÄöËøáÂ§ßÊ®°ÂûãÂíå RAG ÁöÑÁªìÂêàÊù•ÂÆûÁé∞È´òË¥®ÈáèÁöÑ text2sqlÔºõ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Êòì‰∫éÈõÜÊàê&lt;/strong&gt;: ÊîØÊåÅÂø´ÈÄüÂµåÂÖ•Âà∞Á¨¨‰∏âÊñπ‰∏öÂä°Á≥ªÁªüÔºå‰πüÊîØÊåÅË¢´ n8n„ÄÅMaxKB„ÄÅDify„ÄÅCoze Á≠â AI Â∫îÁî®ÂºÄÂèëÂπ≥Âè∞ÈõÜÊàêË∞ÉÁî®ÔºåËÆ©ÂêÑÁ±ªÂ∫îÁî®Âø´ÈÄüÊã•ÊúâÊô∫ËÉΩÈóÆÊï∞ËÉΩÂäõÔºõ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÂÆâÂÖ®ÂèØÊéß&lt;/strong&gt;: Êèê‰æõÂü∫‰∫éÂ∑•‰ΩúÁ©∫Èó¥ÁöÑËµÑÊ∫êÈöîÁ¶ªÊú∫Âà∂ÔºåËÉΩÂ§üÂÆûÁé∞ÁªÜÁ≤íÂ∫¶ÁöÑÊï∞ÊçÆÊùÉÈôêÊéßÂà∂„ÄÇ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Â∑•‰ΩúÂéüÁêÜ&lt;/h2&gt; 
&lt;img width="1189" height="624" alt="system-arch" src="https://github.com/user-attachments/assets/cde40783-369e-493e-bb59-44ce43c2e7c5" /&gt; 
&lt;h2&gt;Âø´ÈÄüÂºÄÂßã&lt;/h2&gt; 
&lt;h3&gt;ÂÆâË£ÖÈÉ®ÁΩ≤&lt;/h3&gt; 
&lt;p&gt;ÂáÜÂ§á‰∏ÄÂè∞ Linux ÊúçÂä°Âô®ÔºåÂÆâË£ÖÂ•Ω &lt;a href="https://docs.docker.com/get-docker/"&gt;Docker&lt;/a&gt;ÔºåÊâßË°å‰ª•‰∏ã‰∏ÄÈîÆÂÆâË£ÖËÑöÊú¨Ôºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d \
  --name sqlbot \
  --restart unless-stopped \
  -p 8000:8000 \
  -p 8001:8001 \
  -v ./data/sqlbot/excel:/opt/sqlbot/data/excel \
  -v ./data/sqlbot/images:/opt/sqlbot/images \
  -v ./data/sqlbot/logs:/opt/sqlbot/logs \
  -v ./data/postgresql:/var/lib/postgresql/data \
  --privileged=true \
  dataease/sqlbot
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;‰Ω†‰πüÂèØ‰ª•ÈÄöËøá &lt;a href="https://apps.fit2cloud.com/1panel"&gt;1Panel Â∫îÁî®ÂïÜÂ∫ó&lt;/a&gt; Âø´ÈÄüÈÉ®ÁΩ≤ SQLBot„ÄÇ&lt;/p&gt; 
&lt;p&gt;Â¶ÇÊûúÊòØÂÜÖÁΩëÁéØÂ¢ÉÔºå‰Ω†ÂèØ‰ª•ÈÄöËøá &lt;a href="https://community.fit2cloud.com/#/products/sqlbot/downloads"&gt;Á¶ªÁ∫øÂÆâË£ÖÂåÖÊñπÂºè&lt;/a&gt; ÈÉ®ÁΩ≤ SQLBot„ÄÇ&lt;/p&gt; 
&lt;h3&gt;ËÆøÈóÆÊñπÂºè&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Âú®ÊµèËßàÂô®‰∏≠ÊâìÂºÄ: http://&amp;lt;‰Ω†ÁöÑÊúçÂä°Âô®IP&amp;gt;:8000/&lt;/li&gt; 
 &lt;li&gt;Áî®Êà∑Âêç: admin&lt;/li&gt; 
 &lt;li&gt;ÂØÜÁ†Å: SQLBot@123456&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ËÅîÁ≥ªÊàë‰ª¨&lt;/h3&gt; 
&lt;p&gt;Â¶Ç‰Ω†ÊúâÊõ¥Â§öÈóÆÈ¢òÔºåÂèØ‰ª•Âä†ÂÖ•Êàë‰ª¨ÁöÑÊäÄÊúØ‰∫§ÊµÅÁæ§‰∏éÊàë‰ª¨‰∫§ÊµÅ„ÄÇ&lt;/p&gt; 
&lt;img width="180" height="180" alt="contact_me_qr" src="https://github.com/user-attachments/assets/2594ff29-5426-4457-b051-279855610030" /&gt; 
&lt;h2&gt;UI Â±ïÁ§∫&lt;/h2&gt;  
&lt;img alt="q&amp;amp;a" src="https://github.com/user-attachments/assets/55526514-52f3-4cfe-98ec-08a986259280" /&gt;  
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#dataease/sqlbot&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=dataease/sqlbot&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;È£ûËá¥‰∫ëÊóó‰∏ãÁöÑÂÖ∂‰ªñÊòéÊòüÈ°πÁõÆ&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dataease/dataease/"&gt;DataEase&lt;/a&gt; - ‰∫∫‰∫∫ÂèØÁî®ÁöÑÂºÄÊ∫ê BI Â∑•ÂÖ∑&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/1panel-dev/1panel/"&gt;1Panel&lt;/a&gt; - Áé∞‰ª£Âåñ„ÄÅÂºÄÊ∫êÁöÑ Linux ÊúçÂä°Âô®ËøêÁª¥ÁÆ°ÁêÜÈù¢Êùø&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/1panel-dev/MaxKB/"&gt;MaxKB&lt;/a&gt; - Âº∫Â§ßÊòìÁî®ÁöÑ‰ºÅ‰∏öÁ∫ßÊô∫ËÉΩ‰ΩìÂπ≥Âè∞&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jumpserver/jumpserver/"&gt;JumpServer&lt;/a&gt; - ÂπøÂèóÊ¨¢ËøéÁöÑÂºÄÊ∫êÂ†°ÂûíÊú∫&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/halo-dev/halo/"&gt;Halo&lt;/a&gt; - Âº∫Â§ßÊòìÁî®ÁöÑÂºÄÊ∫êÂª∫Á´ôÂ∑•ÂÖ∑&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/metersphere/metersphere/"&gt;MeterSphere&lt;/a&gt; - Êñ∞‰∏Ä‰ª£ÁöÑÂºÄÊ∫êÊåÅÁª≠ÊµãËØïÂ∑•ÂÖ∑&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Êú¨‰ªìÂ∫ìÈÅµÂæ™ &lt;a href="https://raw.githubusercontent.com/dataease/SQLBot/main/LICENSE"&gt;FIT2CLOUD Open Source License&lt;/a&gt; ÂºÄÊ∫êÂçèËÆÆÔºåËØ•ËÆ∏ÂèØËØÅÊú¨Ë¥®‰∏äÊòØ GPLv3Ôºå‰ΩÜÊúâ‰∏Ä‰∫õÈ¢ùÂ§ñÁöÑÈôêÂà∂„ÄÇ&lt;/p&gt; 
&lt;p&gt;‰Ω†ÂèØ‰ª•Âü∫‰∫é SQLBot ÁöÑÊ∫ê‰ª£Á†ÅËøõË°å‰∫åÊ¨°ÂºÄÂèëÔºå‰ΩÜÊòØÈúÄË¶ÅÈÅµÂÆà‰ª•‰∏ãËßÑÂÆöÔºö&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;‰∏çËÉΩÊõøÊç¢Âíå‰øÆÊîπ SQLBot ÁöÑ Logo ÂíåÁâàÊùÉ‰ø°ÊÅØÔºõ&lt;/li&gt; 
 &lt;li&gt;‰∫åÊ¨°ÂºÄÂèëÂêéÁöÑË°çÁîü‰ΩúÂìÅÂøÖÈ°ªÈÅµÂÆà GPL V3 ÁöÑÂºÄÊ∫ê‰πâÂä°„ÄÇ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Â¶ÇÈúÄÂïÜ‰∏öÊéàÊùÉÔºåËØ∑ËÅîÁ≥ª &lt;a href="mailto:support@fit2cloud.com"&gt;support@fit2cloud.com&lt;/a&gt; „ÄÇ&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>jordanbaird/Ice</title>
      <link>https://github.com/jordanbaird/Ice</link>
      <description>&lt;p&gt;Powerful menu bar manager for macOS&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/jordanbaird/Ice/main/Ice/Assets.xcassets/AppIcon.appiconset/icon_256x256.png" width="200" height="200" /&gt; 
 &lt;h1&gt;Ice&lt;/h1&gt; 
&lt;/div&gt; 
&lt;p&gt;Ice is a powerful menu bar management tool. While its primary function is hiding and showing menu bar items, it aims to cover a wide variety of additional features to make it one of the most versatile menu bar tools available.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/4423085c-4e4b-4f3d-ad0f-90a217c03470" alt="Banner" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/jordanbaird/Ice/releases/latest"&gt;&lt;img src="https://img.shields.io/badge/download-latest-brightgreen?style=flat-square" alt="Download" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/badge/platform-macOS-blue?style=flat-square" alt="Platform" /&gt; &lt;img src="https://img.shields.io/badge/requirements-macOS%2014%2B-fa4e49?style=flat-square" alt="Requirements" /&gt; &lt;a href="https://github.com/sponsors/jordanbaird"&gt;&lt;img src="https://img.shields.io/badge/Sponsor%20%E2%9D%A4%EF%B8%8F-8A2BE2?style=flat-square" alt="Sponsor" /&gt;&lt;/a&gt; &lt;a href="https://icemenubar.app"&gt;&lt;img src="https://img.shields.io/badge/Website-015FBA?style=flat-square" alt="Website" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/jordanbaird/Ice/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/jordanbaird/Ice?style=flat-square" alt="License" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Ice is currently in active development. Some features have not yet been implemented. Download the latest release &lt;a href="https://github.com/jordanbaird/Ice/releases/latest"&gt;here&lt;/a&gt; and see the roadmap below for upcoming features.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;a href="https://www.buymeacoffee.com/jordanbaird" target="_blank"&gt; &lt;img src="https://cdn.buymeacoffee.com/buttons/v2/default-yellow.png" alt="Buy Me A Coffee" style="height: 60px !important;width: 217px !important;" /&gt; &lt;/a&gt; 
&lt;h2&gt;Install&lt;/h2&gt; 
&lt;h3&gt;Manual Installation&lt;/h3&gt; 
&lt;p&gt;Download the "Ice.zip" file from the &lt;a href="https://github.com/jordanbaird/Ice/releases/latest"&gt;latest release&lt;/a&gt; and move the unzipped app into your &lt;code&gt;Applications&lt;/code&gt; folder.&lt;/p&gt; 
&lt;h3&gt;Homebrew&lt;/h3&gt; 
&lt;p&gt;Install Ice using the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;brew install --cask jordanbaird-ice
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Features/Roadmap&lt;/h2&gt; 
&lt;h3&gt;Menu bar item management&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Hide menu bar items&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; "Always-hidden" menu bar section&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Show hidden menu bar items when hovering over the menu bar&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Show hidden menu bar items when an empty area in the menu bar is clicked&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Show hidden menu bar items by scrolling or swiping in the menu bar&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Automatically rehide menu bar items&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Hide application menus when they overlap with shown menu bar items&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Drag and drop interface to arrange individual menu bar items&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Display hidden menu bar items in a separate bar (e.g. for MacBooks with the notch)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Search menu bar items&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Menu bar item spacing (BETA)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Profiles for menu bar layout&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Individual spacer items&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Menu bar item groups&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Show menu bar items when trigger conditions are met&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Menu bar appearance&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Menu bar tint (solid and gradient)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Menu bar shadow&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Menu bar border&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Custom menu bar shapes (rounded and/or split)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Remove background behind menu bar&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Rounded screen corners&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Different settings for light/dark mode&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Hotkeys&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Toggle individual menu bar sections&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Show the search panel&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Enable/disable the Ice Bar&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Show/hide section divider icons&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Toggle application menus&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Enable/disable auto rehide&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Temporarily show individual menu bar items&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Other&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Launch at login&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Automatic updates&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Menu bar widgets&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Why does Ice only support macOS 14 and later?&lt;/h2&gt; 
&lt;p&gt;Ice uses a number of system APIs that are available starting in macOS 14. As such, there are no plans to support earlier versions of macOS.&lt;/p&gt; 
&lt;h2&gt;Gallery&lt;/h2&gt; 
&lt;h4&gt;Show hidden menu bar items below the menu bar&lt;/h4&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/f1429589-6186-4e1b-8aef-592219d49b9b" alt="Ice Bar" /&gt;&lt;/p&gt; 
&lt;h4&gt;Drag-and-drop interface to arrange menu bar items&lt;/h4&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/095442ba-f2d0-4bb4-9632-91e26ef8d45b" alt="Menu Bar Layout" /&gt;&lt;/p&gt; 
&lt;h4&gt;Customize the menu bar's appearance&lt;/h4&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/8c22c185-c3d2-49bb-971e-e1fc17df04b3" alt="Menu Bar Appearance" /&gt;&lt;/p&gt; 
&lt;h4&gt;Menu bar item search&lt;/h4&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/d1a7df3a-4989-4077-a0b1-8e7d5a1ba5b8" alt="Menu Bar Item Search" /&gt;&lt;/p&gt; 
&lt;h4&gt;Custom menu bar item spacing&lt;/h4&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/b196aa7e-184a-4d4c-b040-502f4aae40a6" alt="Menu Bar Item Spacing" /&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Ice is available under the &lt;a href="https://raw.githubusercontent.com/jordanbaird/Ice/main/LICENSE"&gt;GPL-3.0 license&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>flutter/flutter</title>
      <link>https://github.com/flutter/flutter</link>
      <description>&lt;p&gt;Flutter makes it easy and fast to build beautiful apps for mobile and beyond&lt;/p&gt;&lt;hr&gt;&lt;a href="https://flutter.dev/"&gt; &lt;h1 align="center"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://storage.googleapis.com/cms-storage-bucket/6e19fee6b47b36ca613f.png" /&gt; 
   &lt;img alt="Flutter" src="https://storage.googleapis.com/cms-storage-bucket/c823e53b3a1a7b0d36a9.png" /&gt; 
  &lt;/picture&gt; &lt;/h1&gt; &lt;/a&gt; 
&lt;p&gt;&lt;a href="https://flutter-dashboard.appspot.com/#/build?repo=flutter"&gt;&lt;img src="https://flutter-dashboard.appspot.com/api/public/build-status-badge?repo=flutter" alt="Flutter CI Status" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/flutter/flutter/master/docs/contributing/Chat.md"&gt;&lt;img src="https://img.shields.io/discord/608014603317936148?logo=discord" alt="Discord badge" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/intent/follow?screen_name=flutterdev"&gt;&lt;img src="https://img.shields.io/twitter/follow/flutterdev.svg?style=social&amp;amp;label=Follow" alt="Twitter handle" /&gt;&lt;/a&gt; &lt;a href="https://bsky.app/profile/flutter.dev"&gt;&lt;img src="https://img.shields.io/badge/Bluesky-0285FF?logo=bluesky&amp;amp;logoColor=fff&amp;amp;label=Follow%20me%20on&amp;amp;color=0285FF" alt="BlueSky badge" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/flutter/flutter"&gt;&lt;img src="https://codecov.io/gh/flutter/flutter/branch/master/graph/badge.svg?token=11yDrJU2M2" alt="codecov" /&gt;&lt;/a&gt; &lt;a href="https://bestpractices.coreinfrastructure.org/projects/5631"&gt;&lt;img src="https://bestpractices.coreinfrastructure.org/projects/5631/badge" alt="CII Best Practices" /&gt;&lt;/a&gt; &lt;a href="https://slsa.dev"&gt;&lt;img src="https://slsa.dev/images/gh-badge-level1.svg?sanitize=true" alt="SLSA 1" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Flutter is Google's SDK for crafting beautiful, fast user experiences for mobile, web, and desktop from a single codebase. Flutter works with existing code, is used by developers and organizations around the world, and is free and open source.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://flutter.dev/get-started/"&gt;Install Flutter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.flutter.dev/"&gt;Flutter documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/flutter/flutter/master/docs/README.md"&gt;Development wiki&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/flutter/flutter/raw/main/CONTRIBUTING.md"&gt;Contributing to Flutter&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For announcements about new releases, follow the &lt;a href="https://groups.google.com/forum/#!forum/flutter-announce"&gt;flutter-announce@googlegroups.com&lt;/a&gt; mailing list. Our documentation also tracks &lt;a href="https://docs.flutter.dev/release/breaking-changes"&gt;breaking changes&lt;/a&gt; across releases.&lt;/p&gt; 
&lt;h2&gt;Terms of service&lt;/h2&gt; 
&lt;p&gt;The Flutter tool may occasionally download resources from Google servers. By downloading or using the Flutter SDK, you agree to the Google Terms of Service: &lt;a href="https://policies.google.com/terms"&gt;https://policies.google.com/terms&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;For example, when installed from GitHub (as opposed to from a prepackaged archive), the Flutter tool will download the Dart SDK from Google servers immediately when first run, as it is used to execute the &lt;code&gt;flutter&lt;/code&gt; tool itself. This will also occur when Flutter is upgraded (e.g. by running the &lt;code&gt;flutter upgrade&lt;/code&gt; command).&lt;/p&gt; 
&lt;h2&gt;About Flutter&lt;/h2&gt; 
&lt;p&gt;We think Flutter will help you create beautiful, fast apps, with a productive, extensible and open development model, whether you're targeting iOS or Android, web, Windows, macOS, Linux or embedding it as the UI toolkit for a platform of your choice.&lt;/p&gt; 
&lt;h3&gt;Beautiful user experiences&lt;/h3&gt; 
&lt;p&gt;We want to enable designers to deliver their full creative vision without being forced to water it down due to limitations of the underlying framework. Flutter's &lt;a href="https://docs.flutter.dev/resources/inside-flutter"&gt;layered architecture&lt;/a&gt; gives you control over every pixel on the screen and its powerful compositing capabilities let you overlay and animate graphics, video, text, and controls without limitation. Flutter includes a full &lt;a href="https://flutter.dev/widgets/"&gt;set of widgets&lt;/a&gt; that deliver pixel-perfect experiences whether you're building for iOS (&lt;a href="https://docs.flutter.dev/development/ui/widgets/cupertino"&gt;Cupertino&lt;/a&gt;) or other platforms (&lt;a href="https://docs.flutter.dev/development/ui/widgets/material"&gt;Material&lt;/a&gt;), along with support for customizing or creating entirely new visual components.&lt;/p&gt; 
&lt;p align="center"&gt;&lt;img src="https://github.com/flutter/website/raw/main/src/content/assets/images/docs/homepage/reflectly-hero-600px.png?raw=true" alt="Reflectly hero image" /&gt;&lt;/p&gt; 
&lt;h3&gt;Fast results&lt;/h3&gt; 
&lt;p&gt;Flutter is fast. It's powered by hardware-accelerated 2D graphics libraries like &lt;a href="https://skia.org/"&gt;Skia&lt;/a&gt; (which underpins Chrome and Android) and &lt;a href="https://docs.flutter.dev/perf/impeller"&gt;Impeller&lt;/a&gt;. We architected Flutter to support glitch-free, jank-free graphics at the native speed of your device.&lt;/p&gt; 
&lt;p&gt;Flutter code is powered by the world-class &lt;a href="https://dart.dev/"&gt;Dart platform&lt;/a&gt;, which enables compilation to 32-bit and 64-bit ARM machine code for iOS and Android, JavaScript and WebAssembly for the web, as well as Intel x64 and ARM for desktop devices.&lt;/p&gt; 
&lt;p align="center"&gt;&lt;img src="https://github.com/flutter/website/raw/main/src/content/assets/images/docs/homepage/dart-diagram-small.png?raw=true" alt="Dart diagram" /&gt;&lt;/p&gt; 
&lt;h3&gt;Productive development&lt;/h3&gt; 
&lt;p&gt;Flutter offers &lt;a href="https://docs.flutter.dev/development/tools/hot-reload"&gt;stateful hot reload&lt;/a&gt;, allowing you to make changes to your code and see the results instantly without restarting your app or losing its state.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://docs.flutter.dev/development/tools/hot-reload"&gt;&lt;img src="https://github.com/flutter/website/raw/main/src/content/assets/images/docs/tools/android-studio/hot-reload.gif?raw=true" alt="Hot reload animation" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Extensible and open model&lt;/h3&gt; 
&lt;p&gt;Flutter works with any development tool (or none at all), and also includes editor plug-ins for both &lt;a href="https://marketplace.visualstudio.com/items?itemName=Dart-Code.flutter"&gt;Visual Studio Code&lt;/a&gt; and &lt;a href="https://plugins.jetbrains.com/plugin/9212-flutter"&gt;IntelliJ / Android Studio&lt;/a&gt;. Flutter provides &lt;a href="https://pub.dev/flutter"&gt;tens of thousands of packages&lt;/a&gt; to speed your development, regardless of your target platform. And accessing other native code is easy, with support for both FFI (&lt;a href="https://docs.flutter.dev/development/platform-integration/android/c-interop"&gt;on Android&lt;/a&gt;, &lt;a href="https://docs.flutter.dev/development/platform-integration/ios/c-interop"&gt;on iOS&lt;/a&gt;, &lt;a href="https://docs.flutter.dev/development/platform-integration/macos/c-interop"&gt;on macOS&lt;/a&gt;, and &lt;a href="https://docs.flutter.dev/development/platform-integration/windows/building#integrating-with-windows"&gt;on Windows&lt;/a&gt;) as well as &lt;a href="https://docs.flutter.dev/development/platform-integration/platform-channels"&gt;platform-specific APIs&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Flutter is a fully open-source project, and we welcome contributions. Information on how to get started can be found in our &lt;a href="https://raw.githubusercontent.com/flutter/flutter/master/CONTRIBUTING.md"&gt;contributor guide&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>nanobrowser/nanobrowser</title>
      <link>https://github.com/nanobrowser/nanobrowser</link>
      <description>&lt;p&gt;Open-Source Chrome extension for AI-powered web automation. Run multi-agent workflows using your own LLM API key. Alternative to OpenAI Operator.&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; &lt;img src="https://github.com/user-attachments/assets/ec60b0c4-87ba-48f4-981a-c55ed0e8497b" height="100" width="375" alt="banner" /&gt;&lt;br /&gt; &lt;/h1&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/nanobrowser"&gt;&lt;img src="https://img.shields.io/badge/GitHub-181717?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white" alt="GitHub" /&gt;&lt;/a&gt; &lt;a href="https://x.com/nanobrowser_ai"&gt;&lt;img src="https://img.shields.io/badge/Twitter-000000?style=for-the-badge&amp;amp;logo=x&amp;amp;logoColor=white" alt="Twitter" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/NN3ABHggMK"&gt;&lt;img src="https://img.shields.io/badge/Discord-5865F2?style=for-the-badge&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/nanobrowser/nanobrowser"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" height="28" alt="Ask DeepWiki" /&gt;&lt;/a&gt; &lt;a href="https://github.com/sponsors/alexchenzl"&gt;&lt;img src="https://img.shields.io/badge/Sponsor-ff69b4?style=for-the-badge&amp;amp;logo=githubsponsors&amp;amp;logoColor=white" alt="Sponsor" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;üåê Nanobrowser&lt;/h2&gt; 
&lt;p&gt;Nanobrowser is an open-source AI web automation tool that runs in your browser. A free alternative to OpenAI Operator with flexible LLM options and multi-agent system.&lt;/p&gt; 
&lt;p&gt;‚¨áÔ∏è Get &lt;a href="https://chromewebstore.google.com/detail/nanobrowser/imbddededgmcgfhfpcjmijokokekbkal"&gt;Nanobrowser from Chrome Web Store&lt;/a&gt; for free&lt;/p&gt; 
&lt;p&gt;üëè Join the community in &lt;a href="https://discord.gg/NN3ABHggMK"&gt;Discord&lt;/a&gt; | &lt;a href="https://x.com/nanobrowser_ai"&gt;X&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;üåü Loving Nanobrowser? Give us a star and help spread the word!&lt;/p&gt; 
&lt;p&gt;‚ù§Ô∏è Support the project by &lt;a href="https://github.com/sponsors/alexchenzl"&gt;sponsoring us&lt;/a&gt; - every contribution helps keep Nanobrowser free and open source!&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://github.com/user-attachments/assets/112c4385-7b03-4b81-a352-4f348093351b" width="600" alt="Nanobrowser Demo GIF" /&gt; 
 &lt;p&gt;&lt;em&gt;Nanobrowser's multi-agent system analyzing HuggingFace in real-time, with the Planner intelligently self-correcting when encountering obstacles and dynamically instructing the Navigator to adjust its approach‚Äîall running locally in your browser.&lt;/em&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;üî•Why Nanobrowser?&lt;/h2&gt; 
&lt;p&gt;Looking for a powerful AI browser agent without the $200/month price tag of OpenAI Operator? &lt;strong&gt;Nanobrowser&lt;/strong&gt; , as a chrome extension, delivers premium web automation capabilities while keeping you in complete control:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;100% Free&lt;/strong&gt; - No subscription fees or hidden costs. Just install and use your own API keys, and you only pay what you use with your own API keys.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Privacy-Focused&lt;/strong&gt; - Everything runs in your local browser. Your credentials stay with you, never shared with any cloud service.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexible LLM Options&lt;/strong&gt; - Connect to your preferred LLM providers with the freedom to choose different models for different agents.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Fully Open Source&lt;/strong&gt; - Complete transparency in how your browser is automated. No black boxes or hidden processes.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; We currently support OpenAI, Anthropic, Gemini, Ollama, Groq, Cerebras, Llama and custom OpenAI-Compatible providers, more providers will be supported.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;üìä Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-agent System&lt;/strong&gt;: Specialized AI agents collaborate to accomplish complex web workflows&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Interactive Side Panel&lt;/strong&gt;: Intuitive chat interface with real-time status updates&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Task Automation&lt;/strong&gt;: Seamlessly automate repetitive web automation tasks across websites&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Follow-up Questions&lt;/strong&gt;: Ask contextual follow-up questions about completed tasks&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Conversation History&lt;/strong&gt;: Easily access and manage your AI agent interaction history&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multiple LLM Support&lt;/strong&gt;: Connect your preferred LLM providers and assign different models to different agents&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üåê Browser Support&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Officially Supported:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Chrome&lt;/strong&gt; - Full support with all features&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Edge&lt;/strong&gt; - Full support with all features&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Not Supported:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Firefox, Safari, and other Chromium variants (Opera, Arc, etc.)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: While Nanobrowser may function on other Chromium-based browsers, we recommend using Chrome or Edge for the best experience and guaranteed compatibility.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;üöÄ Quick Start&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Install from Chrome Web Store&lt;/strong&gt; (Stable Version): 
  &lt;ul&gt; 
   &lt;li&gt;Visit the &lt;a href="https://chromewebstore.google.com/detail/nanobrowser/imbddededgmcgfhfpcjmijokokekbkal"&gt;Nanobrowser Chrome Web Store page&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Click "Add to Chrome" button&lt;/li&gt; 
   &lt;li&gt;Confirm the installation when prompted&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Important Note&lt;/strong&gt;: For latest features, install from &lt;a href="https://raw.githubusercontent.com/nanobrowser/nanobrowser/master/#-manually-install-latest-version"&gt;"Manually Install Latest Version"&lt;/a&gt; below, as Chrome Web Store version may be delayed due to review process.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;&lt;strong&gt;Configure Agent Models&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;Click the Nanobrowser icon in your toolbar to open the sidebar&lt;/li&gt; 
   &lt;li&gt;Click the &lt;code&gt;Settings&lt;/code&gt; icon (top right)&lt;/li&gt; 
   &lt;li&gt;Add your LLM API keys&lt;/li&gt; 
   &lt;li&gt;Choose which model to use for different agents (Navigator, Planner)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;üîß Manually Install Latest Version&lt;/h2&gt; 
&lt;p&gt;To get the most recent version with all the latest features:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Download&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Download the latest &lt;code&gt;nanobrowser.zip&lt;/code&gt; file from the official Github &lt;a href="https://github.com/nanobrowser/nanobrowser/releases"&gt;release page&lt;/a&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Install&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Unzip &lt;code&gt;nanobrowser.zip&lt;/code&gt;.&lt;/li&gt; 
   &lt;li&gt;Open &lt;code&gt;chrome://extensions/&lt;/code&gt; in Chrome&lt;/li&gt; 
   &lt;li&gt;Enable &lt;code&gt;Developer mode&lt;/code&gt; (top right)&lt;/li&gt; 
   &lt;li&gt;Click &lt;code&gt;Load unpacked&lt;/code&gt; (top left)&lt;/li&gt; 
   &lt;li&gt;Select the unzipped &lt;code&gt;nanobrowser&lt;/code&gt; folder.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Configure Agent Models&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Click the Nanobrowser icon in your toolbar to open the sidebar&lt;/li&gt; 
   &lt;li&gt;Click the &lt;code&gt;Settings&lt;/code&gt; icon (top right).&lt;/li&gt; 
   &lt;li&gt;Add your LLM API keys.&lt;/li&gt; 
   &lt;li&gt;Choose which model to use for different agents (Navigator, Planner)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Upgrading&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Download the latest &lt;code&gt;nanobrowser.zip&lt;/code&gt; file from the release page.&lt;/li&gt; 
   &lt;li&gt;Unzip and replace your existing Nanobrowser files with the new ones.&lt;/li&gt; 
   &lt;li&gt;Go to &lt;code&gt;chrome://extensions/&lt;/code&gt; in Chrome and click the refresh icon on the Nanobrowser card.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;üõ†Ô∏è Build from Source&lt;/h2&gt; 
&lt;p&gt;If you prefer to build Nanobrowser yourself, follow these steps:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Prerequisites&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://nodejs.org/"&gt;Node.js&lt;/a&gt; (v22.12.0 or higher)&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://pnpm.io/installation"&gt;pnpm&lt;/a&gt; (v9.15.1 or higher)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Clone the Repository&lt;/strong&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/nanobrowser/nanobrowser.git
cd nanobrowser
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Install Dependencies&lt;/strong&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pnpm install
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Build the Extension&lt;/strong&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pnpm build
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Load the Extension&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;The built extension will be in the &lt;code&gt;dist&lt;/code&gt; directory&lt;/li&gt; 
   &lt;li&gt;Follow the installation steps from the Manually Install section to load the extension into your browser&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Development Mode&lt;/strong&gt; (optional):&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pnpm dev
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;ü§ñ Choosing Your Models&lt;/h2&gt; 
&lt;p&gt;Nanobrowser allows you to configure different LLM models for each agent to balance performance and cost. Here are recommended configurations:&lt;/p&gt; 
&lt;h3&gt;Better Performance&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Planner&lt;/strong&gt;: Claude Sonnet 4 
  &lt;ul&gt; 
   &lt;li&gt;Better reasoning and planning capabilities&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Navigator&lt;/strong&gt;: Claude Haiku 3.5 
  &lt;ul&gt; 
   &lt;li&gt;Efficient for web navigation tasks&lt;/li&gt; 
   &lt;li&gt;Good balance of performance and cost&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Cost-Effective Configuration&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Planner&lt;/strong&gt;: Claude Haiku or GPT-4o 
  &lt;ul&gt; 
   &lt;li&gt;Reasonable performance at lower cost&lt;/li&gt; 
   &lt;li&gt;May require more iterations for complex tasks&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Navigator&lt;/strong&gt;: Gemini 2.5 Flash or GPT-4o-mini 
  &lt;ul&gt; 
   &lt;li&gt;Lightweight and cost-efficient&lt;/li&gt; 
   &lt;li&gt;Suitable for basic navigation tasks&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Local Models&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Setup Options&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Use Ollama or other custom OpenAI-compatible providers to run models locally&lt;/li&gt; 
   &lt;li&gt;Zero API costs and complete privacy with no data leaving your machine&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Recommended Models&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Qwen3-30B-A3B-Instruct-2507&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Falcon3 10B&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Qwen 2.5 Coder 14B&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Mistral Small 24B&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://gist.github.com/maximus2600/75d60bf3df62986e2254d5166e2524cb"&gt;Latest test results from community&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;We welcome community experience sharing with other local models in our &lt;a href="https://discord.gg/NN3ABHggMK"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Prompt Engineering&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Local models require more specific and cleaner prompts&lt;/li&gt; 
   &lt;li&gt;Avoid high-level, ambiguous commands&lt;/li&gt; 
   &lt;li&gt;Break complex tasks into clear, detailed steps&lt;/li&gt; 
   &lt;li&gt;Provide explicit context and constraints&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The cost-effective configuration may produce less stable outputs and require more iterations for complex tasks.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Tip&lt;/strong&gt;: Feel free to experiment with your own model configurations! Found a great combination? Share it with the community in our &lt;a href="https://discord.gg/NN3ABHggMK"&gt;Discord&lt;/a&gt; to help others optimize their setup.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;üí° See It In Action&lt;/h2&gt; 
&lt;p&gt;Here are some powerful tasks you can accomplish with just a sentence:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;News Summary&lt;/strong&gt;:&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;"Go to TechCrunch and extract top 10 headlines from the last 24 hours"&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;GitHub Research&lt;/strong&gt;:&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;"Look for the trending Python repositories on GitHub with most stars"&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Shopping Research&lt;/strong&gt;:&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;"Find a portable Bluetooth speaker on Amazon with a water-resistant design, under $50. It should have a minimum battery life of 10 hours"&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;üõ†Ô∏è Roadmap&lt;/h2&gt; 
&lt;p&gt;We're actively developing Nanobrowser with exciting features on the horizon, welcome to join us!&lt;/p&gt; 
&lt;p&gt;Check out our detailed roadmap and upcoming features in our &lt;a href="https://github.com/nanobrowser/nanobrowser/discussions/85"&gt;GitHub Discussions&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;We need your help to make Nanobrowser even better!&lt;/strong&gt; Contributions of all kinds are welcome:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Share Prompts &amp;amp; Use Cases&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Join our &lt;a href="https://discord.gg/NN3ABHggMK"&gt;Discord server&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;share how you're using Nanobrowser. Help us build a library of useful prompts and real-world use cases.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Provide Feedback&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Try Nanobrowser and give us feedback on its performance or suggest improvements in our &lt;a href="https://discord.gg/NN3ABHggMK"&gt;Discord server&lt;/a&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Contribute Code&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Check out our &lt;a href="https://raw.githubusercontent.com/nanobrowser/nanobrowser/master/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for guidelines on how to contribute code to the project.&lt;/li&gt; 
   &lt;li&gt;Submit pull requests for bug fixes, features, or documentation improvements.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We believe in the power of open source and community collaboration. Join us in building the future of web automation!&lt;/p&gt; 
&lt;h2&gt;üîí Security&lt;/h2&gt; 
&lt;p&gt;If you discover a security vulnerability, please &lt;strong&gt;DO NOT&lt;/strong&gt; disclose it publicly through issues, pull requests, or discussions.&lt;/p&gt; 
&lt;p&gt;Instead, please create a &lt;a href="https://github.com/nanobrowser/nanobrowser/security/advisories/new"&gt;GitHub Security Advisory&lt;/a&gt; to report the vulnerability responsibly. This allows us to address the issue before it's publicly disclosed.&lt;/p&gt; 
&lt;p&gt;We appreciate your help in keeping Nanobrowser and its users safe!&lt;/p&gt; 
&lt;h2&gt;üí¨ Community&lt;/h2&gt; 
&lt;p&gt;Join our growing community of developers and users:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/NN3ABHggMK"&gt;Discord&lt;/a&gt; - Chat with team and community&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://x.com/nanobrowser_ai"&gt;Twitter&lt;/a&gt; - Follow for updates and announcements&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nanobrowser/nanobrowser/discussions"&gt;GitHub Discussions&lt;/a&gt; - Share ideas and ask questions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üëè Acknowledgments&lt;/h2&gt; 
&lt;p&gt;Nanobrowser builds on top of other awesome open-source projects:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/browser-use/browser-use"&gt;Browser Use&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/EmergenceAI/Agent-E"&gt;Puppeteer&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Jonghakseo/chrome-extension-boilerplate-react-vite"&gt;Chrome Extension Boilerplate&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/langchain-ai/langchainjs"&gt;LangChain&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Huge thanks to their creators and contributors!&lt;/p&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the Apache License 2.0 - see the &lt;a href="https://raw.githubusercontent.com/nanobrowser/nanobrowser/master/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;p&gt;Made with ‚ù§Ô∏è by the Nanobrowser Team.&lt;/p&gt; 
&lt;p&gt;Like Nanobrowser? Give us a star üåü and join us in &lt;a href="https://discord.gg/NN3ABHggMK"&gt;Discord&lt;/a&gt; | &lt;a href="https://x.com/nanobrowser_ai"&gt;X&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;‚ö†Ô∏è DISCLAIMER ON DERIVATIVE PROJECTS&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;We explicitly &lt;em&gt;DO NOT&lt;/em&gt; endorse, support, or participate in any&lt;/strong&gt; projects involving cryptocurrencies, tokens, NFTs, or other blockchain-related applications &lt;strong&gt;based on this codebase.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Any such derivative projects are&amp;nbsp;NOT&amp;nbsp;Affiliated with, or maintained by, or in any way connected to the official Nanobrowser project or its core team.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;We assume NO LIABILITY for any losses, damages, or issues arising from the use of third-party derivative projects. Users interact with these projects at their own risk.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;We reserve the right to publicly distance ourselves from any misuse or misleading use of our name, codebase, or brand.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;We encourage open-source innovation but urge our community to be discerning and cautious. Please ensure you understand the risks before using any software or service built upon our codebase by independent developers.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>sst/opencode</title>
      <link>https://github.com/sst/opencode</link>
      <description>&lt;p&gt;AI coding agent, built for the terminal.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://opencode.ai"&gt; 
  &lt;picture&gt; 
   &lt;source srcset="packages/web/src/assets/logo-ornate-dark.svg" media="(prefers-color-scheme: dark)" /&gt; 
   &lt;source srcset="packages/web/src/assets/logo-ornate-light.svg" media="(prefers-color-scheme: light)" /&gt; 
   &lt;img src="https://raw.githubusercontent.com/sst/opencode/dev/packages/web/src/assets/logo-ornate-light.svg?sanitize=true" alt="opencode logo" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt;AI coding agent, built for the terminal.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://opencode.ai/discord"&gt;&lt;img alt="Discord" src="https://img.shields.io/discord/1391832426048651334?style=flat-square&amp;amp;label=discord" /&gt;&lt;/a&gt; &lt;a href="https://www.npmjs.com/package/opencode-ai"&gt;&lt;img alt="npm" src="https://img.shields.io/npm/v/opencode-ai?style=flat-square" /&gt;&lt;/a&gt; &lt;a href="https://github.com/sst/opencode/actions/workflows/publish.yml"&gt;&lt;img alt="Build status" src="https://img.shields.io/github/actions/workflow/status/sst/opencode/publish.yml?style=flat-square&amp;amp;branch=dev" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;a href="https://opencode.ai"&gt;&lt;img src="https://raw.githubusercontent.com/sst/opencode/dev/packages/web/src/assets/lander/screenshot.png" alt="opencode Terminal UI" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# YOLO
curl -fsSL https://opencode.ai/install | bash

# Package managers
npm i -g opencode-ai@latest        # or bun/pnpm/yarn
brew install sst/tap/opencode      # macOS and Linux
paru -S opencode-bin               # Arch Linux
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] Remove versions older than 0.1.x before installing.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Installation Directory&lt;/h4&gt; 
&lt;p&gt;The install script respects the following priority order for the installation path:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;code&gt;$OPENCODE_INSTALL_DIR&lt;/code&gt; - Custom installation directory&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;$XDG_BIN_DIR&lt;/code&gt; - XDG Base Directory Specification compliant path&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;$HOME/bin&lt;/code&gt; - Standard user binary directory (if exists or can be created)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;$HOME/.opencode/bin&lt;/code&gt; - Default fallback&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Examples
OPENCODE_INSTALL_DIR=/usr/local/bin curl -fsSL https://opencode.ai/install | bash
XDG_BIN_DIR=$HOME/.local/bin curl -fsSL https://opencode.ai/install | bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Documentation&lt;/h3&gt; 
&lt;p&gt;For more info on how to configure opencode &lt;a href="https://opencode.ai/docs"&gt;&lt;strong&gt;head over to our docs&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Contributing&lt;/h3&gt; 
&lt;p&gt;opencode is an opinionated tool so any fundamental feature needs to go through a design process with the core team.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] We do not accept PRs for core features.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;However we still merge a ton of PRs - you can contribute:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Bug fixes&lt;/li&gt; 
 &lt;li&gt;Improvements to LLM performance&lt;/li&gt; 
 &lt;li&gt;Support for new providers&lt;/li&gt; 
 &lt;li&gt;Fixes for env specific quirks&lt;/li&gt; 
 &lt;li&gt;Missing standard behavior&lt;/li&gt; 
 &lt;li&gt;Documentation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Take a look at the git history to see what kind of PRs we end up merging.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] If you do not follow the above guidelines we might close your PR.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;To run opencode locally you need.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Bun&lt;/li&gt; 
 &lt;li&gt;Golang 1.24.x&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;And run.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ bun install
$ bun dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Development Notes&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;API Client&lt;/strong&gt;: After making changes to the TypeScript API endpoints in &lt;code&gt;packages/opencode/src/server/server.ts&lt;/code&gt;, you will need the opencode team to generate a new stainless sdk for the clients.&lt;/p&gt; 
&lt;h3&gt;FAQ&lt;/h3&gt; 
&lt;h4&gt;How is this different than Claude Code?&lt;/h4&gt; 
&lt;p&gt;It's very similar to Claude Code in terms of capability. Here are the key differences:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;100% open source&lt;/li&gt; 
 &lt;li&gt;Not coupled to any provider. Although Anthropic is recommended, opencode can be used with OpenAI, Google or even local models. As models evolve the gaps between them will close and pricing will drop so being provider-agnostic is important.&lt;/li&gt; 
 &lt;li&gt;A focus on TUI. opencode is built by neovim users and the creators of &lt;a href="https://terminal.shop"&gt;terminal.shop&lt;/a&gt;; we are going to push the limits of what's possible in the terminal.&lt;/li&gt; 
 &lt;li&gt;A client/server architecture. This for example can allow opencode to run on your computer, while you can drive it remotely from a mobile app. Meaning that the TUI frontend is just one of the possible clients.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;What's the other repo?&lt;/h4&gt; 
&lt;p&gt;The other confusingly named repo has no relation to this one. You can &lt;a href="https://x.com/thdxr/status/1933561254481666466"&gt;read the story behind it here&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;Join our community&lt;/strong&gt; &lt;a href="https://discord.gg/opencode"&gt;Discord&lt;/a&gt; | &lt;a href="https://x.com/opencode"&gt;X.com&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Alibaba-NLP/DeepResearch</title>
      <link>https://github.com/Alibaba-NLP/DeepResearch</link>
      <description>&lt;p&gt;Tongyi DeepResearch, the Leading Open-source DeepResearch Agent&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;picture&gt; 
  &lt;img src="https://raw.githubusercontent.com/Alibaba-NLP/DeepResearch/main/assets/logo.png" width="100%" /&gt; 
 &lt;/picture&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;div align="center" style="line-height: 1;"&gt; 
 &lt;p&gt;&lt;a href="https://huggingface.co/Alibaba-NLP/Tongyi-DeepResearch-30B-A3B"&gt;&lt;img src="https://img.shields.io/badge/Models-5EDDD2?style=for-the-badge&amp;amp;logo=huggingface&amp;amp;logoColor=ffffff&amp;amp;labelColor" alt="MODELS" /&gt;&lt;/a&gt; &lt;a href="https://github.com/Alibaba-NLP/DeepResearch"&gt;&lt;img src="https://img.shields.io/badge/Github-24292F?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white" alt="GITHUB" /&gt;&lt;/a&gt; &lt;a href="https://tongyi-agent.github.io/blog/introducing-tongyi-deep-research/"&gt;&lt;img src="https://img.shields.io/badge/Blog-4285F4?style=for-the-badge&amp;amp;logo=google-chrome&amp;amp;logoColor=white" alt="Blog" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt; ü§ó &lt;a href="https://huggingface.co/Alibaba-NLP/Tongyi-DeepResearch-30B-A3B" target="_blank"&gt;HuggingFace&lt;/a&gt; ÔΩú &lt;img src="https://raw.githubusercontent.com/Alibaba-NLP/DeepResearch/main/assets/tongyi.png" width="14px" style="display:inline;" /&gt; &lt;a href="https://modelscope.cn/models/iic/Tongyi-DeepResearch-30B-A3B" target="_blank"&gt;ModelScope&lt;/a&gt; &lt;/p&gt;
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/14217" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/14217" alt="Alibaba-NLP%2FWebAgent | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; &lt;/p&gt;
&lt;h1&gt;Introduction&lt;/h1&gt; 
&lt;p&gt;We present &lt;img src="https://raw.githubusercontent.com/Alibaba-NLP/DeepResearch/main/assets/tongyi.png" width="14px" style="display:inline;" /&gt; &lt;strong&gt;Tongyi DeepResearch&lt;/strong&gt;, an agentic large language model featuring 30.5 billion total parameters, with only 3.3 billion activated per token. Developed by Tongyi Lab, the model is specifically designed for &lt;strong&gt;long-horizon, deep information-seeking&lt;/strong&gt; tasks. Tongyi DeepResearch demonstrates state-of-the-art performance across a range of agentic search benchmarks, including Humanity's Last Exam, BrowserComp, BrowserComp-ZH, WebWalkerQA,xbench-DeepSearch, FRAMES and SimpleQA.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Tongyi DeepResearch builds upon our previous work on the &lt;img src="https://raw.githubusercontent.com/Alibaba-NLP/DeepResearch/main/assets/tongyi.png" width="14px" style="display:inline;" /&gt; &lt;a href="https://raw.githubusercontent.com/Alibaba-NLP/DeepResearch/main/WebAgent/"&gt;WebAgent&lt;/a&gt; project.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;More details can be found in our üì∞&amp;nbsp;&lt;a href="https://tongyi-agent.github.io/blog/introducing-tongyi-deep-research/"&gt;Tech Blog&lt;/a&gt;.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img width="100%" src="https://raw.githubusercontent.com/Alibaba-NLP/DeepResearch/main/assets/performance.png" /&gt; &lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚öôÔ∏è &lt;strong&gt;Fully automated synthetic data generation pipeline&lt;/strong&gt;: We design a highly scalable data synthesis pipeline, which is fully automatic and empowers agentic pre-training, supervised fine-tuning, and reinforcement learning.&lt;/li&gt; 
 &lt;li&gt;üîÑ &lt;strong&gt;Large-scale continual pre-training on agentic data&lt;/strong&gt;: Leveraging diverse, high-quality agentic interaction data to extend model capabilities, maintain freshness, and strengthen reasoning performance.&lt;/li&gt; 
 &lt;li&gt;üîÅ &lt;strong&gt;End-to-end reinforcement learning&lt;/strong&gt;: We employ a strictly on-policy RL approach based on a customized Group Relative Policy Optimization framework, with token-level policy gradients, leave-one-out advantage estimation, and selective filtering of negative samples to stabilize training in a non‚Äëstationary environment.&lt;/li&gt; 
 &lt;li&gt;ü§ñ &lt;strong&gt;Agent Inference Paradigm Compatibility&lt;/strong&gt;: At inference, Tongyi DeepResearch is compatible with two inference paradigms: ReAct, for rigorously evaluating the model's core intrinsic abilities, and an IterResearch-based 'Heavy' mode, which uses a test-time scaling strategy to unlock the model's maximum performance ceiling.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Model Download&lt;/h1&gt; 
&lt;p&gt;You can directly download the model by following the links below.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;Model&lt;/th&gt; 
   &lt;th align="center"&gt;Download Links&lt;/th&gt; 
   &lt;th align="center"&gt;Model Size&lt;/th&gt; 
   &lt;th align="center"&gt;Context Length&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;Tongyi-DeepResearch-30B-A3B&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://huggingface.co/Alibaba-NLP/Tongyi-DeepResearch-30B-A3B"&gt;ü§ó HuggingFace&lt;/a&gt;&lt;br /&gt; &lt;a href="https://modelscope.cn/models/iic/Tongyi-DeepResearch-30B-A3B"&gt;ü§ñ ModelScope&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;30B-A3B&lt;/td&gt; 
   &lt;td align="center"&gt;128K&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h1&gt;News&lt;/h1&gt; 
&lt;p&gt;[2025/09/17]üî• We have released &lt;strong&gt;Tongyi-DeepResearch-30B-A3B&lt;/strong&gt;.&lt;/p&gt; 
&lt;h1&gt;Deep Research Benchmark Results&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;img width="100%" src="https://raw.githubusercontent.com/Alibaba-NLP/DeepResearch/main/assets/benchmark.png" /&gt; &lt;/p&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;This guide provides instructions for setting up the environment and running inference scripts located in the &lt;a href="https://raw.githubusercontent.com/Alibaba-NLP/DeepResearch/main/inference/"&gt;inference&lt;/a&gt; folder.&lt;/p&gt; 
&lt;h3&gt;1. Environment Setup&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Recommended Python version: &lt;strong&gt;3.10.0&lt;/strong&gt; (using other versions may cause dependency issues).&lt;/li&gt; 
 &lt;li&gt;It is strongly advised to create an isolated environment using &lt;code&gt;conda&lt;/code&gt; or &lt;code&gt;virtualenv&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Example with Conda
conda create -n react_infer_env python=3.10.0 
conda activate react_infer_env
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. Installation&lt;/h3&gt; 
&lt;p&gt;Install the required dependencies:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;3. Prepare Evaluation Data&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Create a folder named &lt;code&gt;eval_data/&lt;/code&gt; in the project root.&lt;/li&gt; 
 &lt;li&gt;Place your QA file in &lt;strong&gt;JSONL&lt;/strong&gt; format inside this directory, e.g. &lt;code&gt;eval_data/example.jsonl&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Each line must be a JSON object that includes &lt;strong&gt;both&lt;/strong&gt; of the following keys: &lt;pre&gt;&lt;code class="language-json"&gt;{"question": "...","answer": "..."}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;A sample file is provided in the &lt;code&gt;eval_data&lt;/code&gt; folder for reference.&lt;/li&gt; 
 &lt;li&gt;If you plan to use the &lt;em&gt;file parser&lt;/em&gt; tool, &lt;strong&gt;prepend the file name to the &lt;code&gt;question&lt;/code&gt; field&lt;/strong&gt; and place the referenced file inside the &lt;code&gt;eval_data/file_corpus/&lt;/code&gt; directory.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;4. Configure the Inference Script&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Open &lt;code&gt;run_react_infer.sh&lt;/code&gt; and modify the following variables as instructed in the comments: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;MODEL_PATH&lt;/code&gt; - path to the local or remote model weights.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;DATASET&lt;/code&gt; - path to the evaluation set, e.g. &lt;code&gt;example&lt;/code&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;OUTPUT_PATH&lt;/code&gt; - path for saving the prediction results, e.g. &lt;code&gt;./outputs&lt;/code&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Depending on the tools you enable (retrieval, calculator, web search, etc.), provide the required &lt;code&gt;API_KEY&lt;/code&gt;, &lt;code&gt;BASE_URL&lt;/code&gt;, or other credentials. Each key is explained inline in the bash script.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;5. Run the Inference Script&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;bash run_react_infer.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;p&gt;With these steps, you can fully prepare the environment, configure the dataset, and run the model. For more details, consult the inline comments in each script or open an issue.&lt;/p&gt; 
&lt;h2&gt;Benchmark Evaluation&lt;/h2&gt; 
&lt;p&gt;We provide benchmark evaluation scripts for various datasets. Please refer to the &lt;a href="https://raw.githubusercontent.com/Alibaba-NLP/DeepResearch/main/evaluation/"&gt;evaluation scripts&lt;/a&gt; directory for more details.&lt;/p&gt; 
&lt;h2&gt;Deep Research Agent Family&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img width="100%" src="https://raw.githubusercontent.com/Alibaba-NLP/DeepResearch/main/assets/family.png" /&gt; &lt;/p&gt; 
&lt;p&gt;Tongyi DeepResearch also has an extensive deep research agent family. You can find more information in the following paper:&lt;/p&gt; 
&lt;p&gt;[1] &lt;a href="https://arxiv.org/pdf/2501.07572"&gt;WebWalker: Benchmarking LLMs in Web Traversal&lt;/a&gt;&lt;br /&gt; [2] &lt;a href="https://arxiv.org/pdf/2505.22648"&gt;WebDancer: Towards Autonomous Information Seeking Agency&lt;/a&gt;&lt;br /&gt; [3] &lt;a href="https://arxiv.org/pdf/2507.02592"&gt;WebSailor: Navigating Super-human Reasoning for Web Agent&lt;/a&gt;&lt;br /&gt; [4] &lt;a href="https://arxiv.org/pdf/2507.15061"&gt;WebShaper: Agentically Data Synthesizing via Information-Seeking Formalization&lt;/a&gt;&lt;br /&gt; [5] &lt;a href="https://arxiv.org/pdf/2508.05748"&gt;WebWatcher: Breaking New Frontier of Vision-Language Deep Research Agent&lt;/a&gt;&lt;br /&gt; [6] &lt;a href="https://arxiv.org/pdf/2509.13309"&gt;WebResearcher: Unleashing unbounded reasoning capability in Long-Horizon Agents&lt;/a&gt;&lt;br /&gt; [7] &lt;a href="https://arxiv.org/pdf/2509.13313"&gt;ReSum: Unlocking Long-Horizon Search Intelligence via Context Summarization&lt;/a&gt;&lt;br /&gt; [8] &lt;a href="https://arxiv.org/pdf/2509.13312"&gt;WebWeaver: Structuring Web-Scale Evidence with Dynamic Outlines for Open-Ended Deep Research&lt;/a&gt;&lt;br /&gt; [9] &lt;a href="https://arxiv.org/pdf/2509.13305"&gt;WebSailor-V2: Bridging the Chasm to Proprietary Agents via Synthetic Data and Scalable Reinforcement Learning&lt;/a&gt;&lt;br /&gt; [10] &lt;a href="https://arxiv.org/pdf/2509.13310"&gt;Scaling Agents via Continual Pre-training&lt;/a&gt;&lt;br /&gt; [11] &lt;a href="https://arxiv.org/pdf/2509.13311"&gt;Towards General Agentic Intelligence via Environment Scaling&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üåü Misc&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://www.star-history.com/#Alibaba-NLP/DeepResearch&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=Alibaba-NLP/DeepResearch&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;üö© Talent Recruitment&lt;/h2&gt; 
&lt;p&gt;üî•üî•üî• We are hiring! Research intern positions are open (based in Hangzhou„ÄÅBeijing„ÄÅShanghai)&lt;/p&gt; 
&lt;p&gt;üìö &lt;strong&gt;Research Area&lt;/strong&gt;ÔºöWeb Agent, Search Agent, Agent RL, MultiAgent RL, Agentic RAG&lt;/p&gt; 
&lt;p&gt;‚òéÔ∏è &lt;strong&gt;Contact&lt;/strong&gt;Ôºö&lt;a href=""&gt;yongjiang.jy@alibaba-inc.com&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contact Information&lt;/h2&gt; 
&lt;p&gt;For communications, please contact Yong Jiang (&lt;a href="mailto:yongjiang.jy@alibaba-inc.com"&gt;yongjiang.jy@alibaba-inc.com&lt;/a&gt;).&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{tongyidr,
  author={Tongyi DeepResearch Team},
  title={Tongyi-DeepResearch},
  year={2025},
  howpublished={\url{https://github.com/Alibaba-NLP/DeepResearch}}
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>curl/curl</title>
      <link>https://github.com/curl/curl</link>
      <description>&lt;p&gt;A command line tool and library for transferring data with URL syntax, supporting DICT, FILE, FTP, FTPS, GOPHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET, TFTP, WS and WSS. libcurl offers a myriad of powerful features&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;a href="https://curl.se/"&gt;&lt;img src="https://curl.se/logo/curl-logo.svg?sanitize=true" alt="curl logo" /&gt;&lt;/a&gt;&lt;/h1&gt; 
&lt;p&gt;curl is a command-line tool for transferring data specified with URL syntax. Learn how to use curl by reading &lt;a href="https://curl.se/docs/manpage.html"&gt;the manpage&lt;/a&gt; or &lt;a href="https://everything.curl.dev/"&gt;everything curl&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Find out how to install curl by reading &lt;a href="https://curl.se/docs/install.html"&gt;the INSTALL document&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;libcurl is the library curl is using to do its job. It is readily available to be used by your software. Read &lt;a href="https://curl.se/libcurl/c/libcurl.html"&gt;the libcurl manpage&lt;/a&gt; to learn how.&lt;/p&gt; 
&lt;h2&gt;Open Source&lt;/h2&gt; 
&lt;p&gt;curl is Open Source and is distributed under an MIT-like &lt;a href="https://curl.se/docs/copyright.html"&gt;license&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contact&lt;/h2&gt; 
&lt;p&gt;Contact us on a suitable &lt;a href="https://curl.se/mail/"&gt;mailing list&lt;/a&gt; or use GitHub &lt;a href="https://github.com/curl/curl/issues"&gt;issues&lt;/a&gt;/ &lt;a href="https://github.com/curl/curl/pulls"&gt;pull requests&lt;/a&gt;/ &lt;a href="https://github.com/curl/curl/discussions"&gt;discussions&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;All contributors to the project are listed in &lt;a href="https://curl.se/docs/thanks.html"&gt;the THANKS document&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Commercial support&lt;/h2&gt; 
&lt;p&gt;For commercial support, maybe private and dedicated help with your problems or applications using (lib)curl visit &lt;a href="https://curl.se/support.html"&gt;the support page&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Website&lt;/h2&gt; 
&lt;p&gt;Visit the &lt;a href="https://curl.se/"&gt;curl website&lt;/a&gt; for the latest news and downloads.&lt;/p&gt; 
&lt;h2&gt;Source code&lt;/h2&gt; 
&lt;p&gt;Download the latest source from the Git server:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/curl/curl.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Security problems&lt;/h2&gt; 
&lt;p&gt;Report suspected security problems via &lt;a href="https://hackerone.com/curl"&gt;our HackerOne page&lt;/a&gt; and not in public.&lt;/p&gt; 
&lt;h2&gt;Notice&lt;/h2&gt; 
&lt;p&gt;curl contains pieces of source code that is Copyright (c) 1998, 1999 Kungliga Tekniska H√∂gskolan. This notice is included here to comply with the distribution terms.&lt;/p&gt; 
&lt;h2&gt;Backers&lt;/h2&gt; 
&lt;p&gt;Thank you to all our backers &lt;span&gt;üôè&lt;/span&gt; &lt;a href="https://opencollective.com/curl#section-contribute"&gt;Become a backer&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;p&gt;Support this project by becoming a &lt;a href="https://curl.se/sponsors.html"&gt;sponsor&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>facebookresearch/detectron2</title>
      <link>https://github.com/facebookresearch/detectron2</link>
      <description>&lt;p&gt;Detectron2 is a platform for object detection, segmentation and other visual recognition tasks.&lt;/p&gt;&lt;hr&gt;&lt;img src="https://raw.githubusercontent.com/facebookresearch/detectron2/main/.github/Detectron2-Logo-Horz.svg?sanitize=true" width="300" /&gt; 
&lt;p&gt;Detectron2 is Facebook AI Research's next generation library that provides state-of-the-art detection and segmentation algorithms. It is the successor of &lt;a href="https://github.com/facebookresearch/Detectron/"&gt;Detectron&lt;/a&gt; and &lt;a href="https://github.com/facebookresearch/maskrcnn-benchmark/"&gt;maskrcnn-benchmark&lt;/a&gt;. It supports a number of computer vision research projects and production applications in Facebook.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://user-images.githubusercontent.com/1381301/66535560-d3422200-eace-11e9-9123-5535d469db19.png" /&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;h2&gt;Learn More about Detectron2&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Includes new capabilities such as panoptic segmentation, Densepose, Cascade R-CNN, rotated bounding boxes, PointRend, DeepLab, ViTDet, MViTv2 etc.&lt;/li&gt; 
 &lt;li&gt;Used as a library to support building &lt;a href="https://raw.githubusercontent.com/facebookresearch/detectron2/main/projects/"&gt;research projects&lt;/a&gt; on top of it.&lt;/li&gt; 
 &lt;li&gt;Models can be exported to TorchScript format or Caffe2 format for deployment.&lt;/li&gt; 
 &lt;li&gt;It &lt;a href="https://detectron2.readthedocs.io/notes/benchmarks.html"&gt;trains much faster&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See our &lt;a href="https://ai.meta.com/blog/-detectron2-a-pytorch-based-modular-object-detection-library-/"&gt;blog post&lt;/a&gt; to see more demos. See this &lt;a href="https://ai.meta.com/blog/detectron-everingham-prize/"&gt;interview&lt;/a&gt; to learn more about the stories behind detectron2.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://detectron2.readthedocs.io/tutorials/install.html"&gt;installation instructions&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://detectron2.readthedocs.io/tutorials/getting_started.html"&gt;Getting Started with Detectron2&lt;/a&gt;, and the &lt;a href="https://colab.research.google.com/drive/16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5"&gt;Colab Notebook&lt;/a&gt; to learn about basic usage.&lt;/p&gt; 
&lt;p&gt;Learn more at our &lt;a href="https://detectron2.readthedocs.org"&gt;documentation&lt;/a&gt;. And see &lt;a href="https://raw.githubusercontent.com/facebookresearch/detectron2/main/projects/"&gt;projects/&lt;/a&gt; for some projects that are built on top of detectron2.&lt;/p&gt; 
&lt;h2&gt;Model Zoo and Baselines&lt;/h2&gt; 
&lt;p&gt;We provide a large set of baseline results and trained models available for download in the &lt;a href="https://raw.githubusercontent.com/facebookresearch/detectron2/main/MODEL_ZOO.md"&gt;Detectron2 Model Zoo&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Detectron2 is released under the &lt;a href="https://raw.githubusercontent.com/facebookresearch/detectron2/main/LICENSE"&gt;Apache 2.0 license&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Citing Detectron2&lt;/h2&gt; 
&lt;p&gt;If you use Detectron2 in your research or wish to refer to the baseline results published in the &lt;a href="https://raw.githubusercontent.com/facebookresearch/detectron2/main/MODEL_ZOO.md"&gt;Model Zoo&lt;/a&gt;, please use the following BibTeX entry.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-BibTeX"&gt;@misc{wu2019detectron2,
  author =       {Yuxin Wu and Alexander Kirillov and Francisco Massa and
                  Wan-Yen Lo and Ross Girshick},
  title =        {Detectron2},
  howpublished = {\url{https://github.com/facebookresearch/detectron2}},
  year =         {2019}
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
  </channel>
</rss>