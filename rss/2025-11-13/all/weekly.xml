<rss version="2.0">
  <channel>
    <title>GitHub All Languages Weekly Trending</title>
    <description>Weekly Trending of All Languages in GitHub</description>
    <pubDate>Wed, 12 Nov 2025 01:44:35 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>mudler/LocalAI</title>
      <link>https://github.com/mudler/LocalAI</link>
      <description>&lt;p&gt;ü§ñ The free, Open Source alternative to OpenAI, Claude and others. Self-hosted and local-first. Drop-in replacement for OpenAI, running on consumer-grade hardware. No GPU required. Runs gguf, transformers, diffusers and many more. Features: Generate Text, Audio, Video, Images, Voice Cloning, Distributed, P2P and decentralized inference&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; &lt;br /&gt; &lt;img width="300" src="https://raw.githubusercontent.com/mudler/LocalAI/master/core/http/static/logo.png" /&gt; &lt;br /&gt; &lt;br /&gt; &lt;/h1&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/go-skynet/LocalAI/fork" target="blank"&gt; &lt;img src="https://img.shields.io/github/forks/go-skynet/LocalAI?style=for-the-badge" alt="LocalAI forks" /&gt; &lt;/a&gt; &lt;a href="https://github.com/go-skynet/LocalAI/stargazers" target="blank"&gt; &lt;img src="https://img.shields.io/github/stars/go-skynet/LocalAI?style=for-the-badge" alt="LocalAI stars" /&gt; &lt;/a&gt; &lt;a href="https://github.com/go-skynet/LocalAI/pulls" target="blank"&gt; &lt;img src="https://img.shields.io/github/issues-pr/go-skynet/LocalAI?style=for-the-badge" alt="LocalAI pull-requests" /&gt; &lt;/a&gt; &lt;a href="https://github.com/go-skynet/LocalAI/releases"&gt; &lt;img src="https://img.shields.io/github/release/go-skynet/LocalAI?&amp;amp;label=Latest&amp;amp;style=for-the-badge" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://hub.docker.com/r/localai/localai" target="blank"&gt; &lt;img src="https://img.shields.io/badge/dockerhub-images-important.svg?logo=Docker" alt="LocalAI Docker hub" /&gt; &lt;/a&gt; &lt;a href="https://quay.io/repository/go-skynet/local-ai?tab=tags&amp;amp;tag=latest" target="blank"&gt; &lt;img src="https://img.shields.io/badge/quay.io-images-important.svg?" alt="LocalAI Quay.io" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://twitter.com/LocalAI_API" target="blank"&gt; &lt;img src="https://img.shields.io/badge/X-%23000000.svg?style=for-the-badge&amp;amp;logo=X&amp;amp;logoColor=white&amp;amp;label=LocalAI_API" alt="Follow LocalAI_API" /&gt; &lt;/a&gt; &lt;a href="https://discord.gg/uJAeKSAGDy" target="blank"&gt; &lt;img src="https://dcbadge.vercel.app/api/server/uJAeKSAGDy?style=flat-square&amp;amp;theme=default-inverted" alt="Join LocalAI Discord Community" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/5539" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/5539" alt="mudler%2FLocalAI | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span&gt;üí°&lt;/span&gt; Get help - &lt;a href="https://localai.io/faq/"&gt;‚ùìFAQ&lt;/a&gt; &lt;a href="https://github.com/go-skynet/LocalAI/discussions"&gt;üí≠Discussions&lt;/a&gt; &lt;a href="https://discord.gg/uJAeKSAGDy"&gt;&lt;span&gt;üí¨&lt;/span&gt; Discord&lt;/a&gt; &lt;a href="https://localai.io/"&gt;&lt;span&gt;üìñ&lt;/span&gt; Documentation website&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://localai.io/basics/getting_started/"&gt;üíª Quickstart&lt;/a&gt; &lt;a href="https://models.localai.io/"&gt;üñºÔ∏è Models&lt;/a&gt; &lt;a href="https://github.com/mudler/LocalAI/issues?q=is%3Aissue+is%3Aopen+label%3Aroadmap"&gt;üöÄ Roadmap&lt;/a&gt; &lt;a href="https://github.com/mudler/LocalAI-examples"&gt;üõ´ Examples&lt;/a&gt; Try on &lt;a href="https://t.me/localaiofficial_bot"&gt;&lt;img src="https://img.shields.io/badge/Telegram-2CA5E0?style=for-the-badge&amp;amp;logo=telegram&amp;amp;logoColor=white" alt="Telegram" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://github.com/go-skynet/LocalAI/actions/workflows/test.yml"&gt;&lt;img src="https://github.com/go-skynet/LocalAI/actions/workflows/test.yml/badge.svg?sanitize=true" alt="tests" /&gt;&lt;/a&gt;&lt;a href="https://github.com/go-skynet/LocalAI/actions/workflows/release.yaml"&gt;&lt;img src="https://github.com/go-skynet/LocalAI/actions/workflows/release.yaml/badge.svg?sanitize=true" alt="Build and Release" /&gt;&lt;/a&gt;&lt;a href="https://github.com/go-skynet/LocalAI/actions/workflows/image.yml"&gt;&lt;img src="https://github.com/go-skynet/LocalAI/actions/workflows/image.yml/badge.svg?sanitize=true" alt="build container images" /&gt;&lt;/a&gt;&lt;a href="https://github.com/go-skynet/LocalAI/actions/workflows/bump_deps.yaml"&gt;&lt;img src="https://github.com/go-skynet/LocalAI/actions/workflows/bump_deps.yaml/badge.svg?sanitize=true" alt="Bump dependencies" /&gt;&lt;/a&gt;&lt;a href="https://artifacthub.io/packages/search?repo=localai"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/localai" alt="Artifact Hub" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;LocalAI&lt;/strong&gt; is the free, Open Source OpenAI alternative. LocalAI act as a drop-in replacement REST API that's compatible with OpenAI (Elevenlabs, Anthropic... ) API specifications for local AI inferencing. It allows you to run LLMs, generate images, audio (and not only) locally or on-prem with consumer grade hardware, supporting multiple model families. Does not require GPU. It is created and maintained by &lt;a href="https://github.com/mudler"&gt;Ettore Di Giacinto&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üìöüÜï Local Stack Family&lt;/h2&gt; 
&lt;p&gt;üÜï LocalAI is now part of a comprehensive suite of AI tools designed to work together:&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="50%" valign="top"&gt; &lt;a href="https://github.com/mudler/LocalAGI"&gt; &lt;img src="https://raw.githubusercontent.com/mudler/LocalAGI/refs/heads/main/webui/react-ui/public/logo_2.png" width="300" alt="LocalAGI Logo" /&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td width="50%" valign="top"&gt; &lt;h3&gt;&lt;a href="https://github.com/mudler/LocalAGI"&gt;LocalAGI&lt;/a&gt;&lt;/h3&gt; &lt;p&gt;A powerful Local AI agent management platform that serves as a drop-in replacement for OpenAI's Responses API, enhanced with advanced agentic capabilities.&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" valign="top"&gt; &lt;a href="https://github.com/mudler/LocalRecall"&gt; &lt;img src="https://raw.githubusercontent.com/mudler/LocalRecall/refs/heads/main/static/localrecall_horizontal.png" width="300" alt="LocalRecall Logo" /&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td width="50%" valign="top"&gt; &lt;h3&gt;&lt;a href="https://github.com/mudler/LocalRecall"&gt;LocalRecall&lt;/a&gt;&lt;/h3&gt; &lt;p&gt;A REST-ful API and knowledge base management system that provides persistent memory and storage capabilities for AI agents.&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;Screenshots&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Talk Interface&lt;/th&gt; 
   &lt;th&gt;Generate Audio&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_tts.png" alt="Screenshot 2025-03-31 at 12-01-36 LocalAI - Talk" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_tts.png" alt="Screenshot 2025-03-31 at 12-01-29 LocalAI - Generate audio with voice-en-us-ryan-low" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Models Overview&lt;/th&gt; 
   &lt;th&gt;Generate Images&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_gallery.png" alt="Screenshot 2025-03-31 at 12-01-20 LocalAI - Models" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_image.png" alt="Screenshot 2025-03-31 at 12-31-41 LocalAI - Generate images with flux 1-dev" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Chat Interface&lt;/th&gt; 
   &lt;th&gt;Home&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_chat.png" alt="Screenshot 2025-03-31 at 11-57-44 LocalAI - Chat with localai-functioncall-qwen2 5-7b-v0 5" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_home.png" alt="Screenshot 2025-03-31 at 11-57-23 LocalAI API - c2a39e3 (c2a39e3639227cfd94ffffe9f5691239acc275a8)" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Login&lt;/th&gt; 
   &lt;th&gt;Swarm&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_login.png" alt="Screenshot 2025-03-31 at 12-09-59 " /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_p2p.png" alt="Screenshot 2025-03-31 at 12-10-39 LocalAI - P2P dashboard" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üíª Quickstart&lt;/h2&gt; 
&lt;p&gt;Run the installer script:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Basic installation
curl https://localai.io/install.sh | sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more installation options, see &lt;a href="https://localai.io/docs/advanced/installer/"&gt;Installer Options&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;macOS Download:&lt;/h3&gt; 
&lt;a href="https://github.com/mudler/LocalAI/releases/latest/download/LocalAI.dmg"&gt; &lt;img src="https://img.shields.io/badge/Download-macOS-blue?style=for-the-badge&amp;amp;logo=apple&amp;amp;logoColor=white" alt="Download LocalAI for macOS" /&gt; &lt;/a&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Note: the DMGs are not signed by Apple as quarantined. See &lt;a href="https://github.com/mudler/LocalAI/issues/6268"&gt;https://github.com/mudler/LocalAI/issues/6268&lt;/a&gt; for a workaround, fix is tracked here: &lt;a href="https://github.com/mudler/LocalAI/issues/6244"&gt;https://github.com/mudler/LocalAI/issues/6244&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Or run with docker:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;üí° Docker Run vs Docker Start&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;docker run&lt;/code&gt; creates and starts a new container. If a container with the same name already exists, this command will fail.&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;docker start&lt;/code&gt; starts an existing container that was previously created with &lt;code&gt;docker run&lt;/code&gt;.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;If you've already run LocalAI before and want to start it again, use: &lt;code&gt;docker start -i local-ai&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;CPU only image:&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -ti --name local-ai -p 8080:8080 localai/localai:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;NVIDIA GPU Images:&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# CUDA 12.0
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-gpu-nvidia-cuda-12

# CUDA 11.7
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-gpu-nvidia-cuda-11

# NVIDIA Jetson (L4T) ARM64
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-nvidia-l4t-arm64
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;AMD GPU Images (ROCm):&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -ti --name local-ai -p 8080:8080 --device=/dev/kfd --device=/dev/dri --group-add=video localai/localai:latest-gpu-hipblas
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Intel GPU Images (oneAPI):&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -ti --name local-ai -p 8080:8080 --device=/dev/dri/card1 --device=/dev/dri/renderD128 localai/localai:latest-gpu-intel
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Vulkan GPU Images:&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-gpu-vulkan
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;AIO Images (pre-downloaded models):&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# CPU version
docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-aio-cpu

# NVIDIA CUDA 12 version
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-aio-gpu-nvidia-cuda-12

# NVIDIA CUDA 11 version
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-aio-gpu-nvidia-cuda-11

# Intel GPU version
docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-aio-gpu-intel

# AMD GPU version
docker run -ti --name local-ai -p 8080:8080 --device=/dev/kfd --device=/dev/dri --group-add=video localai/localai:latest-aio-gpu-hipblas
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more information about the AIO images and pre-downloaded models, see &lt;a href="https://localai.io/basics/container/"&gt;Container Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To load models:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# From the model gallery (see available models with `local-ai models list`, in the WebUI from the model tab, or visiting https://models.localai.io)
local-ai run llama-3.2-1b-instruct:q4_k_m
# Start LocalAI with the phi-2 model directly from huggingface
local-ai run huggingface://TheBloke/phi-2-GGUF/phi-2.Q8_0.gguf
# Install and run a model from the Ollama OCI registry
local-ai run ollama://gemma:2b
# Run a model from a configuration file
local-ai run https://gist.githubusercontent.com/.../phi-2.yaml
# Install and run a model from a standard OCI registry (e.g., Docker Hub)
local-ai run oci://localai/phi-2:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;‚ö° &lt;strong&gt;Automatic Backend Detection&lt;/strong&gt;: When you install models from the gallery or YAML files, LocalAI automatically detects your system's GPU capabilities (NVIDIA, AMD, Intel) and downloads the appropriate backend. For advanced configuration options, see &lt;a href="https://localai.io/features/gpu-acceleration/#automatic-backend-detection"&gt;GPU Acceleration&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;For more information, see &lt;a href="https://localai.io/basics/getting_started/index.html"&gt;üíª Getting started&lt;/a&gt;, if you are interested in our roadmap items and future enhancements, you can see the &lt;a href="https://github.com/mudler/LocalAI/issues?q=is%3Aissue+is%3Aopen+label%3Aroadmap"&gt;Issues labeled as Roadmap here&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üì∞ Latest project news&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;October 2025: üîå &lt;a href="https://localai.io/docs/features/mcp/"&gt;Model Context Protocol (MCP)&lt;/a&gt; support added for agentic capabilities with external tools&lt;/li&gt; 
 &lt;li&gt;September 2025: New Launcher application for MacOS and Linux, extended support to many backends for Mac and Nvidia L4T devices. Models: Added MLX-Audio, WAN 2.2. WebUI improvements and Python-based backends now ships portable python environments.&lt;/li&gt; 
 &lt;li&gt;August 2025: MLX, MLX-VLM, Diffusers and llama.cpp are now supported on Mac M1/M2/M3+ chips ( with &lt;code&gt;development&lt;/code&gt; suffix in the gallery ): &lt;a href="https://github.com/mudler/LocalAI/pull/6049"&gt;https://github.com/mudler/LocalAI/pull/6049&lt;/a&gt; &lt;a href="https://github.com/mudler/LocalAI/pull/6119"&gt;https://github.com/mudler/LocalAI/pull/6119&lt;/a&gt; &lt;a href="https://github.com/mudler/LocalAI/pull/6121"&gt;https://github.com/mudler/LocalAI/pull/6121&lt;/a&gt; &lt;a href="https://github.com/mudler/LocalAI/pull/6060"&gt;https://github.com/mudler/LocalAI/pull/6060&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;July/August 2025: üîç &lt;a href="https://localai.io/features/object-detection/"&gt;Object Detection&lt;/a&gt; added to the API featuring &lt;a href="https://github.com/roboflow/rf-detr"&gt;rf-detr&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;July 2025: All backends migrated outside of the main binary. LocalAI is now more lightweight, small, and automatically downloads the required backend to run the model. &lt;a href="https://github.com/mudler/LocalAI/releases/tag/v3.2.0"&gt;Read the release notes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;June 2025: &lt;a href="https://github.com/mudler/LocalAI/pull/5607"&gt;Backend management&lt;/a&gt; has been added. Attention: extras images are going to be deprecated from the next release! Read &lt;a href="https://github.com/mudler/LocalAI/pull/5607"&gt;the backend management PR&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;May 2025: &lt;a href="https://github.com/mudler/LocalAI/pull/5466"&gt;Audio input&lt;/a&gt; and &lt;a href="https://github.com/mudler/LocalAI/pull/5396"&gt;Reranking&lt;/a&gt; in llama.cpp backend, &lt;a href="https://github.com/mudler/LocalAI/pull/5392"&gt;Realtime API&lt;/a&gt;, Support to Gemma, SmollVLM, and more multimodal models (available in the gallery).&lt;/li&gt; 
 &lt;li&gt;May 2025: Important: image name changes &lt;a href="https://github.com/mudler/LocalAI/releases/tag/v2.29.0"&gt;See release&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Apr 2025: Rebrand, WebUI enhancements&lt;/li&gt; 
 &lt;li&gt;Apr 2025: &lt;a href="https://github.com/mudler/LocalAGI"&gt;LocalAGI&lt;/a&gt; and &lt;a href="https://github.com/mudler/LocalRecall"&gt;LocalRecall&lt;/a&gt; join the LocalAI family stack.&lt;/li&gt; 
 &lt;li&gt;Apr 2025: WebUI overhaul, AIO images updates&lt;/li&gt; 
 &lt;li&gt;Feb 2025: Backend cleanup, Breaking changes, new backends (kokoro, OutelTTS, faster-whisper), Nvidia L4T images&lt;/li&gt; 
 &lt;li&gt;Jan 2025: LocalAI model release: &lt;a href="https://huggingface.co/mudler/LocalAI-functioncall-phi-4-v0.3"&gt;https://huggingface.co/mudler/LocalAI-functioncall-phi-4-v0.3&lt;/a&gt;, SANA support in diffusers: &lt;a href="https://github.com/mudler/LocalAI/pull/4603"&gt;https://github.com/mudler/LocalAI/pull/4603&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Dec 2024: stablediffusion.cpp backend (ggml) added ( &lt;a href="https://github.com/mudler/LocalAI/pull/4289"&gt;https://github.com/mudler/LocalAI/pull/4289&lt;/a&gt; )&lt;/li&gt; 
 &lt;li&gt;Nov 2024: Bark.cpp backend added ( &lt;a href="https://github.com/mudler/LocalAI/pull/4287"&gt;https://github.com/mudler/LocalAI/pull/4287&lt;/a&gt; )&lt;/li&gt; 
 &lt;li&gt;Nov 2024: Voice activity detection models (&lt;strong&gt;VAD&lt;/strong&gt;) added to the API: &lt;a href="https://github.com/mudler/LocalAI/pull/4204"&gt;https://github.com/mudler/LocalAI/pull/4204&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Oct 2024: examples moved to &lt;a href="https://github.com/mudler/LocalAI-examples"&gt;LocalAI-examples&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Aug 2024: üÜï FLUX-1, &lt;a href="https://explorer.localai.io"&gt;P2P Explorer&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;July 2024: üî•üî• üÜï P2P Dashboard, LocalAI Federated mode and AI Swarms: &lt;a href="https://github.com/mudler/LocalAI/pull/2723"&gt;https://github.com/mudler/LocalAI/pull/2723&lt;/a&gt;. P2P Global community pools: &lt;a href="https://github.com/mudler/LocalAI/issues/3113"&gt;https://github.com/mudler/LocalAI/issues/3113&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;May 2024: üî•üî• Decentralized P2P llama.cpp: &lt;a href="https://github.com/mudler/LocalAI/pull/2343"&gt;https://github.com/mudler/LocalAI/pull/2343&lt;/a&gt; (peer2peer llama.cpp!) üëâ Docs &lt;a href="https://localai.io/features/distribute/"&gt;https://localai.io/features/distribute/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;May 2024: üî•üî• Distributed inferencing: &lt;a href="https://github.com/mudler/LocalAI/pull/2324"&gt;https://github.com/mudler/LocalAI/pull/2324&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;April 2024: Reranker API: &lt;a href="https://github.com/mudler/LocalAI/pull/2121"&gt;https://github.com/mudler/LocalAI/pull/2121&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Roadmap items: &lt;a href="https://github.com/mudler/LocalAI/issues?q=is%3Aissue+is%3Aopen+label%3Aroadmap"&gt;List of issues&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üöÄ &lt;a href="https://localai.io/features/"&gt;Features&lt;/a&gt;&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üß© &lt;a href="https://localai.io/backends/"&gt;Backend Gallery&lt;/a&gt;: Install/remove backends on the fly, powered by OCI images ‚Äî fully customizable and API-driven.&lt;/li&gt; 
 &lt;li&gt;üìñ &lt;a href="https://localai.io/features/text-generation/"&gt;Text generation with GPTs&lt;/a&gt; (&lt;code&gt;llama.cpp&lt;/code&gt;, &lt;code&gt;transformers&lt;/code&gt;, &lt;code&gt;vllm&lt;/code&gt; ... &lt;a href="https://localai.io/model-compatibility/index.html#model-compatibility-table"&gt;&lt;span&gt;üìñ&lt;/span&gt; and more&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;üó£ &lt;a href="https://localai.io/features/text-to-audio/"&gt;Text to Audio&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üîà &lt;a href="https://localai.io/features/audio-to-text/"&gt;Audio to Text&lt;/a&gt; (Audio transcription with &lt;code&gt;whisper.cpp&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;üé® &lt;a href="https://localai.io/features/image-generation"&gt;Image generation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üî• &lt;a href="https://localai.io/features/openai-functions/"&gt;OpenAI-alike tools API&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üß† &lt;a href="https://localai.io/features/embeddings/"&gt;Embeddings generation for vector databases&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;‚úçÔ∏è &lt;a href="https://localai.io/features/constrained_grammars/"&gt;Constrained grammars&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üñºÔ∏è &lt;a href="https://localai.io/models/"&gt;Download Models directly from Huggingface &lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ü•Ω &lt;a href="https://localai.io/features/gpt-vision/"&gt;Vision API&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üîç &lt;a href="https://localai.io/features/object-detection/"&gt;Object Detection&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üìà &lt;a href="https://localai.io/features/reranker/"&gt;Reranker API&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üÜïüñß &lt;a href="https://localai.io/features/distribute/"&gt;P2P Inferencing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üÜïüîå &lt;a href="https://localai.io/docs/features/mcp/"&gt;Model Context Protocol (MCP)&lt;/a&gt; - Agentic capabilities with external tools and &lt;a href="https://github.com/mudler/LocalAGI"&gt;LocalAGI's Agentic capabilities&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üîä Voice activity detection (Silero-VAD support)&lt;/li&gt; 
 &lt;li&gt;üåç Integrated WebUI!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üß© Supported Backends &amp;amp; Acceleration&lt;/h2&gt; 
&lt;p&gt;LocalAI supports a comprehensive range of AI backends with multiple acceleration options:&lt;/p&gt; 
&lt;h3&gt;Text Generation &amp;amp; Language Models&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Backend&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Acceleration Support&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;llama.cpp&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;LLM inference in C/C++&lt;/td&gt; 
   &lt;td&gt;CUDA 11/12, ROCm, Intel SYCL, Vulkan, Metal, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;vLLM&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Fast LLM inference with PagedAttention&lt;/td&gt; 
   &lt;td&gt;CUDA 12, ROCm, Intel&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;transformers&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;HuggingFace transformers framework&lt;/td&gt; 
   &lt;td&gt;CUDA 11/12, ROCm, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;exllama2&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;GPTQ inference library&lt;/td&gt; 
   &lt;td&gt;CUDA 12&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;MLX&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Apple Silicon LLM inference&lt;/td&gt; 
   &lt;td&gt;Metal (M1/M2/M3+)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;MLX-VLM&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Apple Silicon Vision-Language Models&lt;/td&gt; 
   &lt;td&gt;Metal (M1/M2/M3+)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Audio &amp;amp; Speech Processing&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Backend&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Acceleration Support&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;whisper.cpp&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;OpenAI Whisper in C/C++&lt;/td&gt; 
   &lt;td&gt;CUDA 12, ROCm, Intel SYCL, Vulkan, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;faster-whisper&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Fast Whisper with CTranslate2&lt;/td&gt; 
   &lt;td&gt;CUDA 12, ROCm, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;bark&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Text-to-audio generation&lt;/td&gt; 
   &lt;td&gt;CUDA 12, ROCm, Intel&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;bark-cpp&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;C++ implementation of Bark&lt;/td&gt; 
   &lt;td&gt;CUDA, Metal, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;coqui&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Advanced TTS with 1100+ languages&lt;/td&gt; 
   &lt;td&gt;CUDA 12, ROCm, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;kokoro&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Lightweight TTS model&lt;/td&gt; 
   &lt;td&gt;CUDA 12, ROCm, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;chatterbox&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Production-grade TTS&lt;/td&gt; 
   &lt;td&gt;CUDA 11/12, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;piper&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Fast neural TTS system&lt;/td&gt; 
   &lt;td&gt;CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;kitten-tts&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Kitten TTS models&lt;/td&gt; 
   &lt;td&gt;CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;silero-vad&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Voice Activity Detection&lt;/td&gt; 
   &lt;td&gt;CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;neutts&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Text-to-speech with voice cloning&lt;/td&gt; 
   &lt;td&gt;CUDA 12, ROCm, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Image &amp;amp; Video Generation&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Backend&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Acceleration Support&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;stablediffusion.cpp&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Stable Diffusion in C/C++&lt;/td&gt; 
   &lt;td&gt;CUDA 12, Intel SYCL, Vulkan, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;diffusers&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;HuggingFace diffusion models&lt;/td&gt; 
   &lt;td&gt;CUDA 11/12, ROCm, Intel, Metal, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Specialized AI Tasks&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Backend&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Acceleration Support&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;rfdetr&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Real-time object detection&lt;/td&gt; 
   &lt;td&gt;CUDA 12, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;rerankers&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Document reranking API&lt;/td&gt; 
   &lt;td&gt;CUDA 11/12, ROCm, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;local-store&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Vector database&lt;/td&gt; 
   &lt;td&gt;CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;huggingface&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;HuggingFace API integration&lt;/td&gt; 
   &lt;td&gt;API-based&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Hardware Acceleration Matrix&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Acceleration Type&lt;/th&gt; 
   &lt;th&gt;Supported Backends&lt;/th&gt; 
   &lt;th&gt;Hardware Support&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;NVIDIA CUDA 11&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;llama.cpp, whisper, stablediffusion, diffusers, rerankers, bark, chatterbox&lt;/td&gt; 
   &lt;td&gt;Nvidia hardware&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;NVIDIA CUDA 12&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;All CUDA-compatible backends&lt;/td&gt; 
   &lt;td&gt;Nvidia hardware&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;AMD ROCm&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;llama.cpp, whisper, vllm, transformers, diffusers, rerankers, coqui, kokoro, bark, neutts&lt;/td&gt; 
   &lt;td&gt;AMD Graphics&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Intel oneAPI&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;llama.cpp, whisper, stablediffusion, vllm, transformers, diffusers, rfdetr, rerankers, exllama2, coqui, kokoro, bark&lt;/td&gt; 
   &lt;td&gt;Intel Arc, Intel iGPUs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Apple Metal&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;llama.cpp, whisper, diffusers, MLX, MLX-VLM, bark-cpp&lt;/td&gt; 
   &lt;td&gt;Apple M1/M2/M3+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Vulkan&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;llama.cpp, whisper, stablediffusion&lt;/td&gt; 
   &lt;td&gt;Cross-platform GPUs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;NVIDIA Jetson&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;llama.cpp, whisper, stablediffusion, diffusers, rfdetr&lt;/td&gt; 
   &lt;td&gt;ARM64 embedded AI&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;CPU Optimized&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;All backends&lt;/td&gt; 
   &lt;td&gt;AVX/AVX2/AVX512, quantization support&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;üîó Community and integrations&lt;/h3&gt; 
&lt;p&gt;Build and deploy custom containers:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sozercan/aikit"&gt;https://github.com/sozercan/aikit&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;WebUIs:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Jirubizu/localai-admin"&gt;https://github.com/Jirubizu/localai-admin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/go-skynet/LocalAI-frontend"&gt;https://github.com/go-skynet/LocalAI-frontend&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;QA-Pilot(An interactive chat project that leverages LocalAI LLMs for rapid understanding and navigation of GitHub code repository) &lt;a href="https://github.com/reid41/QA-Pilot"&gt;https://github.com/reid41/QA-Pilot&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Agentic Libraries:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mudler/cogito"&gt;https://github.com/mudler/cogito&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;MCPs:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mudler/MCPs"&gt;https://github.com/mudler/MCPs&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Model galleries&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/go-skynet/model-gallery"&gt;https://github.com/go-skynet/model-gallery&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Voice:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/richiejp/VoxInput"&gt;https://github.com/richiejp/VoxInput&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Other:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Helm chart &lt;a href="https://github.com/go-skynet/helm-charts"&gt;https://github.com/go-skynet/helm-charts&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;VSCode extension &lt;a href="https://github.com/badgooooor/localai-vscode-plugin"&gt;https://github.com/badgooooor/localai-vscode-plugin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Langchain: &lt;a href="https://python.langchain.com/docs/integrations/providers/localai/"&gt;https://python.langchain.com/docs/integrations/providers/localai/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Terminal utility &lt;a href="https://github.com/djcopley/ShellOracle"&gt;https://github.com/djcopley/ShellOracle&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Local Smart assistant &lt;a href="https://github.com/mudler/LocalAGI"&gt;https://github.com/mudler/LocalAGI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Home Assistant &lt;a href="https://github.com/sammcj/homeassistant-localai"&gt;https://github.com/sammcj/homeassistant-localai&lt;/a&gt; / &lt;a href="https://github.com/drndos/hass-openai-custom-conversation"&gt;https://github.com/drndos/hass-openai-custom-conversation&lt;/a&gt; / &lt;a href="https://github.com/valentinfrlch/ha-gpt4vision"&gt;https://github.com/valentinfrlch/ha-gpt4vision&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Discord bot &lt;a href="https://github.com/mudler/LocalAGI/tree/main/examples/discord"&gt;https://github.com/mudler/LocalAGI/tree/main/examples/discord&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Slack bot &lt;a href="https://github.com/mudler/LocalAGI/tree/main/examples/slack"&gt;https://github.com/mudler/LocalAGI/tree/main/examples/slack&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Shell-Pilot(Interact with LLM using LocalAI models via pure shell scripts on your Linux or MacOS system) &lt;a href="https://github.com/reid41/shell-pilot"&gt;https://github.com/reid41/shell-pilot&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Telegram bot &lt;a href="https://github.com/mudler/LocalAI/tree/master/examples/telegram-bot"&gt;https://github.com/mudler/LocalAI/tree/master/examples/telegram-bot&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Another Telegram Bot &lt;a href="https://github.com/JackBekket/Hellper"&gt;https://github.com/JackBekket/Hellper&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Auto-documentation &lt;a href="https://github.com/JackBekket/Reflexia"&gt;https://github.com/JackBekket/Reflexia&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Github bot which answer on issues, with code and documentation as context &lt;a href="https://github.com/JackBekket/GitHelper"&gt;https://github.com/JackBekket/GitHelper&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Github Actions: &lt;a href="https://github.com/marketplace/actions/start-localai"&gt;https://github.com/marketplace/actions/start-localai&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Examples: &lt;a href="https://github.com/mudler/LocalAI/tree/master/examples/"&gt;https://github.com/mudler/LocalAI/tree/master/examples/&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üîó Resources&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://localai.io/docs/advanced/fine-tuning/"&gt;LLM finetuning guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://localai.io/basics/build/index.html"&gt;How to build locally&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://localai.io/basics/getting_started/index.html#run-localai-in-kubernetes"&gt;How to install in Kubernetes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://localai.io/docs/integrations/"&gt;Projects integrating LocalAI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://io.midori-ai.xyz/howtos/"&gt;How tos section&lt;/a&gt; (curated by our community)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;span&gt;üìñ&lt;/span&gt; üé• &lt;a href="https://localai.io/basics/news/#media-blogs-social"&gt;Media, Blogs, Social&lt;/a&gt;&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.suse.com/c/running-ai-locally/"&gt;Run Visual studio code with LocalAI (SUSE)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üÜï &lt;a href="https://mudler.pm/posts/local-ai-jetson-nano-devkit/"&gt;Run LocalAI on Jetson Nano Devkit&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.pulumi.com/blog/low-code-llm-apps-with-local-ai-flowise-and-pulumi/"&gt;Run LocalAI on AWS EKS with Pulumi&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://staleks.hashnode.dev/installing-localai-on-aws-ec2-instance"&gt;Run LocalAI on AWS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mudler.pm/posts/smart-slackbot-for-teams/"&gt;Create a slackbot for teams and OSS projects that answer to documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=PKrDNuJ_dfE"&gt;LocalAI meets k8sgpt&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mudler.pm/posts/localai-question-answering/"&gt;Question Answering on Documents locally with LangChain, LocalAI, Chroma, and GPT4All&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://medium.com/@tyler_97636/k8sgpt-localai-unlock-kubernetes-superpowers-for-free-584790de9b65"&gt;Tutorial to use k8sgpt with LocalAI&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you utilize this repository, data in a downstream project, please consider citing it with:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@misc{localai,
  author = {Ettore Di Giacinto},
  title = {LocalAI: The free, Open source OpenAI alternative},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/go-skynet/LocalAI}},
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;‚ù§Ô∏è Sponsors&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Do you find LocalAI useful?&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Support the project by becoming &lt;a href="https://github.com/sponsors/mudler"&gt;a backer or sponsor&lt;/a&gt;. Your logo will show up here with a link to your website.&lt;/p&gt; 
&lt;p&gt;A huge thank you to our generous sponsors who support this project covering CI expenses, and our &lt;a href="https://github.com/sponsors/mudler"&gt;Sponsor list&lt;/a&gt;:&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.spectrocloud.com/" target="blank"&gt; &lt;img height="200" src="https://github.com/user-attachments/assets/72eab1dd-8b93-4fc0-9ade-84db49f24962" /&gt; &lt;/a&gt; &lt;a href="https://www.premai.io/" target="blank"&gt; &lt;img height="200" src="https://github.com/mudler/LocalAI/assets/2420543/42e4ca83-661e-4f79-8e46-ae43689683d6" /&gt; &lt;br /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;üåü Star history&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#go-skynet/LocalAI&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=go-skynet/LocalAI&amp;amp;type=Date" alt="LocalAI Star history Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üìñ License&lt;/h2&gt; 
&lt;p&gt;LocalAI is a community-driven project created by &lt;a href="https://github.com/mudler/"&gt;Ettore Di Giacinto&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;MIT - Author Ettore Di Giacinto &lt;a href="mailto:mudler@localai.io"&gt;mudler@localai.io&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üôá Acknowledgements&lt;/h2&gt; 
&lt;p&gt;LocalAI couldn't have been built without the help of great software already available from the community. Thank you!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ggerganov/llama.cpp"&gt;llama.cpp&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tatsu-lab/stanford_alpaca"&gt;https://github.com/tatsu-lab/stanford_alpaca&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cornelk/llama-go"&gt;https://github.com/cornelk/llama-go&lt;/a&gt; for the initial ideas&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/antimatter15/alpaca.cpp"&gt;https://github.com/antimatter15/alpaca.cpp&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/EdVince/Stable-Diffusion-NCNN"&gt;https://github.com/EdVince/Stable-Diffusion-NCNN&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ggerganov/whisper.cpp"&gt;https://github.com/ggerganov/whisper.cpp&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rhasspy/piper"&gt;https://github.com/rhasspy/piper&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ü§ó Contributors&lt;/h2&gt; 
&lt;p&gt;This is a community project, a special thanks to our contributors! ü§ó &lt;a href="https://github.com/go-skynet/LocalAI/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=go-skynet/LocalAI" /&gt; &lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>kvcache-ai/ktransformers</title>
      <link>https://github.com/kvcache-ai/ktransformers</link>
      <description>&lt;p&gt;A Flexible Framework for Experiencing Cutting-edge LLM Inference Optimizations&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p align="center"&gt; 
  &lt;picture&gt; 
   &lt;img alt="KTransformers" src="https://github.com/user-attachments/assets/d5a2492f-a415-4456-af99-4ab102f13f8b" width="50%" /&gt; 
  &lt;/picture&gt; &lt;/p&gt; 
 &lt;h3&gt;A Flexible Framework for Experiencing Cutting-edge LLM Inference/Fine-tune Optimizations&lt;/h3&gt; 
 &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/#-overview"&gt;üéØ Overview&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/#-kt-kernel---high-performance-inference-kernels"&gt;üöÄ kt-kernel&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/#-kt-sft---fine-tuning-framework"&gt;üéì KT-SFT&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/#-citation"&gt;üî• Citation&lt;/a&gt; | &lt;a href="https://github.com/kvcache-ai/ktransformers/discussions"&gt;üí¨ Discussion&lt;/a&gt; | &lt;a href="https://github.com/kvcache-ai/ktransformers/issues/1582"&gt;üöÄ Roadmap(2025Q4)&lt;/a&gt; &lt;/strong&gt; 
&lt;/div&gt; 
&lt;h2&gt;üéØ Overview&lt;/h2&gt; 
&lt;p&gt;KTransformers is a research project focused on efficient inference and fine-tuning of large language models through CPU-GPU heterogeneous computing. The project has evolved into &lt;strong&gt;two core modules&lt;/strong&gt;: &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/kt-kernel/"&gt;kt-kernel&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/KT-SFT/"&gt;KT-SFT&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üî• Updates&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Nov 6, 2025&lt;/strong&gt;: Support Kimi-K2-Thinking inference (&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/Kimi-K2-Thinking.md"&gt;Tutorial&lt;/a&gt;) and fine-tune (&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/SFT_Installation_Guide_KimiK2.md"&gt;Tutorial&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Nov 4, 2025&lt;/strong&gt;: KTransformers Fine-Tuning √ó LLaMA-Factory Integration. (&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/KTransformers-Fine-Tuning_User-Guide.md"&gt;Tutorial&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Oct 27, 2025&lt;/strong&gt;: Support Ascend NPU. (&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/zh/DeepseekR1_V3_tutorial_zh_for_Ascend_NPU.md"&gt;Tutorial&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Oct 10, 2025&lt;/strong&gt;: Integrating into SGLang. (&lt;a href="https://github.com/sgl-project/sglang/issues/11425"&gt;Roadmap&lt;/a&gt;, &lt;a href="https://lmsys.org/blog/2025-10-22-KTransformers/"&gt;Blog&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Sept 11, 2025&lt;/strong&gt;: Support Qwen3-Next. (&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/Qwen3-Next.md"&gt;Tutorial&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Sept 05, 2025&lt;/strong&gt;: Support Kimi-K2-0905. (&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/Kimi-K2.md"&gt;Tutorial&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;July 26, 2025&lt;/strong&gt;: Support SmallThinker and GLM4-MoE. (&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/SmallThinker_and_Glm4moe.md"&gt;Tutorial&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;July 11, 2025&lt;/strong&gt;: Support Kimi-K2. (&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/Kimi-K2.md"&gt;Tutorial&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;June 30, 2025&lt;/strong&gt;: Support 3-layer (GPU-CPU-Disk) &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/prefix_cache.md"&gt;prefix cache&lt;/a&gt; reuse.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;May 14, 2025&lt;/strong&gt;: Support Intel Arc GPU (&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/xpu.md"&gt;Tutorial&lt;/a&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Apr 29, 2025&lt;/strong&gt;: Support AMX-Int8„ÄÅ AMX-BF16 and Qwen3MoE (&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/AMX.md"&gt;Tutorial&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Apr 9, 2025&lt;/strong&gt;: Experimental support for LLaMA 4 models (&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/llama4.md"&gt;Tutorial&lt;/a&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Apr 2, 2025&lt;/strong&gt;: Support Multi-concurrency. (&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/balance-serve.md"&gt;Tutorial&lt;/a&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Mar 15, 2025&lt;/strong&gt;: Support ROCm on AMD GPU (&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/ROCm.md"&gt;Tutorial&lt;/a&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Mar 5, 2025&lt;/strong&gt;: Support unsloth 1.58/2.51 bits weights and &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/fp8_kernel.md"&gt;IQ1_S/FP8 hybrid&lt;/a&gt; weights. Support 139K &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/DeepseekR1_V3_tutorial.md#v022--v023-longer-context--fp8-kernel"&gt;Longer Context&lt;/a&gt; for DeepSeek-V3 and R1 in 24GB VRAM.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Feb 25, 2025&lt;/strong&gt;: Support &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/fp8_kernel.md"&gt;FP8 GPU kernel&lt;/a&gt; for DeepSeek-V3 and R1; &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/DeepseekR1_V3_tutorial.md#v022-longer-context"&gt;Longer Context&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Feb 15, 2025&lt;/strong&gt;: Longer Context (from 4K to 8K for 24GB VRAM) &amp;amp; Slightly Faster Speed Ôºà+15%, up to 16 Tokens/s), update &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/DeepseekR1_V3_tutorial.md"&gt;docs&lt;/a&gt; and &lt;a href="https://kvcache-ai.github.io/ktransformers/"&gt;online books&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Feb 10, 2025&lt;/strong&gt;: Support Deepseek-R1 and V3 on single (24GB VRAM)/multi gpu and 382G DRAM, up to 3~28x speedup. For detailed show case and reproduction tutorial, see &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/DeepseekR1_V3_tutorial.md"&gt;here&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Aug 28, 2024&lt;/strong&gt;: Decrease DeepseekV2's required VRAM from 21G to 11G.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Aug 15, 2024&lt;/strong&gt;: Update detailed &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/en/injection_tutorial.md"&gt;tutorial&lt;/a&gt; for injection and multi-GPU.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Aug 14, 2024&lt;/strong&gt;: Support llamfile as linear backend.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Aug 12, 2024&lt;/strong&gt;: Support multiple GPU; Support new model: mixtral 8*7B and 8*22B; Support q2k, q3k, q5k dequant on gpu.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Aug 9, 2024&lt;/strong&gt;: Support windows native.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üì¶ Core Modules&lt;/h2&gt; 
&lt;h3&gt;üöÄ &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/kt-kernel/"&gt;kt-kernel&lt;/a&gt; - High-Performance Inference Kernels&lt;/h3&gt; 
&lt;p&gt;CPU-optimized kernel operations for heterogeneous LLM inference.&lt;/p&gt; 
&lt;img width="1049" height="593" alt="image" src="https://github.com/user-attachments/assets/68f423da-3f55-4025-bdc9-9ceaa554f00b" /&gt; 
&lt;p&gt;&lt;strong&gt;Key Features:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;AMX/AVX Acceleration&lt;/strong&gt;: Intel AMX and AVX512/AVX2 optimized kernels for INT4/INT8 quantized inference&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MoE Optimization&lt;/strong&gt;: Efficient Mixture-of-Experts inference with NUMA-aware memory management&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Quantization Support&lt;/strong&gt;: CPU-side INT4/INT8 quantized weights, GPU-side GPTQ support&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Easy Integration&lt;/strong&gt;: Clean Python API for SGLang and other frameworks&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Quick Start:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd kt-kernel
pip install .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Use Cases:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;CPU-GPU hybrid inference for large MoE models&lt;/li&gt; 
 &lt;li&gt;Integration with SGLang for production serving&lt;/li&gt; 
 &lt;li&gt;Heterogeneous expert placement (hot experts on GPU, cold experts on CPU)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Performance Examples:&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model&lt;/th&gt; 
   &lt;th&gt;Hardware Configuration&lt;/th&gt; 
   &lt;th&gt;Total Throughput&lt;/th&gt; 
   &lt;th&gt;Output Throughput&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DeepSeek-R1-0528 (FP8)&lt;/td&gt; 
   &lt;td&gt;8√óL20 GPU + Xeon Gold 6454S&lt;/td&gt; 
   &lt;td&gt;227.85 tokens/s&lt;/td&gt; 
   &lt;td&gt;87.58 tokens/s (8-way concurrency)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;üëâ &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/kt-kernel/README.md"&gt;Full Documentation ‚Üí&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;üéì &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/KT-SFT/"&gt;KT-SFT&lt;/a&gt; - Fine-Tuning Framework&lt;/h3&gt; 
&lt;p&gt;KTransformers √ó LLaMA-Factory integration for ultra-large MoE model fine-tuning.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/doc/assets/image-20251011010558909.png" alt="image-20251011010558909" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Key Features:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Resource Efficient&lt;/strong&gt;: Fine-tune 671B DeepSeek-V3 with just &lt;strong&gt;70GB GPU memory&lt;/strong&gt; + 1.3TB RAM&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;LoRA Support&lt;/strong&gt;: Full LoRA fine-tuning with heterogeneous acceleration&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;LLaMA-Factory Integration&lt;/strong&gt;: Seamless integration with popular fine-tuning framework&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Production Ready&lt;/strong&gt;: Chat, batch inference, and metrics evaluation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Performance Examples:&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model&lt;/th&gt; 
   &lt;th&gt;Configuration&lt;/th&gt; 
   &lt;th&gt;Throughput&lt;/th&gt; 
   &lt;th&gt;GPU Memory&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DeepSeek-V3 (671B)&lt;/td&gt; 
   &lt;td&gt;LoRA + AMX&lt;/td&gt; 
   &lt;td&gt;~40 tokens/s&lt;/td&gt; 
   &lt;td&gt;70GB (multi-GPU)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DeepSeek-V2-Lite (14B)&lt;/td&gt; 
   &lt;td&gt;LoRA + AMX&lt;/td&gt; 
   &lt;td&gt;~530 tokens/s&lt;/td&gt; 
   &lt;td&gt;6GB&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Quick Start:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd KT-SFT
# Install environment following KT-SFT/README.md
USE_KT=1 llamafactory-cli train examples/train_lora/deepseek3_lora_sft_kt.yaml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;üëâ &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/KT-SFT/README.md"&gt;Full Documentation ‚Üí&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üî• Citation&lt;/h2&gt; 
&lt;p&gt;If you use KTransformers in your research, please cite our paper:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@inproceedings{10.1145/3731569.3764843,
  title = {KTransformers: Unleashing the Full Potential of CPU/GPU Hybrid Inference for MoE Models},
  author = {Chen, Hongtao and Xie, Weiyu and Zhang, Boxin and Tang, Jingqi and Wang, Jiahao and Dong, Jianwei and Chen, Shaoyuan and Yuan, Ziwei and Lin, Chen and Qiu, Chengyu and Zhu, Yuening and Ou, Qingliang and Liao, Jiaqi and Chen, Xianglin and Ai, Zhiyuan and Wu, Yongwei and Zhang, Mingxing},
  booktitle = {Proceedings of the ACM SIGOPS 31st Symposium on Operating Systems Principles},
  year = {2025}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üë• Contributors &amp;amp; Team&lt;/h2&gt; 
&lt;p&gt;Developed and maintained by:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://madsys.cs.tsinghua.edu.cn/"&gt;MADSys Lab&lt;/a&gt; @ Tsinghua University&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://approaching.ai/"&gt;Approaching.AI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Community contributors&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We welcome contributions! Please feel free to submit issues and pull requests.&lt;/p&gt; 
&lt;h2&gt;üí¨ Community &amp;amp; Support&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub Issues&lt;/strong&gt;: &lt;a href="https://github.com/kvcache-ai/ktransformers/issues"&gt;Report bugs or request features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub Discussions&lt;/strong&gt;: &lt;a href="https://github.com/kvcache-ai/ktransformers/discussions"&gt;Ask questions and share ideas&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;WeChat Group&lt;/strong&gt;: See &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/archive/WeChatGroup.png"&gt;archive/WeChatGroup.png&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üì¶ KT original Code&lt;/h2&gt; 
&lt;p&gt;The original integrated KTransformers framework has been archived to the &lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/archive/"&gt;&lt;code&gt;archive/&lt;/code&gt;&lt;/a&gt; directory for reference. The project now focuses on the two core modules above for better modularity and maintainability.&lt;/p&gt; 
&lt;p&gt;For the original documentation with full quick-start guides and examples, see:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/archive/README.md"&gt;archive/README.md&lt;/a&gt; (English)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kvcache-ai/ktransformers/main/archive/README_ZH.md"&gt;archive/README_ZH.md&lt;/a&gt; (‰∏≠Êñá)&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>HKUDS/DeepCode</title>
      <link>https://github.com/HKUDS/DeepCode</link>
      <description>&lt;p&gt;"DeepCode: Open Agentic Coding (Paper2Code &amp; Text2Web &amp; Text2Backend)"&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;table style="border: none; margin: 0 auto; padding: 0; border-collapse: collapse;"&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td align="center" style="vertical-align: middle; padding: 10px; border: none; width: 250px;"&gt; &lt;img src="https://raw.githubusercontent.com/HKUDS/DeepCode/main/assets/logo.png" alt="DeepCode Logo" width="200" style="margin: 0; padding: 0; display: block;" /&gt; &lt;/td&gt; 
    &lt;td align="left" style="vertical-align: middle; padding: 10px 0 10px 30px; border: none;"&gt; &lt;pre style="font-family: 'Courier New', monospace; font-size: 16px; color: #0EA5E9; margin: 0; padding: 0; text-shadow: 0 0 10px #0EA5E9, 0 0 20px rgba(14,165,233,0.5); line-height: 1.2; transform: skew(-1deg, 0deg); display: block;"&gt;    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó
    ‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù
    ‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó
    ‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù  ‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù  ‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïù ‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù
    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë     ‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó
    ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïù      ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù&lt;/pre&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://trendshift.io/repositories/14665" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/14665" alt="HKUDS%2FDeepCode | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; 
 &lt;/div&gt; 
 &lt;!-- &lt;img src="https://readme-typing-svg.herokuapp.com?font=Russo+One&amp;size=28&amp;duration=2000&amp;pause=800&amp;color=06B6D4&amp;background=00000000&amp;center=true&amp;vCenter=true&amp;width=800&amp;height=50&amp;lines=%E2%9A%A1+OPEN+AGENTIC+CODING+%E2%9A%A1" alt="DeepCode Tech Subtitle" style="margin-top: 5px; filter: drop-shadow(0 0 12px #06B6D4) drop-shadow(0 0 24px rgba(6,182,212,0.4));"/&gt; --&gt; 
 &lt;h1&gt;&lt;img src="https://github.com/Zongwei9888/Experiment_Images/raw/43c585dca3d21b8e4b6390d835cdd34dc4b4b23d/DeepCode_images/title_logo.svg?sanitize=true" alt="DeepCode Logo" width="32" height="32" style="vertical-align: middle; margin-right: 8px;" /&gt; DeepCode: Open Agentic Coding&lt;/h1&gt; 
 &lt;h3&gt;&lt;em&gt;Advancing Code Generation with Multi-Agent Systems&lt;/em&gt;&lt;/h3&gt; 
 &lt;!-- &lt;p align="center"&gt;
  &lt;img src="https://img.shields.io/badge/Version-1.0.0-00d4ff?style=for-the-badge&amp;logo=rocket&amp;logoColor=white" alt="Version"&gt;

  &lt;img src="https://img.shields.io/badge/License-MIT-4ecdc4?style=for-the-badge&amp;logo=opensourceinitiative&amp;logoColor=white" alt="License"&gt;
  &lt;img src="https://img.shields.io/badge/AI-Multi--Agent-9b59b6?style=for-the-badge&amp;logo=brain&amp;logoColor=white" alt="AI"&gt;
  &lt;img src="https://img.shields.io/badge/HKU-Data_Intelligence_Lab-f39c12?style=for-the-badge&amp;logo=university&amp;logoColor=white" alt="HKU"&gt;
&lt;/p&gt; --&gt; 
 &lt;p&gt; &lt;a href="https://github.com/HKUDS/DeepCode/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/HKUDS/DeepCode?color=00d9ff&amp;amp;style=for-the-badge&amp;amp;logo=star&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/badge/üêçPython-3.13-4ecdc4?style=for-the-badge&amp;amp;logo=python&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt; &lt;a href="https://pypi.org/project/deepcode-hku/"&gt;&lt;img src="https://img.shields.io/pypi/v/deepcode-hku.svg?style=for-the-badge&amp;amp;logo=pypi&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e&amp;amp;color=ff6b6b" /&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;p&gt; &lt;a href="https://discord.gg/yF2MmDJyGJ"&gt;&lt;img src="https://img.shields.io/badge/üí¨Discord-Community-7289da?style=for-the-badge&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;a href="https://github.com/HKUDS/DeepCode/issues/11"&gt;&lt;img src="https://img.shields.io/badge/üí¨WeChat-Group-07c160?style=for-the-badge&amp;amp;logo=wechat&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;div style="width: 100%; height: 2px; margin: 20px 0; background: linear-gradient(90deg, transparent, #00d9ff, transparent);"&gt;&lt;/div&gt; 
 &lt;/div&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-quick-start" style="text-decoration: none;"&gt; &lt;img src="https://img.shields.io/badge/Quick%20Start-Get%20Started%20Now-00d9ff?style=for-the-badge&amp;amp;logo=rocket&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt; &lt;/a&gt; 
 &lt;/div&gt; 
 &lt;div align="center" style="margin-top: 10px;"&gt; 
  &lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/README.md"&gt; &lt;img src="https://img.shields.io/badge/English-00d4ff?style=for-the-badge&amp;amp;logo=readme&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" alt="English" /&gt; &lt;/a&gt; 
  &lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/README_ZH.md"&gt; &lt;img src="https://img.shields.io/badge/‰∏≠Êñá-00d4ff?style=for-the-badge&amp;amp;logo=readme&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" alt="‰∏≠Êñá" /&gt; &lt;/a&gt; 
 &lt;/div&gt; 
 &lt;h3&gt;üñ•Ô∏è &lt;strong&gt;Interface Showcase&lt;/strong&gt;&lt;/h3&gt; 
 &lt;table align="center" width="100%" style="border: none; border-collapse: collapse; margin: 30px 0;"&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td width="50%" align="center" style="vertical-align: top; padding: 20px;"&gt; &lt;h4&gt;üñ•Ô∏è &lt;strong&gt;CLI Interface&lt;/strong&gt;&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;Terminal-Based Development&lt;/strong&gt;&lt;/p&gt; 
     &lt;div align="center"&gt; 
      &lt;img src="https://github.com/Zongwei9888/Experiment_Images/raw/8882a7313c504ca97ead6e7b36c51aa761b6a4f3/DeepCode_images/CLI.gif" alt="CLI Interface Demo" width="100%" style="border-radius: 10px; box-shadow: 0 8px 20px rgba(45,55,72,0.3); margin: 15px 0;" /&gt; 
      &lt;div style="background: linear-gradient(135deg, #2D3748 0%, #4A5568 100%); border-radius: 12px; padding: 15px; margin: 15px 0; color: white;"&gt; 
       &lt;strong&gt;üöÄ Advanced Terminal Experience&lt;/strong&gt;
       &lt;br /&gt; 
       &lt;small&gt;‚ö° Fast command-line workflow&lt;br /&gt;üîß Developer-friendly interface&lt;br /&gt;üìä Real-time progress tracking&lt;/small&gt; 
      &lt;/div&gt; 
      &lt;p&gt;&lt;em&gt;Professional terminal interface for advanced users and CI/CD integration&lt;/em&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
    &lt;td width="50%" align="center" style="vertical-align: top; padding: 20px;"&gt; &lt;h4&gt;üåê &lt;strong&gt;Web Interface&lt;/strong&gt;&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;Visual Interactive Experience&lt;/strong&gt;&lt;/p&gt; 
     &lt;div align="center"&gt; 
      &lt;img src="https://github.com/Zongwei9888/Experiment_Images/raw/8882a7313c504ca97ead6e7b36c51aa761b6a4f3/DeepCode_images/UI.gif" alt="Web Interface Demo" width="100%" style="border-radius: 10px; box-shadow: 0 8px 20px rgba(14,165,233,0.3); margin: 15px 0;" /&gt; 
      &lt;div style="background: linear-gradient(135deg, #0EA5E9 0%, #00D4FF 100%); border-radius: 12px; padding: 15px; margin: 15px 0; color: white;"&gt; 
       &lt;strong&gt;üé® Modern Web Dashboard&lt;/strong&gt;
       &lt;br /&gt; 
       &lt;small&gt;üñ±Ô∏è Intuitive drag-and-drop&lt;br /&gt;üì± Responsive design&lt;br /&gt;üéØ Visual progress tracking&lt;/small&gt; 
      &lt;/div&gt; 
      &lt;p&gt;&lt;em&gt;Beautiful web interface with streamlined workflow for all skill levels&lt;/em&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
 &lt;hr /&gt; 
 &lt;div align="center"&gt; 
  &lt;h3&gt;üé¨ &lt;strong&gt;Introduction Video&lt;/strong&gt;&lt;/h3&gt; 
  &lt;div style="margin: 20px 0;"&gt; 
   &lt;a href="https://youtu.be/PRgmP8pOI08" target="_blank"&gt; &lt;img src="https://img.youtube.com/vi/PRgmP8pOI08/maxresdefault.jpg" alt="DeepCode Introduction Video" width="75%" style="border-radius: 12px; box-shadow: 0 8px 25px rgba(0,0,0,0.15); transition: transform 0.3s ease;" /&gt; &lt;/a&gt; 
  &lt;/div&gt; 
  &lt;p&gt;&lt;em&gt;üéØ &lt;strong&gt;Watch our complete introduction&lt;/strong&gt; - See how DeepCode transforms research papers and natural language into production-ready code&lt;/em&gt;&lt;/p&gt; 
  &lt;p&gt; &lt;a href="https://youtu.be/PRgmP8pOI08" target="_blank"&gt; &lt;img src="https://img.shields.io/badge/‚ñ∂Ô∏è_Watch_Video-FF0000?style=for-the-badge&amp;amp;logo=youtube&amp;amp;logoColor=white" alt="Watch Video" /&gt; &lt;/a&gt; &lt;/p&gt; 
 &lt;/div&gt; 
 &lt;hr /&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;&lt;em&gt;"Where AI Agents Transform Ideas into Production-Ready Code"&lt;/em&gt;&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìë Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-news"&gt;üì∞ News&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-key-features"&gt;üöÄ Key Features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#%EF%B8%8F-architecture"&gt;üèóÔ∏è Architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-experimental-results"&gt;üìä Experimental Results&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-quick-start"&gt;üöÄ Quick Start&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-examples"&gt;üí° Examples&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-live-demonstrations"&gt;üé¨ Live Demonstrations&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-star-history"&gt;‚≠ê Star History&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-license"&gt;üìÑ License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üì∞ News&lt;/h2&gt; 
&lt;p&gt;üéâ &lt;strong&gt;[2025-10] üéâ [2025-10-28] DeepCode Achieves SOTA on PaperBench!&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;DeepCode sets new benchmarks on OpenAI's PaperBench Code-Dev across all categories:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üèÜ &lt;strong&gt;Surpasses Human Experts&lt;/strong&gt;: &lt;strong&gt;75.9%&lt;/strong&gt; (DeepCode) vs Top Machine Learning PhDs 72.4% (+3.5%).&lt;/li&gt; 
 &lt;li&gt;ü•á &lt;strong&gt;Outperforms SOTA Commercial Code Agents&lt;/strong&gt;: &lt;strong&gt;84.8%&lt;/strong&gt; (DeepCode) vs Leading Commercial Code Agents (+26.1%) (Cursor, Claude Code, and Codex).&lt;/li&gt; 
 &lt;li&gt;üî¨ &lt;strong&gt;Advances Scientific Coding&lt;/strong&gt;: &lt;strong&gt;73.5%&lt;/strong&gt; (DeepCode) vs PaperCoder 51.1% (+22.4%).&lt;/li&gt; 
 &lt;li&gt;üöÄ &lt;strong&gt;Beats LLM Agents&lt;/strong&gt;: &lt;strong&gt;73.5%&lt;/strong&gt; (DeepCode) vs best LLM frameworks 43.3% (+30.2%).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üöÄ Key Features&lt;/h2&gt; 
&lt;br /&gt; 
&lt;table align="center" width="100%" style="border: none; table-layout: fixed;"&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="30%" align="center" style="vertical-align: top; padding: 20px;"&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;h3 style="margin: 0; padding: 0;"&gt;üöÄ &lt;strong&gt;Paper2Code&lt;/strong&gt;&lt;/h3&gt; 
    &lt;/div&gt; 
    &lt;div align="center" style="margin: 15px 0;"&gt; 
     &lt;img src="https://img.shields.io/badge/ALGORITHM-IMPLEMENTATION-ff6b6b?style=for-the-badge&amp;amp;logo=algorithm&amp;amp;logoColor=white" alt="Algorithm Badge" /&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;&lt;strong&gt;Automated Implementation of Complex Algorithms&lt;/strong&gt;&lt;/p&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 60px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;Effortlessly converts complex algorithms from research papers into &lt;strong&gt;high-quality&lt;/strong&gt;, &lt;strong&gt;production-ready&lt;/strong&gt; code, accelerating algorithm reproduction.&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
   &lt;td width="30%" align="center" style="vertical-align: top; padding: 20px;"&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;h3 style="margin: 0; padding: 0;"&gt;üé® &lt;strong&gt;Text2Web&lt;/strong&gt;&lt;/h3&gt; 
    &lt;/div&gt; 
    &lt;div align="center" style="margin: 15px 0;"&gt; 
     &lt;img src="https://img.shields.io/badge/FRONTEND-DEVELOPMENT-4ecdc4?style=for-the-badge&amp;amp;logo=react&amp;amp;logoColor=white" alt="Frontend Badge" /&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;&lt;strong&gt;Automated Front-End Web Development&lt;/strong&gt;&lt;/p&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 60px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;Translates plain textual descriptions into &lt;strong&gt;fully functional&lt;/strong&gt;, &lt;strong&gt;visually appealing&lt;/strong&gt; front-end web code for rapid interface creation.&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
   &lt;td width="30%" align="center" style="vertical-align: top; padding: 20px;"&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;h3 style="margin: 0; padding: 0;"&gt;‚öôÔ∏è &lt;strong&gt;Text2Backend&lt;/strong&gt;&lt;/h3&gt; 
    &lt;/div&gt; 
    &lt;div align="center" style="margin: 15px 0;"&gt; 
     &lt;img src="https://img.shields.io/badge/BACKEND-DEVELOPMENT-9b59b6?style=for-the-badge&amp;amp;logo=server&amp;amp;logoColor=white" alt="Backend Badge" /&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;&lt;strong&gt;Automated Back-End Development&lt;/strong&gt;&lt;/p&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 60px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;Generates &lt;strong&gt;efficient&lt;/strong&gt;, &lt;strong&gt;scalable&lt;/strong&gt;, and &lt;strong&gt;feature-rich&lt;/strong&gt; back-end code from simple text inputs, streamlining server-side development.&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;br /&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìä Experimental Results&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/HKUDS/DeepCode/main/assets/result_main02.jpg" /&gt;
 &lt;br /&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;p&gt;We evaluate &lt;strong&gt;DeepCode&lt;/strong&gt; on the &lt;a href="https://openai.com/index/paperbench/"&gt;&lt;em&gt;PaperBench&lt;/em&gt;&lt;/a&gt; benchmark (released by OpenAI), a rigorous testbed requiring AI agents to independently reproduce 20 ICML 2024 papers from scratch. The benchmark comprises 8,316 gradable components assessed using SimpleJudge with hierarchical weighting.&lt;/p&gt; 
&lt;p&gt;Our experiments compare DeepCode against four baseline categories: &lt;strong&gt;(1) Human Experts&lt;/strong&gt;, &lt;strong&gt;(2) State-of-the-Art Commercial Code Agents&lt;/strong&gt;, &lt;strong&gt;(3) Scientific Code Agents&lt;/strong&gt;, and &lt;strong&gt;(4) LLM-Based Agents&lt;/strong&gt;.&lt;/p&gt; 
&lt;h3&gt;‚ë† üß† Human Expert Performance (Top Machine Learning PhD)&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;DeepCode: 75.9% vs. Top Machine Learning PhD: 72.4% (+3.5%)&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;DeepCode achieves &lt;strong&gt;75.9%&lt;/strong&gt; on the 3-paper human evaluation subset, &lt;strong&gt;surpassing the best-of-3 human expert baseline (72.4%) by +3.5 percentage points&lt;/strong&gt;. This demonstrates that our framework not only matches but exceeds expert-level code reproduction capabilities, representing a significant milestone in autonomous scientific software engineering.&lt;/p&gt; 
&lt;h3&gt;‚ë° üíº State-of-the-Art Commercial Code Agents&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;DeepCode: 84.8% vs. Best Commercial Agent: 58.7% (+26.1%)&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;On the 5-paper subset, DeepCode substantially outperforms leading commercial coding tools:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Cursor: 58.4%&lt;/li&gt; 
 &lt;li&gt;Claude Code: 58.7%&lt;/li&gt; 
 &lt;li&gt;Codex: 40.0%&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;DeepCode: 84.8%&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This represents a &lt;strong&gt;+26.1% improvement&lt;/strong&gt; over the leading commercial code agent. All commercial agents utilize Claude Sonnet 4.5 or GPT-5 Codex-high, highlighting that &lt;strong&gt;DeepCode's superior architecture&lt;/strong&gt;‚Äîrather than base model capability‚Äîdrives this performance gap.&lt;/p&gt; 
&lt;h3&gt;‚ë¢ üî¨ Scientific Code Agents&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;DeepCode: 73.5% vs. PaperCoder: 51.1% (+22.4%)&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Compared to PaperCoder (&lt;strong&gt;51.1%&lt;/strong&gt;), the state-of-the-art scientific code reproduction framework, DeepCode achieves &lt;strong&gt;73.5%&lt;/strong&gt;, demonstrating a &lt;strong&gt;+22.4% relative improvement&lt;/strong&gt;. This substantial margin validates our multi-module architecture combining planning, hierarchical task decomposition, code generation, and iterative debugging over simpler pipeline-based approaches.&lt;/p&gt; 
&lt;h3&gt;‚ë£ ü§ñ LLM-Based Agents&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;DeepCode: 73.5% vs. Best LLM Agent: 43.3% (+30.2%)&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;DeepCode significantly outperforms all tested LLM agents:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Claude 3.5 Sonnet + IterativeAgent: 27.5%&lt;/li&gt; 
 &lt;li&gt;o1 + IterativeAgent (36 hours): 42.4%&lt;/li&gt; 
 &lt;li&gt;o1 BasicAgent: 43.3%&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;DeepCode: 73.5%&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The &lt;strong&gt;+30.2% improvement&lt;/strong&gt; over the best-performing LLM agent demonstrates that sophisticated agent scaffolding, rather than extended inference time or larger models, is critical for complex code reproduction tasks.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;üéØ &lt;strong&gt;Autonomous Self-Orchestrating Multi-Agent Architecture&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;The Challenges&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;üìÑ &lt;strong&gt;Implementation Complexity&lt;/strong&gt;: Converting academic papers and complex algorithms into working code requires significant technical effort and domain expertise&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;üî¨ &lt;strong&gt;Research Bottleneck&lt;/strong&gt;: Researchers spend valuable time implementing algorithms instead of focusing on their core research and discovery work&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;‚è±Ô∏è &lt;strong&gt;Development Delays&lt;/strong&gt;: Product teams experience long wait times between concept and testable prototypes, slowing down innovation cycles&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;üîÑ &lt;strong&gt;Repetitive Coding&lt;/strong&gt;: Developers repeatedly implement similar patterns and functionality instead of building on existing solutions&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;DeepCode&lt;/strong&gt; addresses these workflow inefficiencies by providing reliable automation for common development tasks, streamlining your development workflow from concept to code.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;pre&gt;&lt;code class="language-mermaid"&gt;flowchart LR
    A["üìÑ Research Papers&amp;lt;br/&amp;gt;üí¨ Text Prompts&amp;lt;br/&amp;gt;üåê URLs &amp;amp; Document&amp;lt;br/&amp;gt;üìé Files: PDF, DOC, PPTX, TXT, HTML"] --&amp;gt; B["üß† DeepCode&amp;lt;br/&amp;gt;Multi-Agent Engine"]
    B --&amp;gt; C["üöÄ Algorithm Implementation &amp;lt;br/&amp;gt;üé® Frontend Development &amp;lt;br/&amp;gt;‚öôÔ∏è Backend Development"]

    style A fill:#ff6b6b,stroke:#c0392b,stroke-width:2px,color:#000
    style B fill:#00d4ff,stroke:#0984e3,stroke-width:3px,color:#000
    style C fill:#00b894,stroke:#00a085,stroke-width:2px,color:#000
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üèóÔ∏è Architecture&lt;/h2&gt; 
&lt;h3&gt;üìä &lt;strong&gt;System Overview&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;DeepCode&lt;/strong&gt; is an AI-powered development platform that automates code generation and implementation tasks. Our multi-agent system handles the complexity of translating requirements into functional, well-structured code, allowing you to focus on innovation rather than implementation details.&lt;/p&gt; 
&lt;p&gt;üéØ &lt;strong&gt;Technical Capabilities&lt;/strong&gt;:&lt;/p&gt; 
&lt;p&gt;üß¨ &lt;strong&gt;Research-to-Production Pipeline&lt;/strong&gt;&lt;br /&gt; Multi-modal document analysis engine that extracts algorithmic logic and mathematical models from academic papers. Generates optimized implementations with proper data structures while preserving computational complexity characteristics.&lt;/p&gt; 
&lt;p&gt;ü™Ñ &lt;strong&gt;Natural Language Code Synthesis&lt;/strong&gt;&lt;br /&gt; Context-aware code generation using fine-tuned language models trained on curated code repositories. Maintains architectural consistency across modules while supporting multiple programming languages and frameworks.&lt;/p&gt; 
&lt;p&gt;‚ö° &lt;strong&gt;Automated Prototyping Engine&lt;/strong&gt;&lt;br /&gt; Intelligent scaffolding system generating complete application structures including database schemas, API endpoints, and frontend components. Uses dependency analysis to ensure scalable architecture from initial generation.&lt;/p&gt; 
&lt;p&gt;üíé &lt;strong&gt;Quality Assurance Automation&lt;/strong&gt;&lt;br /&gt; Integrated static analysis with automated unit test generation and documentation synthesis. Employs AST analysis for code correctness and property-based testing for comprehensive coverage.&lt;/p&gt; 
&lt;p&gt;üîÆ &lt;strong&gt;CodeRAG Integration System&lt;/strong&gt;&lt;br /&gt; Advanced retrieval-augmented generation combining semantic vector embeddings with graph-based dependency analysis. Automatically discovers optimal libraries and implementation patterns from large-scale code corpus.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;üîß &lt;strong&gt;Core Techniques&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;üß† &lt;strong&gt;Intelligent Orchestration Agent&lt;/strong&gt;: Central decision-making system that coordinates workflow phases and analyzes requirements. Employs dynamic planning algorithms to adapt execution strategies in real-time based on evolving project complexity. Dynamically selects optimal processing strategies for each implementation step. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;üíæ &lt;strong&gt;Efficient Memory Mechanism&lt;/strong&gt;: Advanced context engineering system that manages large-scale code contexts efficiently. Implements hierarchical memory structures with intelligent compression for handling complex codebases. This component enables instant retrieval of implementation patterns and maintains semantic coherence across extended development sessions. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;üîç &lt;strong&gt;Advanced CodeRAG System&lt;/strong&gt;: Global code comprehension engine that analyzes complex inter-dependencies across repositories. Performs cross-codebase relationship mapping to understand architectural patterns from a holistic perspective. This module leverages dependency graphs and semantic analysis to provide globally-aware code recommendations during implementation.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h3&gt;ü§ñ &lt;strong&gt;Multi-Agent Architecture of DeepCode&lt;/strong&gt;:&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üéØ Central Orchestrating Agent&lt;/strong&gt;: Orchestrates entire workflow execution and makes strategic decisions. Coordinates specialized agents based on input complexity analysis. Implements dynamic task planning and resource allocation algorithms. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üìù Intent Understanding Agent&lt;/strong&gt;: Performs deep semantic analysis of user requirements to decode complex intentions. Extracts functional specifications and technical constraints through advanced NLP processing. Transforms ambiguous human descriptions into precise, actionable development specifications with structured task decomposition. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üìÑ Document Parsing Agent&lt;/strong&gt;: Processes complex technical documents and research papers with advanced parsing capabilities. Extracts algorithms and methodologies using document understanding models. Converts academic concepts into practical implementation specifications through intelligent content analysis. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üèóÔ∏è Code Planning Agent&lt;/strong&gt;: Performs architectural design and technology stack optimization. Dynamic planning for adaptive development roadmaps. Enforces coding standards and generates modular structures through automated design pattern selection.&lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üîç Code Reference Mining Agent&lt;/strong&gt;: Discovers relevant repositories and frameworks through intelligent search algorithms. Analyzes codebases for compatibility and integration potential. Provides recommendations based on similarity metrics and automated dependency analysis. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üìö Code Indexing Agent&lt;/strong&gt;: Builds comprehensive knowledge graphs of discovered codebases. Maintains semantic relationships between code components. Enables intelligent retrieval and cross-reference capabilities. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üß¨ Code Generation Agent&lt;/strong&gt;: Synthesizes gathered information into executable code implementations. Creates functional interfaces and integrates discovered components. Generates comprehensive test suites and documentation for reproducibility.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h4&gt;üõ†Ô∏è &lt;strong&gt;Implementation Tools Matrix&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;üîß Powered by MCP (Model Context Protocol)&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;DeepCode leverages the &lt;strong&gt;Model Context Protocol (MCP)&lt;/strong&gt; standard to seamlessly integrate with various tools and services. This standardized approach ensures reliable communication between AI agents and external systems, enabling powerful automation capabilities.&lt;/p&gt; 
&lt;h5&gt;üì° &lt;strong&gt;MCP Servers &amp;amp; Tools&lt;/strong&gt;&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;üõ†Ô∏è &lt;strong&gt;MCP Server&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;üîß &lt;strong&gt;Primary Function&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;üí° &lt;strong&gt;Purpose &amp;amp; Capabilities&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üîç brave&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Web Search Engine&lt;/td&gt; 
   &lt;td&gt;Real-time information retrieval via Brave Search API&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üåê bocha-mcp&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Alternative Search&lt;/td&gt; 
   &lt;td&gt;Secondary search option with independent API access&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üìÇ filesystem&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;File System Operations&lt;/td&gt; 
   &lt;td&gt;Local file and directory management, read/write operations&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üåê fetch&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Web Content Retrieval&lt;/td&gt; 
   &lt;td&gt;Fetch and extract content from URLs and web resources&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üì• github-downloader&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Repository Management&lt;/td&gt; 
   &lt;td&gt;Clone and download GitHub repositories for analysis&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üìã file-downloader&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Document Processing&lt;/td&gt; 
   &lt;td&gt;Download and convert files (PDF, DOCX, etc.) to Markdown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;‚ö° command-executor&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;System Commands&lt;/td&gt; 
   &lt;td&gt;Execute bash/shell commands for environment management&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üß¨ code-implementation&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Code Generation Hub&lt;/td&gt; 
   &lt;td&gt;Comprehensive code reproduction with execution and testing&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üìö code-reference-indexer&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Smart Code Search&lt;/td&gt; 
   &lt;td&gt;Intelligent indexing and search of code repositories&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üìÑ document-segmentation&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Smart Document Analysis&lt;/td&gt; 
   &lt;td&gt;Intelligent document segmentation for large papers and technical documents&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h5&gt;üîß &lt;strong&gt;Legacy Tool Functions&lt;/strong&gt; &lt;em&gt;(for reference)&lt;/em&gt;&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;üõ†Ô∏è &lt;strong&gt;Function&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;üéØ &lt;strong&gt;Usage Context&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üìÑ read_code_mem&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Efficient code context retrieval from memory&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;‚úçÔ∏è write_file&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Direct file content generation and modification&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üêç execute_python&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Python code testing and validation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üìÅ get_file_structure&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Project structure analysis and organization&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;‚öôÔ∏è set_workspace&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Dynamic workspace and environment configuration&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;üìä get_operation_history&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Process monitoring and operation tracking&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;p&gt;üéõÔ∏è &lt;strong&gt;Multi-Interface Framework&lt;/strong&gt;&lt;br /&gt; RESTful API with CLI and web frontends featuring real-time code streaming, interactive debugging, and extensible plugin architecture for CI/CD integration.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;üöÄ Multi-Agent Intelligent Pipeline:&lt;/strong&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;üåü &lt;strong&gt;Intelligence Processing Flow&lt;/strong&gt;&lt;/h3&gt; 
 &lt;table align="center" width="100%" style="border: none; border-collapse: collapse;"&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td colspan="3" align="center" style="padding: 20px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 15px; color: white; font-weight: bold;"&gt; üí° &lt;strong&gt;INPUT LAYER&lt;/strong&gt;&lt;br /&gt; üìÑ Research Papers ‚Ä¢ üí¨ Natural Language ‚Ä¢ üåê URLs ‚Ä¢ üìã Requirements &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="20"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td colspan="3" align="center" style="padding: 15px; background: linear-gradient(135deg, #ff6b6b 0%, #ee5a24 100%); border-radius: 12px; color: white; font-weight: bold;"&gt; üéØ &lt;strong&gt;CENTRAL ORCHESTRATION&lt;/strong&gt;&lt;br /&gt; Strategic Decision Making ‚Ä¢ Workflow Coordination ‚Ä¢ Agent Management &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="15"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center" style="padding: 12px; background: linear-gradient(135deg, #3742fa 0%, #2f3542 100%); border-radius: 10px; color: white; width: 50%;"&gt; üìù &lt;strong&gt;TEXT ANALYSIS&lt;/strong&gt;&lt;br /&gt; &lt;small&gt;Requirement Processing&lt;/small&gt; &lt;/td&gt; 
    &lt;td width="10"&gt;&lt;/td&gt; 
    &lt;td align="center" style="padding: 12px; background: linear-gradient(135deg, #8c7ae6 0%, #9c88ff 100%); border-radius: 10px; color: white; width: 50%;"&gt; üìÑ &lt;strong&gt;DOCUMENT ANALYSIS&lt;/strong&gt;&lt;br /&gt; &lt;small&gt;Paper &amp;amp; Spec Processing&lt;/small&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="15"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td colspan="3" align="center" style="padding: 15px; background: linear-gradient(135deg, #00d2d3 0%, #54a0ff 100%); border-radius: 12px; color: white; font-weight: bold;"&gt; üìã &lt;strong&gt;REPRODUCTION PLANNING&lt;/strong&gt;&lt;br /&gt; Deep Paper Analysis ‚Ä¢ Code Requirements Parsing ‚Ä¢ Reproduction Strategy Development &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="15"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center" style="padding: 12px; background: linear-gradient(135deg, #ffa726 0%, #ff7043 100%); border-radius: 10px; color: white; width: 50%;"&gt; üîç &lt;strong&gt;REFERENCE ANALYSIS&lt;/strong&gt;&lt;br /&gt; &lt;small&gt;Repository Discovery&lt;/small&gt; &lt;/td&gt; 
    &lt;td width="10"&gt;&lt;/td&gt; 
    &lt;td align="center" style="padding: 12px; background: linear-gradient(135deg, #e056fd 0%, #f368e0 100%); border-radius: 10px; color: white; width: 50%;"&gt; üìö &lt;strong&gt;CODE INDEXING&lt;/strong&gt;&lt;br /&gt; &lt;small&gt;Knowledge Graph Building&lt;/small&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="15"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td colspan="3" align="center" style="padding: 15px; background: linear-gradient(135deg, #26de81 0%, #20bf6b 100%); border-radius: 12px; color: white; font-weight: bold;"&gt; üß¨ &lt;strong&gt;CODE IMPLEMENTATION&lt;/strong&gt;&lt;br /&gt; Implementation Generation ‚Ä¢ Testing ‚Ä¢ Documentation &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="15"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td colspan="3" align="center" style="padding: 20px; background: linear-gradient(135deg, #045de9 0%, #09c6f9 100%); border-radius: 15px; color: white; font-weight: bold;"&gt; ‚ö° &lt;strong&gt;OUTPUT DELIVERY&lt;/strong&gt;&lt;br /&gt; üì¶ Complete Codebase ‚Ä¢ üß™ Test Suite ‚Ä¢ üìö Documentation ‚Ä¢ üöÄ Deployment Ready &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;br /&gt; 
 &lt;h3&gt;üîÑ &lt;strong&gt;Process Intelligence Features&lt;/strong&gt;&lt;/h3&gt; 
 &lt;table align="center" style="border: none;"&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td align="center" width="25%" style="padding: 15px;"&gt; 
     &lt;div style="background: #f8f9fa; border-radius: 10px; padding: 15px; border-left: 4px solid #ff6b6b;"&gt; 
      &lt;h4&gt;üéØ Adaptive Flow&lt;/h4&gt; 
      &lt;p&gt;&lt;small&gt;Dynamic agent selection based on input complexity&lt;/small&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
    &lt;td align="center" width="25%" style="padding: 15px;"&gt; 
     &lt;div style="background: #f8f9fa; border-radius: 10px; padding: 15px; border-left: 4px solid #4ecdc4;"&gt; 
      &lt;h4&gt;üß† Smart Coordination&lt;/h4&gt; 
      &lt;p&gt;&lt;small&gt;Intelligent task distribution and parallel processing&lt;/small&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
    &lt;td align="center" width="25%" style="padding: 15px;"&gt; 
     &lt;div style="background: #f8f9fa; border-radius: 10px; padding: 15px; border-left: 4px solid #45b7d1;"&gt; 
      &lt;h4&gt;üîç Context Awareness&lt;/h4&gt; 
      &lt;p&gt;&lt;small&gt;Deep understanding through CodeRAG integration&lt;/small&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
    &lt;td align="center" width="25%" style="padding: 15px;"&gt; 
     &lt;div style="background: #f8f9fa; border-radius: 10px; padding: 15px; border-left: 4px solid #96ceb4;"&gt; 
      &lt;h4&gt;‚ö° Quality Assurance&lt;/h4&gt; 
      &lt;p&gt;&lt;small&gt;Automated testing and validation throughout&lt;/small&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üöÄ Quick Start&lt;/h2&gt; 
&lt;h3&gt;üì¶ &lt;strong&gt;Step 1: Installation&lt;/strong&gt;&lt;/h3&gt; 
&lt;h4&gt;‚ö° &lt;strong&gt;Direct Installation (Recommended)&lt;/strong&gt;&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# üöÄ Install DeepCode package directly
pip install deepcode-hku

# üîë Download configuration files
curl -O https://raw.githubusercontent.com/HKUDS/DeepCode/main/mcp_agent.config.yaml
curl -O https://raw.githubusercontent.com/HKUDS/DeepCode/main/mcp_agent.secrets.yaml

# üîë Configure API keys (required)
# Edit mcp_agent.secrets.yaml with your API keys and base_url:
# - openai: api_key, base_url (for OpenAI/custom endpoints)
# - anthropic: api_key (for Claude models)

# üîë Configure search API keys for web search (optional)
# Edit mcp_agent.config.yaml to set your API keys:
# - For Brave Search: Set BRAVE_API_KEY: "your_key_here" in brave.env section (line ~28)
# - For Bocha-MCP: Set BOCHA_API_KEY: "your_key_here" in bocha-mcp.env section (line ~74)

# üìÑ Configure document segmentation (optional)
# Edit mcp_agent.config.yaml to control document processing:
# - enabled: true/false (whether to use intelligent document segmentation)
# - size_threshold_chars: 50000 (document size threshold to trigger segmentation)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;üîß &lt;strong&gt;Development Installation (From Source)&lt;/strong&gt;&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üìÇ Click to expand development installation options&lt;/strong&gt;&lt;/summary&gt; 
 &lt;h5&gt;üî• &lt;strong&gt;Using UV (Recommended for Development)&lt;/strong&gt;&lt;/h5&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# üîΩ Clone the repository
git clone https://github.com/HKUDS/DeepCode.git
cd DeepCode/

# üì¶ Install UV package manager
curl -LsSf https://astral.sh/uv/install.sh | sh

# üîß Install dependencies with UV
uv venv --python=3.13
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
uv pip install -r requirements.txt

# üîë Configure API keys (required)
# Edit mcp_agent.secrets.yaml with your API keys and base_url:
# - openai: api_key, base_url (for OpenAI/custom endpoints)
# - anthropic: api_key (for Claude models)

# üîë Configure search API keys for web search (optional)
# Edit mcp_agent.config.yaml to set your API keys:
# - For Brave Search: Set BRAVE_API_KEY: "your_key_here" in brave.env section (line ~28)
# - For Bocha-MCP: Set BOCHA_API_KEY: "your_key_here" in bocha-mcp.env section (line ~74)

# üìÑ Configure document segmentation (optional)
# Edit mcp_agent.config.yaml to control document processing:
# - enabled: true/false (whether to use intelligent document segmentation)
# - size_threshold_chars: 50000 (document size threshold to trigger segmentation)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h5&gt;üêç &lt;strong&gt;Using Traditional pip&lt;/strong&gt;&lt;/h5&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# üîΩ Clone the repository
git clone https://github.com/HKUDS/DeepCode.git
cd DeepCode/

# üì¶ Install dependencies
pip install -r requirements.txt

# üîë Configure API keys (required)
# Edit mcp_agent.secrets.yaml with your API keys and base_url:
# - openai: api_key, base_url (for OpenAI/custom endpoints)
# - anthropic: api_key (for Claude models)

# üîë Configure search API keys for web search (optional)
# Edit mcp_agent.config.yaml to set your API keys:
# - For Brave Search: Set BRAVE_API_KEY: "your_key_here" in brave.env section (line ~28)
# - For Bocha-MCP: Set BOCHA_API_KEY: "your_key_here" in bocha-mcp.env section (line ~74)

# üìÑ Configure document segmentation (optional)
# Edit mcp_agent.config.yaml to control document processing:
# - enabled: true/false (whether to use intelligent document segmentation)
# - size_threshold_chars: 50000 (document size threshold to trigger segmentation)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h4&gt;ü™ü &lt;strong&gt;Windows Users: Additional MCP Server Configuration&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;If you're using Windows, you may need to configure MCP servers manually in &lt;code&gt;mcp_agent.config.yaml&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# 1. Install MCP servers globally
npm i -g @modelcontextprotocol/server-brave-search
npm i -g @modelcontextprotocol/server-filesystem

# 2. Find your global node_modules path
npm -g root
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then update your &lt;code&gt;mcp_agent.config.yaml&lt;/code&gt; to use absolute paths:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;mcp:
  servers:
    brave:
      command: "node"
      args: ["C:/Program Files/nodejs/node_modules/@modelcontextprotocol/server-brave-search/dist/index.js"]
    filesystem:
      command: "node"
      args: ["C:/Program Files/nodejs/node_modules/@modelcontextprotocol/server-filesystem/dist/index.js", "."]
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Replace the path with your actual global node_modules path from step 2.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;üîç &lt;strong&gt;Search Server Configuration (Optional)&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;DeepCode supports multiple search servers for web search functionality. You can configure your preferred option in &lt;code&gt;mcp_agent.config.yaml&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# Default search server configuration
# Options: "brave" or "bocha-mcp"
default_search_server: "brave"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Available Options:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üîç Brave Search&lt;/strong&gt; (&lt;code&gt;"brave"&lt;/code&gt;):&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Default option with high-quality search results&lt;/li&gt; 
   &lt;li&gt;Requires BRAVE_API_KEY configuration&lt;/li&gt; 
   &lt;li&gt;Recommended for most users&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üåê Bocha-MCP&lt;/strong&gt; (&lt;code&gt;"bocha-mcp"&lt;/code&gt;):&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Alternative search server option&lt;/li&gt; 
   &lt;li&gt;Requires BOCHA_API_KEY configuration&lt;/li&gt; 
   &lt;li&gt;Uses local Python server implementation&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;API Key Configuration in mcp_agent.config.yaml:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# For Brave Search (default) - around line 28
brave:
  command: "npx"
  args: ["-y", "@modelcontextprotocol/server-brave-search"]
  env:
    BRAVE_API_KEY: "your_brave_api_key_here"

# For Bocha-MCP (alternative) - around line 74
bocha-mcp:
  command: "python"
  args: ["tools/bocha_search_server.py"]
  env:
    PYTHONPATH: "."
    BOCHA_API_KEY: "your_bocha_api_key_here"
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;üí° Tip&lt;/strong&gt;: Both search servers require API key configuration. Choose the one that best fits your API access and requirements.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;‚ö° &lt;strong&gt;Step 2: Launch Application&lt;/strong&gt;&lt;/h3&gt; 
&lt;h4&gt;üöÄ &lt;strong&gt;Using Installed Package (Recommended)&lt;/strong&gt;&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# üåê Launch web interface directly
deepcode

# The application will automatically start at http://localhost:8501
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;üõ†Ô∏è &lt;strong&gt;Using Source Code&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;Choose your preferred interface:&lt;/p&gt; 
&lt;h5&gt;üåê &lt;strong&gt;Web Interface&lt;/strong&gt; (Recommended)&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Using UV
uv run streamlit run ui/streamlit_app.py
# Or using traditional Python
streamlit run ui/streamlit_app.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://img.shields.io/badge/Access-localhost:8501-00d4ff?style=flat-square&amp;amp;logo=streamlit&amp;amp;logoColor=white" alt="Web Access" /&gt; 
&lt;/div&gt; 
&lt;h5&gt;üñ•Ô∏è &lt;strong&gt;CLI Interface&lt;/strong&gt; (Advanced Users)&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Using UV
uv run python cli/main_cli.py
# Or using traditional Python
python cli/main_cli.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://img.shields.io/badge/Mode-Interactive_Terminal-9b59b6?style=flat-square&amp;amp;logo=terminal&amp;amp;logoColor=white" alt="CLI Mode" /&gt; 
&lt;/div&gt; 
&lt;h3&gt;üéØ &lt;strong&gt;Step 3: Generate Code&lt;/strong&gt;&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;üìÑ Input&lt;/strong&gt;: Upload your research paper, provide requirements, or paste a URL&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ü§ñ Processing&lt;/strong&gt;: Watch the multi-agent system analyze and plan&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;‚ö° Output&lt;/strong&gt;: Receive production-ready code with tests and documentation&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üí° Examples&lt;/h2&gt; 
&lt;h3&gt;üé¨ &lt;strong&gt;Live Demonstrations&lt;/strong&gt;&lt;/h3&gt; 
&lt;table align="center"&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="33%" align="center"&gt; &lt;h4&gt;üìÑ &lt;strong&gt;Paper2Code Demo&lt;/strong&gt;&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;Research to Implementation&lt;/strong&gt;&lt;/p&gt; 
    &lt;div align="center"&gt; 
     &lt;a href="https://www.youtube.com/watch?v=MQZYpLkzsbw"&gt; &lt;img src="https://img.youtube.com/vi/MQZYpLkzsbw/maxresdefault.jpg" alt="Paper2Code Demo" width="100%" style="border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);" /&gt; &lt;/a&gt; 
     &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.youtube.com/watch?v=MQZYpLkzsbw"&gt;‚ñ∂Ô∏è Watch Demo&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
     &lt;p&gt;&lt;em&gt;Transform academic papers into production-ready code automatically&lt;/em&gt;&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
   &lt;td width="33%" align="center"&gt; &lt;h4&gt;üñºÔ∏è &lt;strong&gt;Image Processing Demo&lt;/strong&gt;&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;AI-Powered Image Tools&lt;/strong&gt;&lt;/p&gt; 
    &lt;div align="center"&gt; 
     &lt;a href="https://www.youtube.com/watch?v=nFt5mLaMEac"&gt; &lt;img src="https://img.youtube.com/vi/nFt5mLaMEac/maxresdefault.jpg" alt="Image Processing Demo" width="100%" style="border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);" /&gt; &lt;/a&gt; 
     &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.youtube.com/watch?v=nFt5mLaMEac"&gt;‚ñ∂Ô∏è Watch Demo&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
     &lt;p&gt;&lt;em&gt;Intelligent image processing with background removal and enhancement&lt;/em&gt;&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
   &lt;td width="33%" align="center"&gt; &lt;h4&gt;üåê &lt;strong&gt;Frontend Implementation&lt;/strong&gt;&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;Complete Web Application&lt;/strong&gt;&lt;/p&gt; 
    &lt;div align="center"&gt; 
     &lt;a href="https://www.youtube.com/watch?v=78wx3dkTaAU"&gt; &lt;img src="https://img.youtube.com/vi/78wx3dkTaAU/maxresdefault.jpg" alt="Frontend Demo" width="100%" style="border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);" /&gt; &lt;/a&gt; 
     &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.youtube.com/watch?v=78wx3dkTaAU"&gt;‚ñ∂Ô∏è Watch Demo&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
     &lt;p&gt;&lt;em&gt;Full-stack web development from concept to deployment&lt;/em&gt;&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h3&gt;üÜï &lt;strong&gt;Recent Updates&lt;/strong&gt;&lt;/h3&gt; 
&lt;h4&gt;üìÑ &lt;strong&gt;Smart Document Segmentation (v1.2.0)&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Intelligent Processing&lt;/strong&gt;: Automatically handles large research papers and technical documents that exceed LLM token limits&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Configurable Control&lt;/strong&gt;: Toggle segmentation via configuration with size-based thresholds&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Semantic Analysis&lt;/strong&gt;: Advanced content understanding with algorithm, concept, and formula preservation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Backward Compatibility&lt;/strong&gt;: Seamlessly falls back to traditional processing for smaller documents&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üöÄ &lt;strong&gt;Coming Soon&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;We're continuously enhancing DeepCode with exciting new features:&lt;/p&gt; 
&lt;h4&gt;üîß &lt;strong&gt;Enhanced Code Reliability &amp;amp; Validation&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Automated Testing&lt;/strong&gt;: Comprehensive functionality testing with execution verification and error detection.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Code Quality Assurance&lt;/strong&gt;: Multi-level validation through static analysis, dynamic testing, and performance benchmarking.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Smart Debugging&lt;/strong&gt;: AI-powered error detection with automatic correction suggestions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;üìä &lt;strong&gt;PaperBench Performance Showcase&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Benchmark Dashboard&lt;/strong&gt;: Comprehensive performance metrics on the PaperBench evaluation suite.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Accuracy Metrics&lt;/strong&gt;: Detailed comparison with state-of-the-art paper reproduction systems.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Success Analytics&lt;/strong&gt;: Statistical analysis across paper categories and complexity levels.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;‚ö° &lt;strong&gt;System-wide Optimizations&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Performance Boost&lt;/strong&gt;: Multi-threaded processing and optimized agent coordination for faster generation.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enhanced Reasoning&lt;/strong&gt;: Advanced reasoning capabilities with improved context understanding.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Expanded Support&lt;/strong&gt;: Extended compatibility with additional programming languages and frameworks.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;‚≠ê Star History&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;em&gt;Community Growth Trajectory&lt;/em&gt;&lt;/p&gt; 
 &lt;a href="https://star-history.com/#HKUDS/DeepCode&amp;amp;Date"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=HKUDS/DeepCode&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
   &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=HKUDS/DeepCode&amp;amp;type=Date" /&gt; 
   &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=HKUDS/DeepCode&amp;amp;type=Date" style="border-radius: 15px; box-shadow: 0 0 30px rgba(0, 217, 255, 0.3);" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h3&gt;üöÄ &lt;strong&gt;Ready to Transform Development?&lt;/strong&gt;&lt;/h3&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt; &lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-quick-start"&gt;&lt;img src="https://img.shields.io/badge/üöÄ_Get_Started-00d4ff?style=for-the-badge&amp;amp;logo=rocket&amp;amp;logoColor=white" alt="Get Started" /&gt;&lt;/a&gt; &lt;a href="https://github.com/HKUDS"&gt;&lt;img src="https://img.shields.io/badge/üèõÔ∏è_View_on_GitHub-00d4ff?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white" alt="View on GitHub" /&gt;&lt;/a&gt; &lt;a href="https://github.com/HKUDS/deepcode-agent"&gt;&lt;img src="https://img.shields.io/badge/‚≠ê_Star_Project-00d4ff?style=for-the-badge&amp;amp;logo=star&amp;amp;logoColor=white" alt="Star Project" /&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;hr /&gt; 
 &lt;h3&gt;üìÑ &lt;strong&gt;License&lt;/strong&gt;&lt;/h3&gt; 
 &lt;img src="https://img.shields.io/badge/License-MIT-4ecdc4?style=for-the-badge&amp;amp;logo=opensourceinitiative&amp;amp;logoColor=white" alt="MIT License" /&gt; 
 &lt;p&gt;&lt;strong&gt;MIT License&lt;/strong&gt; - Copyright (c) 2025 Data Intelligence Lab, The University of Hong Kong&lt;/p&gt; 
 &lt;hr /&gt; 
 &lt;img src="https://visitor-badge.laobi.icu/badge?page_id=deepcode.readme&amp;amp;style=for-the-badge&amp;amp;color=00d4ff" alt="Visitors" /&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>lima-vm/lima</title>
      <link>https://github.com/lima-vm/lima</link>
      <description>&lt;p&gt;Linux virtual machines, with a focus on running containers&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://lima-vm.io/"&gt;[üåé&lt;strong&gt;Web site&lt;/strong&gt;]&lt;/a&gt; &lt;a href="https://lima-vm.io/docs/"&gt;[üìñ&lt;strong&gt;Documentation&lt;/strong&gt;]&lt;/a&gt; &lt;a href="https://slack.cncf.io"&gt;[üë§&lt;strong&gt;Slack (&lt;code&gt;#lima&lt;/code&gt;)&lt;/strong&gt;]&lt;/a&gt;&lt;/p&gt; 
&lt;picture&gt; 
 &lt;source media="(prefers-color-scheme: dark)" srcset="website/static/images/logo-dark.svg" /&gt; 
 &lt;img alt="Shows a stylized 'Lima' text in bold, modern font" src="https://raw.githubusercontent.com/lima-vm/lima/master/website/static/images/logo.svg?sanitize=true" width="400" /&gt; 
&lt;/picture&gt; 
&lt;h1&gt;Lima: Linux Machines&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://deepwiki.com/lima-vm/lima"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt; &lt;a href="https://www.bestpractices.dev/projects/6505"&gt;&lt;img src="https://www.bestpractices.dev/projects/6505/badge" alt="OpenSSF Best Practices" /&gt;&lt;/a&gt; &lt;a href="https://scorecard.dev/viewer/?uri=github.com/lima-vm/lima"&gt;&lt;img src="https://api.scorecard.dev/projects/github.com/lima-vm/lima/badge" alt="OpenSSF Scorecard" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://lima-vm.io/"&gt;Lima&lt;/a&gt; launches Linux virtual machines with automatic file sharing and port forwarding (similar to WSL2).&lt;/p&gt; 
&lt;p&gt;The original goal of Lima was to promote &lt;a href="https://containerd.io"&gt;containerd&lt;/a&gt; including &lt;a href="https://github.com/containerd/nerdctl"&gt;nerdctl (contaiNERD ctl)&lt;/a&gt; to Mac users, but Lima can be used for non-container applications as well.&lt;/p&gt; 
&lt;p&gt;Lima also supports other container engines (Docker, Podman, Kubernetes, etc.) and non-macOS hosts (Linux, NetBSD, etc.).&lt;/p&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;p&gt;Set up (Homebrew):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;brew install lima
limactl start
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To run Linux commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;lima uname -a
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To run containers with containerd:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;lima nerdctl run --rm hello-world
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To run containers with Docker:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;limactl start template://docker
export DOCKER_HOST=$(limactl list docker --format 'unix://{{.Dir}}/sock/docker.sock')
docker run --rm hello-world
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To run containers with Kubernetes:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;limactl start template://k8s
export KUBECONFIG=$(limactl list k8s --format 'unix://{{.Dir}}/copied-from-guest/kubeconfig.yaml')
kubectl apply -f ...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://lima-vm.io/docs/"&gt;https://lima-vm.io/docs/&lt;/a&gt; for the further information.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions! Please see our &lt;a href="https://lima-vm.io/docs/community/contributing/"&gt;Contributing Guide&lt;/a&gt; for details on:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Developer Certificate of Origin (DCO)&lt;/strong&gt;: All commits must be signed off with &lt;code&gt;git commit -s&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Code licensing and pull request guidelines&lt;/li&gt; 
 &lt;li&gt;Testing requirements&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;h3&gt;Adopters&lt;/h3&gt; 
&lt;p&gt;Container environments:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://rancherdesktop.io/"&gt;Rancher Desktop&lt;/a&gt;: Kubernetes and container management to the desktop&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/abiosoft/colima"&gt;Colima&lt;/a&gt;: Docker (and Kubernetes) on macOS with minimal setup&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/runfinch/finch"&gt;Finch&lt;/a&gt;: Finch is a command line client for local container development&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://podman-desktop.io/"&gt;Podman Desktop&lt;/a&gt;: Podman Desktop GUI has a plug-in for Lima virtual machines&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;GUI:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/unixorn/lima-xbar-plugin"&gt;Lima xbar plugin&lt;/a&gt;: &lt;a href="https://xbarapp.com/"&gt;xbar&lt;/a&gt; plugin to start/stop VMs from the menu bar and see their running status.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/afbjorklund/lima-gui"&gt;lima-gui&lt;/a&gt;: Qt GUI for Lima&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Communication channels&lt;/h3&gt; 
&lt;!-- Duplicated from https://lima-vm.io/docs/community/ --&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/lima-vm/lima/discussions"&gt;GitHub Discussions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;#lima&lt;/code&gt; channel in the CNCF Slack 
  &lt;ul&gt; 
   &lt;li&gt;New account: &lt;a href="https://slack.cncf.io/"&gt;https://slack.cncf.io/&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Login: &lt;a href="https://cloud-native.slack.com/"&gt;https://cloud-native.slack.com/&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Zoom meetings (tentatively monthly) 
  &lt;ul&gt; 
   &lt;li&gt;Meeting notes &amp;amp; agenda proposals: &lt;a href="https://github.com/lima-vm/lima/discussions/categories/meetings"&gt;https://github.com/lima-vm/lima/discussions/categories/meetings&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Calendar: &lt;a href="https://zoom-lfx.platform.linuxfoundation.org/meetings/lima"&gt;https://zoom-lfx.platform.linuxfoundation.org/meetings/lima&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Code of Conduct&lt;/h3&gt; 
&lt;p&gt;Lima follows the &lt;a href="https://github.com/cncf/foundation/raw/main/code-of-conduct.md"&gt;CNCF Code of Conduct&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;We are a &lt;a href="https://cncf.io/"&gt;Cloud Native Computing Foundation&lt;/a&gt; incubating project.&lt;/strong&gt;&lt;/p&gt; 
&lt;picture&gt; 
 &lt;source media="(prefers-color-scheme: dark)" srcset="https://www.cncf.io/wp-content/uploads/2022/07/cncf-white-logo.svg" /&gt; 
 &lt;img src="https://www.cncf.io/wp-content/uploads/2022/07/cncf-color-bg.svg?sanitize=true" width="300" /&gt; 
&lt;/picture&gt; 
&lt;p&gt;The Linux Foundation¬Æ (TLF) has registered trademarks and uses trademarks. For a list of TLF trademarks, see &lt;a href="https://www.linuxfoundation.org/legal/trademark-usage"&gt;Trademark Usage&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>usestrix/strix</title>
      <link>https://github.com/usestrix/strix</link>
      <description>&lt;p&gt;‚ú® Open-source AI hackers for your apps üë®üèª‚Äçüíª&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://usestrix.com/"&gt; &lt;img src="https://raw.githubusercontent.com/usestrix/strix/main/.github/logo.png" width="150" alt="Strix Logo" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h1 align="center"&gt; Strix &lt;/h1&gt; 
&lt;h2 align="center"&gt;Open-source AI Hackers to secure your Apps&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://pypi.org/project/strix-agent/"&gt;&lt;img src="https://img.shields.io/pypi/pyversions/strix-agent?color=3776AB" alt="Python" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/strix-agent/"&gt;&lt;img src="https://img.shields.io/pypi/v/strix-agent?color=10b981" alt="PyPI" /&gt;&lt;/a&gt; &lt;a href="https://pepy.tech/projects/strix-agent"&gt;&lt;img src="https://static.pepy.tech/personalized-badge/strix-agent?period=total&amp;amp;units=INTERNATIONAL_SYSTEM&amp;amp;left_color=GREY&amp;amp;right_color=RED&amp;amp;left_text=Downloads" alt="PyPI Downloads" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/usestrix/strix/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-Apache%202.0-blue.svg?sanitize=true" alt="License" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/usestrix/strix"&gt;&lt;img src="https://img.shields.io/github/stars/usestrix/strix" alt="GitHub Stars" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/YjKFvEZSdZ"&gt;&lt;img src="https://img.shields.io/badge/Discord-%235865F2.svg?&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://usestrix.com"&gt;&lt;img src="https://img.shields.io/badge/Website-usestrix.com-2d3748.svg?sanitize=true" alt="Website" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/15362" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/15362" alt="usestrix%2Fstrix | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span&gt;‚≠ê&lt;/span&gt; &lt;em&gt;Love Strix? Give us a star to help other developers discover it!&lt;/em&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/usestrix/strix/main/.github/screenshot.png" alt="Strix Demo" width="800" style="border-radius: 16px;" /&gt; 
&lt;/div&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] &lt;strong&gt;New!&lt;/strong&gt; Strix now integrates seamlessly with GitHub Actions and CI/CD pipelines. Automatically scan for vulnerabilities on every pull request and block insecure code before it reaches production!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] Only test systems you own or have permission to test. You are responsible for using Strix ethically and legally.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ü¶â Strix Overview&lt;/h2&gt; 
&lt;p&gt;Strix are autonomous AI agents that act just like real hackers - they run your code dynamically, find vulnerabilities, and validate them through actual proof-of-concepts. Built for developers and security teams who need fast, accurate security testing without the overhead of manual pentesting or the false positives of static analysis tools.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Full hacker toolkit&lt;/strong&gt; out of the box&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Teams of agents&lt;/strong&gt; that collaborate and scale&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Real validation&lt;/strong&gt; with PoCs, not false positives&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Developer‚Äëfirst&lt;/strong&gt; CLI with actionable reports&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Auto‚Äëfix &amp;amp; reporting&lt;/strong&gt; to accelerate remediation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h3&gt;üéØ Use Cases&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Detect and validate critical vulnerabilities in your applications.&lt;/li&gt; 
 &lt;li&gt;Get penetration tests done in hours, not weeks, with compliance reports.&lt;/li&gt; 
 &lt;li&gt;Automate bug bounty research and generate PoCs for faster reporting.&lt;/li&gt; 
 &lt;li&gt;Run tests in CI/CD to block vulnerabilities before reaching production.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h3&gt;üöÄ Quick Start&lt;/h3&gt; 
&lt;p&gt;Prerequisites:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Docker (running)&lt;/li&gt; 
 &lt;li&gt;Python 3.12+&lt;/li&gt; 
 &lt;li&gt;An LLM provider key (or a local LLM)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install
pipx install strix-agent

# Configure AI provider
export STRIX_LLM="openai/gpt-5"
export LLM_API_KEY="your-api-key"

# Run security assessment
strix --target ./app-directory
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;First run pulls the sandbox Docker image. Results are saved under &lt;code&gt;agent_runs/&amp;lt;run-name&amp;gt;&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;üèÜ Enterprise Platform&lt;/h3&gt; 
&lt;p&gt;Want to skip the setup? Try our cloud-hosted version: &lt;strong&gt;&lt;a href="https://usestrix.com"&gt;usestrix.com&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Our managed platform provides:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;üìà Executive Dashboards&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üß† Custom Fine-Tuned Models&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;‚öôÔ∏è CI/CD Integration&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîç Large-Scale Scanning&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîå Third-Party Integrations&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üéØ Enterprise Support&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://usestrix.com"&gt;&lt;strong&gt;Get Enterprise Demo ‚Üí&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;‚ú® Features&lt;/h2&gt; 
&lt;h3&gt;üõ†Ô∏è Agentic Security Tools&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;üîå Full HTTP Proxy&lt;/strong&gt; - Full request/response manipulation and analysis&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üåê Browser Automation&lt;/strong&gt; - Multi-tab browser for testing of XSS, CSRF, auth flows&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üíª Terminal Environments&lt;/strong&gt; - Interactive shells for command execution and testing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üêç Python Runtime&lt;/strong&gt; - Custom exploit development and validation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîç Reconnaissance&lt;/strong&gt; - Automated OSINT and attack surface mapping&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üìÅ Code Analysis&lt;/strong&gt; - Static and dynamic analysis capabilities&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üìù Knowledge Management&lt;/strong&gt; - Structured findings and attack documentation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üéØ Comprehensive Vulnerability Detection&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Access Control&lt;/strong&gt; - IDOR, privilege escalation, auth bypass&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Injection Attacks&lt;/strong&gt; - SQL, NoSQL, command injection&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Server-Side&lt;/strong&gt; - SSRF, XXE, deserialization flaws&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Client-Side&lt;/strong&gt; - XSS, prototype pollution, DOM vulnerabilities&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Business Logic&lt;/strong&gt; - Race conditions, workflow manipulation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Authentication&lt;/strong&gt; - JWT vulnerabilities, session management&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Infrastructure&lt;/strong&gt; - Misconfigurations, exposed services&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üï∏Ô∏è Graph of Agents&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Distributed Workflows&lt;/strong&gt; - Specialized agents for different attacks and assets&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Scalable Testing&lt;/strong&gt; - Parallel execution for fast comprehensive coverage&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dynamic Coordination&lt;/strong&gt; - Agents collaborate and share discoveries&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üíª Usage Examples&lt;/h2&gt; 
&lt;h3&gt;Default Usage&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Local codebase analysis
strix --target ./app-directory

# Repository security review
strix --target https://github.com/org/repo

# Black-Box Web application assessment
strix --target https://your-app.com

# Grey-Box Security Assesment
strix --target https://your-app.com --instructions "Perform authenticated testing using the following credentials user:pass"

# Multi-target white-box testing (source code + deployed app)
strix -t https://github.com/org/app -t https://your-app.com

# Focused testing with instructions
strix --target api.your-app.com --instruction "Focus on business logic flaws and IDOR vulnerabilities"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;ü§ñ Headless Mode&lt;/h3&gt; 
&lt;p&gt;Run Strix programmatically without interactive UI using the &lt;code&gt;-n/--non-interactive&lt;/code&gt; flag‚Äîperfect for servers and automated jobs. The CLI prints real-time vulnerability findings, and the final report before exiting. Exits with non-zero code when vulnerabilities are found.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;strix -n --target https://your-app.com
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;üîÑ CI/CD (GitHub Actions)&lt;/h3&gt; 
&lt;p&gt;Strix can be added to your pipeline to run a security test on pull requests with a lightweight GitHub Actions workflow:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;name: strix-penetration-test

on:
  pull_request:

jobs:
  security-scan:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Install Strix
        run: pipx install strix-agent

      - name: Run Strix
        env:
          STRIX_LLM: ${{ secrets.STRIX_LLM }}
          LLM_API_KEY: ${{ secrets.LLM_API_KEY }}

        run: strix -n -t ./
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;‚öôÔ∏è Configuration&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export STRIX_LLM="openai/gpt-5"
export LLM_API_KEY="your-api-key"

# Optional
export LLM_API_BASE="your-api-base-url"  # if using a local model, e.g. Ollama, LMStudio
export PERPLEXITY_API_KEY="your-api-key"  # for search capabilities
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://docs.litellm.ai/docs/providers"&gt;üìö View supported AI models&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions from the community! There are several ways to contribute:&lt;/p&gt; 
&lt;h3&gt;Code Contributions&lt;/h3&gt; 
&lt;p&gt;See our &lt;a href="https://raw.githubusercontent.com/usestrix/strix/main/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt; for details on:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Setting up your development environment&lt;/li&gt; 
 &lt;li&gt;Running tests and quality checks&lt;/li&gt; 
 &lt;li&gt;Submitting pull requests&lt;/li&gt; 
 &lt;li&gt;Code style guidelines&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Prompt Modules Collection&lt;/h3&gt; 
&lt;p&gt;Help expand our collection of specialized prompt modules for AI agents:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Advanced testing techniques for vulnerabilities, frameworks, and technologies&lt;/li&gt; 
 &lt;li&gt;See &lt;a href="https://raw.githubusercontent.com/usestrix/strix/main/strix/prompts/README.md"&gt;Prompt Modules Documentation&lt;/a&gt; for guidelines&lt;/li&gt; 
 &lt;li&gt;Submit via &lt;a href="https://github.com/usestrix/strix/pulls"&gt;pull requests&lt;/a&gt; or &lt;a href="https://github.com/usestrix/strix/issues"&gt;issues&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üë• Join Our Community&lt;/h2&gt; 
&lt;p&gt;Have questions? Found a bug? Want to contribute? &lt;strong&gt;&lt;a href="https://discord.gg/YjKFvEZSdZ"&gt;Join our Discord!&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;üåü Support the Project&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Love Strix?&lt;/strong&gt; Give us a ‚≠ê on GitHub!&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://api.star-history.com/svg?repos=usestrix/strix&amp;amp;type=date&amp;amp;legend=top-left" alt="Star History Chart" width="800" style="border-radius: 16px;" /&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>sst/opentui</title>
      <link>https://github.com/sst/opentui</link>
      <description>&lt;p&gt;OpenTUI is a library for building terminal user interfaces (TUIs)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;OpenTUI&lt;/h1&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://www.npmjs.com/package/@opentui/core"&gt;&lt;img alt="npm" src="https://img.shields.io/npm/v/@opentui/core?style=flat-square" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/sst/opentui/actions/workflows/build-core.yml"&gt;&lt;img alt="Build status" src="https://img.shields.io/github/actions/workflow/status/sst/opentui/build-core.yml?style=flat-square&amp;amp;branch=main" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/msmps/awesome-opentui"&gt;&lt;img alt="awesome opentui list" src="https://awesome.re/badge-flat.svg?sanitize=true" /&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;p&gt;OpenTUI is a TypeScript library for building terminal user interfaces (TUIs). It is currently in development and is not ready for production use. It will be the foundational TUI framework for both &lt;a href="https://opencode.ai"&gt;opencode&lt;/a&gt; and &lt;a href="https://terminal.shop"&gt;terminaldotshop&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Quick start with &lt;a href="https://bun.sh"&gt;bun&lt;/a&gt; and &lt;a href="https://github.com/msmps/create-tui"&gt;create-tui&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;bun create tui
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This monorepo contains the following packages:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/sst/opentui/main/packages/core"&gt;&lt;code&gt;@opentui/core&lt;/code&gt;&lt;/a&gt; - The core library works completely standalone, providing an imperative API and all the primitives.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/sst/opentui/main/packages/solid"&gt;&lt;code&gt;@opentui/solid&lt;/code&gt;&lt;/a&gt; - The SolidJS reconciler for OpenTUI.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/sst/opentui/main/packages/react"&gt;&lt;code&gt;@opentui/react&lt;/code&gt;&lt;/a&gt; - The React reconciler for OpenTUI.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/sst/opentui/main/packages/vue"&gt;&lt;code&gt;@opentui/vue&lt;/code&gt;&lt;/a&gt; - The Vue reconciler (unmaintained)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/sst/opentui/main/packages/go"&gt;&lt;code&gt;@opentui/go&lt;/code&gt;&lt;/a&gt; - Go bindings (unmaintained)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Install&lt;/h2&gt; 
&lt;p&gt;NOTE: You must have &lt;a href="https://ziglang.org/learn/getting-started/"&gt;Zig&lt;/a&gt; installed on your system to build the packages.&lt;/p&gt; 
&lt;h3&gt;TypeScript/JavaScript&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;bun install @opentui/core
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Running Examples (from the repo root)&lt;/h2&gt; 
&lt;h3&gt;TypeScript Examples&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;bun install
cd packages/core
bun run src/examples/index.ts
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;h3&gt;Local Development Linking&lt;/h3&gt; 
&lt;p&gt;When developing OpenTUI, you may want to test your changes in another project without publishing. The &lt;code&gt;link-opentui-dev.sh&lt;/code&gt; script makes this easy by creating symlinks (or copies) from your OpenTUI workspace to another project's &lt;code&gt;node_modules&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Basic usage:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/link-opentui-dev.sh /path/to/your/project
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will link &lt;code&gt;@opentui/core&lt;/code&gt; to your target project.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Options:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--react&lt;/code&gt; - Also link &lt;code&gt;@opentui/react&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--solid&lt;/code&gt; - Also link &lt;code&gt;@opentui/solid&lt;/code&gt; and &lt;code&gt;solid-js&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--dist&lt;/code&gt; - Link the built &lt;code&gt;dist&lt;/code&gt; directories instead of source packages&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--copy&lt;/code&gt; - Copy the dist directories instead of symlinking (requires &lt;code&gt;--dist&lt;/code&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Examples:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Link only core (default)
./scripts/link-opentui-dev.sh /path/to/your/project

# Link core and solid
./scripts/link-opentui-dev.sh /path/to/your/project --solid

# Link core and react, using dist directories
./scripts/link-opentui-dev.sh /path/to/your/project --react --dist

# Copy dist directories (useful for environments where symlinks don't work)
./scripts/link-opentui-dev.sh /path/to/your/project --dist --copy
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Notes:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The target project must have already run &lt;code&gt;bun install&lt;/code&gt; (or &lt;code&gt;npm install&lt;/code&gt;) to have a &lt;code&gt;node_modules&lt;/code&gt; directory&lt;/li&gt; 
 &lt;li&gt;By default, the script links to the source packages, allowing hot-reloading of changes&lt;/li&gt; 
 &lt;li&gt;Use &lt;code&gt;--dist&lt;/code&gt; when you need to test the built artifacts&lt;/li&gt; 
 &lt;li&gt;Use &lt;code&gt;--copy&lt;/code&gt; mode when working in environments that don't support symlinks well (e.g., Docker containers, Windows)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Showcase&lt;/h2&gt; 
&lt;p&gt;Consider showcasing your work on the &lt;a href="https://github.com/msmps/awesome-opentui"&gt;awesome-opentui&lt;/a&gt; list. A curated list of awesome resources and terminal user interfaces built with OpenTUI.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>NginxProxyManager/nginx-proxy-manager</title>
      <link>https://github.com/NginxProxyManager/nginx-proxy-manager</link>
      <description>&lt;p&gt;Docker container for managing Nginx proxy hosts with a simple, powerful interface&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://nginxproxymanager.com/github.png" /&gt; &lt;br /&gt;&lt;br /&gt; &lt;img src="https://img.shields.io/badge/version-2.13.3-green.svg?style=for-the-badge" /&gt; &lt;a href="https://hub.docker.com/repository/docker/jc21/nginx-proxy-manager"&gt; &lt;img src="https://img.shields.io/docker/stars/jc21/nginx-proxy-manager.svg?style=for-the-badge" /&gt; &lt;/a&gt; &lt;a href="https://hub.docker.com/repository/docker/jc21/nginx-proxy-manager"&gt; &lt;img src="https://img.shields.io/docker/pulls/jc21/nginx-proxy-manager.svg?style=for-the-badge" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;This project comes as a pre-built docker image that enables you to easily forward to your websites running at home or otherwise, including free SSL, without having to know too much about Nginx or Letsencrypt.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/NginxProxyManager/nginx-proxy-manager/develop/#quick-setup"&gt;Quick Setup&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://nginxproxymanager.com/setup/"&gt;Full Setup&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://nginxproxymanager.com/screenshots/"&gt;Screenshots&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Project Goal&lt;/h2&gt; 
&lt;p&gt;I created this project to fill a personal need to provide users with an easy way to accomplish reverse proxying hosts with SSL termination and it had to be so easy that a monkey could do it. This goal hasn't changed. While there might be advanced options they are optional and the project should be as simple as possible so that the barrier for entry here is low.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.buymeacoffee.com/jc21" target="_blank"&gt;&lt;img src="http://public.jc21.com/github/by-me-a-coffee.png" alt="Buy Me A Coffee" style="height: 51px !important;width: 217px !important;" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Beautiful and Secure Admin Interface based on &lt;a href="https://tabler.github.io/"&gt;Tabler&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Easily create forwarding domains, redirections, streams and 404 hosts without knowing anything about Nginx&lt;/li&gt; 
 &lt;li&gt;Free SSL using Let's Encrypt or provide your own custom SSL certificates&lt;/li&gt; 
 &lt;li&gt;Access Lists and basic HTTP Authentication for your hosts&lt;/li&gt; 
 &lt;li&gt;Advanced Nginx configuration available for super users&lt;/li&gt; 
 &lt;li&gt;User management, permissions and audit log&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Hosting your home network&lt;/h2&gt; 
&lt;p&gt;I won't go in to too much detail here but here are the basics for someone new to this self-hosted world.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Your home router will have a Port Forwarding section somewhere. Log in and find it&lt;/li&gt; 
 &lt;li&gt;Add port forwarding for port 80 and 443 to the server hosting this project&lt;/li&gt; 
 &lt;li&gt;Configure your domain name details to point to your home, either with a static ip or a service like DuckDNS or &lt;a href="https://github.com/jc21/route53-ddns"&gt;Amazon Route53&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Use the Nginx Proxy Manager as your gateway to forward to your other web based services&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Quick Setup&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install Docker and Docker-Compose&lt;/li&gt; 
&lt;/ol&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.docker.com/install/"&gt;Docker Install documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.docker.com/compose/install/"&gt;Docker-Compose Install documentation&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Create a docker-compose.yml file similar to this:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-yml"&gt;services:
  app:
    image: 'docker.io/jc21/nginx-proxy-manager:latest'
    restart: unless-stopped
    ports:
      - '80:80'
      - '81:81'
      - '443:443'
    volumes:
      - ./data:/data
      - ./letsencrypt:/etc/letsencrypt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This is the bare minimum configuration required. See the &lt;a href="https://nginxproxymanager.com/setup/"&gt;documentation&lt;/a&gt; for more.&lt;/p&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Bring up your stack by running&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;Log in to the Admin UI&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;When your docker container is running, connect to it on port &lt;code&gt;81&lt;/code&gt; for the admin interface. Sometimes this can take a little bit because of the entropy of keys.&lt;/p&gt; 
&lt;p&gt;&lt;a href="http://127.0.0.1:81"&gt;http://127.0.0.1:81&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;All are welcome to create pull requests for this project, against the &lt;code&gt;develop&lt;/code&gt; branch. Official releases are created from the &lt;code&gt;master&lt;/code&gt; branch.&lt;/p&gt; 
&lt;p&gt;CI is used in this project. All PR's must pass before being considered. After passing, docker builds for PR's are available on dockerhub for manual verifications.&lt;/p&gt; 
&lt;p&gt;Documentation within the &lt;code&gt;develop&lt;/code&gt; branch is available for preview at &lt;a href="https://develop.nginxproxymanager.com"&gt;https://develop.nginxproxymanager.com&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Contributors&lt;/h3&gt; 
&lt;p&gt;Special thanks to &lt;a href="https://github.com/NginxProxyManager/nginx-proxy-manager/graphs/contributors"&gt;all of our contributors&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Getting Support&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://github.com/NginxProxyManager/nginx-proxy-manager/issues"&gt;Found a bug?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/NginxProxyManager/nginx-proxy-manager/discussions"&gt;Discussions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://reddit.com/r/nginxproxymanager"&gt;Reddit&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt;</description>
    </item>
    
    <item>
      <title>ggml-org/llama.cpp</title>
      <link>https://github.com/ggml-org/llama.cpp</link>
      <description>&lt;p&gt;LLM inference in C/C++&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;llama.cpp&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/1991296/230134379-7181e485-c521-4d23-a0d6-f7b3b61ba524.png" alt="llama" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://opensource.org/licenses/MIT"&gt;&lt;img src="https://img.shields.io/badge/license-MIT-blue.svg?sanitize=true" alt="License: MIT" /&gt;&lt;/a&gt; &lt;a href="https://github.com/ggml-org/llama.cpp/releases"&gt;&lt;img src="https://img.shields.io/github/v/release/ggml-org/llama.cpp" alt="Release" /&gt;&lt;/a&gt; &lt;a href="https://github.com/ggml-org/llama.cpp/actions/workflows/server.yml"&gt;&lt;img src="https://github.com/ggml-org/llama.cpp/actions/workflows/server.yml/badge.svg?sanitize=true" alt="Server" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/ggml-org/llama.cpp/discussions/205"&gt;Manifesto&lt;/a&gt; / &lt;a href="https://github.com/ggml-org/ggml"&gt;ggml&lt;/a&gt; / &lt;a href="https://github.com/ggml-org/llama.cpp/raw/master/docs/ops.md"&gt;ops&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;LLM inference in C/C++&lt;/p&gt; 
&lt;h2&gt;Recent API changes&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ggml-org/llama.cpp/issues/9289"&gt;Changelog for &lt;code&gt;libllama&lt;/code&gt; API&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ggml-org/llama.cpp/issues/9291"&gt;Changelog for &lt;code&gt;llama-server&lt;/code&gt; REST API&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Hot topics&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/ggml-org/llama.cpp/discussions/16938"&gt;guide : using the new WebUI of llama.cpp&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ggml-org/llama.cpp/discussions/15396"&gt;guide : running gpt-oss with llama.cpp&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ggml-org/llama.cpp/discussions/15313"&gt;[FEEDBACK] Better packaging for llama.cpp to support downstream consumers ü§ó&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Support for the &lt;code&gt;gpt-oss&lt;/code&gt; model with native MXFP4 format has been added | &lt;a href="https://github.com/ggml-org/llama.cpp/pull/15091"&gt;PR&lt;/a&gt; | &lt;a href="https://blogs.nvidia.com/blog/rtx-ai-garage-openai-oss"&gt;Collaboration with NVIDIA&lt;/a&gt; | &lt;a href="https://github.com/ggml-org/llama.cpp/discussions/15095"&gt;Comment&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Multimodal support arrived in &lt;code&gt;llama-server&lt;/code&gt;: &lt;a href="https://github.com/ggml-org/llama.cpp/pull/12898"&gt;#12898&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/ggml-org/llama.cpp/master/docs/multimodal.md"&gt;documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;VS Code extension for FIM completions: &lt;a href="https://github.com/ggml-org/llama.vscode"&gt;https://github.com/ggml-org/llama.vscode&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Vim/Neovim plugin for FIM completions: &lt;a href="https://github.com/ggml-org/llama.vim"&gt;https://github.com/ggml-org/llama.vim&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Hugging Face Inference Endpoints now support GGUF out of the box! &lt;a href="https://github.com/ggml-org/llama.cpp/discussions/9669"&gt;https://github.com/ggml-org/llama.cpp/discussions/9669&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Hugging Face GGUF editor: &lt;a href="https://github.com/ggml-org/llama.cpp/discussions/9268"&gt;discussion&lt;/a&gt; | &lt;a href="https://huggingface.co/spaces/CISCai/gguf-editor"&gt;tool&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Quick start&lt;/h2&gt; 
&lt;p&gt;Getting started with llama.cpp is straightforward. Here are several ways to install it on your machine:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install &lt;code&gt;llama.cpp&lt;/code&gt; using &lt;a href="https://raw.githubusercontent.com/ggml-org/llama.cpp/master/docs/install.md"&gt;brew, nix or winget&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Run with Docker - see our &lt;a href="https://raw.githubusercontent.com/ggml-org/llama.cpp/master/docs/docker.md"&gt;Docker documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Download pre-built binaries from the &lt;a href="https://github.com/ggml-org/llama.cpp/releases"&gt;releases page&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Build from source by cloning this repository - check out &lt;a href="https://raw.githubusercontent.com/ggml-org/llama.cpp/master/docs/build.md"&gt;our build guide&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Once installed, you'll need a model to work with. Head to the &lt;a href="https://raw.githubusercontent.com/ggml-org/llama.cpp/master/#obtaining-and-quantizing-models"&gt;Obtaining and quantizing models&lt;/a&gt; section to learn more.&lt;/p&gt; 
&lt;p&gt;Example command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# Use a local model file
llama-cli -m my_model.gguf

# Or download and run a model directly from Hugging Face
llama-cli -hf ggml-org/gemma-3-1b-it-GGUF

# Launch OpenAI-compatible API server
llama-server -hf ggml-org/gemma-3-1b-it-GGUF
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Description&lt;/h2&gt; 
&lt;p&gt;The main goal of &lt;code&gt;llama.cpp&lt;/code&gt; is to enable LLM inference with minimal setup and state-of-the-art performance on a wide range of hardware - locally and in the cloud.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Plain C/C++ implementation without any dependencies&lt;/li&gt; 
 &lt;li&gt;Apple silicon is a first-class citizen - optimized via ARM NEON, Accelerate and Metal frameworks&lt;/li&gt; 
 &lt;li&gt;AVX, AVX2, AVX512 and AMX support for x86 architectures&lt;/li&gt; 
 &lt;li&gt;1.5-bit, 2-bit, 3-bit, 4-bit, 5-bit, 6-bit, and 8-bit integer quantization for faster inference and reduced memory use&lt;/li&gt; 
 &lt;li&gt;Custom CUDA kernels for running LLMs on NVIDIA GPUs (support for AMD GPUs via HIP and Moore Threads GPUs via MUSA)&lt;/li&gt; 
 &lt;li&gt;Vulkan and SYCL backend support&lt;/li&gt; 
 &lt;li&gt;CPU+GPU hybrid inference to partially accelerate models larger than the total VRAM capacity&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The &lt;code&gt;llama.cpp&lt;/code&gt; project is the main playground for developing new features for the &lt;a href="https://github.com/ggml-org/ggml"&gt;ggml&lt;/a&gt; library.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Models&lt;/summary&gt; 
 &lt;p&gt;Typically finetunes of the base models below are supported as well.&lt;/p&gt; 
 &lt;p&gt;Instructions for adding support for new models: &lt;a href="https://raw.githubusercontent.com/ggml-org/llama.cpp/master/docs/development/HOWTO-add-model.md"&gt;HOWTO-add-model.md&lt;/a&gt;&lt;/p&gt; 
 &lt;h4&gt;Text-only&lt;/h4&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; LLaMA ü¶ô&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; LLaMA 2 ü¶ôü¶ô&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; LLaMA 3 ü¶ôü¶ôü¶ô&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://huggingface.co/mistralai/Mistral-7B-v0.1"&gt;Mistral 7B&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://huggingface.co/models?search=mistral-ai/Mixtral"&gt;Mixtral MoE&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://huggingface.co/databricks/dbrx-instruct"&gt;DBRX&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://huggingface.co/ai21labs"&gt;Jamba&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://huggingface.co/models?search=tiiuae/falcon"&gt;Falcon&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://github.com/ymcui/Chinese-LLaMA-Alpaca"&gt;Chinese LLaMA / Alpaca&lt;/a&gt; and &lt;a href="https://github.com/ymcui/Chinese-LLaMA-Alpaca-2"&gt;Chinese LLaMA-2 / Alpaca-2&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://github.com/bofenghuang/vigogne"&gt;Vigogne (French)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://github.com/ggml-org/llama.cpp/pull/5423"&gt;BERT&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://bair.berkeley.edu/blog/2023/04/03/koala/"&gt;Koala&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://huggingface.co/models?search=baichuan-inc/Baichuan"&gt;Baichuan 1 &amp;amp; 2&lt;/a&gt; + &lt;a href="https://huggingface.co/hiyouga/baichuan-7b-sft"&gt;derivations&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://huggingface.co/models?search=BAAI/Aquila"&gt;Aquila 1 &amp;amp; 2&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://github.com/ggml-org/llama.cpp/pull/3187"&gt;Starcoder models&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://huggingface.co/smallcloudai/Refact-1_6B-fim"&gt;Refact&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://github.com/ggml-org/llama.cpp/pull/3417"&gt;MPT&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://github.com/ggml-org/llama.cpp/pull/3553"&gt;Bloom&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://huggingface.co/models?search=01-ai/Yi"&gt;Yi models&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://huggingface.co/stabilityai"&gt;StableLM models&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://huggingface.co/models?search=deepseek-ai/deepseek"&gt;Deepseek models&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://huggingface.co/models?search=Qwen/Qwen"&gt;Qwen models&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://github.com/ggml-org/llama.cpp/pull/3557"&gt;PLaMo-13B&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://huggingface.co/models?search=microsoft/phi"&gt;Phi models&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://github.com/ggml-org/llama.cpp/pull/11003"&gt;PhiMoE&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://huggingface.co/gpt2"&gt;GPT-2&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://github.com/ggml-org/llama.cpp/pull/5118"&gt;Orion 14B&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://huggingface.co/models?search=internlm2"&gt;InternLM2&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://github.com/WisdomShell/codeshell"&gt;CodeShell&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://ai.google.dev/gemma"&gt;Gemma&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://github.com/state-spaces/mamba"&gt;Mamba&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://huggingface.co/keyfan/grok-1-hf"&gt;Grok-1&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://huggingface.co/models?search=xverse"&gt;Xverse&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://huggingface.co/models?search=CohereForAI/c4ai-command-r"&gt;Command-R models&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://huggingface.co/models?search=sea-lion"&gt;SEA-LION&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://huggingface.co/GritLM/GritLM-7B"&gt;GritLM-7B&lt;/a&gt; + &lt;a href="https://huggingface.co/GritLM/GritLM-8x7B"&gt;GritLM-8x7B&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://allenai.org/olmo"&gt;OLMo&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://allenai.org/olmo"&gt;OLMo 2&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://huggingface.co/allenai/OLMoE-1B-7B-0924"&gt;OLMoE&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://huggingface.co/collections/ibm-granite/granite-code-models-6624c5cec322e4c148c8b330"&gt;Granite models&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://github.com/EleutherAI/gpt-neox"&gt;GPT-NeoX&lt;/a&gt; + &lt;a href="https://github.com/EleutherAI/pythia"&gt;Pythia&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://huggingface.co/collections/Snowflake/arctic-66290090abe542894a5ac520"&gt;Snowflake-Arctic MoE&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://huggingface.co/models?search=Smaug"&gt;Smaug&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://huggingface.co/LumiOpen/Poro-34B"&gt;Poro 34B&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://huggingface.co/1bitLLM"&gt;Bitnet b1.58 models&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://huggingface.co/models?search=flan-t5"&gt;Flan T5&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://huggingface.co/collections/apple/openelm-instruct-models-6619ad295d7ae9f868b759ca"&gt;Open Elm models&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://huggingface.co/THUDM/chatglm3-6b"&gt;ChatGLM3-6b&lt;/a&gt; + &lt;a href="https://huggingface.co/THUDM/glm-4-9b"&gt;ChatGLM4-9b&lt;/a&gt; + &lt;a href="https://huggingface.co/THUDM/glm-edge-1.5b-chat"&gt;GLMEdge-1.5b&lt;/a&gt; + &lt;a href="https://huggingface.co/THUDM/glm-edge-4b-chat"&gt;GLMEdge-4b&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://huggingface.co/collections/THUDM/glm-4-0414-67f3cbcb34dd9d252707cb2e"&gt;GLM-4-0414&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://huggingface.co/collections/HuggingFaceTB/smollm-6695016cad7167254ce15966"&gt;SmolLM&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://huggingface.co/LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct"&gt;EXAONE-3.0-7.8B-Instruct&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://huggingface.co/collections/tiiuae/falconmamba-7b-66b9a580324dd1598b0f6d4a"&gt;FalconMamba Models&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://huggingface.co/inceptionai/jais-13b-chat"&gt;Jais&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://huggingface.co/collections/speakleash/bielik-11b-v23-66ee813238d9b526a072408a"&gt;Bielik-11B-v2.3&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://github.com/BlinkDL/RWKV-LM"&gt;RWKV-6&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://huggingface.co/recursal/QRWKV6-32B-Instruct-Preview-v0.1"&gt;QRWKV-6&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://huggingface.co/ai-sage/GigaChat-20B-A3B-instruct"&gt;GigaChat-20B-A3B&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://huggingface.co/trillionlabs/Trillion-7B-preview"&gt;Trillion-7B-preview&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://huggingface.co/collections/inclusionAI/ling-67c51c85b34a7ea0aba94c32"&gt;Ling models&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://huggingface.co/collections/LiquidAI/lfm2-686d721927015b2ad73eaa38"&gt;LFM2 models&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://huggingface.co/collections/tencent/hunyuan-dense-model-6890632cda26b19119c9c5e7"&gt;Hunyuan models&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://huggingface.co/collections/inclusionAI/ling-v2-68bf1dd2fc34c306c1fa6f86"&gt;BailingMoeV2 (Ring/Ling 2.0) models&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h4&gt;Multimodal&lt;/h4&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://huggingface.co/collections/liuhaotian/llava-15-653aac15d994e992e2677a7e"&gt;LLaVA 1.5 models&lt;/a&gt;, &lt;a href="https://huggingface.co/collections/liuhaotian/llava-16-65b9e40155f60fd046a5ccf2"&gt;LLaVA 1.6 models&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://huggingface.co/models?search=SkunkworksAI/Bakllava"&gt;BakLLaVA&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://huggingface.co/NousResearch/Obsidian-3B-V0.5"&gt;Obsidian&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://huggingface.co/models?search=Lin-Chen/ShareGPT4V"&gt;ShareGPT4V&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://huggingface.co/models?search=mobileVLM"&gt;MobileVLM 1.7B/3B models&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://huggingface.co/models?search=Yi-VL"&gt;Yi-VL&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://huggingface.co/models?search=MiniCPM"&gt;Mini CPM&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://huggingface.co/vikhyatk/moondream2"&gt;Moondream&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://github.com/BAAI-DCAI/Bunny"&gt;Bunny&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://huggingface.co/models?search=glm-edge"&gt;GLM-EDGE&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://huggingface.co/collections/Qwen/qwen2-vl-66cee7455501d7126940800d"&gt;Qwen2-VL&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://huggingface.co/collections/LiquidAI/lfm2-vl-68963bbc84a610f7638d5ffa"&gt;LFM2-VL&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Bindings&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Python: &lt;a href="https://github.com/ddh0/easy-llama"&gt;ddh0/easy-llama&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Python: &lt;a href="https://github.com/abetlen/llama-cpp-python"&gt;abetlen/llama-cpp-python&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Go: &lt;a href="https://github.com/go-skynet/go-llama.cpp"&gt;go-skynet/go-llama.cpp&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Node.js: &lt;a href="https://github.com/withcatai/node-llama-cpp"&gt;withcatai/node-llama-cpp&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;JS/TS (llama.cpp server client): &lt;a href="https://modelfusion.dev/integration/model-provider/llamacpp"&gt;lgrammel/modelfusion&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;JS/TS (Programmable Prompt Engine CLI): &lt;a href="https://github.com/offline-ai/cli"&gt;offline-ai/cli&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;JavaScript/Wasm (works in browser): &lt;a href="https://github.com/tangledgroup/llama-cpp-wasm"&gt;tangledgroup/llama-cpp-wasm&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Typescript/Wasm (nicer API, available on npm): &lt;a href="https://github.com/ngxson/wllama"&gt;ngxson/wllama&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Ruby: &lt;a href="https://github.com/yoshoku/llama_cpp.rb"&gt;yoshoku/llama_cpp.rb&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Rust (more features): &lt;a href="https://github.com/edgenai/llama_cpp-rs"&gt;edgenai/llama_cpp-rs&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Rust (nicer API): &lt;a href="https://github.com/mdrokz/rust-llama.cpp"&gt;mdrokz/rust-llama.cpp&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Rust (more direct bindings): &lt;a href="https://github.com/utilityai/llama-cpp-rs"&gt;utilityai/llama-cpp-rs&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Rust (automated build from crates.io): &lt;a href="https://github.com/ShelbyJenkins/llm_client"&gt;ShelbyJenkins/llm_client&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;C#/.NET: &lt;a href="https://github.com/SciSharp/LLamaSharp"&gt;SciSharp/LLamaSharp&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;C#/VB.NET (more features - community license): &lt;a href="https://docs.lm-kit.com/lm-kit-net/index.html"&gt;LM-Kit.NET&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Scala 3: &lt;a href="https://github.com/donderom/llm4s"&gt;donderom/llm4s&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Clojure: &lt;a href="https://github.com/phronmophobic/llama.clj"&gt;phronmophobic/llama.clj&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;React Native: &lt;a href="https://github.com/mybigday/llama.rn"&gt;mybigday/llama.rn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Java: &lt;a href="https://github.com/kherud/java-llama.cpp"&gt;kherud/java-llama.cpp&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Java: &lt;a href="https://github.com/QuasarByte/llama-cpp-jna"&gt;QuasarByte/llama-cpp-jna&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Zig: &lt;a href="https://github.com/Deins/llama.cpp.zig"&gt;deins/llama.cpp.zig&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Flutter/Dart: &lt;a href="https://github.com/netdur/llama_cpp_dart"&gt;netdur/llama_cpp_dart&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Flutter: &lt;a href="https://github.com/xuegao-tzx/Fllama"&gt;xuegao-tzx/Fllama&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;PHP (API bindings and features built on top of llama.cpp): &lt;a href="https://github.com/distantmagic/resonance"&gt;distantmagic/resonance&lt;/a&gt; &lt;a href="https://github.com/ggml-org/llama.cpp/pull/6326"&gt;(more info)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Guile Scheme: &lt;a href="https://savannah.nongnu.org/projects/guile-llama-cpp"&gt;guile_llama_cpp&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Swift &lt;a href="https://github.com/srgtuszy/llama-cpp-swift"&gt;srgtuszy/llama-cpp-swift&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Swift &lt;a href="https://github.com/ShenghaiWang/SwiftLlama"&gt;ShenghaiWang/SwiftLlama&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Delphi &lt;a href="https://github.com/Embarcadero/llama-cpp-delphi"&gt;Embarcadero/llama-cpp-delphi&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Go (no CGo needed): &lt;a href="https://github.com/hybridgroup/yzma"&gt;hybridgroup/yzma&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;UIs&lt;/summary&gt; 
 &lt;p&gt;&lt;em&gt;(to have a project listed here, it should clearly state that it depends on &lt;code&gt;llama.cpp&lt;/code&gt;)&lt;/em&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/yaroslavyaroslav/OpenAI-sublime-text"&gt;AI Sublime Text plugin&lt;/a&gt; (MIT)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/cztomsik/ava"&gt;cztomsik/ava&lt;/a&gt; (MIT)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/alexpinel/Dot"&gt;Dot&lt;/a&gt; (GPL)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/ylsdamxssjxxdd/eva"&gt;eva&lt;/a&gt; (MIT)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/iohub/coLLaMA"&gt;iohub/collama&lt;/a&gt; (Apache-2.0)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/janhq/jan"&gt;janhq/jan&lt;/a&gt; (AGPL)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/johnbean393/Sidekick"&gt;johnbean393/Sidekick&lt;/a&gt; (MIT)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/zhouwg/kantv?tab=readme-ov-file"&gt;KanTV&lt;/a&gt; (Apache-2.0)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/firatkiral/kodibot"&gt;KodiBot&lt;/a&gt; (GPL)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/ggml-org/llama.vim"&gt;llama.vim&lt;/a&gt; (MIT)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/abgulati/LARS"&gt;LARS&lt;/a&gt; (AGPL)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/vietanhdev/llama-assistant"&gt;Llama Assistant&lt;/a&gt; (GPL)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/guinmoon/LLMFarm?tab=readme-ov-file"&gt;LLMFarm&lt;/a&gt; (MIT)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/undreamai/LLMUnity"&gt;LLMUnity&lt;/a&gt; (MIT)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://lmstudio.ai/"&gt;LMStudio&lt;/a&gt; (proprietary)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/mudler/LocalAI"&gt;LocalAI&lt;/a&gt; (MIT)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/LostRuins/koboldcpp"&gt;LostRuins/koboldcpp&lt;/a&gt; (AGPL)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://mindmac.app"&gt;MindMac&lt;/a&gt; (proprietary)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/MindWorkAI/AI-Studio"&gt;MindWorkAI/AI-Studio&lt;/a&gt; (FSL-1.1-MIT)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/Mobile-Artificial-Intelligence/maid"&gt;Mobile-Artificial-Intelligence/maid&lt;/a&gt; (MIT)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/Mozilla-Ocho/llamafile"&gt;Mozilla-Ocho/llamafile&lt;/a&gt; (Apache-2.0)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/nat/openplayground"&gt;nat/openplayground&lt;/a&gt; (MIT)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/nomic-ai/gpt4all"&gt;nomic-ai/gpt4all&lt;/a&gt; (MIT)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/ollama/ollama"&gt;ollama/ollama&lt;/a&gt; (MIT)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/oobabooga/text-generation-webui"&gt;oobabooga/text-generation-webui&lt;/a&gt; (AGPL)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/a-ghorbani/pocketpal-ai"&gt;PocketPal AI&lt;/a&gt; (MIT)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/psugihara/FreeChat"&gt;psugihara/FreeChat&lt;/a&gt; (MIT)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/ptsochantaris/emeltal"&gt;ptsochantaris/emeltal&lt;/a&gt; (MIT)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/pythops/tenere"&gt;pythops/tenere&lt;/a&gt; (AGPL)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/containers/ramalama"&gt;ramalama&lt;/a&gt; (MIT)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/semperai/amica"&gt;semperai/amica&lt;/a&gt; (MIT)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/withcatai/catai"&gt;withcatai/catai&lt;/a&gt; (MIT)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/blackhole89/autopen"&gt;Autopen&lt;/a&gt; (GPL)&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Tools&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/akx/ggify"&gt;akx/ggify&lt;/a&gt; ‚Äì download PyTorch models from HuggingFace Hub and convert them to GGML&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/akx/ollama-dl"&gt;akx/ollama-dl&lt;/a&gt; ‚Äì download models from the Ollama library to be used directly with llama.cpp&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/crashr/gppm"&gt;crashr/gppm&lt;/a&gt; ‚Äì launch llama.cpp instances utilizing NVIDIA Tesla P40 or P100 GPUs with reduced idle power consumption&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/gpustack/gguf-parser-go/tree/main/cmd/gguf-parser"&gt;gpustack/gguf-parser&lt;/a&gt; - review/check the GGUF file and estimate the memory usage&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://marketplace.unity.com/packages/tools/generative-ai/styled-lines-llama-cpp-model-292902"&gt;Styled Lines&lt;/a&gt; (proprietary licensed, async wrapper of inference part for game development in Unity3d with pre-built Mobile and Web platform wrappers and a model example)&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Infrastructure&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/intentee/paddler"&gt;Paddler&lt;/a&gt; - Open-source LLMOps platform for hosting and scaling AI in your own infrastructure&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/gpustack/gpustack"&gt;GPUStack&lt;/a&gt; - Manage GPU clusters for running LLMs&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/onicai/llama_cpp_canister"&gt;llama_cpp_canister&lt;/a&gt; - llama.cpp as a smart contract on the Internet Computer, using WebAssembly&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/mostlygeek/llama-swap"&gt;llama-swap&lt;/a&gt; - transparent proxy that adds automatic model switching with llama-server&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/kalavai-net/kalavai-client"&gt;Kalavai&lt;/a&gt; - Crowdsource end to end LLM deployment at any scale&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/InftyAI/llmaz"&gt;llmaz&lt;/a&gt; - ‚ò∏Ô∏è Easy, advanced inference platform for large language models on Kubernetes.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Games&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/MorganRO8/Lucys_Labyrinth"&gt;Lucy's Labyrinth&lt;/a&gt; - A simple maze game where agents controlled by an AI model will try to trick you.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;Supported backends&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Backend&lt;/th&gt; 
   &lt;th&gt;Target devices&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ggml-org/llama.cpp/master/docs/build.md#metal-build"&gt;Metal&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Apple Silicon&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ggml-org/llama.cpp/master/docs/build.md#blas-build"&gt;BLAS&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;All&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ggml-org/llama.cpp/master/docs/backend/BLIS.md"&gt;BLIS&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;All&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ggml-org/llama.cpp/master/docs/backend/SYCL.md"&gt;SYCL&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Intel and Nvidia GPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ggml-org/llama.cpp/master/docs/build.md#musa"&gt;MUSA&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Moore Threads GPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ggml-org/llama.cpp/master/docs/build.md#cuda"&gt;CUDA&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Nvidia GPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ggml-org/llama.cpp/master/docs/build.md#hip"&gt;HIP&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;AMD GPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ggml-org/llama.cpp/master/docs/build.md#vulkan"&gt;Vulkan&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ggml-org/llama.cpp/master/docs/build.md#cann"&gt;CANN&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Ascend NPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ggml-org/llama.cpp/master/docs/backend/OPENCL.md"&gt;OpenCL&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Adreno GPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ggml-org/llama.cpp/master/docs/backend/zDNN.md"&gt;IBM zDNN&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;IBM Z &amp;amp; LinuxONE&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ggml-org/llama.cpp/master/docs/build.md#webgpu"&gt;WebGPU [In Progress]&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;All&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/ggml-org/llama.cpp/tree/master/tools/rpc"&gt;RPC&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;All&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ggml-org/llama.cpp/master/docs/backend/hexagon/README.md"&gt;Hexagon [In Progress]&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Snapdragon&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Obtaining and quantizing models&lt;/h2&gt; 
&lt;p&gt;The &lt;a href="https://huggingface.co"&gt;Hugging Face&lt;/a&gt; platform hosts a &lt;a href="https://huggingface.co/models?library=gguf&amp;amp;sort=trending"&gt;number of LLMs&lt;/a&gt; compatible with &lt;code&gt;llama.cpp&lt;/code&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/models?library=gguf&amp;amp;sort=trending"&gt;Trending&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/models?sort=trending&amp;amp;search=llama+gguf"&gt;LLaMA&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You can either manually download the GGUF file or directly use any &lt;code&gt;llama.cpp&lt;/code&gt;-compatible models from &lt;a href="https://huggingface.co/"&gt;Hugging Face&lt;/a&gt; or other model hosting sites, such as &lt;a href="https://modelscope.cn/"&gt;ModelScope&lt;/a&gt;, by using this CLI argument: &lt;code&gt;-hf &amp;lt;user&amp;gt;/&amp;lt;model&amp;gt;[:quant]&lt;/code&gt;. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;llama-cli -hf ggml-org/gemma-3-1b-it-GGUF
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;By default, the CLI would download from Hugging Face, you can switch to other options with the environment variable &lt;code&gt;MODEL_ENDPOINT&lt;/code&gt;. For example, you may opt to downloading model checkpoints from ModelScope or other model sharing communities by setting the environment variable, e.g. &lt;code&gt;MODEL_ENDPOINT=https://www.modelscope.cn/&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;After downloading a model, use the CLI tools to run it locally - see below.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;llama.cpp&lt;/code&gt; requires the model to be stored in the &lt;a href="https://github.com/ggml-org/ggml/raw/master/docs/gguf.md"&gt;GGUF&lt;/a&gt; file format. Models in other data formats can be converted to GGUF using the &lt;code&gt;convert_*.py&lt;/code&gt; Python scripts in this repo.&lt;/p&gt; 
&lt;p&gt;The Hugging Face platform provides a variety of online tools for converting, quantizing and hosting models with &lt;code&gt;llama.cpp&lt;/code&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Use the &lt;a href="https://huggingface.co/spaces/ggml-org/gguf-my-repo"&gt;GGUF-my-repo space&lt;/a&gt; to convert to GGUF format and quantize model weights to smaller sizes&lt;/li&gt; 
 &lt;li&gt;Use the &lt;a href="https://huggingface.co/spaces/ggml-org/gguf-my-lora"&gt;GGUF-my-LoRA space&lt;/a&gt; to convert LoRA adapters to GGUF format (more info: &lt;a href="https://github.com/ggml-org/llama.cpp/discussions/10123"&gt;https://github.com/ggml-org/llama.cpp/discussions/10123&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;Use the &lt;a href="https://huggingface.co/spaces/CISCai/gguf-editor"&gt;GGUF-editor space&lt;/a&gt; to edit GGUF meta data in the browser (more info: &lt;a href="https://github.com/ggml-org/llama.cpp/discussions/9268"&gt;https://github.com/ggml-org/llama.cpp/discussions/9268&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;Use the &lt;a href="https://ui.endpoints.huggingface.co/"&gt;Inference Endpoints&lt;/a&gt; to directly host &lt;code&gt;llama.cpp&lt;/code&gt; in the cloud (more info: &lt;a href="https://github.com/ggml-org/llama.cpp/discussions/9669"&gt;https://github.com/ggml-org/llama.cpp/discussions/9669&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To learn more about model quantization, &lt;a href="https://raw.githubusercontent.com/ggml-org/llama.cpp/master/tools/quantize/README.md"&gt;read this documentation&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;a href="https://raw.githubusercontent.com/ggml-org/llama.cpp/master/tools/main"&gt;&lt;code&gt;llama-cli&lt;/code&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;h4&gt;A CLI tool for accessing and experimenting with most of &lt;code&gt;llama.cpp&lt;/code&gt;'s functionality.&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt; 
  &lt;details open&gt; 
   &lt;summary&gt;Run in conversation mode&lt;/summary&gt; 
   &lt;p&gt;Models with a built-in chat template will automatically activate conversation mode. If this doesn't occur, you can manually enable it by adding &lt;code&gt;-cnv&lt;/code&gt; and specifying a suitable chat template with &lt;code&gt;--chat-template NAME&lt;/code&gt;&lt;/p&gt; 
   &lt;pre&gt;&lt;code class="language-bash"&gt;llama-cli -m model.gguf

# &amp;gt; hi, who are you?
# Hi there! I'm your helpful assistant! I'm an AI-powered chatbot designed to assist and provide information to users like you. I'm here to help answer your questions, provide guidance, and offer support on a wide range of topics. I'm a friendly and knowledgeable AI, and I'm always happy to help with anything you need. What's on your mind, and how can I assist you today?
#
# &amp;gt; what is 1+1?
# Easy peasy! The answer to 1+1 is... 2!
&lt;/code&gt;&lt;/pre&gt; 
  &lt;/details&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;details&gt; 
   &lt;summary&gt;Run in conversation mode with custom chat template&lt;/summary&gt; 
   &lt;pre&gt;&lt;code class="language-bash"&gt;# use the "chatml" template (use -h to see the list of supported templates)
llama-cli -m model.gguf -cnv --chat-template chatml

# use a custom template
llama-cli -m model.gguf -cnv --in-prefix 'User: ' --reverse-prompt 'User:'
&lt;/code&gt;&lt;/pre&gt; 
  &lt;/details&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;details&gt; 
   &lt;summary&gt;Run simple text completion&lt;/summary&gt; 
   &lt;p&gt;To disable conversation mode explicitly, use &lt;code&gt;-no-cnv&lt;/code&gt;&lt;/p&gt; 
   &lt;pre&gt;&lt;code class="language-bash"&gt;llama-cli -m model.gguf -p "I believe the meaning of life is" -n 128 -no-cnv

# I believe the meaning of life is to find your own truth and to live in accordance with it. For me, this means being true to myself and following my passions, even if they don't align with societal expectations. I think that's what I love about yoga ‚Äì it's not just a physical practice, but a spiritual one too. It's about connecting with yourself, listening to your inner voice, and honoring your own unique journey.
&lt;/code&gt;&lt;/pre&gt; 
  &lt;/details&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;details&gt; 
   &lt;summary&gt;Constrain the output with a custom grammar&lt;/summary&gt; 
   &lt;pre&gt;&lt;code class="language-bash"&gt;llama-cli -m model.gguf -n 256 --grammar-file grammars/json.gbnf -p 'Request: schedule a call at 8pm; Command:'

# {"appointmentTime": "8pm", "appointmentDetails": "schedule a a call"}
&lt;/code&gt;&lt;/pre&gt; 
   &lt;p&gt;The &lt;a href="https://raw.githubusercontent.com/ggml-org/llama.cpp/master/grammars/"&gt;grammars/&lt;/a&gt; folder contains a handful of sample grammars. To write your own, check out the &lt;a href="https://raw.githubusercontent.com/ggml-org/llama.cpp/master/grammars/README.md"&gt;GBNF Guide&lt;/a&gt;.&lt;/p&gt; 
   &lt;p&gt;For authoring more complex JSON grammars, check out &lt;a href="https://grammar.intrinsiclabs.ai/"&gt;https://grammar.intrinsiclabs.ai/&lt;/a&gt;&lt;/p&gt; 
  &lt;/details&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;a href="https://raw.githubusercontent.com/ggml-org/llama.cpp/master/tools/server"&gt;&lt;code&gt;llama-server&lt;/code&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;h4&gt;A lightweight, &lt;a href="https://github.com/openai/openai-openapi"&gt;OpenAI API&lt;/a&gt; compatible, HTTP server for serving LLMs.&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt; 
  &lt;details open&gt; 
   &lt;summary&gt;Start a local HTTP server with default configuration on port 8080&lt;/summary&gt; 
   &lt;pre&gt;&lt;code class="language-bash"&gt;llama-server -m model.gguf --port 8080

# Basic web UI can be accessed via browser: http://localhost:8080
# Chat completion endpoint: http://localhost:8080/v1/chat/completions
&lt;/code&gt;&lt;/pre&gt; 
  &lt;/details&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;details&gt; 
   &lt;summary&gt;Support multiple-users and parallel decoding&lt;/summary&gt; 
   &lt;pre&gt;&lt;code class="language-bash"&gt;# up to 4 concurrent requests, each with 4096 max context
llama-server -m model.gguf -c 16384 -np 4
&lt;/code&gt;&lt;/pre&gt; 
  &lt;/details&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;details&gt; 
   &lt;summary&gt;Enable speculative decoding&lt;/summary&gt; 
   &lt;pre&gt;&lt;code class="language-bash"&gt;# the draft.gguf model should be a small variant of the target model.gguf
llama-server -m model.gguf -md draft.gguf
&lt;/code&gt;&lt;/pre&gt; 
  &lt;/details&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;details&gt; 
   &lt;summary&gt;Serve an embedding model&lt;/summary&gt; 
   &lt;pre&gt;&lt;code class="language-bash"&gt;# use the /embedding endpoint
llama-server -m model.gguf --embedding --pooling cls -ub 8192
&lt;/code&gt;&lt;/pre&gt; 
  &lt;/details&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;details&gt; 
   &lt;summary&gt;Serve a reranking model&lt;/summary&gt; 
   &lt;pre&gt;&lt;code class="language-bash"&gt;# use the /reranking endpoint
llama-server -m model.gguf --reranking
&lt;/code&gt;&lt;/pre&gt; 
  &lt;/details&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;details&gt; 
   &lt;summary&gt;Constrain all outputs with a grammar&lt;/summary&gt; 
   &lt;pre&gt;&lt;code class="language-bash"&gt;# custom grammar
llama-server -m model.gguf --grammar-file grammar.gbnf

# JSON
llama-server -m model.gguf --grammar-file grammars/json.gbnf
&lt;/code&gt;&lt;/pre&gt; 
  &lt;/details&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;a href="https://raw.githubusercontent.com/ggml-org/llama.cpp/master/tools/perplexity"&gt;&lt;code&gt;llama-perplexity&lt;/code&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;h4&gt;A tool for measuring the &lt;a href="https://raw.githubusercontent.com/ggml-org/llama.cpp/master/tools/perplexity/README.md"&gt;perplexity&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/ggml-org/llama.cpp/master/%5Bhttps://huggingface.co/docs/transformers/perplexity%5D(https://huggingface.co/docs/transformers/perplexity)"&gt;^1&lt;/a&gt; (and other quality metrics) of a model over a given text.&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt; 
  &lt;details open&gt; 
   &lt;summary&gt;Measure the perplexity over a text file&lt;/summary&gt; 
   &lt;pre&gt;&lt;code class="language-bash"&gt;llama-perplexity -m model.gguf -f file.txt

# [1]15.2701,[2]5.4007,[3]5.3073,[4]6.2965,[5]5.8940,[6]5.6096,[7]5.7942,[8]4.9297, ...
# Final estimate: PPL = 5.4007 +/- 0.67339
&lt;/code&gt;&lt;/pre&gt; 
  &lt;/details&gt; &lt;/li&gt; 
 &lt;li&gt; 
  &lt;details&gt; 
   &lt;summary&gt;Measure KL divergence&lt;/summary&gt; 
   &lt;pre&gt;&lt;code class="language-bash"&gt;# TODO
&lt;/code&gt;&lt;/pre&gt; 
  &lt;/details&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;a href="https://raw.githubusercontent.com/ggml-org/llama.cpp/master/tools/llama-bench"&gt;&lt;code&gt;llama-bench&lt;/code&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;h4&gt;Benchmark the performance of the inference for various parameters.&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt; 
  &lt;details open&gt; 
   &lt;summary&gt;Run default benchmark&lt;/summary&gt; 
   &lt;pre&gt;&lt;code class="language-bash"&gt;llama-bench -m model.gguf

# Output:
# | model               |       size |     params | backend    | threads |          test |                  t/s |
# | ------------------- | ---------: | ---------: | ---------- | ------: | ------------: | -------------------: |
# | qwen2 1.5B Q4_0     | 885.97 MiB |     1.54 B | Metal,BLAS |      16 |         pp512 |      5765.41 ¬± 20.55 |
# | qwen2 1.5B Q4_0     | 885.97 MiB |     1.54 B | Metal,BLAS |      16 |         tg128 |        197.71 ¬± 0.81 |
#
# build: 3e0ba0e60 (4229)
&lt;/code&gt;&lt;/pre&gt; 
  &lt;/details&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;a href="https://raw.githubusercontent.com/ggml-org/llama.cpp/master/tools/run"&gt;&lt;code&gt;llama-run&lt;/code&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;h4&gt;A comprehensive example for running &lt;code&gt;llama.cpp&lt;/code&gt; models. Useful for inferencing. Used with RamaLama &lt;a href="https://raw.githubusercontent.com/ggml-org/llama.cpp/master/%5BRamaLama%5D(https://github.com/containers/ramalama)"&gt;^3&lt;/a&gt;.&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt; 
  &lt;details&gt; 
   &lt;summary&gt;Run a model with a specific prompt (by default it's pulled from Ollama registry)&lt;/summary&gt; 
   &lt;pre&gt;&lt;code class="language-bash"&gt;llama-run granite-code
&lt;/code&gt;&lt;/pre&gt; 
  &lt;/details&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;a href="https://raw.githubusercontent.com/ggml-org/llama.cpp/master/examples/simple"&gt;&lt;code&gt;llama-simple&lt;/code&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;h4&gt;A minimal example for implementing apps with &lt;code&gt;llama.cpp&lt;/code&gt;. Useful for developers.&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt; 
  &lt;details&gt; 
   &lt;summary&gt;Basic text completion&lt;/summary&gt; 
   &lt;pre&gt;&lt;code class="language-bash"&gt;llama-simple -m model.gguf

# Hello my name is Kaitlyn and I am a 16 year old girl. I am a junior in high school and I am currently taking a class called "The Art of
&lt;/code&gt;&lt;/pre&gt; 
  &lt;/details&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Contributors can open PRs&lt;/li&gt; 
 &lt;li&gt;Collaborators will be invited based on contributions&lt;/li&gt; 
 &lt;li&gt;Maintainers can push to branches in the &lt;code&gt;llama.cpp&lt;/code&gt; repo and merge PRs into the &lt;code&gt;master&lt;/code&gt; branch&lt;/li&gt; 
 &lt;li&gt;Any help with managing issues, PRs and projects is very appreciated!&lt;/li&gt; 
 &lt;li&gt;See &lt;a href="https://github.com/ggml-org/llama.cpp/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22"&gt;good first issues&lt;/a&gt; for tasks suitable for first contributions&lt;/li&gt; 
 &lt;li&gt;Read the &lt;a href="https://raw.githubusercontent.com/ggml-org/llama.cpp/master/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for more information&lt;/li&gt; 
 &lt;li&gt;Make sure to read this: &lt;a href="https://github.com/ggml-org/llama.cpp/discussions/205"&gt;Inference at the edge&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;A bit of backstory for those who are interested: &lt;a href="https://changelog.com/podcast/532"&gt;Changelog podcast&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Other documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ggml-org/llama.cpp/master/tools/main/README.md"&gt;main (cli)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ggml-org/llama.cpp/master/tools/server/README.md"&gt;server&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ggml-org/llama.cpp/master/grammars/README.md"&gt;GBNF grammars&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Development documentation&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ggml-org/llama.cpp/master/docs/build.md"&gt;How to build&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ggml-org/llama.cpp/master/docs/docker.md"&gt;Running on Docker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ggml-org/llama.cpp/master/docs/android.md"&gt;Build on Android&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ggml-org/llama.cpp/master/docs/development/token_generation_performance_tips.md"&gt;Performance troubleshooting&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ggml-org/llama.cpp/wiki/GGML-Tips-&amp;amp;-Tricks"&gt;GGML tips &amp;amp; tricks&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Seminal papers and background on the models&lt;/h4&gt; 
&lt;p&gt;If your issue is with model generation quality, then please at least scan the following links and papers to understand the limitations of LLaMA models. This is especially important when choosing an appropriate model size and appreciating both the significant and subtle differences between LLaMA models and ChatGPT:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;LLaMA: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://ai.facebook.com/blog/large-language-model-llama-meta-ai/"&gt;Introducing LLaMA: A foundational, 65-billion-parameter large language model&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://arxiv.org/abs/2302.13971"&gt;LLaMA: Open and Efficient Foundation Language Models&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;GPT-3 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://arxiv.org/abs/2005.14165"&gt;Language Models are Few-Shot Learners&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;GPT-3.5 / InstructGPT / ChatGPT: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://openai.com/research/instruction-following"&gt;Aligning language models to follow instructions&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://arxiv.org/abs/2203.02155"&gt;Training language models to follow instructions with human feedback&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;XCFramework&lt;/h2&gt; 
&lt;p&gt;The XCFramework is a precompiled version of the library for iOS, visionOS, tvOS, and macOS. It can be used in Swift projects without the need to compile the library from source. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-swift"&gt;// swift-tools-version: 5.10
// The swift-tools-version declares the minimum version of Swift required to build this package.

import PackageDescription

let package = Package(
    name: "MyLlamaPackage",
    targets: [
        .executableTarget(
            name: "MyLlamaPackage",
            dependencies: [
                "LlamaFramework"
            ]),
        .binaryTarget(
            name: "LlamaFramework",
            url: "https://github.com/ggml-org/llama.cpp/releases/download/b5046/llama-b5046-xcframework.zip",
            checksum: "c19be78b5f00d8d29a25da41042cb7afa094cbf6280a225abe614b03b20029ab"
        )
    ]
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The above example is using an intermediate build &lt;code&gt;b5046&lt;/code&gt; of the library. This can be modified to use a different version by changing the URL and checksum.&lt;/p&gt; 
&lt;h2&gt;Completions&lt;/h2&gt; 
&lt;p&gt;Command-line completion is available for some environments.&lt;/p&gt; 
&lt;h4&gt;Bash Completion&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ build/bin/llama-cli --completion-bash &amp;gt; ~/.llama-completion.bash
$ source ~/.llama-completion.bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Optionally this can be added to your &lt;code&gt;.bashrc&lt;/code&gt; or &lt;code&gt;.bash_profile&lt;/code&gt; to load it automatically. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ echo "source ~/.llama-completion.bash" &amp;gt;&amp;gt; ~/.bashrc
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Dependencies&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/yhirose/cpp-httplib"&gt;yhirose/cpp-httplib&lt;/a&gt; - Single-header HTTP server, used by &lt;code&gt;llama-server&lt;/code&gt; - MIT license&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nothings/stb"&gt;stb-image&lt;/a&gt; - Single-header image format decoder, used by multimodal subsystem - Public domain&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nlohmann/json"&gt;nlohmann/json&lt;/a&gt; - Single-header JSON library, used by various tools/examples - MIT License&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/google/minja"&gt;minja&lt;/a&gt; - Minimal Jinja parser in C++, used by various tools/examples - MIT License&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ggml-org/llama.cpp/master/tools/run/linenoise.cpp/linenoise.cpp"&gt;linenoise.cpp&lt;/a&gt; - C++ library that provides readline-like line editing capabilities, used by &lt;code&gt;llama-run&lt;/code&gt; - BSD 2-Clause License&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://curl.se/"&gt;curl&lt;/a&gt; - Client-side URL transfer library, used by various tools/examples - &lt;a href="https://curl.se/docs/copyright.html"&gt;CURL License&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mackron/miniaudio"&gt;miniaudio.h&lt;/a&gt; - Single-header audio format decoder, used by multimodal subsystem - Public domain&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>nocobase/nocobase</title>
      <link>https://github.com/nocobase/nocobase</link>
      <description>&lt;p&gt;NocoBase is the most extensible AI-powered no-code/low-code platform for building business applications and enterprise solutions.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;English | &lt;a href="https://raw.githubusercontent.com/nocobase/nocobase/main/README.zh-CN.md"&gt;‰∏≠Êñá&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/nocobase/nocobase/main/README.ja-JP.md"&gt;Êó•Êú¨Ë™û&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/4d11a87b-00e2-48f3-9bf7-389d21072d13"&gt;https://github.com/user-attachments/assets/4d11a87b-00e2-48f3-9bf7-389d21072d13&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/4112" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/4112" alt="nocobase%2Fnocobase | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; &lt;a href="https://www.producthunt.com/posts/nocobase?embed=true&amp;amp;utm_source=badge-top-post-topic-badge&amp;amp;utm_medium=badge&amp;amp;utm_souce=badge-nocobase" target="_blank"&gt;&lt;img src="https://api.producthunt.com/widgets/embed-image/v1/top-post-topic-badge.svg?post_id=456520&amp;amp;theme=light&amp;amp;period=weekly&amp;amp;topic_id=267" alt="NocoBase - Scalability-first, open-source no-code platform | Product Hunt" style="width: 250px; height: 54px;" width="250" height="54" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;What is NocoBase&lt;/h2&gt; 
&lt;p&gt;NocoBase is the most extensible AI-powered no-code platform.&lt;br /&gt; Total control. Infinite extensibility. AI collaboration.&lt;br /&gt; Enable your team to adapt quickly and cut costs dramatically.&lt;br /&gt; No years of development. No millions wasted.&lt;br /&gt; Deploy NocoBase in minutes ‚Äî and take control of everything.&lt;/p&gt; 
&lt;p&gt;Homepage:&lt;br /&gt; &lt;a href="https://www.nocobase.com/"&gt;https://www.nocobase.com/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Online Demo:&lt;br /&gt; &lt;a href="https://demo.nocobase.com/new"&gt;https://demo.nocobase.com/new&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Documents:&lt;br /&gt; &lt;a href="https://docs.nocobase.com/"&gt;https://docs.nocobase.com/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Forum:&lt;br /&gt; &lt;a href="https://forum.nocobase.com/"&gt;https://forum.nocobase.com/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Use Cases:&lt;br /&gt; &lt;a href="https://www.nocobase.com/en/blog/tags/customer-stories"&gt;https://www.nocobase.com/en/blog/tags/customer-stories&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Release Notes&lt;/h2&gt; 
&lt;p&gt;Our &lt;a href="https://www.nocobase.com/en/blog/timeline"&gt;blog&lt;/a&gt; is regularly updated with release notes and provides a weekly summary.&lt;/p&gt; 
&lt;h2&gt;Distinctive features&lt;/h2&gt; 
&lt;h3&gt;1. Data model-driven, not form/table‚Äìdriven&lt;/h3&gt; 
&lt;p&gt;Instead of being constrained by forms or tables, NocoBase adopts a data model‚Äìdriven approach, separating data structure from user interface to unlock unlimited possibilities.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;UI and data structure are fully decoupled&lt;/li&gt; 
 &lt;li&gt;Multiple blocks and actions can be created for the same table or record in any quantity or form&lt;/li&gt; 
 &lt;li&gt;Supports the main database, external databases, and third-party APIs as data sources&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static-docs.nocobase.com/model.png" alt="model" /&gt;&lt;/p&gt; 
&lt;h3&gt;2. AI employees, integrated into your business systems&lt;/h3&gt; 
&lt;p&gt;Unlike standalone AI demos, NocoBase allows you to embed AI capabilities seamlessly into your interfaces, workflows, and data context, making AI truly useful in real business scenarios.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Define AI employees for roles such as translator, analyst, researcher, or assistant&lt;/li&gt; 
 &lt;li&gt;Seamless AI‚Äìhuman collaboration in interfaces and workflows&lt;/li&gt; 
 &lt;li&gt;Ensure AI usage is secure, transparent, and customizable for your business needs&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static-docs.nocobase.com/ai-employee-home.png" alt="AI-employee" /&gt;&lt;/p&gt; 
&lt;h3&gt;3. What you see is what you get, incredibly easy to use&lt;/h3&gt; 
&lt;p&gt;While enabling the development of complex business systems, NocoBase keeps the experience simple and intuitive.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;One-click switch between usage mode and configuration mode&lt;/li&gt; 
 &lt;li&gt;Pages serve as a canvas to arrange blocks and actions, similar to Notion&lt;/li&gt; 
 &lt;li&gt;Configuration mode is designed for ordinary users, not just programmers&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static-docs.nocobase.com/wysiwyg.gif" alt="wysiwyg" /&gt;&lt;/p&gt; 
&lt;h3&gt;4. Everything is a plugin, designed for extension&lt;/h3&gt; 
&lt;p&gt;Adding more no-code features will never cover every business case. NocoBase is built for extension through its plugin-based microkernel architecture.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;All functionalities are plugins, similar to WordPress&lt;/li&gt; 
 &lt;li&gt;Plugins are ready to use upon installation&lt;/li&gt; 
 &lt;li&gt;Pages, blocks, actions, APIs, and data sources can all be extended through custom plugins&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://static-docs.nocobase.com/plugins.png" alt="plugins" /&gt;&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;NocoBase supports three installation methods:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a target="_blank" href="https://docs.nocobase.com/welcome/getting-started/installation/docker-compose"&gt;Installing With Docker (üëçRecommended)&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Suitable for no-code scenarios, no code to write. When upgrading, just download the latest image and reboot.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a target="_blank" href="https://docs.nocobase.com/welcome/getting-started/installation/create-nocobase-app"&gt;Installing from create-nocobase-app CLI&lt;/a&gt;&lt;/p&gt; &lt;p&gt;The business code of the project is completely independent and supports low-code development.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a target="_blank" href="https://docs.nocobase.com/welcome/getting-started/installation/git-clone"&gt;Installing from Git source code&lt;/a&gt;&lt;/p&gt; &lt;p&gt;If you want to experience the latest unreleased version, or want to participate in the contribution, you need to make changes and debug on the source code, it is recommended to choose this installation method, which requires a high level of development skills, and if the code has been updated, you can git pull the latest code.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;How NocoBase works&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/8d183b44-9bb5-4792-b08f-bc08fe8dfaaf"&gt;https://github.com/user-attachments/assets/8d183b44-9bb5-4792-b08f-bc08fe8dfaaf&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>prometheus/alertmanager</title>
      <link>https://github.com/prometheus/alertmanager</link>
      <description>&lt;p&gt;Prometheus Alertmanager&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Alertmanager &lt;a href="https://circleci.com/gh/prometheus/alertmanager"&gt;&lt;img src="https://circleci.com/gh/prometheus/alertmanager/tree/main.svg?style=shield" alt="CircleCI" /&gt;&lt;/a&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://quay.io/repository/prometheus/alertmanager"&gt;&lt;img src="https://quay.io/repository/prometheus/alertmanager/status" alt="Docker Repository on Quay" title="Docker Repository on Quay" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/prom/alertmanager/"&gt;&lt;img src="https://img.shields.io/docker/pulls/prom/alertmanager.svg?maxAge=604800" alt="Docker Pulls" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;The Alertmanager handles alerts sent by client applications such as the Prometheus server. It takes care of deduplicating, grouping, and routing them to the correct &lt;a href="https://prometheus.io/docs/alerting/latest/configuration/#receiver"&gt;receiver integrations&lt;/a&gt; such as email, PagerDuty, OpsGenie, or many other &lt;a href="https://prometheus.io/docs/operating/integrations/#alertmanager-webhook-receiver"&gt;mechanisms&lt;/a&gt; thanks to the webhook receiver. It also takes care of silencing and inhibition of alerts.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://prometheus.io/docs/alerting/alertmanager/"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Install&lt;/h2&gt; 
&lt;p&gt;There are various ways of installing Alertmanager.&lt;/p&gt; 
&lt;h3&gt;Precompiled binaries&lt;/h3&gt; 
&lt;p&gt;Precompiled binaries for released versions are available in the &lt;a href="https://prometheus.io/download/"&gt;&lt;em&gt;download&lt;/em&gt; section&lt;/a&gt; on &lt;a href="https://prometheus.io"&gt;prometheus.io&lt;/a&gt;. Using the latest production release binary is the recommended way of installing Alertmanager.&lt;/p&gt; 
&lt;h3&gt;Docker images&lt;/h3&gt; 
&lt;p&gt;Docker images are available on &lt;a href="https://quay.io/repository/prometheus/alertmanager"&gt;Quay.io&lt;/a&gt; or &lt;a href="https://hub.docker.com/r/prom/alertmanager/"&gt;Docker Hub&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can launch an Alertmanager container for trying it out with&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ docker run --name alertmanager -d -p 127.0.0.1:9093:9093 quay.io/prometheus/alertmanager
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alertmanager will now be reachable at &lt;a href="http://localhost:9093/"&gt;http://localhost:9093/&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Compiling the binary&lt;/h3&gt; 
&lt;p&gt;You can either &lt;code&gt;go install&lt;/code&gt; it:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ go install github.com/prometheus/alertmanager/cmd/...@latest
# cd $GOPATH/src/github.com/prometheus/alertmanager
$ alertmanager --config.file=&amp;lt;your_file&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or clone the repository and build manually:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ mkdir -p $GOPATH/src/github.com/prometheus
$ cd $GOPATH/src/github.com/prometheus
$ git clone https://github.com/prometheus/alertmanager.git
$ cd alertmanager
$ make build
$ ./alertmanager --config.file=&amp;lt;your_file&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also build just one of the binaries in this repo by passing a name to the build function:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ make build BINARIES=amtool
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Example&lt;/h2&gt; 
&lt;p&gt;This is an example configuration that should cover most relevant aspects of the new YAML configuration format. The full documentation of the configuration can be found &lt;a href="https://prometheus.io/docs/alerting/configuration/"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;global:
  # The smarthost and SMTP sender used for mail notifications.
  smtp_smarthost: 'localhost:25'
  smtp_from: 'alertmanager@example.org'

# The root route on which each incoming alert enters.
route:
  # The root route must not have any matchers as it is the entry point for
  # all alerts. It needs to have a receiver configured so alerts that do not
  # match any of the sub-routes are sent to someone.
  receiver: 'team-X-mails'

  # The labels by which incoming alerts are grouped together. For example,
  # multiple alerts coming in for cluster=A and alertname=LatencyHigh would
  # be batched into a single group.
  #
  # To aggregate by all possible labels use '...' as the sole label name.
  # This effectively disables aggregation entirely, passing through all
  # alerts as-is. This is unlikely to be what you want, unless you have
  # a very low alert volume or your upstream notification system performs
  # its own grouping. Example: group_by: [...]
  group_by: ['alertname', 'cluster']

  # When a new group of alerts is created by an incoming alert, wait at
  # least 'group_wait' to send the initial notification.
  # This way ensures that you get multiple alerts for the same group that start
  # firing shortly after another are batched together on the first
  # notification.
  group_wait: 30s

  # When the first notification was sent, wait 'group_interval' to send a batch
  # of new alerts that started firing for that group.
  group_interval: 5m

  # If an alert has successfully been sent, wait 'repeat_interval' to
  # resend them.
  repeat_interval: 3h

  # All the above attributes are inherited by all child routes and can
  # overwritten on each.

  # The child route trees.
  routes:
  # This route performs a regular expression match on alert labels to
  # catch alerts that are related to a list of services.
  - matchers:
    - service=~"^(foo1|foo2|baz)$"
    receiver: team-X-mails

    # The service has a sub-route for critical alerts, any alerts
    # that do not match, i.e. severity != critical, fall-back to the
    # parent node and are sent to 'team-X-mails'
    routes:
    - matchers:
      - severity="critical"
      receiver: team-X-pager

  - matchers:
    - service="files"
    receiver: team-Y-mails

    routes:
    - matchers:
      - severity="critical"
      receiver: team-Y-pager

  # This route handles all alerts coming from a database service. If there's
  # no team to handle it, it defaults to the DB team.
  - matchers:
    - service="database"

    receiver: team-DB-pager
    # Also group alerts by affected database.
    group_by: [alertname, cluster, database]

    routes:
    - matchers:
      - owner="team-X"
      receiver: team-X-pager

    - matchers:
      - owner="team-Y"
      receiver: team-Y-pager


# Inhibition rules allow to mute a set of alerts given that another alert is
# firing.
# We use this to mute any warning-level notifications if the same alert is
# already critical.
inhibit_rules:
- source_matchers:
    - severity="critical"
  target_matchers:
    - severity="warning"
  # Apply inhibition if the alertname is the same.
  # CAUTION: 
  #   If all label names listed in `equal` are missing 
  #   from both the source and target alerts,
  #   the inhibition rule will apply!
  equal: ['alertname']


receivers:
- name: 'team-X-mails'
  email_configs:
  - to: 'team-X+alerts@example.org, team-Y+alerts@example.org'

- name: 'team-X-pager'
  email_configs:
  - to: 'team-X+alerts-critical@example.org'
  pagerduty_configs:
  - routing_key: &amp;lt;team-X-key&amp;gt;

- name: 'team-Y-mails'
  email_configs:
  - to: 'team-Y+alerts@example.org'

- name: 'team-Y-pager'
  pagerduty_configs:
  - routing_key: &amp;lt;team-Y-key&amp;gt;

- name: 'team-DB-pager'
  pagerduty_configs:
  - routing_key: &amp;lt;team-DB-key&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;API&lt;/h2&gt; 
&lt;p&gt;The current Alertmanager API is version 2. This API is fully generated via the &lt;a href="https://github.com/OAI/OpenAPI-Specification/raw/master/versions/2.0.md"&gt;OpenAPI project&lt;/a&gt; and &lt;a href="https://github.com/go-swagger/go-swagger/"&gt;Go Swagger&lt;/a&gt; with the exception of the HTTP handlers themselves. The API specification can be found in &lt;a href="https://raw.githubusercontent.com/prometheus/alertmanager/main/api/v2/openapi.yaml"&gt;api/v2/openapi.yaml&lt;/a&gt;. A HTML rendered version can be accessed &lt;a href="http://petstore.swagger.io/?url=https://raw.githubusercontent.com/prometheus/alertmanager/main/api/v2/openapi.yaml"&gt;here&lt;/a&gt;. Clients can be easily generated via any OpenAPI generator for all major languages.&lt;/p&gt; 
&lt;p&gt;APIv2 is accessed via the &lt;code&gt;/api/v2&lt;/code&gt; prefix. APIv1 was deprecated in &lt;code&gt;0.16.0&lt;/code&gt; and is removed as of version &lt;code&gt;0.27.0&lt;/code&gt;. The v2 &lt;code&gt;/status&lt;/code&gt; endpoint would be &lt;code&gt;/api/v2/status&lt;/code&gt;. If &lt;code&gt;--web.route-prefix&lt;/code&gt; is set then API routes are prefixed with that as well, so &lt;code&gt;--web.route-prefix=/alertmanager/&lt;/code&gt; would relate to &lt;code&gt;/alertmanager/api/v2/status&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;amtool&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;amtool&lt;/code&gt; is a cli tool for interacting with the Alertmanager API. It is bundled with all releases of Alertmanager.&lt;/p&gt; 
&lt;h3&gt;Install&lt;/h3&gt; 
&lt;p&gt;Alternatively you can install with:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ go install github.com/prometheus/alertmanager/cmd/amtool@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Examples&lt;/h3&gt; 
&lt;p&gt;View all currently firing alerts:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ amtool alert
Alertname        Starts At                Summary
Test_Alert       2017-08-02 18:30:18 UTC  This is a testing alert!
Test_Alert       2017-08-02 18:30:18 UTC  This is a testing alert!
Check_Foo_Fails  2017-08-02 18:30:18 UTC  This is a testing alert!
Check_Foo_Fails  2017-08-02 18:30:18 UTC  This is a testing alert!
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;View all currently firing alerts with extended output:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ amtool -o extended alert
Labels                                        Annotations                                                    Starts At                Ends At                  Generator URL
alertname="Test_Alert" instance="node0"       link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
alertname="Test_Alert" instance="node1"       link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
alertname="Check_Foo_Fails" instance="node0"  link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
alertname="Check_Foo_Fails" instance="node1"  link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In addition to viewing alerts, you can use the rich query syntax provided by Alertmanager:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ amtool -o extended alert query alertname="Test_Alert"
Labels                                   Annotations                                                    Starts At                Ends At                  Generator URL
alertname="Test_Alert" instance="node0"  link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
alertname="Test_Alert" instance="node1"  link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local

$ amtool -o extended alert query instance=~".+1"
Labels                                        Annotations                                                    Starts At                Ends At                  Generator URL
alertname="Test_Alert" instance="node1"       link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
alertname="Check_Foo_Fails" instance="node1"  link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local

$ amtool -o extended alert query alertname=~"Test.*" instance=~".+1"
Labels                                   Annotations                                                    Starts At                Ends At                  Generator URL
alertname="Test_Alert" instance="node1"  link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Silence an alert:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ amtool silence add alertname=Test_Alert
b3ede22e-ca14-4aa0-932c-ca2f3445f926

$ amtool silence add alertname="Test_Alert" instance=~".+0"
e48cb58a-0b17-49ba-b734-3585139b1d25
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;View silences:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ amtool silence query
ID                                    Matchers              Ends At                  Created By  Comment
b3ede22e-ca14-4aa0-932c-ca2f3445f926  alertname=Test_Alert  2017-08-02 19:54:50 UTC  kellel

$ amtool silence query instance=~".+0"
ID                                    Matchers                            Ends At                  Created By  Comment
e48cb58a-0b17-49ba-b734-3585139b1d25  alertname=Test_Alert instance=~.+0  2017-08-02 22:41:39 UTC  kellel
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Expire a silence:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ amtool silence expire b3ede22e-ca14-4aa0-932c-ca2f3445f926
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Expire all silences matching a query:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ amtool silence query instance=~".+0"
ID                                    Matchers                            Ends At                  Created By  Comment
e48cb58a-0b17-49ba-b734-3585139b1d25  alertname=Test_Alert instance=~.+0  2017-08-02 22:41:39 UTC  kellel

$ amtool silence expire $(amtool silence query -q instance=~".+0")

$ amtool silence query instance=~".+0"

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Expire all silences:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ amtool silence expire $(amtool silence query -q)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Try out how a template works. Let's say you have this in your configuration file:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;templates:
  - '/foo/bar/*.tmpl'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then you can test out how a template would look like with example by using this command:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;amtool template render --template.glob='/foo/bar/*.tmpl' --template.text='{{ template "slack.default.markdown.v1" . }}'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Configuration&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;amtool&lt;/code&gt; allows a configuration file to specify some options for convenience. The default configuration file paths are &lt;code&gt;$HOME/.config/amtool/config.yml&lt;/code&gt; or &lt;code&gt;/etc/amtool/config.yml&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;An example configuration file might look like the following:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# Define the path that `amtool` can find your `alertmanager` instance
alertmanager.url: "http://localhost:9093"

# Override the default author. (unset defaults to your username)
author: me@example.com

# Force amtool to give you an error if you don't include a comment on a silence
comment_required: true

# Set a default output format. (unset defaults to simple)
output: extended

# Set a default receiver
receiver: team-X-pager
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Routes&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;amtool&lt;/code&gt; allows you to visualize the routes of your configuration in form of text tree view. Also you can use it to test the routing by passing it label set of an alert and it prints out all receivers the alert would match ordered and separated by &lt;code&gt;,&lt;/code&gt;. (If you use &lt;code&gt;--verify.receivers&lt;/code&gt; amtool returns error code 1 on mismatch)&lt;/p&gt; 
&lt;p&gt;Example of usage:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# View routing tree of remote Alertmanager
$ amtool config routes --alertmanager.url=http://localhost:9090

# Test if alert matches expected receiver
$ amtool config routes test --config.file=doc/examples/simple.yml --tree --verify.receivers=team-X-pager service=database owner=team-X
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;High Availability&lt;/h2&gt; 
&lt;p&gt;Alertmanager's high availability is in production use at many companies and is enabled by default.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Important: Both UDP and TCP are needed in alertmanager 0.15 and higher for the cluster to work.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;If you are using a firewall, make sure to whitelist the clustering port for both protocols.&lt;/li&gt; 
  &lt;li&gt;If you are running in a container, make sure to expose the clustering port for both protocols.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;To create a highly available cluster of the Alertmanager the instances need to be configured to communicate with each other. This is configured using the &lt;code&gt;--cluster.*&lt;/code&gt; flags.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.listen-address&lt;/code&gt; string: cluster listen address (default "0.0.0.0:9094"; empty string disables HA mode)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.advertise-address&lt;/code&gt; string: cluster advertise address&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.peer&lt;/code&gt; value: initial peers (repeat flag for each additional peer)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.peer-timeout&lt;/code&gt; value: peer timeout period (default "15s")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.peers-resolve-timeout&lt;/code&gt; value: peers resolve timeout period (default "15s")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.gossip-interval&lt;/code&gt; value: cluster message propagation speed (default "200ms")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.pushpull-interval&lt;/code&gt; value: lower values will increase convergence speeds at expense of bandwidth (default "1m0s")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.settle-timeout&lt;/code&gt; value: maximum time to wait for cluster connections to settle before evaluating notifications.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.tcp-timeout&lt;/code&gt; value: timeout value for tcp connections, reads and writes (default "10s")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.probe-timeout&lt;/code&gt; value: time to wait for ack before marking node unhealthy (default "500ms")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.probe-interval&lt;/code&gt; value: interval between random node probes (default "1s")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.reconnect-interval&lt;/code&gt; value: interval between attempting to reconnect to lost peers (default "10s")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.reconnect-timeout&lt;/code&gt; value: length of time to attempt to reconnect to a lost peer (default: "6h0m0s")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.label&lt;/code&gt; value: the label is an optional string to include on each packet and stream. It uniquely identifies the cluster and prevents cross-communication issues when sending gossip messages (default:"")&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The chosen port in the &lt;code&gt;cluster.listen-address&lt;/code&gt; flag is the port that needs to be specified in the &lt;code&gt;cluster.peer&lt;/code&gt; flag of the other peers.&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;cluster.advertise-address&lt;/code&gt; flag is required if the instance doesn't have an IP address that is part of &lt;a href="https://tools.ietf.org/html/rfc6890"&gt;RFC 6890&lt;/a&gt; with a default route.&lt;/p&gt; 
&lt;p&gt;To start a cluster of three peers on your local machine use &lt;a href="https://github.com/mattn/goreman"&gt;&lt;code&gt;goreman&lt;/code&gt;&lt;/a&gt; and the Procfile within this repository.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;goreman start
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To point your Prometheus 1.4, or later, instance to multiple Alertmanagers, configure them in your &lt;code&gt;prometheus.yml&lt;/code&gt; configuration file, for example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;alerting:
  alertmanagers:
  - static_configs:
    - targets:
      - alertmanager1:9093
      - alertmanager2:9093
      - alertmanager3:9093
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Important: Do not load balance traffic between Prometheus and its Alertmanagers, but instead point Prometheus to a list of all Alertmanagers. The Alertmanager implementation expects all alerts to be sent to all Alertmanagers to ensure high availability.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Turn off high availability&lt;/h3&gt; 
&lt;p&gt;If running Alertmanager in high availability mode is not desired, setting &lt;code&gt;--cluster.listen-address=&lt;/code&gt; prevents Alertmanager from listening to incoming peer requests.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Check the &lt;a href="https://github.com/prometheus/prometheus/raw/main/CONTRIBUTING.md"&gt;Prometheus contributing page&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To contribute to the user interface, refer to &lt;a href="https://raw.githubusercontent.com/prometheus/alertmanager/main/ui/app/CONTRIBUTING.md"&gt;ui/app/CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Architecture&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/prometheus/alertmanager/main/doc/arch.svg?sanitize=true" alt="" /&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Apache License 2.0, see &lt;a href="https://github.com/prometheus/alertmanager/raw/main/LICENSE"&gt;LICENSE&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>opencloud-eu/opencloud</title>
      <link>https://github.com/opencloud-eu/opencloud</link>
      <description>&lt;p&gt;üå§Ô∏èThis is the main repository of the OpenCloud server. It contains the golang codebase for the backend services.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/opencloud-eu/opencloud/refs/heads/main/opencloud_logo.png" alt="OpenCloud logo" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://ci.opencloud.eu/repos/3"&gt;&lt;img src="https://ci.opencloud.eu/api/badges/3/status.svg?sanitize=true" alt="status-badge" /&gt;&lt;/a&gt; &lt;a href="https://app.element.io/#/room/#opencloud:matrix.org"&gt;&lt;img src="https://img.shields.io/matrix/opencloud%3Amatrix.org?logo=matrix" alt="Matrix" /&gt;&lt;/a&gt; &lt;a href="https://opensource.org/licenses/Apache-2.0"&gt;&lt;img src="https://img.shields.io/badge/License-Apache%202.0-blue.svg?sanitize=true" alt="License" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Server Backend&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] For general information about OpenCloud and how to install please visit &lt;a href="https://github.com/opencloud-eu/"&gt;OpenCloud on Github&lt;/a&gt; and &lt;a href="https://opencloud.eu"&gt;OpenCloud GmbH&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;This is the main repository of the OpenCloud server. It contains the golang codebase for the backend services.&lt;/p&gt; 
&lt;h2&gt;Getting Involved&lt;/h2&gt; 
&lt;p&gt;The OpenCloud server is released under &lt;a href="https://github.com/opencloud-eu/opencloud/raw/main/LICENSE"&gt;Apache 2.0&lt;/a&gt;. The project is thrilled to receive contributions in all forms. Start hacking now, there are many ways to get involved such as:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Reporting &lt;a href="https://github.com/opencloud-eu/opencloud/issues"&gt;issues or bugs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Requesting &lt;a href="https://github.com/opencloud-eu/opencloud/issues"&gt;features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/opencloud-eu/docs"&gt;Writing documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/opencloud-eu/opencloud/pulls"&gt;Writing code or extend our tests&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/opencloud-eu/opencloud/pulls"&gt;Reviewing code&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Helping others in the &lt;a href="https://app.element.io/#/room/#opencloud:matrix.org"&gt;community&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Every contribution is meaningful and appreciated! Please refer to our &lt;a href="https://github.com/opencloud-eu/opencloud/raw/main/CONTRIBUTING.md"&gt;Contribution Guidelines&lt;/a&gt; if you want to get started.&lt;/p&gt; 
&lt;h2&gt;Build OpenCloud&lt;/h2&gt; 
&lt;p&gt;To build the backend, follow these instructions:&lt;/p&gt; 
&lt;p&gt;Generate the assets needed by e.g., the web UI and the builtin IDP&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;make generate
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then compile the &lt;code&gt;opencloud&lt;/code&gt; binary&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;make -C opencloud build
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;That will produce the binary &lt;code&gt;opencloud/bin/opencloud&lt;/code&gt;. It can be started as a local test instance right away with a two step command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;opencloud/bin/opencloud init &amp;amp;&amp;amp; opencloud/bin/opencloud server
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This creates a server configuration (by default in &lt;code&gt;$HOME/.opencloud&lt;/code&gt;) and starts the server.&lt;/p&gt; 
&lt;p&gt;For more setup- and installation options consult the &lt;a href="https://docs.opencloud.eu/"&gt;Development Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Technology&lt;/h2&gt; 
&lt;p&gt;Important information for contributors about the technology in use.&lt;/p&gt; 
&lt;h3&gt;Authentication&lt;/h3&gt; 
&lt;p&gt;The OpenCloud backend authenticates users via &lt;a href="https://openid.net/connect/"&gt;OpenID Connect&lt;/a&gt; using either an external IdP like &lt;a href="https://www.keycloak.org/"&gt;Keycloak&lt;/a&gt; or the embedded &lt;a href="https://github.com/libregraph/lico"&gt;LibreGraph Connect&lt;/a&gt; identity provider.&lt;/p&gt; 
&lt;h3&gt;Database&lt;/h3&gt; 
&lt;p&gt;The OpenCloud backend does not use a database. It stores all data in the filesystem. By default, the root directory of the backend is &lt;code&gt;$HOME/.opencloud/&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;p&gt;If you find a security-related issue, please contact &lt;a href="mailto:security@opencloud.eu"&gt;security@opencloud.eu&lt;/a&gt; immediately.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>666ghj/BettaFish</title>
      <link>https://github.com/666ghj/BettaFish</link>
      <description>&lt;p&gt;ÂæÆËàÜÔºö‰∫∫‰∫∫ÂèØÁî®ÁöÑÂ§öAgentËàÜÊÉÖÂàÜÊûêÂä©ÊâãÔºåÊâìÁ†¥‰ø°ÊÅØËåßÊàøÔºåËøòÂéüËàÜÊÉÖÂéüË≤åÔºåÈ¢ÑÊµãÊú™Êù•Ëµ∞ÂêëÔºåËæÖÂä©ÂÜ≥Á≠ñÔºÅ‰ªé0ÂÆûÁé∞Ôºå‰∏ç‰æùËµñ‰ªª‰ΩïÊ°ÜÊû∂„ÄÇ&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/logo_compressed.png" alt="BettaFish Logo" width="100%" /&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/15286" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/15286" alt="666ghj%2FBettaFish | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://aihubmix.com/?aff=8Ds9" target="_blank"&gt;&lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/logo_aihubmix.png" alt="666ghj%2FBettaFish | Trendshift" height="40" /&gt;&lt;/a&gt;‚ÄÇ &lt;a href="https://lioncc.ai/" target="_blank"&gt;&lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/logo_loincc.png" alt="666ghj%2FBettaFish | Trendshift" height="40" /&gt;&lt;/a&gt;‚ÄÇ &lt;a href="https://share.302.ai/P66Qe3" target="_blank"&gt;&lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/logo_302ai.png" alt="666ghj%2FBettaFish | Trendshift" height="40" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/666ghj/BettaFish/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/666ghj/BettaFish?style=flat-square" alt="GitHub Stars" /&gt;&lt;/a&gt; &lt;a href="https://github.com/666ghj/BettaFish/watchers"&gt;&lt;img src="https://img.shields.io/github/watchers/666ghj/BettaFish?style=flat-square" alt="GitHub Watchers" /&gt;&lt;/a&gt; &lt;a href="https://github.com/666ghj/BettaFish/network"&gt;&lt;img src="https://img.shields.io/github/forks/666ghj/BettaFish?style=flat-square" alt="GitHub Forks" /&gt;&lt;/a&gt; &lt;a href="https://github.com/666ghj/BettaFish/issues"&gt;&lt;img src="https://img.shields.io/github/issues/666ghj/BettaFish?style=flat-square" alt="GitHub Issues" /&gt;&lt;/a&gt; &lt;a href="https://github.com/666ghj/BettaFish/pulls"&gt;&lt;img src="https://img.shields.io/github/issues-pr/666ghj/BettaFish?style=flat-square" alt="GitHub Pull Requests" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/666ghj/BettaFish/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/666ghj/BettaFish?style=flat-square" alt="GitHub License" /&gt;&lt;/a&gt; &lt;a href="https://github.com/666ghj/BettaFish"&gt;&lt;img src="https://img.shields.io/badge/version-v1.2.1-green.svg?style=flat-square" alt="Version" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/"&gt;&lt;img src="https://img.shields.io/badge/Docker-Build-2496ED?style=flat-square&amp;amp;logo=docker&amp;amp;logoColor=white" alt="Docker" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/666ghj/BettaFish/main/README-EN.md"&gt;English&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/666ghj/BettaFish/main/README.md"&gt;‰∏≠ÊñáÊñáÊ°£&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;üåü Âä†ÂÖ•ÂÆòÊñπ‰∫§ÊµÅÁæ§&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://capsule-render.vercel.app/api?type=waving&amp;amp;color=gradient&amp;amp;height=200&amp;amp;section=header&amp;amp;text=Ê¨¢ËøéÂä†ÂÖ•Êàë‰ª¨ÁöÑÊäÄÊúØ‰∫§ÊµÅQQÁæ§ÔºÅ&amp;amp;fontSize=40&amp;amp;fontAlignY=35&amp;amp;desc=Êâ´Êèè‰∏ãÊñπ‰∫åÁª¥Á†ÅÂä†ÂÖ•Áæ§ËÅä&amp;amp;descAlignY=55" alt="Ê¨¢ËøéÂä†ÂÖ•Êàë‰ª¨ÁöÑÊäÄÊúØ‰∫§ÊµÅQQÁæ§ÔºÅ" style="width:60%; max-width:900px; display:block; margin:0 auto;" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/QQ_Light_Horizenal.png" alt="BettaFish ÊäÄÊúØ‰∫§ÊµÅÁæ§‰∫åÁª¥Á†Å" style="width:60%; max-width:360px; display:block; margin:20px auto 0;" /&gt; 
&lt;/div&gt; 
&lt;h2&gt;‚ö° È°πÁõÆÊ¶ÇËø∞&lt;/h2&gt; 
&lt;p&gt;‚Äú&lt;strong&gt;ÂæÆËàÜ&lt;/strong&gt;‚Äù ÊòØ‰∏Ä‰∏™‰ªé0ÂÆûÁé∞ÁöÑÂàõÊñ∞Âûã Â§öÊô∫ËÉΩ‰Ωì ËàÜÊÉÖÂàÜÊûêÁ≥ªÁªüÔºåÂ∏ÆÂä©Â§ßÂÆ∂Á†¥Èô§‰ø°ÊÅØËåßÊàøÔºåËøòÂéüËàÜÊÉÖÂéüË≤åÔºåÈ¢ÑÊµãÊú™Êù•Ëµ∞ÂêëÔºåËæÖÂä©ÂÜ≥Á≠ñ„ÄÇÁî®Êà∑Âè™ÈúÄÂÉèËÅäÂ§©‰∏ÄÊ†∑ÊèêÂá∫ÂàÜÊûêÈúÄÊ±ÇÔºåÊô∫ËÉΩ‰ΩìÂºÄÂßãÂÖ®Ëá™Âä®ÂàÜÊûê ÂõΩÂÜÖÂ§ñ30+‰∏ªÊµÅÁ§æÂ™í ‰∏é Êï∞Áôæ‰∏áÊù°Â§ß‰ºóËØÑËÆ∫„ÄÇ&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;‚ÄúÂæÆËàÜ‚ÄùË∞êÈü≥‚ÄúÂæÆÈ±º‚ÄùÔºåBettaFishÊòØ‰∏ÄÁßç‰ΩìÂûãÂæàÂ∞è‰ΩÜÈùûÂ∏∏Â•ΩÊñó„ÄÅÊºÇ‰∫ÆÁöÑÈ±ºÔºåÂÆÉË±°ÂæÅÁùÄ‚ÄúÂ∞èËÄåÂº∫Â§ßÔºå‰∏çÁïèÊåëÊàò‚Äù&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Êü•ÁúãÁ≥ªÁªü‰ª•‚ÄúÊ≠¶Ê±âÂ§ßÂ≠¶ËàÜÊÉÖ‚Äù‰∏∫‰æãÔºåÁîüÊàêÁöÑÁ†îÁ©∂Êä•ÂëäÔºö&lt;a href="https://raw.githubusercontent.com/666ghj/BettaFish/main/final_reports/final_report__20250827_131630.html"&gt;Ê≠¶Ê±âÂ§ßÂ≠¶ÂìÅÁâåÂ£∞Ë™âÊ∑±Â∫¶ÂàÜÊûêÊä•Âëä&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Êü•ÁúãÁ≥ªÁªü‰ª•‚ÄúÊ≠¶Ê±âÂ§ßÂ≠¶ËàÜÊÉÖ‚Äù‰∏∫‰æãÔºå‰∏ÄÊ¨°ÂÆåÊï¥ËøêË°åÁöÑËßÜÈ¢ëÔºö&lt;a href="https://www.bilibili.com/video/BV1TH1WBxEWN/?vd_source=da3512187e242ce17dceee4c537ec7a6#reply279744466833"&gt;ËßÜÈ¢ë-Ê≠¶Ê±âÂ§ßÂ≠¶ÂìÅÁâåÂ£∞Ë™âÊ∑±Â∫¶ÂàÜÊûêÊä•Âëä&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;‰∏ç‰ªÖ‰ªÖ‰ΩìÁé∞Âú®Êä•ÂëäË¥®Èáè‰∏äÔºåÁõ∏ÊØîÂêåÁ±ª‰∫ßÂìÅÔºåÊàë‰ª¨Êã•ÊúâüöÄÂÖ≠Â§ß‰ºòÂäøÔºö&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;AIÈ©±Âä®ÁöÑÂÖ®ÂüüÁõëÊéß&lt;/strong&gt;ÔºöAIÁà¨Ëô´ÈõÜÁæ§7x24Â∞èÊó∂‰∏çÈó¥Êñ≠‰Ωú‰∏öÔºåÂÖ®Èù¢Ë¶ÜÁõñÂæÆÂçö„ÄÅÂ∞èÁ∫¢‰π¶„ÄÅÊäñÈü≥„ÄÅÂø´ÊâãÁ≠â10+ÂõΩÂÜÖÂ§ñÂÖ≥ÈîÆÁ§æÂ™í„ÄÇ‰∏ç‰ªÖÂÆûÊó∂ÊçïËé∑ÁÉ≠ÁÇπÂÜÖÂÆπÔºåÊõ¥ËÉΩ‰∏ãÈíªËá≥Êµ∑ÈáèÁî®Êà∑ËØÑËÆ∫ÔºåËÆ©ÊÇ®Âê¨Âà∞ÊúÄÁúüÂÆû„ÄÅÊúÄÂπøÊ≥õÁöÑÂ§ß‰ºóÂ£∞Èü≥„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Ë∂ÖË∂äLLMÁöÑÂ§çÂêàÂàÜÊûêÂºïÊìé&lt;/strong&gt;ÔºöÊàë‰ª¨‰∏ç‰ªÖ‰æùËµñËÆæËÆ°ÁöÑ5Á±ª‰∏ì‰∏öAgentÔºåÊõ¥ËûçÂêà‰∫ÜÂæÆË∞ÉÊ®°Âûã„ÄÅÁªüËÆ°Ê®°ÂûãÁ≠â‰∏≠Èó¥‰ª∂„ÄÇÈÄöËøáÂ§öÊ®°ÂûãÂçèÂêåÂ∑•‰ΩúÔºåÁ°Æ‰øù‰∫ÜÂàÜÊûêÁªìÊûúÁöÑÊ∑±Â∫¶„ÄÅÂáÜÂ∫¶‰∏éÂ§öÁª¥ËßÜËßí„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Âº∫Â§ßÁöÑÂ§öÊ®°ÊÄÅËÉΩÂäõ&lt;/strong&gt;ÔºöÁ™ÅÁ†¥ÂõæÊñáÈôêÂà∂ÔºåËÉΩÊ∑±Â∫¶Ëß£ÊûêÊäñÈü≥„ÄÅÂø´ÊâãÁ≠âÁü≠ËßÜÈ¢ëÂÜÖÂÆπÔºåÂπ∂Á≤æÂáÜÊèêÂèñÁé∞‰ª£ÊêúÁ¥¢ÂºïÊìé‰∏≠ÁöÑÂ§©Ê∞î„ÄÅÊó•ÂéÜ„ÄÅËÇ°Á•®Á≠âÁªìÊûÑÂåñÂ§öÊ®°ÊÄÅ‰ø°ÊÅØÂç°ÁâáÔºåËÆ©ÊÇ®ÂÖ®Èù¢ÊéåÊè°ËàÜÊÉÖÂä®ÊÄÅ„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Agent‚ÄúËÆ∫Âùõ‚ÄùÂçè‰ΩúÊú∫Âà∂&lt;/strong&gt;Ôºö‰∏∫‰∏çÂêåAgentËµã‰∫àÁã¨ÁâπÁöÑÂ∑•ÂÖ∑ÈõÜ‰∏éÊÄùÁª¥Ê®°ÂºèÔºåÂºïÂÖ•Ëæ©ËÆ∫‰∏ªÊåÅ‰∫∫Ê®°ÂûãÔºåÈÄöËøá‚ÄúËÆ∫Âùõ‚ÄùÊú∫Âà∂ËøõË°åÈìæÂºèÊÄùÁª¥Á¢∞Êíû‰∏éËæ©ËÆ∫„ÄÇËøô‰∏ç‰ªÖÈÅøÂÖç‰∫ÜÂçï‰∏ÄÊ®°ÂûãÁöÑÊÄùÁª¥Â±ÄÈôê‰∏é‰∫§ÊµÅÂØºËá¥ÁöÑÂêåË¥®ÂåñÔºåÊõ¥ÂÇ¨ÁîüÂá∫Êõ¥È´òË¥®ÈáèÁöÑÈõÜ‰ΩìÊô∫ËÉΩ‰∏éÂÜ≥Á≠ñÊîØÊåÅ„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ÂÖ¨ÁßÅÂüüÊï∞ÊçÆÊó†ÁºùËûçÂêà&lt;/strong&gt;ÔºöÂπ≥Âè∞‰∏ç‰ªÖÂàÜÊûêÂÖ¨ÂºÄËàÜÊÉÖÔºåËøòÊèê‰æõÈ´òÂÆâÂÖ®ÊÄßÁöÑÊé•Âè£ÔºåÊîØÊåÅÊÇ®Â∞ÜÂÜÖÈÉ®‰∏öÂä°Êï∞ÊçÆÂ∫ì‰∏éËàÜÊÉÖÊï∞ÊçÆÊó†ÁºùÈõÜÊàê„ÄÇÊâìÈÄöÊï∞ÊçÆÂ£ÅÂûíÔºå‰∏∫ÂûÇÁõ¥‰∏öÂä°Êèê‰æõ‚ÄúÂ§ñÈÉ®Ë∂ãÂäø+ÂÜÖÈÉ®Ê¥ûÂØü‚ÄùÁöÑÂº∫Â§ßÂàÜÊûêËÉΩÂäõ„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ËΩªÈáèÂåñ‰∏éÈ´òÊâ©Â±ïÊÄßÊ°ÜÊû∂&lt;/strong&gt;ÔºöÂü∫‰∫éÁ∫ØPythonÊ®°ÂùóÂåñËÆæËÆ°ÔºåÂÆûÁé∞ËΩªÈáèÂåñ„ÄÅ‰∏ÄÈîÆÂºèÈÉ®ÁΩ≤„ÄÇ‰ª£Á†ÅÁªìÊûÑÊ∏ÖÊô∞ÔºåÂºÄÂèëËÄÖÂèØËΩªÊùæÈõÜÊàêËá™ÂÆö‰πâÊ®°Âûã‰∏é‰∏öÂä°ÈÄªËæëÔºåÂÆûÁé∞Âπ≥Âè∞ÁöÑÂø´ÈÄüÊâ©Â±ï‰∏éÊ∑±Â∫¶ÂÆöÂà∂„ÄÇ&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Âßã‰∫éËàÜÊÉÖÔºåËÄå‰∏çÊ≠¢‰∫éËàÜÊÉÖ&lt;/strong&gt;„ÄÇ‚ÄúÂæÆËàÜ‚ÄùÁöÑÁõÆÊ†áÔºåÊòØÊàê‰∏∫È©±Âä®‰∏ÄÂàá‰∏öÂä°Âú∫ÊôØÁöÑÁÆÄÊ¥ÅÈÄöÁî®ÁöÑÊï∞ÊçÆÂàÜÊûêÂºïÊìé„ÄÇ&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;‰∏æ‰∏™‰æãÂ≠ê. ‰Ω†Âè™ÈúÄÁÆÄÂçï‰øÆÊîπAgentÂ∑•ÂÖ∑ÈõÜÁöÑapiÂèÇÊï∞‰∏épromptÔºåÂ∞±ÂèØ‰ª•Êää‰ªñÂèòÊàê‰∏Ä‰∏™ÈáëËûçÈ¢ÜÂüüÁöÑÂ∏ÇÂú∫ÂàÜÊûêÁ≥ªÁªü&lt;/p&gt; 
 &lt;p&gt;ÈôÑ‰∏Ä‰∏™ÊØîËæÉÊ¥ªË∑ÉÁöÑLÁ´ôÈ°πÁõÆËÆ®ËÆ∫Â∏ñÔºö&lt;a href="https://linux.do/t/topic/1009280"&gt;https://linux.do/t/topic/1009280&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;Êü•ÁúãLÁ´ô‰Ω¨ÂèãÂÅöÁöÑÊµãËØÑ &lt;a href="https://linux.do/t/topic/1148040"&gt;ÂºÄÊ∫êÈ°πÁõÆ(ÂæÆËàÜ)‰∏émanus|minimax|ChatGPTÂØπÊØî&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/system_schematic.png" alt="banner" width="800" /&gt; 
 &lt;p&gt;ÂëäÂà´‰º†ÁªüÁöÑÊï∞ÊçÆÁúãÊùøÔºåÂú®‚ÄúÂæÆËàÜ‚ÄùÔºå‰∏ÄÂàáÁî±‰∏Ä‰∏™ÁÆÄÂçïÁöÑÈóÆÈ¢òÂºÄÂßãÔºåÊÇ®Âè™ÈúÄÂÉèÂØπËØù‰∏ÄÊ†∑ÔºåÊèêÂá∫ÊÇ®ÁöÑÂàÜÊûêÈúÄÊ±Ç&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;ü™Ñ ËµûÂä©ÂïÜ&lt;/h2&gt; 
&lt;p&gt;LLMÊ®°ÂûãAPIËµûÂä©Ôºö&lt;a href="https://aihubmix.com/?aff=8Ds9" target="_blank"&gt;&lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/logo_aihubmix.png" alt="666ghj%2FBettaFish | Trendshift" height="40" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;(ÁÇπÂºÄ‚ñ∂ÊúâËµûÂä©LLMÁÆóÂäõÁ¶èÂà©)ÁºñÁ®ãÊãºËΩ¶codecodex.aiÔºõÁºñÁ®ãÁÆóÂäõVibeCodingAPI.aiÔºö&lt;span style="margin-left: 10px"&gt;&lt;a href="https://codecodex.ai/" target="_blank"&gt;&lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/logo_loincc.png" alt="666ghj%2FBettaFish | Trendshift" height="40" /&gt;&lt;/a&gt;&lt;/span&gt;&lt;/summary&gt; 
 &lt;ol&gt; 
  &lt;li&gt;ÊâÄÁΩóÈó®ÂçöÂÆ¢LionCC.aiÂ∑≤Êõ¥Êñ∞„ÄäBettaFish ÂæÆËàÜÁ≥ªÁªü - LionCC API ÈÉ®ÁΩ≤ÈÖçÁΩÆÂÆåÂÖ®ÊåáÂçó„ÄãÊ≠£Âú®‰∫åÂºÄ‰ºòÂåñ‰∏ÄÈîÆÈÉ®ÁΩ≤Âíå‰∫ëÊúçÂä°Âô®Ë∞ÉÁî®ÊñπÊ°à„ÄÇ&lt;/li&gt; 
  &lt;li&gt;VibeCodingapi.aiÁãÆÂ≠êÁÆóÂäõÂπ≥Âè∞Â∑≤ÁªèÈÄÇÈÖç„ÄäBettaFish ÂæÆËàÜÁ≥ªÁªü„ÄãÊâÄÊúâLLMÊ®°ÂûãÂê´claude codeÂíåopenai codexÂíågemini cliÁºñÁ®ãÂºÄÂèë‰∏âÂ∑®Â§¥ÁÆóÂäõ„ÄÇÈ¢ùÂ∫¶‰ª∑Ê†ºÔºåÂè™Ë¶Å‰∏ÄÊØî‰∏ÄÔºà100ÂÖÉÁ≠â‰∫é100ÁæéÂàÄÈ¢ùÂ∫¶Ôºâ&lt;/li&gt; 
  &lt;li&gt;Codecodex.aiÁãÆÂ≠êÁºñÁ®ãÊãºËΩ¶Á≥ªÁªüÔºåÂ∑≤ÂÆûÁé∞Êó†IPÈó®ÊßõÁªïËøáclaude codeÂíåopenai codexÂ∞ÅÈîÅÔºåÊåâÂÆòÊñπÈÉ®ÁΩ≤ÊïôÁ®ãÂêéÂàáÊç¢BASE_URLË∞ÉÁî®Âú∞ÂùÄÂíåToken keyË∞ÉÁî®ÂØÜÈí•Âç≥ÂèØ‰ΩøÁî®ÊúÄÂº∫ÁºñÁ®ãÊ®°Âûã„ÄÇ&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;ÊâÄÁΩóÈó®LionCCËµûÂä©BettaFish ÂæÆËàÜÁ¶èÂà©ÔºöÊâìÂºÄcodecodex.aiÁãÆÂ≠êÁºñÁ®ãÈ¢ëÈÅìÊâ´Á†ÅÂä†ÂÖ•ÂæÆ‰ø°Á§æÁæ§ÔºåÊ≥®ÂÜåVibeCodingapi.aiÁãÆÂ≠êÁÆóÂäõÔºåÁªü‰∏ÄÈÄÅ20ÂàÄAPIÈ¢ùÂ∫¶Ôºà‰ªÖÈôêÂâç‰∏ÄÂçÉÂêçÔºâ&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;ÊåâÁî®Èáè‰ªòË¥πÁöÑ‰ºÅ‰∏öÁ∫ßAIËµÑÊ∫êÂπ≥Âè∞ÔºåÊèê‰æõÂ∏ÇÂú∫‰∏äÂÖ®Èù¢ÁöÑAIÊ®°ÂûãÂíåAPIÔºå‰ª•ÂèäÂ§öÁßçÂú®Á∫øAIÂ∫îÁî®Ôºö&lt;span style="margin-left: 10px"&gt;&lt;a href="https://share.302.ai/P66Qe3" target="_blank"&gt;&lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/logo_302ai.png" alt="666ghj%2FBettaFish | Trendshift" height="40" /&gt;&lt;/a&gt;&lt;/span&gt;&lt;/summary&gt; 
 &lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/banner_302ai_ch.jpg" alt="banner" /&gt;302.AIÊòØ‰∏Ä‰∏™ÊåâÁî®Èáè‰ªòË¥πÁöÑ‰ºÅ‰∏öÁ∫ßAIËµÑÊ∫êÂπ≥Âè∞ÔºåÊèê‰æõÂ∏ÇÂú∫‰∏äÊúÄÊñ∞„ÄÅÊúÄÂÖ®Èù¢ÁöÑAIÊ®°ÂûãÂíåAPIÔºå‰ª•ÂèäÂ§öÁßçÂºÄÁÆ±Âç≥Áî®ÁöÑÂú®Á∫øAIÂ∫îÁî®„ÄÇ 
&lt;/details&gt; 
&lt;h2&gt;üèóÔ∏è Á≥ªÁªüÊû∂ÊûÑ&lt;/h2&gt; 
&lt;h3&gt;Êï¥‰ΩìÊû∂ÊûÑÂõæ&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Insight Agent&lt;/strong&gt; ÁßÅÊúâÊï∞ÊçÆÂ∫ìÊåñÊéòÔºöÁßÅÊúâËàÜÊÉÖÊï∞ÊçÆÂ∫ìÊ∑±Â∫¶ÂàÜÊûêAI‰ª£ÁêÜ&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Media Agent&lt;/strong&gt; Â§öÊ®°ÊÄÅÂÜÖÂÆπÂàÜÊûêÔºöÂÖ∑Â§áÂº∫Â§ßÂ§öÊ®°ÊÄÅËÉΩÂäõÁöÑAI‰ª£ÁêÜ&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Query Agent&lt;/strong&gt; Á≤æÂáÜ‰ø°ÊÅØÊêúÁ¥¢ÔºöÂÖ∑Â§áÂõΩÂÜÖÂ§ñÁΩëÈ°µÊêúÁ¥¢ËÉΩÂäõÁöÑAI‰ª£ÁêÜ&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Report Agent&lt;/strong&gt; Êô∫ËÉΩÊä•ÂëäÁîüÊàêÔºöÂÜÖÁΩÆÊ®°ÊùøÁöÑÂ§öËΩÆÊä•ÂëäÁîüÊàêAI‰ª£ÁêÜ&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/framework.png" alt="banner" width="800" /&gt; 
&lt;/div&gt; 
&lt;h3&gt;‰∏ÄÊ¨°ÂÆåÊï¥ÂàÜÊûêÊµÅÁ®ã&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Ê≠•È™§&lt;/th&gt; 
   &lt;th&gt;Èò∂ÊÆµÂêçÁß∞&lt;/th&gt; 
   &lt;th&gt;‰∏ªË¶ÅÊìç‰Ωú&lt;/th&gt; 
   &lt;th&gt;ÂèÇ‰∏éÁªÑ‰ª∂&lt;/th&gt; 
   &lt;th&gt;Âæ™ÁéØÁâπÊÄß&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;1&lt;/td&gt; 
   &lt;td&gt;Áî®Êà∑ÊèêÈóÆ&lt;/td&gt; 
   &lt;td&gt;Flask‰∏ªÂ∫îÁî®Êé•Êî∂Êü•ËØ¢&lt;/td&gt; 
   &lt;td&gt;Flask‰∏ªÂ∫îÁî®&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;2&lt;/td&gt; 
   &lt;td&gt;Âπ∂Ë°åÂêØÂä®&lt;/td&gt; 
   &lt;td&gt;‰∏â‰∏™AgentÂêåÊó∂ÂºÄÂßãÂ∑•‰Ωú&lt;/td&gt; 
   &lt;td&gt;Query Agent„ÄÅMedia Agent„ÄÅInsight Agent&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3&lt;/td&gt; 
   &lt;td&gt;ÂàùÊ≠•ÂàÜÊûê&lt;/td&gt; 
   &lt;td&gt;ÂêÑAgent‰ΩøÁî®‰∏ìÂ±ûÂ∑•ÂÖ∑ËøõË°åÊ¶ÇËßàÊêúÁ¥¢&lt;/td&gt; 
   &lt;td&gt;ÂêÑAgent + ‰∏ìÂ±ûÂ∑•ÂÖ∑ÈõÜ&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;4&lt;/td&gt; 
   &lt;td&gt;Á≠ñÁï•Âà∂ÂÆö&lt;/td&gt; 
   &lt;td&gt;Âü∫‰∫éÂàùÊ≠•ÁªìÊûúÂà∂ÂÆöÂàÜÂùóÁ†îÁ©∂Á≠ñÁï•&lt;/td&gt; 
   &lt;td&gt;ÂêÑAgentÂÜÖÈÉ®ÂÜ≥Á≠ñÊ®°Âùó&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5-N&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Âæ™ÁéØÈò∂ÊÆµ&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;ËÆ∫ÂùõÂçè‰Ωú + Ê∑±Â∫¶Á†îÁ©∂&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;ForumEngine + ÊâÄÊúâAgent&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Â§öËΩÆÂæ™ÁéØ&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.1&lt;/td&gt; 
   &lt;td&gt;Ê∑±Â∫¶Á†îÁ©∂&lt;/td&gt; 
   &lt;td&gt;ÂêÑAgentÂü∫‰∫éËÆ∫Âùõ‰∏ªÊåÅ‰∫∫ÂºïÂØºËøõË°å‰∏ìÈ°πÊêúÁ¥¢&lt;/td&gt; 
   &lt;td&gt;ÂêÑAgent + ÂèçÊÄùÊú∫Âà∂ + ËÆ∫ÂùõÂºïÂØº&lt;/td&gt; 
   &lt;td&gt;ÊØèËΩÆÂæ™ÁéØ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.2&lt;/td&gt; 
   &lt;td&gt;ËÆ∫ÂùõÂçè‰Ωú&lt;/td&gt; 
   &lt;td&gt;ForumEngineÁõëÊéßAgentÂèëË®ÄÂπ∂ÁîüÊàê‰∏ªÊåÅ‰∫∫ÊÄªÁªì&lt;/td&gt; 
   &lt;td&gt;ForumEngine + LLM‰∏ªÊåÅ‰∫∫&lt;/td&gt; 
   &lt;td&gt;ÊØèËΩÆÂæ™ÁéØ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.3&lt;/td&gt; 
   &lt;td&gt;‰∫§ÊµÅËûçÂêà&lt;/td&gt; 
   &lt;td&gt;ÂêÑAgentÊ†πÊçÆËÆ®ËÆ∫Ë∞ÉÊï¥Á†îÁ©∂ÊñπÂêë&lt;/td&gt; 
   &lt;td&gt;ÂêÑAgent + forum_readerÂ∑•ÂÖ∑&lt;/td&gt; 
   &lt;td&gt;ÊØèËΩÆÂæ™ÁéØ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;N+1&lt;/td&gt; 
   &lt;td&gt;ÁªìÊûúÊï¥Âêà&lt;/td&gt; 
   &lt;td&gt;Report AgentÊî∂ÈõÜÊâÄÊúâÂàÜÊûêÁªìÊûúÂíåËÆ∫ÂùõÂÜÖÂÆπ&lt;/td&gt; 
   &lt;td&gt;Report Agent&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;N+2&lt;/td&gt; 
   &lt;td&gt;Êä•ÂëäÁîüÊàê&lt;/td&gt; 
   &lt;td&gt;Âä®ÊÄÅÈÄâÊã©Ê®°ÊùøÂíåÊ†∑ÂºèÔºåÂ§öËΩÆÁîüÊàêÊúÄÁªàÊä•Âëä&lt;/td&gt; 
   &lt;td&gt;Report Agent + Ê®°ÊùøÂºïÊìé&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;È°πÁõÆ‰ª£Á†ÅÁªìÊûÑÊ†ë&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;BettaFish/
‚îú‚îÄ‚îÄ QueryEngine/                   # ÂõΩÂÜÖÂ§ñÊñ∞ÈóªÂπøÂ∫¶ÊêúÁ¥¢Agent
‚îÇ   ‚îú‚îÄ‚îÄ agent.py                   # Agent‰∏ªÈÄªËæë
‚îÇ   ‚îú‚îÄ‚îÄ llms/                      # LLMÊé•Âè£Â∞ÅË£Ö
‚îÇ   ‚îú‚îÄ‚îÄ nodes/                     # Â§ÑÁêÜËäÇÁÇπ
‚îÇ   ‚îú‚îÄ‚îÄ tools/                     # ÊêúÁ¥¢Â∑•ÂÖ∑
‚îÇ   ‚îú‚îÄ‚îÄ utils/                     # Â∑•ÂÖ∑ÂáΩÊï∞
‚îÇ   ‚îî‚îÄ‚îÄ ...                        # ÂÖ∂‰ªñÊ®°Âùó
‚îú‚îÄ‚îÄ MediaEngine/                   # Âº∫Â§ßÁöÑÂ§öÊ®°ÊÄÅÁêÜËß£Agent
‚îÇ   ‚îú‚îÄ‚îÄ agent.py                   # Agent‰∏ªÈÄªËæë
‚îÇ   ‚îú‚îÄ‚îÄ nodes/                     # Â§ÑÁêÜËäÇÁÇπ
‚îÇ   ‚îú‚îÄ‚îÄ llms/                      # LLMÊé•Âè£
‚îÇ   ‚îú‚îÄ‚îÄ tools/                     # ÊêúÁ¥¢Â∑•ÂÖ∑
‚îÇ   ‚îú‚îÄ‚îÄ utils/                     # Â∑•ÂÖ∑ÂáΩÊï∞
‚îÇ   ‚îî‚îÄ‚îÄ ...                        # ÂÖ∂‰ªñÊ®°Âùó
‚îú‚îÄ‚îÄ InsightEngine/                 # ÁßÅÊúâÊï∞ÊçÆÂ∫ìÊåñÊéòAgent
‚îÇ   ‚îú‚îÄ‚îÄ agent.py                   # Agent‰∏ªÈÄªËæë
‚îÇ   ‚îú‚îÄ‚îÄ llms/                      # LLMÊé•Âè£Â∞ÅË£Ö
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ base.py                # Áªü‰∏ÄÁöÑ OpenAI ÂÖºÂÆπÂÆ¢Êà∑Á´Ø
‚îÇ   ‚îú‚îÄ‚îÄ nodes/                     # Â§ÑÁêÜËäÇÁÇπ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base_node.py           # Âü∫Á°ÄËäÇÁÇπÁ±ª
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ formatting_node.py     # Ê†ºÂºèÂåñËäÇÁÇπ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ report_structure_node.py # Êä•ÂëäÁªìÊûÑËäÇÁÇπ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ search_node.py         # ÊêúÁ¥¢ËäÇÁÇπ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ summary_node.py        # ÊÄªÁªìËäÇÁÇπ
‚îÇ   ‚îú‚îÄ‚îÄ tools/                     # Êï∞ÊçÆÂ∫ìÊü•ËØ¢ÂíåÂàÜÊûêÂ∑•ÂÖ∑
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ keyword_optimizer.py   # QwenÂÖ≥ÈîÆËØç‰ºòÂåñ‰∏≠Èó¥‰ª∂
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ search.py              # Êï∞ÊçÆÂ∫ìÊìç‰ΩúÂ∑•ÂÖ∑ÈõÜ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ sentiment_analyzer.py  # ÊÉÖÊÑüÂàÜÊûêÈõÜÊàêÂ∑•ÂÖ∑
‚îÇ   ‚îú‚îÄ‚îÄ state/                     # Áä∂ÊÄÅÁÆ°ÁêÜ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ state.py               # AgentÁä∂ÊÄÅÂÆö‰πâ
‚îÇ   ‚îú‚îÄ‚îÄ prompts/                   # ÊèêÁ§∫ËØçÊ®°Êùø
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ prompts.py             # ÂêÑÁ±ªÊèêÁ§∫ËØç
‚îÇ   ‚îî‚îÄ‚îÄ utils/                     # Â∑•ÂÖ∑ÂáΩÊï∞
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ config.py              # ÈÖçÁΩÆÁÆ°ÁêÜ
‚îÇ       ‚îî‚îÄ‚îÄ text_processing.py     # ÊñáÊú¨Â§ÑÁêÜÂ∑•ÂÖ∑
‚îú‚îÄ‚îÄ ReportEngine/                  # Â§öËΩÆÊä•ÂëäÁîüÊàêAgent
‚îÇ   ‚îú‚îÄ‚îÄ agent.py                   # Agent‰∏ªÈÄªËæë
‚îÇ   ‚îú‚îÄ‚îÄ llms/                      # LLMÊé•Âè£
‚îÇ   ‚îú‚îÄ‚îÄ nodes/                     # Êä•ÂëäÁîüÊàêËäÇÁÇπ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ template_selection.py  # Ê®°ÊùøÈÄâÊã©ËäÇÁÇπ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ html_generation.py     # HTMLÁîüÊàêËäÇÁÇπ
‚îÇ   ‚îú‚îÄ‚îÄ report_template/           # Êä•ÂëäÊ®°ÊùøÂ∫ì
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Á§æ‰ºöÂÖ¨ÂÖ±ÁÉ≠ÁÇπ‰∫ã‰ª∂ÂàÜÊûê.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ÂïÜ‰∏öÂìÅÁâåËàÜÊÉÖÁõëÊµã.md
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...                    # Êõ¥Â§öÊ®°Êùø
‚îÇ   ‚îî‚îÄ‚îÄ flask_interface.py         # Flask APIÊé•Âè£
‚îú‚îÄ‚îÄ ForumEngine/                   # ËÆ∫ÂùõÂºïÊìéÁÆÄÊòìÂÆûÁé∞
‚îÇ   ‚îú‚îÄ‚îÄ monitor.py                 # Êó•ÂøóÁõëÊéßÂíåËÆ∫ÂùõÁÆ°ÁêÜ
‚îÇ   ‚îî‚îÄ‚îÄ llm_host.py                # ËÆ∫Âùõ‰∏ªÊåÅ‰∫∫LLMÊ®°Âùó
‚îú‚îÄ‚îÄ MindSpider/                    # ÂæÆÂçöÁà¨Ëô´Á≥ªÁªü
‚îÇ   ‚îú‚îÄ‚îÄ main.py                    # Áà¨Ëô´‰∏ªÁ®ãÂ∫è
‚îÇ   ‚îú‚îÄ‚îÄ config.py                  # Áà¨Ëô´ÈÖçÁΩÆÊñá‰ª∂
‚îÇ   ‚îú‚îÄ‚îÄ BroadTopicExtraction/      # ËØùÈ¢òÊèêÂèñÊ®°Âùó
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ database_manager.py    # Êï∞ÊçÆÂ∫ìÁÆ°ÁêÜÂô®
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ get_today_news.py      # ‰ªäÊó•Êñ∞ÈóªËé∑Âèñ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py                # ËØùÈ¢òÊèêÂèñ‰∏ªÁ®ãÂ∫è
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ topic_extractor.py     # ËØùÈ¢òÊèêÂèñÂô®
‚îÇ   ‚îú‚îÄ‚îÄ DeepSentimentCrawling/     # Ê∑±Â∫¶ËàÜÊÉÖÁà¨Âèñ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ keyword_manager.py     # ÂÖ≥ÈîÆËØçÁÆ°ÁêÜÂô®
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py                # Ê∑±Â∫¶Áà¨Âèñ‰∏ªÁ®ãÂ∫è
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ MediaCrawler/          # Â™í‰ΩìÁà¨Ëô´Ê†∏ÂøÉ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ platform_crawler.py    # Âπ≥Âè∞Áà¨Ëô´ÁÆ°ÁêÜ
‚îÇ   ‚îî‚îÄ‚îÄ schema/                    # Êï∞ÊçÆÂ∫ìÁªìÊûÑ
‚îÇ       ‚îú‚îÄ‚îÄ db_manager.py          # Êï∞ÊçÆÂ∫ìÁÆ°ÁêÜÂô®
‚îÇ       ‚îú‚îÄ‚îÄ init_database.py       # Êï∞ÊçÆÂ∫ìÂàùÂßãÂåñ
‚îÇ       ‚îî‚îÄ‚îÄ mindspider_tables.sql  # Êï∞ÊçÆÂ∫ìË°®ÁªìÊûÑ
‚îú‚îÄ‚îÄ SentimentAnalysisModel/        # ÊÉÖÊÑüÂàÜÊûêÊ®°ÂûãÈõÜÂêà
‚îÇ   ‚îú‚îÄ‚îÄ WeiboSentiment_Finetuned/  # ÂæÆË∞ÉBERT/GPT-2Ê®°Âûã
‚îÇ   ‚îú‚îÄ‚îÄ WeiboMultilingualSentiment/# Â§öËØ≠Ë®ÄÊÉÖÊÑüÂàÜÊûêÔºàÊé®ËçêÔºâ
‚îÇ   ‚îú‚îÄ‚îÄ WeiboSentiment_SmallQwen/  # Â∞èÂèÇÊï∞Qwen3ÂæÆË∞É
‚îÇ   ‚îî‚îÄ‚îÄ WeiboSentiment_MachineLearning/ # ‰º†ÁªüÊú∫Âô®Â≠¶‰π†ÊñπÊ≥ï
‚îú‚îÄ‚îÄ SingleEngineApp/               # ÂçïÁã¨AgentÁöÑStreamlitÂ∫îÁî®
‚îÇ   ‚îú‚îÄ‚îÄ query_engine_streamlit_app.py
‚îÇ   ‚îú‚îÄ‚îÄ media_engine_streamlit_app.py
‚îÇ   ‚îî‚îÄ‚îÄ insight_engine_streamlit_app.py
‚îú‚îÄ‚îÄ templates/                     # FlaskÊ®°Êùø
‚îÇ   ‚îî‚îÄ‚îÄ index.html                 # ‰∏ªÁïåÈù¢ÂâçÁ´Ø
‚îú‚îÄ‚îÄ static/                        # ÈùôÊÄÅËµÑÊ∫ê
‚îú‚îÄ‚îÄ logs/                          # ËøêË°åÊó•ÂøóÁõÆÂΩï
‚îú‚îÄ‚îÄ final_reports/                 # ÊúÄÁªàÁîüÊàêÁöÑHTMLÊä•ÂëäÊñá‰ª∂
‚îú‚îÄ‚îÄ utils/                         # ÈÄöÁî®Â∑•ÂÖ∑ÂáΩÊï∞
‚îÇ   ‚îú‚îÄ‚îÄ forum_reader.py            # AgentÈó¥ËÆ∫ÂùõÈÄö‰ø°
‚îÇ   ‚îî‚îÄ‚îÄ retry_helper.py            # ÁΩëÁªúËØ∑Ê±ÇÈáçËØïÊú∫Âà∂Â∑•ÂÖ∑
‚îú‚îÄ‚îÄ app.py                         # Flask‰∏ªÂ∫îÁî®ÂÖ•Âè£
‚îú‚îÄ‚îÄ config.py                      # ÂÖ®Â±ÄÈÖçÁΩÆÊñá‰ª∂
‚îî‚îÄ‚îÄ requirements.txt               # Python‰æùËµñÂåÖÊ∏ÖÂçï
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üöÄ Âø´ÈÄüÂºÄÂßãÔºàDockerÔºâ&lt;/h2&gt; 
&lt;h3&gt;1. ÂêØÂä®È°πÁõÆ&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;ËøêË°åÂëΩ‰ª§Ôºö&lt;/strong&gt; ÊâßË°å‰ª•‰∏ãÂëΩ‰ª§Âú®&lt;strong&gt;ÂêéÂè∞&lt;/strong&gt;ÂêØÂä®ÊâÄÊúâÊúçÂä°Ôºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Ê≥®ÔºöÈïúÂÉèÊãâÂèñÈÄüÂ∫¶ÊÖ¢&lt;/strong&gt;ÔºåÂú®Âéü &lt;code&gt;docker-compose.yml&lt;/code&gt; Êñá‰ª∂‰∏≠ÔºåÊàë‰ª¨Â∑≤ÁªèÈÄöËøá&lt;strong&gt;Ê≥®Èáä&lt;/strong&gt;ÁöÑÊñπÂºèÊèê‰æõ‰∫ÜÂ§áÁî®ÈïúÂÉèÂú∞ÂùÄ‰æõÊÇ®ÊõøÊç¢&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;2. ÈÖçÁΩÆËØ¥Êòé&lt;/h3&gt; 
&lt;h4&gt;Êï∞ÊçÆÂ∫ìÈÖçÁΩÆÔºàPostgreSQLÔºâ&lt;/h4&gt; 
&lt;p&gt;ËØ∑ÊåâÁÖß‰ª•‰∏ãÂèÇÊï∞ÈÖçÁΩÆÊï∞ÊçÆÂ∫ìËøûÊé•‰ø°ÊÅØÔºå‰πüÊîØÊåÅMysqlÂèØËá™Ë°å‰øÆÊîπÔºö&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;ÈÖçÁΩÆÈ°π&lt;/th&gt; 
   &lt;th align="left"&gt;Â°´ÂÜôÂÄº&lt;/th&gt; 
   &lt;th align="left"&gt;ËØ¥Êòé&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;DB_HOST&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;db&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Êï∞ÊçÆÂ∫ìÊúçÂä°ÂêçÁß∞ (ÂØπÂ∫î &lt;code&gt;docker-compose.yml&lt;/code&gt; ‰∏≠ÁöÑÊúçÂä°Âêç)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;DB_PORT&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;5432&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;ÈªòËÆ§ PostgreSQL Á´ØÂè£&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;DB_USER&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;bettafish&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Êï∞ÊçÆÂ∫ìÁî®Êà∑Âêç&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;DB_PASSWORD&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;bettafish&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Êï∞ÊçÆÂ∫ìÂØÜÁ†Å&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;DB_NAME&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;bettafish&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Êï∞ÊçÆÂ∫ìÂêçÁß∞&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;ÂÖ∂‰ªñ&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;‰øùÊåÅÈªòËÆ§&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Êï∞ÊçÆÂ∫ìËøûÊé•Ê±†Á≠âÂÖ∂‰ªñÂèÇÊï∞ËØ∑‰øùÊåÅÈªòËÆ§ËÆæÁΩÆ„ÄÇ&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Â§ßÊ®°ÂûãÈÖçÁΩÆ&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Êàë‰ª¨ÊâÄÊúâ LLM Ë∞ÉÁî®‰ΩøÁî® OpenAI ÁöÑ API Êé•Âè£Ê†áÂáÜ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Âú®ÂÆåÊàêÊï∞ÊçÆÂ∫ìÈÖçÁΩÆÂêéÔºåËØ∑Ê≠£Â∏∏ÈÖçÁΩÆ&lt;strong&gt;ÊâÄÊúâÂ§ßÊ®°ÂûãÁõ∏ÂÖ≥ÁöÑÂèÇÊï∞&lt;/strong&gt;ÔºåÁ°Æ‰øùÁ≥ªÁªüËÉΩÂ§üËøûÊé•Âà∞ÊÇ®ÈÄâÊã©ÁöÑÂ§ßÊ®°ÂûãÊúçÂä°„ÄÇ&lt;/p&gt; 
&lt;p&gt;ÂÆåÊàê‰∏äËø∞ÊâÄÊúâÈÖçÁΩÆÂπ∂‰øùÂ≠òÂêéÔºåÁ≥ªÁªüÂç≥ÂèØÊ≠£Â∏∏ËøêË°å„ÄÇ&lt;/p&gt; 
&lt;h2&gt;üîß Ê∫êÁ†ÅÂêØÂä®ÊåáÂçó&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Â¶ÇÊûú‰Ω†ÊòØÂàùÊ¨°Â≠¶‰π†‰∏Ä‰∏™AgentÁ≥ªÁªüÁöÑÊê≠Âª∫ÔºåÂèØ‰ª•‰ªé‰∏Ä‰∏™ÈùûÂ∏∏ÁÆÄÂçïÁöÑdemoÂºÄÂßãÔºö&lt;a href="https://github.com/666ghj/DeepSearchAgent-Demo"&gt;Deep Search Agent Demo&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;ÁéØÂ¢ÉË¶ÅÊ±Ç&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Êìç‰ΩúÁ≥ªÁªü&lt;/strong&gt;: Windows„ÄÅLinux„ÄÅMacOS&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;PythonÁâàÊú¨&lt;/strong&gt;: 3.9+&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Conda&lt;/strong&gt;: AnacondaÊàñMiniconda&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Êï∞ÊçÆÂ∫ì&lt;/strong&gt;: PostgreSQLÔºàÊé®ËçêÔºâÊàñMySQL&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÂÜÖÂ≠ò&lt;/strong&gt;: Âª∫ËÆÆ2GB‰ª•‰∏ä&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;1. ÂàõÂª∫ÁéØÂ¢É&lt;/h3&gt; 
&lt;h4&gt;Â¶ÇÊûú‰ΩøÁî®Conda&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ÂàõÂª∫condaÁéØÂ¢É
conda create -n your_conda_name python=3.11
conda activate your_conda_name
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Â¶ÇÊûú‰ΩøÁî®uv&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ÂàõÂª∫uvÁéØÂ¢É
uv venv --python 3.11 # ÂàõÂª∫3.11ÁéØÂ¢É
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. ÂÆâË£Ö‰æùËµñÂåÖ&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Âü∫Á°Ä‰æùËµñÂÆâË£Ö
pip install -r requirements.txt

# uvÁâàÊú¨ÂëΩ‰ª§ÔºàÊõ¥Âø´ÈÄüÂÆâË£ÖÔºâ
uv pip install -r requirements.txt
# Â¶ÇÊûú‰∏çÊÉ≥‰ΩøÁî®Êú¨Âú∞ÊÉÖÊÑüÂàÜÊûêÊ®°ÂûãÔºàÁÆóÂäõÈúÄÊ±ÇÂæàÂ∞èÔºåÈªòËÆ§ÂÆâË£ÖcpuÁâàÊú¨ÔºâÔºåÂèØ‰ª•Â∞ÜËØ•Êñá‰ª∂‰∏≠ÁöÑ‚ÄúÊú∫Âô®Â≠¶‰π†‚ÄùÈÉ®ÂàÜÊ≥®ÈáäÊéâÂÜçÊâßË°åÊåá‰ª§
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;3. ÂÆâË£ÖPlaywrightÊµèËßàÂô®È©±Âä®&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ÂÆâË£ÖÊµèËßàÂô®È©±Âä®ÔºàÁî®‰∫éÁà¨Ëô´ÂäüËÉΩÔºâ
playwright install chromium
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;4. ÈÖçÁΩÆLLM‰∏éÊï∞ÊçÆÂ∫ì&lt;/h3&gt; 
&lt;p&gt;Â§çÂà∂‰∏Ä‰ªΩÈ°πÁõÆÊ†πÁõÆÂΩï &lt;code&gt;.env.example&lt;/code&gt; Êñá‰ª∂ÔºåÂëΩÂêç‰∏∫ &lt;code&gt;.env&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;ÁºñËæë &lt;code&gt;.env&lt;/code&gt; Êñá‰ª∂ÔºåÂ°´ÂÖ•ÊÇ®ÁöÑAPIÂØÜÈí•ÔºàÊÇ®‰πüÂèØ‰ª•ÈÄâÊã©Ëá™Â∑±ÁöÑÊ®°Âûã„ÄÅÊêúÁ¥¢‰ª£ÁêÜÔºåËØ¶ÊÉÖËßÅÊ†πÁõÆÂΩï.env.exampleÊñá‰ª∂ÂÜÖÊàñÊ†πÁõÆÂΩïconfig.py‰∏≠ÁöÑËØ¥ÊòéÔºâÔºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yml"&gt;# ====================== Êï∞ÊçÆÂ∫ìÈÖçÁΩÆ ======================
# Êï∞ÊçÆÂ∫ì‰∏ªÊú∫Ôºå‰æãÂ¶Çlocalhost Êàñ 127.0.0.1
DB_HOST=your_db_host
# Êï∞ÊçÆÂ∫ìÁ´ØÂè£Âè∑ÔºåÈªòËÆ§‰∏∫3306
DB_PORT=3306
# Êï∞ÊçÆÂ∫ìÁî®Êà∑Âêç
DB_USER=your_db_user
# Êï∞ÊçÆÂ∫ìÂØÜÁ†Å
DB_PASSWORD=your_db_password
# Êï∞ÊçÆÂ∫ìÂêçÁß∞
DB_NAME=your_db_name
# Êï∞ÊçÆÂ∫ìÂ≠óÁ¨¶ÈõÜÔºåÊé®Ëçêutf8mb4ÔºåÂÖºÂÆπemoji
DB_CHARSET=utf8mb4
# Êï∞ÊçÆÂ∫ìÁ±ªÂûãpostgresqlÊàñmysql
DB_DIALECT=postgresql
# Êï∞ÊçÆÂ∫ì‰∏çÈúÄË¶ÅÂàùÂßãÂåñÔºåÊâßË°åapp.pyÊó∂‰ºöËá™Âä®Ê£ÄÊµã

# ====================== LLMÈÖçÁΩÆ ======================
# ÊÇ®ÂèØ‰ª•Êõ¥ÊîπÊØè‰∏™ÈÉ®ÂàÜLLM‰ΩøÁî®ÁöÑAPIÔºåÂè™Ë¶ÅÂÖºÂÆπOpenAIËØ∑Ê±ÇÊ†ºÂºèÈÉΩÂèØ‰ª•

# Insight Agent
INSIGHT_ENGINE_API_KEY=
# Insight Agent LLMÊé•Âè£BaseUrlÔºåÂèØËá™ÂÆö‰πâÂéÇÂïÜAPI
INSIGHT_ENGINE_BASE_URL=
# Insight Agent LLMÊ®°ÂûãÂêçÁß∞ÔºåÂ¶Çkimi-k2-0711-preview
INSIGHT_ENGINE_MODEL_NAME=

# Media Agent
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Êé®ËçêLLM API‰æõÂ∫îÂïÜÔºö&lt;a href="https://aihubmix.com/?aff=8Ds9"&gt;Êé®ÁêÜÊó∂‰ª£&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;5. ÂêØÂä®Á≥ªÁªü&lt;/h3&gt; 
&lt;h4&gt;5.1 ÂÆåÊï¥Á≥ªÁªüÂêØÂä®ÔºàÊé®ËçêÔºâ&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Âú®È°πÁõÆÊ†πÁõÆÂΩï‰∏ãÔºåÊøÄÊ¥ªcondaÁéØÂ¢É
conda activate your_conda_name

# ÂêØÂä®‰∏ªÂ∫îÁî®Âç≥ÂèØ
python app.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;uv ÁâàÊú¨ÂêØÂä®ÂëΩ‰ª§&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Âú®È°πÁõÆÊ†πÁõÆÂΩï‰∏ãÔºåÊøÄÊ¥ªuvÁéØÂ¢É
.venv\Scripts\activate

# ÂêØÂä®‰∏ªÂ∫îÁî®Âç≥ÂèØ
python app.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Ê≥®1Ôºö‰∏ÄÊ¨°ËøêË°åÁªàÊ≠¢ÂêéÔºåstreamlit appÂèØËÉΩÁªìÊùüÂºÇÂ∏∏‰ªçÁÑ∂Âç†Áî®Á´ØÂè£ÔºåÊ≠§Êó∂ÊêúÁ¥¢Âç†Áî®Á´ØÂè£ÁöÑËøõÁ®ãkillÊéâÂç≥ÂèØ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Ê≥®2ÔºöÊï∞ÊçÆÁà¨ÂèñÈúÄË¶ÅÂçïÁã¨Êìç‰ΩúÔºåËßÅ5.3ÊåáÂºï&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Ê≥®3ÔºöÂ¶ÇÊûúÊúçÂä°Âô®ËøúÁ®ãÈÉ®ÁΩ≤Âá∫Áé∞È°µÈù¢ÊòæÁ§∫ÈóÆÈ¢òÔºåËßÅ&lt;a href="https://github.com/666ghj/BettaFish/pull/45"&gt;PR#45&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;ËÆøÈóÆ &lt;a href="http://localhost:5000"&gt;http://localhost:5000&lt;/a&gt; Âç≥ÂèØ‰ΩøÁî®ÂÆåÊï¥Á≥ªÁªü&lt;/p&gt; 
&lt;h4&gt;5.2 ÂçïÁã¨ÂêØÂä®Êüê‰∏™Agent&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ÂêØÂä®QueryEngine
streamlit run SingleEngineApp/query_engine_streamlit_app.py --server.port 8503

# ÂêØÂä®MediaEngine  
streamlit run SingleEngineApp/media_engine_streamlit_app.py --server.port 8502

# ÂêØÂä®InsightEngine
streamlit run SingleEngineApp/insight_engine_streamlit_app.py --server.port 8501
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;5.3 Áà¨Ëô´Á≥ªÁªüÂçïÁã¨‰ΩøÁî®&lt;/h4&gt; 
&lt;p&gt;ËøôÈÉ®ÂàÜÊúâËØ¶ÁªÜÁöÑÈÖçÁΩÆÊñáÊ°£Ôºö&lt;a href="https://raw.githubusercontent.com/666ghj/BettaFish/main/MindSpider/README.md"&gt;MindSpider‰ΩøÁî®ËØ¥Êòé&lt;/a&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="MindSpider\img\example.png" alt="banner" width="600" /&gt; 
 &lt;p&gt;MindSpider ËøêË°åÁ§∫‰æã&lt;/p&gt; 
&lt;/div&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ËøõÂÖ•Áà¨Ëô´ÁõÆÂΩï
cd MindSpider

# È°πÁõÆÂàùÂßãÂåñ
python main.py --setup

# ËøêË°åËØùÈ¢òÊèêÂèñÔºàËé∑ÂèñÁÉ≠ÁÇπÊñ∞ÈóªÂíåÂÖ≥ÈîÆËØçÔºâ
python main.py --broad-topic

# ËøêË°åÂÆåÊï¥Áà¨Ëô´ÊµÅÁ®ã
python main.py --complete --date 2024-01-20

# ‰ªÖËøêË°åËØùÈ¢òÊèêÂèñ
python main.py --broad-topic --date 2024-01-20

# ‰ªÖËøêË°åÊ∑±Â∫¶Áà¨Âèñ
python main.py --deep-sentiment --platforms xhs dy wb
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;‚öôÔ∏è È´òÁ∫ßÈÖçÁΩÆÔºàÂ∑≤ËøáÊó∂ÔºåÂ∑≤ÁªèÁªü‰∏Ä‰∏∫È°πÁõÆÊ†πÁõÆÂΩï.envÊñá‰ª∂ÁÆ°ÁêÜÔºåÂÖ∂‰ªñÂ≠êagentËá™Âä®ÁªßÊâøÊ†πÁõÆÂΩïÈÖçÁΩÆÔºâ&lt;/h2&gt; 
&lt;h3&gt;‰øÆÊîπÂÖ≥ÈîÆÂèÇÊï∞&lt;/h3&gt; 
&lt;h4&gt;AgentÈÖçÁΩÆÂèÇÊï∞&lt;/h4&gt; 
&lt;p&gt;ÊØè‰∏™AgentÈÉΩÊúâ‰∏ìÈó®ÁöÑÈÖçÁΩÆÊñá‰ª∂ÔºåÂèØÊ†πÊçÆÈúÄÊ±ÇË∞ÉÊï¥Ôºå‰∏ãÈù¢ÊòØÈÉ®ÂàÜÁ§∫‰æãÔºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# QueryEngine/utils/config.py
class Config:
    max_reflections = 2           # ÂèçÊÄùËΩÆÊ¨°
    max_search_results = 15       # ÊúÄÂ§ßÊêúÁ¥¢ÁªìÊûúÊï∞
    max_content_length = 8000     # ÊúÄÂ§ßÂÜÖÂÆπÈïøÂ∫¶
    
# MediaEngine/utils/config.py  
class Config:
    comprehensive_search_limit = 10  # ÁªºÂêàÊêúÁ¥¢ÈôêÂà∂
    web_search_limit = 15           # ÁΩëÈ°µÊêúÁ¥¢ÈôêÂà∂
    
# InsightEngine/utils/config.py
class Config:
    default_search_topic_globally_limit = 200    # ÂÖ®Â±ÄÊêúÁ¥¢ÈôêÂà∂
    default_get_comments_limit = 500             # ËØÑËÆ∫Ëé∑ÂèñÈôêÂà∂
    max_search_results_for_llm = 50              # ‰º†ÁªôLLMÁöÑÊúÄÂ§ßÁªìÊûúÊï∞
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;ÊÉÖÊÑüÂàÜÊûêÊ®°ÂûãÈÖçÁΩÆ&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# InsightEngine/tools/sentiment_analyzer.py
SENTIMENT_CONFIG = {
    'model_type': 'multilingual',     # ÂèØÈÄâ: 'bert', 'multilingual', 'qwen'Á≠â
    'confidence_threshold': 0.8,      # ÁΩÆ‰ø°Â∫¶ÈòàÂÄº
    'batch_size': 32,                 # ÊâπÂ§ÑÁêÜÂ§ßÂ∞è
    'max_sequence_length': 512,       # ÊúÄÂ§ßÂ∫èÂàóÈïøÂ∫¶
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Êé•ÂÖ•‰∏çÂêåÁöÑLLMÊ®°Âûã&lt;/h3&gt; 
&lt;p&gt;ÊîØÊåÅ‰ªªÊÑèopenAIË∞ÉÁî®Ê†ºÂºèÁöÑLLMÊèê‰æõÂïÜÔºåÂè™ÈúÄË¶ÅÂú®/config.py‰∏≠Â°´ÂÜôÂØπÂ∫îÁöÑKEY„ÄÅBASE_URL„ÄÅMODEL_NAMEÂç≥ÂèØ„ÄÇ&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;‰ªÄ‰πàÊòØopenAIË∞ÉÁî®Ê†ºÂºèÔºü‰∏ãÈù¢Êèê‰æõ‰∏Ä‰∏™ÁÆÄÂçïÁöÑ‰æãÂ≠êÔºö&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;from openai import OpenAI

client = OpenAI(api_key="your_api_key", 
               base_url="https://api.siliconflow.cn/v1")

response = client.chat.completions.create(
   model="Qwen/Qwen2.5-72B-Instruct",
   messages=[
       {'role': 'user', 
        'content': "Êé®ÁêÜÊ®°Âûã‰ºöÁªôÂ∏ÇÂú∫Â∏¶Êù•Âì™‰∫õÊñ∞ÁöÑÊú∫‰ºö"}
   ],
)

complete_response = response.choices[0].message.content
print(complete_response)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Êõ¥ÊîπÊÉÖÊÑüÂàÜÊûêÊ®°Âûã&lt;/h3&gt; 
&lt;p&gt;Á≥ªÁªüÈõÜÊàê‰∫ÜÂ§öÁßçÊÉÖÊÑüÂàÜÊûêÊñπÊ≥ïÔºåÂèØÊ†πÊçÆÈúÄÊ±ÇÈÄâÊã©Ôºö&lt;/p&gt; 
&lt;h4&gt;1. Â§öËØ≠Ë®ÄÊÉÖÊÑüÂàÜÊûê&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd SentimentAnalysisModel/WeiboMultilingualSentiment
python predict.py --text "This product is amazing!" --lang "en"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2. Â∞èÂèÇÊï∞Qwen3ÂæÆË∞É&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd SentimentAnalysisModel/WeiboSentiment_SmallQwen
python predict_universal.py --text "ËøôÊ¨°Ê¥ªÂä®ÂäûÂæóÂæàÊàêÂäü"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;3. Âü∫‰∫éBERTÁöÑÂæÆË∞ÉÊ®°Âûã&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ‰ΩøÁî®BERT‰∏≠ÊñáÊ®°Âûã
cd SentimentAnalysisModel/WeiboSentiment_Finetuned/BertChinese-Lora
python predict.py --text "Ëøô‰∏™‰∫ßÂìÅÁúüÁöÑÂæà‰∏çÈîô"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;4. GPT-2 LoRAÂæÆË∞ÉÊ®°Âûã&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd SentimentAnalysisModel/WeiboSentiment_Finetuned/GPT2-Lora
python predict.py --text "‰ªäÂ§©ÂøÉÊÉÖ‰∏çÂ§™Â•Ω"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;5. ‰º†ÁªüÊú∫Âô®Â≠¶‰π†ÊñπÊ≥ï&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd SentimentAnalysisModel/WeiboSentiment_MachineLearning
python predict.py --model_type "svm" --text "ÊúçÂä°ÊÄÅÂ∫¶ÈúÄË¶ÅÊîπËøõ"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Êé•ÂÖ•Ëá™ÂÆö‰πâ‰∏öÂä°Êï∞ÊçÆÂ∫ì&lt;/h3&gt; 
&lt;h4&gt;1. ‰øÆÊîπÊï∞ÊçÆÂ∫ìËøûÊé•ÈÖçÁΩÆ&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# config.py ‰∏≠Ê∑ªÂä†ÊÇ®ÁöÑ‰∏öÂä°Êï∞ÊçÆÂ∫ìÈÖçÁΩÆ
BUSINESS_DB_HOST = "your_business_db_host"
BUSINESS_DB_PORT = 3306
BUSINESS_DB_USER = "your_business_user"
BUSINESS_DB_PASSWORD = "your_business_password"
BUSINESS_DB_NAME = "your_business_database"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2. ÂàõÂª∫Ëá™ÂÆö‰πâÊï∞ÊçÆËÆøÈóÆÂ∑•ÂÖ∑&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# InsightEngine/tools/custom_db_tool.py
class CustomBusinessDBTool:
    """Ëá™ÂÆö‰πâ‰∏öÂä°Êï∞ÊçÆÂ∫ìÊü•ËØ¢Â∑•ÂÖ∑"""
    
    def __init__(self):
        self.connection_config = {
            'host': config.BUSINESS_DB_HOST,
            'port': config.BUSINESS_DB_PORT,
            'user': config.BUSINESS_DB_USER,
            'password': config.BUSINESS_DB_PASSWORD,
            'database': config.BUSINESS_DB_NAME,
        }
    
    def search_business_data(self, query: str, table: str):
        """Êü•ËØ¢‰∏öÂä°Êï∞ÊçÆ"""
        # ÂÆûÁé∞ÊÇ®ÁöÑ‰∏öÂä°ÈÄªËæë
        pass
    
    def get_customer_feedback(self, product_id: str):
        """Ëé∑ÂèñÂÆ¢Êà∑ÂèçÈ¶àÊï∞ÊçÆ"""
        # ÂÆûÁé∞ÂÆ¢Êà∑ÂèçÈ¶àÊü•ËØ¢ÈÄªËæë
        pass
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;3. ÈõÜÊàêÂà∞InsightEngine&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# InsightEngine/agent.py ‰∏≠ÈõÜÊàêËá™ÂÆö‰πâÂ∑•ÂÖ∑
from .tools.custom_db_tool import CustomBusinessDBTool

class DeepSearchAgent:
    def __init__(self, config=None):
        # ... ÂÖ∂‰ªñÂàùÂßãÂåñ‰ª£Á†Å
        self.custom_db_tool = CustomBusinessDBTool()
    
    def execute_custom_search(self, query: str):
        """ÊâßË°åËá™ÂÆö‰πâ‰∏öÂä°Êï∞ÊçÆÊêúÁ¥¢"""
        return self.custom_db_tool.search_business_data(query, "your_table")
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Ëá™ÂÆö‰πâÊä•ÂëäÊ®°Êùø&lt;/h3&gt; 
&lt;h4&gt;1. Âú®WebÁïåÈù¢‰∏≠‰∏ä‰º†&lt;/h4&gt; 
&lt;p&gt;Á≥ªÁªüÊîØÊåÅ‰∏ä‰º†Ëá™ÂÆö‰πâÊ®°ÊùøÊñá‰ª∂Ôºà.mdÊàñ.txtÊ†ºÂºèÔºâÔºåÂèØÂú®ÁîüÊàêÊä•ÂëäÊó∂ÈÄâÊã©‰ΩøÁî®„ÄÇ&lt;/p&gt; 
&lt;h4&gt;2. ÂàõÂª∫Ê®°ÊùøÊñá‰ª∂&lt;/h4&gt; 
&lt;p&gt;Âú® &lt;code&gt;ReportEngine/report_template/&lt;/code&gt; ÁõÆÂΩï‰∏ãÂàõÂª∫Êñ∞ÁöÑÊ®°ÊùøÔºåÊàë‰ª¨ÁöÑAgent‰ºöËá™Ë°åÈÄâÁî®ÊúÄÂêàÈÄÇÁöÑÊ®°Êùø„ÄÇ&lt;/p&gt; 
&lt;h2&gt;ü§ù Ë¥°ÁåÆÊåáÂçó&lt;/h2&gt; 
&lt;p&gt;Êàë‰ª¨Ê¨¢ËøéÊâÄÊúâÂΩ¢ÂºèÁöÑË¥°ÁåÆÔºÅ&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ËØ∑ÈòÖËØª‰ª•‰∏ãË¥°ÁåÆÊåáÂçóÔºö&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/666ghj/BettaFish/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ü¶ñ ‰∏ã‰∏ÄÊ≠•ÂºÄÂèëËÆ°Âàí&lt;/h2&gt; 
&lt;p&gt;Áé∞Âú®Á≥ªÁªüÂè™ÂÆåÊàê‰∫Ü"‰∏âÊùøÊñß"‰∏≠ÁöÑÂâç‰∏§Ê≠•ÔºåÂç≥ÔºöËæìÂÖ•Ë¶ÅÊ±Ç-&amp;gt;ËØ¶ÁªÜÂàÜÊûêÔºåËøòÁº∫Â∞ë‰∏ÄÊ≠•È¢ÑÊµãÔºåÁõ¥Êé•Â∞Ü‰ªñÁªßÁª≠‰∫§ÁªôLLMÊòØ‰∏çÂÖ∑ÊúâËØ¥ÊúçÂäõÁöÑ„ÄÇ&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/666ghj/BettaFish/main/static/image/banner_compressed.png" alt="banner" width="800" /&gt; 
&lt;/div&gt; 
&lt;p&gt;ÁõÆÂâçÊàë‰ª¨ÁªèËøáÂæàÈïø‰∏ÄÊÆµÊó∂Èó¥ÁöÑÁà¨ÂèñÊî∂ÈõÜÔºåÊã•Êúâ‰∫ÜÂ§ßÈáèÂÖ®ÁΩëËØùÈ¢òÁÉ≠Â∫¶ÈöèÊó∂Èó¥„ÄÅÁàÜÁÇπÁ≠âÁöÑÂèòÂåñË∂ãÂäøÁÉ≠Â∫¶Êï∞ÊçÆÔºåÂ∑≤ÁªèÂÖ∑Â§á‰∫ÜÂèØ‰ª•ÂºÄÂèëÈ¢ÑÊµãÊ®°ÂûãÁöÑÊù°‰ª∂„ÄÇÊàë‰ª¨Âõ¢ÈòüÂ∞ÜËøêÁî®Êó∂Â∫èÊ®°Âûã„ÄÅÂõæÁ•ûÁªèÁΩëÁªú„ÄÅÂ§öÊ®°ÊÄÅËûçÂêàÁ≠âÈ¢ÑÊµãÊ®°ÂûãÊäÄÊúØÂÇ®Â§á‰∫éÊ≠§ÔºåÂÆûÁé∞ÁúüÊ≠£Âü∫‰∫éÊï∞ÊçÆÈ©±Âä®ÁöÑËàÜÊÉÖÈ¢ÑÊµãÂäüËÉΩ„ÄÇ&lt;/p&gt; 
&lt;h2&gt;‚ö†Ô∏è ÂÖçË¥£Â£∞Êòé&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;ÈáçË¶ÅÊèêÈÜíÔºöÊú¨È°πÁõÆ‰ªÖ‰æõÂ≠¶‰π†„ÄÅÂ≠¶ÊúØÁ†îÁ©∂ÂíåÊïôËÇ≤ÁõÆÁöÑ‰ΩøÁî®&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ÂêàËßÑÊÄßÂ£∞Êòé&lt;/strong&gt;Ôºö&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Êú¨È°πÁõÆ‰∏≠ÁöÑÊâÄÊúâ‰ª£Á†Å„ÄÅÂ∑•ÂÖ∑ÂíåÂäüËÉΩÂùá‰ªÖ‰æõÂ≠¶‰π†„ÄÅÂ≠¶ÊúØÁ†îÁ©∂ÂíåÊïôËÇ≤ÁõÆÁöÑ‰ΩøÁî®&lt;/li&gt; 
   &lt;li&gt;‰∏•Á¶ÅÂ∞ÜÊú¨È°πÁõÆÁî®‰∫é‰ªª‰ΩïÂïÜ‰∏öÁî®ÈÄîÊàñÁõàÂà©ÊÄßÊ¥ªÂä®&lt;/li&gt; 
   &lt;li&gt;‰∏•Á¶ÅÂ∞ÜÊú¨È°πÁõÆÁî®‰∫é‰ªª‰ΩïËøùÊ≥ï„ÄÅËøùËßÑÊàñ‰æµÁäØ‰ªñ‰∫∫ÊùÉÁõäÁöÑË°å‰∏∫&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Áà¨Ëô´ÂäüËÉΩÂÖçË¥£&lt;/strong&gt;Ôºö&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;È°πÁõÆ‰∏≠ÁöÑÁà¨Ëô´ÂäüËÉΩ‰ªÖÁî®‰∫éÊäÄÊúØÂ≠¶‰π†ÂíåÁ†îÁ©∂ÁõÆÁöÑ&lt;/li&gt; 
   &lt;li&gt;‰ΩøÁî®ËÄÖÂøÖÈ°ªÈÅµÂÆàÁõÆÊ†áÁΩëÁ´ôÁöÑrobots.txtÂçèËÆÆÂíå‰ΩøÁî®Êù°Ê¨æ&lt;/li&gt; 
   &lt;li&gt;‰ΩøÁî®ËÄÖÂøÖÈ°ªÈÅµÂÆàÁõ∏ÂÖ≥Ê≥ïÂæãÊ≥ïËßÑÔºå‰∏çÂæóËøõË°åÊÅ∂ÊÑèÁà¨ÂèñÊàñÊï∞ÊçÆÊª•Áî®&lt;/li&gt; 
   &lt;li&gt;Âõ†‰ΩøÁî®Áà¨Ëô´ÂäüËÉΩ‰∫ßÁîüÁöÑ‰ªª‰ΩïÊ≥ïÂæãÂêéÊûúÁî±‰ΩøÁî®ËÄÖËá™Ë°åÊâøÊãÖ&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Êï∞ÊçÆ‰ΩøÁî®ÂÖçË¥£&lt;/strong&gt;Ôºö&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;È°πÁõÆÊ∂âÂèäÁöÑÊï∞ÊçÆÂàÜÊûêÂäüËÉΩ‰ªÖ‰æõÂ≠¶ÊúØÁ†îÁ©∂‰ΩøÁî®&lt;/li&gt; 
   &lt;li&gt;‰∏•Á¶ÅÂ∞ÜÂàÜÊûêÁªìÊûúÁî®‰∫éÂïÜ‰∏öÂÜ≥Á≠ñÊàñÁõàÂà©ÁõÆÁöÑ&lt;/li&gt; 
   &lt;li&gt;‰ΩøÁî®ËÄÖÂ∫îÁ°Æ‰øùÊâÄÂàÜÊûêÊï∞ÊçÆÁöÑÂêàÊ≥ïÊÄßÂíåÂêàËßÑÊÄß&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ÊäÄÊúØÂÖçË¥£&lt;/strong&gt;Ôºö&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Êú¨È°πÁõÆÊåâ"Áé∞Áä∂"Êèê‰æõÔºå‰∏çÊèê‰æõ‰ªª‰ΩïÊòéÁ§∫ÊàñÊöóÁ§∫ÁöÑ‰øùËØÅ&lt;/li&gt; 
   &lt;li&gt;‰ΩúËÄÖ‰∏çÂØπ‰ΩøÁî®Êú¨È°πÁõÆÈÄ†ÊàêÁöÑ‰ªª‰ΩïÁõ¥Êé•ÊàñÈó¥Êé•ÊçüÂ§±ÊâøÊãÖË¥£‰ªª&lt;/li&gt; 
   &lt;li&gt;‰ΩøÁî®ËÄÖÂ∫îËá™Ë°åËØÑ‰º∞È°πÁõÆÁöÑÈÄÇÁî®ÊÄßÂíåÈ£éÈô©&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Ë¥£‰ªªÈôêÂà∂&lt;/strong&gt;Ôºö&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;‰ΩøÁî®ËÄÖÂú®‰ΩøÁî®Êú¨È°πÁõÆÂâçÂ∫îÂÖÖÂàÜ‰∫ÜËß£Áõ∏ÂÖ≥Ê≥ïÂæãÊ≥ïËßÑ&lt;/li&gt; 
   &lt;li&gt;‰ΩøÁî®ËÄÖÂ∫îÁ°Æ‰øùÂÖ∂‰ΩøÁî®Ë°å‰∏∫Á¨¶ÂêàÂΩìÂú∞Ê≥ïÂæãÊ≥ïËßÑË¶ÅÊ±Ç&lt;/li&gt; 
   &lt;li&gt;Âõ†ËøùÂèçÊ≥ïÂæãÊ≥ïËßÑ‰ΩøÁî®Êú¨È°πÁõÆËÄå‰∫ßÁîüÁöÑ‰ªª‰ΩïÂêéÊûúÁî±‰ΩøÁî®ËÄÖËá™Ë°åÊâøÊãÖ&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;ËØ∑Âú®‰ΩøÁî®Êú¨È°πÁõÆÂâç‰ªîÁªÜÈòÖËØªÂπ∂ÁêÜËß£‰∏äËø∞ÂÖçË¥£Â£∞Êòé„ÄÇ‰ΩøÁî®Êú¨È°πÁõÆÂç≥Ë°®Á§∫ÊÇ®Â∑≤ÂêåÊÑèÂπ∂Êé•Âèó‰∏äËø∞ÊâÄÊúâÊù°Ê¨æ„ÄÇ&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;üìÑ ËÆ∏ÂèØËØÅ&lt;/h2&gt; 
&lt;p&gt;Êú¨È°πÁõÆÈááÁî® &lt;a href="https://raw.githubusercontent.com/666ghj/BettaFish/main/LICENSE"&gt;GPL-2.0ËÆ∏ÂèØËØÅ&lt;/a&gt;„ÄÇËØ¶ÁªÜ‰ø°ÊÅØËØ∑ÂèÇÈòÖLICENSEÊñá‰ª∂„ÄÇ&lt;/p&gt; 
&lt;h2&gt;üéâ ÊîØÊåÅ‰∏éËÅîÁ≥ª&lt;/h2&gt; 
&lt;h3&gt;Ëé∑ÂèñÂ∏ÆÂä©&lt;/h3&gt; 
&lt;p&gt;Â∏∏ËßÅÈóÆÈ¢òËß£Á≠îÔºö&lt;a href="https://github.com/666ghj/BettaFish/issues/185"&gt;https://github.com/666ghj/BettaFish/issues/185&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;È°πÁõÆ‰∏ªÈ°µ&lt;/strong&gt;Ôºö&lt;a href="https://github.com/666ghj/BettaFish"&gt;GitHub‰ªìÂ∫ì&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÈóÆÈ¢òÂèçÈ¶à&lt;/strong&gt;Ôºö&lt;a href="https://github.com/666ghj/BettaFish/issues"&gt;IssuesÈ°µÈù¢&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÂäüËÉΩÂª∫ËÆÆ&lt;/strong&gt;Ôºö&lt;a href="https://github.com/666ghj/BettaFish/discussions"&gt;DiscussionsÈ°µÈù¢&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ËÅîÁ≥ªÊñπÂºè&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üìß &lt;strong&gt;ÈÇÆÁÆ±&lt;/strong&gt;Ôºö&lt;a href="mailto:670939375@qq.com"&gt;670939375@qq.com&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ÂïÜÂä°Âêà‰Ωú&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;‰ºÅ‰∏öÂÆöÂà∂ÂºÄÂèë&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Â§ßÊï∞ÊçÆÊúçÂä°&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Â≠¶ÊúØÂêà‰Ωú&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÊäÄÊúØÂüπËÆ≠&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üë• Ë¥°ÁåÆËÄÖ&lt;/h2&gt; 
&lt;p&gt;ÊÑüË∞¢‰ª•‰∏ã‰ºòÁßÄÁöÑË¥°ÁåÆËÄÖ‰ª¨Ôºö&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/666ghj/BettaFish/graphs/contributors"&gt;&lt;img src="https://contrib.rocks/image?repo=666ghj/BettaFish" alt="Contributors" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üìà È°πÁõÆÁªüËÆ°&lt;/h2&gt; 
&lt;a href="https://www.star-history.com/#666ghj/BettaFish&amp;amp;type=date&amp;amp;legend=top-left"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=666ghj/BettaFish&amp;amp;type=date&amp;amp;theme=dark&amp;amp;legend=top-left" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=666ghj/BettaFish&amp;amp;type=date&amp;amp;legend=top-left" /&gt; 
  &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=666ghj/BettaFish&amp;amp;type=date&amp;amp;legend=top-left" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;p&gt;&lt;img src="https://repobeats.axiom.co/api/embed/e04e3eea4674edc39c148a7845c8d09c1b7b1922.svg?sanitize=true" alt="Alt" title="Repobeats analytics image" /&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>sansan0/TrendRadar</title>
      <link>https://github.com/sansan0/TrendRadar</link>
      <description>&lt;p&gt;üéØ ÂëäÂà´‰ø°ÊÅØËøáËΩΩÔºåAI Âä©‰Ω†ÁúãÊáÇÊñ∞ÈóªËµÑËÆØÁÉ≠ÁÇπÔºåÁÆÄÂçïÁöÑËàÜÊÉÖÁõëÊéßÂàÜÊûê - Â§öÂπ≥Âè∞ÁÉ≠ÁÇπËÅöÂêà+Âü∫‰∫é MCP ÁöÑAIÂàÜÊûêÂ∑•ÂÖ∑„ÄÇÁõëÊéß35‰∏™Âπ≥Âè∞ÔºàÊäñÈü≥„ÄÅÁü•‰πé„ÄÅBÁ´ô„ÄÅÂçéÂ∞îË°óËßÅÈóª„ÄÅË¥¢ËÅîÁ§æÁ≠âÔºâÔºåÊô∫ËÉΩÁ≠õÈÄâ+Ëá™Âä®Êé®ÈÄÅ+AIÂØπËØùÂàÜÊûêÔºàÁî®Ëá™ÁÑ∂ËØ≠Ë®ÄÊ∑±Â∫¶ÊåñÊéòÊñ∞ÈóªÔºöË∂ãÂäøËøΩË∏™„ÄÅÊÉÖÊÑüÂàÜÊûê„ÄÅÁõ∏‰ººÊ£ÄÁ¥¢Á≠â13ÁßçÂ∑•ÂÖ∑Ôºâ„ÄÇÊîØÊåÅ‰ºÅ‰∏öÂæÆ‰ø°/È£û‰π¶/ÈíâÈíâ/Telegram/ÈÇÆ‰ª∂/ntfyÊé®ÈÄÅÔºå30ÁßíÁΩëÈ°µÈÉ®ÁΩ≤Ôºå1ÂàÜÈíüÊâãÊú∫ÈÄöÁü•ÔºåÊó†ÈúÄÁºñÁ®ã„ÄÇÊîØÊåÅDockerÈÉ®ÁΩ≤‚≠ê ËÆ©ÁÆóÊ≥ï‰∏∫‰Ω†ÊúçÂä°ÔºåÁî®AIÁêÜËß£ÁÉ≠ÁÇπ&lt;/p&gt;&lt;hr&gt;&lt;div align="center" id="trendradar"&gt; 
 &lt;a href="https://github.com/sansan0/TrendRadar" title="TrendRadar"&gt; &lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/banner.jpg" alt="TrendRadar Banner" width="50%" /&gt; &lt;/a&gt; 
 &lt;p&gt;üöÄ ÊúÄÂø´&lt;strong&gt;30Áßí&lt;/strong&gt;ÈÉ®ÁΩ≤ÁöÑÁÉ≠ÁÇπÂä©Êâã ‚Äî‚Äî ÂëäÂà´Êó†ÊïàÂà∑Â±èÔºåÂè™ÁúãÁúüÊ≠£ÂÖ≥ÂøÉÁöÑÊñ∞ÈóªËµÑËÆØ&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/14726" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/14726" alt="sansan0%2FTrendRadar | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/sansan0/TrendRadar/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/sansan0/TrendRadar?style=flat-square&amp;amp;logo=github&amp;amp;color=yellow" alt="GitHub Stars" /&gt;&lt;/a&gt; &lt;a href="https://github.com/sansan0/TrendRadar/network/members"&gt;&lt;img src="https://img.shields.io/github/forks/sansan0/TrendRadar?style=flat-square&amp;amp;logo=github&amp;amp;color=blue" alt="GitHub Forks" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-GPL--3.0-blue.svg?style=flat-square" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://github.com/sansan0/TrendRadar"&gt;&lt;img src="https://img.shields.io/badge/version-v3.0.4-blue.svg?sanitize=true" alt="Version" /&gt;&lt;/a&gt; &lt;a href="https://github.com/sansan0/TrendRadar"&gt;&lt;img src="https://img.shields.io/badge/MCP-v1.0.1-green.svg?sanitize=true" alt="MCP" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://work.weixin.qq.com/"&gt;&lt;img src="https://img.shields.io/badge/%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1-%E9%80%9A%E7%9F%A5-00D4AA?style=flat-square" alt="‰ºÅ‰∏öÂæÆ‰ø°ÈÄöÁü•" /&gt;&lt;/a&gt; &lt;a href="https://telegram.org/"&gt;&lt;img src="https://img.shields.io/badge/Telegram-%E9%80%9A%E7%9F%A5-00D4AA?style=flat-square" alt="TelegramÈÄöÁü•" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#"&gt;&lt;img src="https://img.shields.io/badge/%E9%92%89%E9%92%89-%E9%80%9A%E7%9F%A5-00D4AA?style=flat-square" alt="dingtalkÈÄöÁü•" /&gt;&lt;/a&gt; &lt;a href="https://www.feishu.cn/"&gt;&lt;img src="https://img.shields.io/badge/%E9%A3%9E%E4%B9%A6-%E9%80%9A%E7%9F%A5-00D4AA?style=flat-square" alt="È£û‰π¶ÈÄöÁü•" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#"&gt;&lt;img src="https://img.shields.io/badge/Email-%E9%80%9A%E7%9F%A5-00D4AA?style=flat-square" alt="ÈÇÆ‰ª∂ÈÄöÁü•" /&gt;&lt;/a&gt; &lt;a href="https://github.com/binwiederhier/ntfy"&gt;&lt;img src="https://img.shields.io/badge/ntfy-%E9%80%9A%E7%9F%A5-00D4AA?style=flat-square" alt="ntfyÈÄöÁü•" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/sansan0/TrendRadar"&gt;&lt;img src="https://img.shields.io/badge/GitHub_Actions-%E8%87%AA%E5%8A%A8%E5%8C%96-2088FF?style=flat-square&amp;amp;logo=github-actions&amp;amp;logoColor=white" alt="GitHub Actions" /&gt;&lt;/a&gt; &lt;a href="https://sansan0.github.io/TrendRadar"&gt;&lt;img src="https://img.shields.io/badge/GitHub_Pages-%E9%83%A8%E7%BD%B2-4285F4?style=flat-square&amp;amp;logo=github&amp;amp;logoColor=white" alt="GitHub Pages" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/wantcat/trendradar"&gt;&lt;img src="https://img.shields.io/badge/Docker-%E9%83%A8%E7%BD%B2-2496ED?style=flat-square&amp;amp;logo=docker&amp;amp;logoColor=white" alt="Docker" /&gt;&lt;/a&gt; &lt;a href="https://modelcontextprotocol.io/"&gt;&lt;img src="https://img.shields.io/badge/MCP-AI%E5%88%86%E6%9E%90%E6%94%AF%E6%8C%81-FF6B6B?style=flat-square&amp;amp;logo=ai&amp;amp;logoColor=white" alt="MCP Support" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Êú¨È°πÁõÆ‰ª•ËΩªÈáèÔºåÊòìÈÉ®ÁΩ≤‰∏∫ÁõÆÊ†á&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;üìë Âø´ÈÄüÂØºËà™&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th align="center"&gt;&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#-%E6%A0%B8%E5%BF%83%E5%8A%9F%E8%83%BD"&gt;üéØ Ê†∏ÂøÉÂäüËÉΩ&lt;/a&gt;&lt;/th&gt; 
    &lt;th align="center"&gt;&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#-%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B"&gt;üöÄ Âø´ÈÄüÂºÄÂßã&lt;/a&gt;&lt;/th&gt; 
    &lt;th align="center"&gt;&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#-docker-%E9%83%A8%E7%BD%B2"&gt;üê≥ DockerÈÉ®ÁΩ≤&lt;/a&gt;&lt;/th&gt; 
    &lt;th align="center"&gt;&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#-ai-%E6%99%BA%E8%83%BD%E5%88%86%E6%9E%90%E9%83%A8%E7%BD%B2"&gt;ü§ñ AIÂàÜÊûê‰∏ìÂå∫&lt;/a&gt;&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#-%E6%9B%B4%E6%96%B0%E6%97%A5%E5%BF%97"&gt;üìù Êõ¥Êñ∞Êó•Âøó&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#-mcp-%E5%AE%A2%E6%88%B7%E7%AB%AF"&gt;üîå MCPÂÆ¢Êà∑Á´Ø&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#%E9%97%AE%E9%A2%98%E7%AD%94%E7%96%91%E4%B8%8E1%E5%85%83%E7%82%B9%E8%B5%9E"&gt;‚ùì Á≠îÁñë‰∏éÂ∏∏ËßÅÈóÆÈ¢ò&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#%E9%A1%B9%E7%9B%AE%E7%9B%B8%E5%85%B3"&gt;‚≠ê È°πÁõÆÁõ∏ÂÖ≥&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;ÊÑüË∞¢&lt;strong&gt;ËÄêÂøÉÂèçÈ¶à bug&lt;/strong&gt; ÁöÑË¥°ÁåÆËÄÖÔºå‰Ω†‰ª¨ÁöÑÊØè‰∏ÄÊù°ÂèçÈ¶àËÆ©È°πÁõÆÊõ¥Âä†ÂÆåÂñÑüòâ;&lt;/li&gt; 
 &lt;li&gt;ÊÑüË∞¢&lt;strong&gt;‰∏∫È°πÁõÆÁÇπ star&lt;/strong&gt; ÁöÑËßÇ‰ºó‰ª¨Ôºå&lt;strong&gt;fork&lt;/strong&gt; ‰Ω†ÊâÄÊ¨≤‰πüÔºå&lt;strong&gt;star&lt;/strong&gt; ÊàëÊâÄÊ¨≤‰πüÔºå‰∏§ËÄÖÂæóÂÖºüòçÊòØÂØπÂºÄÊ∫êÁ≤æÁ•ûÊúÄÂ•ΩÁöÑÊîØÊåÅ;&lt;/li&gt; 
 &lt;li&gt;ÊÑüË∞¢&lt;strong&gt;ÂÖ≥Ê≥®&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#%E9%97%AE%E9%A2%98%E7%AD%94%E7%96%91%E4%B8%8E1%E5%85%83%E7%82%B9%E8%B5%9E"&gt;ÂÖ¨‰ºóÂè∑&lt;/a&gt;&lt;/strong&gt; ÁöÑËØªËÄÖ‰ª¨Ôºå‰Ω†‰ª¨ÁöÑÁïôË®Ä„ÄÅÁÇπËµû„ÄÅÂàÜ‰∫´ÂíåÊé®ËçêÁ≠âÁßØÊûÅ‰∫íÂä®ËÆ©ÂÜÖÂÆπÊõ¥ÊúâÊ∏©Â∫¶üòé„ÄÇ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;üëâ ÁÇπÂáªÊü•Áúã&lt;strong&gt;Ëá¥Ë∞¢ÂêçÂçï&lt;/strong&gt; (ÂΩìÂâç &lt;strong&gt;üî•49üî•&lt;/strong&gt; ‰Ωç)&lt;/summary&gt; 
 &lt;h3&gt;Êï∞ÊçÆÊîØÊåÅ&lt;/h3&gt; 
 &lt;p&gt;Êú¨È°πÁõÆ‰ΩøÁî®‰∫Ü &lt;a href="https://github.com/ourongxing/newsnow"&gt;newsnow&lt;/a&gt; È°πÁõÆÊèê‰æõÁöÑ API Êé•Âè£Ëé∑ÂèñÂ§öÂπ≥Âè∞Êï∞ÊçÆ&lt;/p&gt; 
 &lt;h3&gt;Êé®ÂπøÂä©Âäõ&lt;/h3&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;ÊÑüË∞¢‰ª•‰∏ãÂπ≥Âè∞Âíå‰∏™‰∫∫ÁöÑÊé®Ëçê(ÊåâÊó∂Èó¥ÊéíÂàó)&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s/fvutkJ_NPUelSW9OGK39aA"&gt;Â∞è‰ºóËΩØ‰ª∂&lt;/a&gt; - ÂºÄÊ∫êËΩØ‰ª∂Êé®ËçêÂπ≥Âè∞&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://linux.do/"&gt;LinuxDo Á§æÂå∫&lt;/a&gt; - ÊäÄÊúØÁà±Â•ΩËÄÖÁöÑËÅöÈõÜÂú∞&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/ruanyf/weekly"&gt;ÈòÆ‰∏ÄÂ≥∞Âë®Âàä&lt;/a&gt; - ÊäÄÊúØÂúàÊúâÂΩ±ÂìçÂäõÁöÑÂë®Âàä&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;ËßÇ‰ºóÊîØÊåÅ&lt;/h3&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;ÊÑüË∞¢&lt;strong&gt;Áªô‰∫àËµÑÈáëÊîØÊåÅ&lt;/strong&gt; ÁöÑÊúãÂèã‰ª¨,‰Ω†‰ª¨ÁöÑÊÖ∑ÊÖ®Â∑≤ÂåñË∫´‰∏∫ÈîÆÁõòÊóÅÁöÑÈõ∂È£üÈ•ÆÊñô,Èô™‰º¥ÁùÄÈ°πÁõÆÁöÑÊØè‰∏ÄÊ¨°Ëø≠‰ª£&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th align="center"&gt;ÁÇπËµû‰∫∫&lt;/th&gt; 
    &lt;th align="center"&gt;ÈáëÈ¢ù&lt;/th&gt; 
    &lt;th align="center"&gt;Êó•Êúü&lt;/th&gt; 
    &lt;th align="center"&gt;Â§áÊ≥®&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*‰∏ª&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.10&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*‰∫Ü&lt;/td&gt; 
    &lt;td align="center"&gt;10&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.09&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*Êù∞&lt;/td&gt; 
    &lt;td align="center"&gt;5&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.08&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*ÁÇπ&lt;/td&gt; 
    &lt;td align="center"&gt;8.80&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.07&lt;/td&gt; 
    &lt;td align="center"&gt;ÂºÄÂèë‰∏çÊòìÔºåÊîØÊåÅ‰∏Ä‰∏ã„ÄÇ&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;Q*Q&lt;/td&gt; 
    &lt;td align="center"&gt;6.66&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.07&lt;/td&gt; 
    &lt;td align="center"&gt;ÊÑüË∞¢ÂºÄÊ∫êÔºÅ&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;C*e&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.11.05&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;Peter Fan&lt;/td&gt; 
    &lt;td align="center"&gt;20&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.29&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;M*n&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.27&lt;/td&gt; 
    &lt;td align="center"&gt;ÊÑüË∞¢ÂºÄÊ∫ê&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*ËÆ∏&lt;/td&gt; 
    &lt;td align="center"&gt;8.88&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.23&lt;/td&gt; 
    &lt;td align="center"&gt;ËÄÅÂ∏à Â∞èÁôΩ‰∏ÄÊûöÔºåÊë∏‰∫ÜÂá†Â§©‰∫ÜËøòÊ≤°Êï¥Ëµ∑Êù•ÔºåÊ±ÇÊïô&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;Eason&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.22&lt;/td&gt; 
    &lt;td align="center"&gt;ËøòÊ≤°Êï¥ÊòéÁôΩÔºå‰ΩÜ‰Ω†Âú®ÂÅöÂ•Ω‰∫ã&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;P*n&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.20&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*Êù∞&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.19&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*Âæê&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.18&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*Âøó&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.17&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*üòÄ&lt;/td&gt; 
    &lt;td align="center"&gt;10&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.16&lt;/td&gt; 
    &lt;td align="center"&gt;ÁÇπËµû&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;**Êù∞&lt;/td&gt; 
    &lt;td align="center"&gt;10&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.16&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*Âï∏&lt;/td&gt; 
    &lt;td align="center"&gt;10&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.16&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*Á∫™&lt;/td&gt; 
    &lt;td align="center"&gt;5&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.14&lt;/td&gt; 
    &lt;td align="center"&gt;TrendRadar&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;J*d&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.14&lt;/td&gt; 
    &lt;td align="center"&gt;Ë∞¢Ë∞¢‰Ω†ÁöÑÂ∑•ÂÖ∑ÔºåÂæàÂ•ΩÁé©...&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*H&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.14&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;ÈÇ£*O&lt;/td&gt; 
    &lt;td align="center"&gt;10&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.13&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*ÂúÜ&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.13&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;P*g&lt;/td&gt; 
    &lt;td align="center"&gt;6&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.13&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;Ocean&lt;/td&gt; 
    &lt;td align="center"&gt;20&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.12&lt;/td&gt; 
    &lt;td align="center"&gt;...ÁúüÁöÑÂ§™Ê£í‰∫ÜÔºÅÔºÅÔºÅÂ∞èÁôΩÁ∫ßÂà´‰πüËÉΩÁõ¥Êé•Áî®...&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;**Âüπ&lt;/td&gt; 
    &lt;td align="center"&gt;5.2&lt;/td&gt; 
    &lt;td align="center"&gt;2025.10.2&lt;/td&gt; 
    &lt;td align="center"&gt;github-yzyf1312:ÂºÄÊ∫ê‰∏áÂ≤Å&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*Ê§ø&lt;/td&gt; 
    &lt;td align="center"&gt;3&lt;/td&gt; 
    &lt;td align="center"&gt;2025.9.23&lt;/td&gt; 
    &lt;td align="center"&gt;Âä†Ê≤πÔºåÂæà‰∏çÈîô&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*üçç&lt;/td&gt; 
    &lt;td align="center"&gt;10&lt;/td&gt; 
    &lt;td align="center"&gt;2025.9.21&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;E*f&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.9.20&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*ËÆ∞&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.9.20&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;z*u&lt;/td&gt; 
    &lt;td align="center"&gt;2&lt;/td&gt; 
    &lt;td align="center"&gt;2025.9.19&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;**Êòä&lt;/td&gt; 
    &lt;td align="center"&gt;5&lt;/td&gt; 
    &lt;td align="center"&gt;2025.9.17&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*Âè∑&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.9.15&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;T*T&lt;/td&gt; 
    &lt;td align="center"&gt;2&lt;/td&gt; 
    &lt;td align="center"&gt;2025.9.15&lt;/td&gt; 
    &lt;td align="center"&gt;ÁÇπËµû&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*ÂÆ∂&lt;/td&gt; 
    &lt;td align="center"&gt;10&lt;/td&gt; 
    &lt;td align="center"&gt;2025.9.10&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*X&lt;/td&gt; 
    &lt;td align="center"&gt;1.11&lt;/td&gt; 
    &lt;td align="center"&gt;2025.9.3&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*È£ô&lt;/td&gt; 
    &lt;td align="center"&gt;20&lt;/td&gt; 
    &lt;td align="center"&gt;2025.8.31&lt;/td&gt; 
    &lt;td align="center"&gt;Êù•Ëá™ËÄÅÁ´•Ë∞¢Ë∞¢&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*‰∏ã&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.8.30&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;2*D&lt;/td&gt; 
    &lt;td align="center"&gt;88&lt;/td&gt; 
    &lt;td align="center"&gt;2025.8.13 ‰∏ãÂçà&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;2*D&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.8.13 ‰∏äÂçà&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;S*o&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.8.05&lt;/td&gt; 
    &lt;td align="center"&gt;ÊîØÊåÅ‰∏Ä‰∏ã&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*‰æ†&lt;/td&gt; 
    &lt;td align="center"&gt;10&lt;/td&gt; 
    &lt;td align="center"&gt;2025.8.04&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;x*x&lt;/td&gt; 
    &lt;td align="center"&gt;2&lt;/td&gt; 
    &lt;td align="center"&gt;2025.8.03&lt;/td&gt; 
    &lt;td align="center"&gt;trendRadar Â•ΩÈ°πÁõÆ ÁÇπËµû&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*Ëøú&lt;/td&gt; 
    &lt;td align="center"&gt;1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.8.01&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*ÈÇ™&lt;/td&gt; 
    &lt;td align="center"&gt;5&lt;/td&gt; 
    &lt;td align="center"&gt;2025.8.01&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;*Ê¢¶&lt;/td&gt; 
    &lt;td align="center"&gt;0.1&lt;/td&gt; 
    &lt;td align="center"&gt;2025.7.30&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;**Èæô&lt;/td&gt; 
    &lt;td align="center"&gt;10&lt;/td&gt; 
    &lt;td align="center"&gt;2025.7.29&lt;/td&gt; 
    &lt;td align="center"&gt;ÊîØÊåÅ‰∏Ä‰∏ã&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;h2&gt;‚ú® Ê†∏ÂøÉÂäüËÉΩ&lt;/h2&gt; 
&lt;h3&gt;&lt;strong&gt;ÂÖ®ÁΩëÁÉ≠ÁÇπËÅöÂêà&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Áü•‰πé&lt;/li&gt; 
 &lt;li&gt;ÊäñÈü≥&lt;/li&gt; 
 &lt;li&gt;bilibili ÁÉ≠Êêú&lt;/li&gt; 
 &lt;li&gt;ÂçéÂ∞îË°óËßÅÈóª&lt;/li&gt; 
 &lt;li&gt;Ë¥¥Âêß&lt;/li&gt; 
 &lt;li&gt;ÁôæÂ∫¶ÁÉ≠Êêú&lt;/li&gt; 
 &lt;li&gt;Ë¥¢ËÅîÁ§æÁÉ≠Èó®&lt;/li&gt; 
 &lt;li&gt;ÊæéÊπÉÊñ∞Èóª&lt;/li&gt; 
 &lt;li&gt;Âá§Âá∞ÁΩë&lt;/li&gt; 
 &lt;li&gt;‰ªäÊó•Â§¥Êù°&lt;/li&gt; 
 &lt;li&gt;ÂæÆÂçö&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;ÈªòËÆ§ÁõëÊéß 11 ‰∏™‰∏ªÊµÅÂπ≥Âè∞Ôºå‰πüÂèØËá™Ë°åÂ¢ûÂä†È¢ùÂ§ñÁöÑÂπ≥Âè∞&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üëâ Ëá™ÂÆö‰πâÁõëÊéßÂπ≥Âè∞&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;Êú¨È°πÁõÆÁöÑËµÑËÆØÊï∞ÊçÆÊù•Ê∫ê‰∫é &lt;a href="https://github.com/ourongxing/newsnow"&gt;newsnow&lt;/a&gt; Ôºå‰Ω†ÂèØ‰ª•ÁÇπÂáª&lt;a href="https://newsnow.busiyi.world/"&gt;ÁΩëÁ´ô&lt;/a&gt;ÔºåÁÇπÂáª[Êõ¥Â§ö]ÔºåÊü•ÁúãÊòØÂê¶Êúâ‰Ω†ÊÉ≥Ë¶ÅÁöÑÂπ≥Âè∞„ÄÇ&lt;/p&gt; 
 &lt;p&gt;ÂÖ∑‰ΩìÊ∑ªÂä†ÂèØËÆøÈóÆ &lt;a href="https://github.com/ourongxing/newsnow/tree/main/server/sources"&gt;È°πÁõÆÊ∫ê‰ª£Á†Å&lt;/a&gt;ÔºåÊ†πÊçÆÈáåÈù¢ÁöÑÊñá‰ª∂ÂêçÔºåÂú® &lt;code&gt;config/config.yaml&lt;/code&gt; Êñá‰ª∂‰∏≠‰øÆÊîπ &lt;code&gt;platforms&lt;/code&gt; ÈÖçÁΩÆÔºö&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;platforms:
  - id: "toutiao"
    name: "‰ªäÊó•Â§¥Êù°"
  - id: "baidu"  
    name: "ÁôæÂ∫¶ÁÉ≠Êêú"
  - id: "wallstreetcn-hot"
    name: "ÂçéÂ∞îË°óËßÅÈóª"
  # Ê∑ªÂä†Êõ¥Â§öÂπ≥Âè∞...
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Â¶ÇÊûú‰∏ç‰ºöÁúãÁöÑËØùÔºåÂ∞±Áõ¥Êé•Â§çÂà∂‰ªñ‰∫∫Êï¥ÁêÜÂ•ΩÁöÑÈÉ®ÂàÜ&lt;a href="https://github.com/sansan0/TrendRadar/issues/95"&gt;Âπ≥Âè∞ÈÖçÁΩÆ&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;h3&gt;&lt;strong&gt;Êô∫ËÉΩÊé®ÈÄÅÁ≠ñÁï•&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;‰∏âÁßçÊé®ÈÄÅÊ®°Âºè&lt;/strong&gt;Ôºö&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Ê®°Âºè&lt;/th&gt; 
   &lt;th&gt;ÈÄÇÁî®‰∫∫Áæ§&lt;/th&gt; 
   &lt;th&gt;Êé®ÈÄÅÊó∂Êú∫&lt;/th&gt; 
   &lt;th&gt;ÊòæÁ§∫ÂÜÖÂÆπ&lt;/th&gt; 
   &lt;th&gt;ÈÄÇÁî®Âú∫ÊôØ&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ÂΩìÊó•Ê±áÊÄª&lt;/strong&gt;&lt;br /&gt;&lt;code&gt;daily&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;üìã ‰ºÅ‰∏öÁÆ°ÁêÜËÄÖ/ÊôÆÈÄöÁî®Êà∑&lt;/td&gt; 
   &lt;td&gt;ÊåâÊó∂Êé®ÈÄÅ(ÈªòËÆ§ÊØèÂ∞èÊó∂Êé®ÈÄÅ‰∏ÄÊ¨°)&lt;/td&gt; 
   &lt;td&gt;ÂΩìÊó•ÊâÄÊúâÂåπÈÖçÊñ∞Èóª&lt;br /&gt;+ Êñ∞Â¢ûÊñ∞ÈóªÂå∫Âüü&lt;/td&gt; 
   &lt;td&gt;Êó•Êä•ÊÄªÁªì&lt;br /&gt;ÂÖ®Èù¢‰∫ÜËß£ÂΩìÊó•ÁÉ≠ÁÇπË∂ãÂäø&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ÂΩìÂâçÊ¶úÂçï&lt;/strong&gt;&lt;br /&gt;&lt;code&gt;current&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;üì∞ Ëá™Â™í‰Ωì‰∫∫/ÂÜÖÂÆπÂàõ‰ΩúËÄÖ&lt;/td&gt; 
   &lt;td&gt;ÊåâÊó∂Êé®ÈÄÅ(ÈªòËÆ§ÊØèÂ∞èÊó∂Êé®ÈÄÅ‰∏ÄÊ¨°)&lt;/td&gt; 
   &lt;td&gt;ÂΩìÂâçÊ¶úÂçïÂåπÈÖçÊñ∞Èóª&lt;br /&gt;+ Êñ∞Â¢ûÊñ∞ÈóªÂå∫Âüü&lt;/td&gt; 
   &lt;td&gt;ÂÆûÊó∂ÁÉ≠ÁÇπËøΩË∏™&lt;br /&gt;‰∫ÜËß£ÂΩìÂâçÊúÄÁÅ´ÁöÑÂÜÖÂÆπ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Â¢ûÈáèÁõëÊéß&lt;/strong&gt;&lt;br /&gt;&lt;code&gt;incremental&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;üìà ÊäïËµÑËÄÖ/‰∫§ÊòìÂëò&lt;/td&gt; 
   &lt;td&gt;ÊúâÊñ∞Â¢ûÊâçÊé®ÈÄÅ&lt;/td&gt; 
   &lt;td&gt;Êñ∞Âá∫Áé∞ÁöÑÂåπÈÖçÈ¢ëÁéáËØçÊñ∞Èóª&lt;/td&gt; 
   &lt;td&gt;ÈÅøÂÖçÈáçÂ§ç‰ø°ÊÅØÂπ≤Êâ∞&lt;br /&gt;È´òÈ¢ëÁõëÊéßÂú∫ÊôØ&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;ÈôÑÂä†ÂäüËÉΩ - Êé®ÈÄÅÊó∂Èó¥Á™óÂè£ÊéßÂà∂&lt;/strong&gt;ÔºàÂèØÈÄâÔºâÔºö&lt;/p&gt; 
&lt;p&gt;Ê≠§ÂäüËÉΩÁã¨Á´ã‰∫é‰∏äËø∞‰∏âÁßçÊé®ÈÄÅÊ®°Âºè,ÂèØ‰∏é‰ªªÊÑèÊ®°ÂºèÊê≠ÈÖç‰ΩøÁî®:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Êó∂Èó¥Á™óÂè£ÈôêÂà∂&lt;/strong&gt;: ËÆæÂÆöÊé®ÈÄÅÊó∂Èó¥ËåÉÂõ¥ÔºàÂ¶Ç 09:00-18:00 Êàñ 20:00-22:00Ôºâ,Âè™Âú®ÊåáÂÆöÊó∂Èó¥ÂÜÖÊé®ÈÄÅ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Êé®ÈÄÅÈ¢ëÁéáÊéßÂà∂&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;Á™óÂè£ÂÜÖÂ§öÊ¨°Êé®ÈÄÅ: Êó∂Èó¥Á™óÂè£ÂÜÖÊØèÊ¨°ÊâßË°åÈÉΩÊé®ÈÄÅ&lt;/li&gt; 
   &lt;li&gt;ÊØèÂ§©‰ªÖÊé®ÈÄÅ‰∏ÄÊ¨°: Êó∂Èó¥Á™óÂè£ÂÜÖÂè™Êé®ÈÄÅ‰∏ÄÊ¨°ÔºàÈÄÇÂêàÂΩìÊó•Ê±áÊÄªÊàñÂΩìÂâçÊ¶úÂçïÊ®°ÂºèÔºâ&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÂÖ∏ÂûãÂú∫ÊôØ&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;Â∑•‰ΩúÊó∂Èó¥Êé®ÈÄÅ: Âè™Âú®Â∑•‰ΩúÊó• 09:00-18:00 Êé•Êî∂Ê∂àÊÅØ&lt;/li&gt; 
   &lt;li&gt;ÊôöÈó¥Ê±áÊÄªÊé®ÈÄÅ: Â∏åÊúõÂú®Êôö‰∏äÂõ∫ÂÆöÊó∂Èó¥ÔºàÂ¶Ç 20:00-22:00ÔºâÊî∂Âà∞Ê±áÊÄª&lt;/li&gt; 
   &lt;li&gt;ÈÅøÂÖçÊâìÊâ∞: Èò≤Ê≠¢ÈùûÂ∑•‰ΩúÊó∂Èó¥Êî∂Âà∞Êé®ÈÄÅÈÄöÁü•&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ÊèêÁ§∫: Ê≠§ÂäüËÉΩÈªòËÆ§ÂÖ≥Èó≠,ÈúÄÂú® &lt;code&gt;config/config.yaml&lt;/code&gt; ‰∏≠ÊâãÂä®ÂêØÁî® &lt;code&gt;push_window.enabled&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;&lt;strong&gt;Á≤æÂáÜÂÜÖÂÆπÁ≠õÈÄâ&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;ËÆæÁΩÆ‰∏™‰∫∫ÂÖ≥ÈîÆËØçÔºàÂ¶ÇÔºöAI„ÄÅÊØî‰∫öËø™„ÄÅÊïôËÇ≤ÊîøÁ≠ñÔºâÔºåÂè™Êé®ÈÄÅÁõ∏ÂÖ≥ÁÉ≠ÁÇπÔºåËøáÊª§Êó†ÂÖ≥‰ø°ÊÅØ&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ÊîØÊåÅÊôÆÈÄöËØç„ÄÅÂøÖÈ°ªËØç(+)„ÄÅËøáÊª§ËØç(!)‰∏âÁßçËØ≠Ê≥ïÔºåËßÅ„Äêfrequency_words.txt ÈÖçÁΩÆÊïôÁ®ã„Äë&lt;/li&gt; 
 &lt;li&gt;ËØçÁªÑÂåñÁÆ°ÁêÜÔºåÁã¨Á´ãÁªüËÆ°‰∏çÂêå‰∏ªÈ¢òÁÉ≠ÁÇπ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;‰πüÂèØ‰ª•‰∏çÂÅöÁ≠õÈÄâÔºåÂÆåÊï¥ÁöÑÊé®ÈÄÅÊâÄÊúâÁÉ≠ÁÇπÔºåÂÖ∑‰ΩìËßÅ„ÄêÂéÜÂè≤Êõ¥Êñ∞„Äë‰∏≠ÁöÑ v2.0.1&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üëâ frequency_words.txt ÈÖçÁΩÆÊïôÁ®ã&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;Âú® &lt;code&gt;frequency_words.txt&lt;/code&gt; Êñá‰ª∂‰∏≠ÈÖçÁΩÆÁõëÊéßÁöÑÂÖ≥ÈîÆËØçÔºåÊîØÊåÅ‰∏âÁßçËØ≠Ê≥ïÂíåËØçÁªÑÂäüËÉΩ„ÄÇ&lt;/p&gt; 
 &lt;p&gt;ÂÖ≥ÈîÆËØçË∂äÈù†ÂâçÔºåÊñ∞ÈóªÁöÑ‰ºòÂÖàÁ∫ßË∂äÈ´òÔºå‰Ω†ÂèØ‰ª•Ê†πÊçÆËá™Â∑±ÁöÑÂÖ≥Ê≥®Â∫¶Ë∞ÉÊï¥ÂÖ≥ÈîÆËØçÈ°∫Â∫è&lt;/p&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;ËØ≠Ê≥ïÁ±ªÂûã&lt;/th&gt; 
    &lt;th&gt;Á¨¶Âè∑&lt;/th&gt; 
    &lt;th&gt;‰ΩúÁî®&lt;/th&gt; 
    &lt;th&gt;Á§∫‰æã&lt;/th&gt; 
    &lt;th&gt;ÂåπÈÖçÈÄªËæë&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;ÊôÆÈÄöËØç&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;Êó†&lt;/td&gt; 
    &lt;td&gt;Âü∫Á°ÄÂåπÈÖç&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;Âçé‰∏∫&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;ÂåÖÂê´‰ªªÊÑè‰∏Ä‰∏™Âç≥ÂèØ&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;ÂøÖÈ°ªËØç&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;+&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;ÈôêÂÆöËåÉÂõ¥&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;+ÊâãÊú∫&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;ÂøÖÈ°ªÂêåÊó∂ÂåÖÂê´&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;ËøáÊª§ËØç&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;!&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;ÊéíÈô§Âπ≤Êâ∞&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;!ÂπøÂëä&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;ÂåÖÂê´ÂàôÁõ¥Êé•ÊéíÈô§&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;h3&gt;üìã Âü∫Á°ÄËØ≠Ê≥ïËØ¥Êòé&lt;/h3&gt; 
 &lt;h4&gt;1. &lt;strong&gt;ÊôÆÈÄöÂÖ≥ÈîÆËØç&lt;/strong&gt; - Âü∫Á°ÄÂåπÈÖç&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-txt"&gt;Âçé‰∏∫
OPPO
ËãπÊûú
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;‰ΩúÁî®Ôºö&lt;/strong&gt; Êñ∞ÈóªÊ†áÈ¢òÂåÖÂê´ÂÖ∂‰∏≠&lt;strong&gt;‰ªªÊÑè‰∏Ä‰∏™ËØç&lt;/strong&gt;Â∞±‰ºöË¢´ÊçïËé∑&lt;/p&gt; 
 &lt;h4&gt;2. &lt;strong&gt;ÂøÖÈ°ªËØç&lt;/strong&gt; &lt;code&gt;+ËØçÊ±á&lt;/code&gt; - ÈôêÂÆöËåÉÂõ¥&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-txt"&gt;Âçé‰∏∫
OPPO
+ÊâãÊú∫
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;‰ΩúÁî®Ôºö&lt;/strong&gt; ÂøÖÈ°ªÂêåÊó∂ÂåÖÂê´ÊôÆÈÄöËØç&lt;strong&gt;Âíå&lt;/strong&gt;ÂøÖÈ°ªËØçÊâç‰ºöË¢´ÊçïËé∑&lt;/p&gt; 
 &lt;h4&gt;3. &lt;strong&gt;ËøáÊª§ËØç&lt;/strong&gt; &lt;code&gt;!ËØçÊ±á&lt;/code&gt; - ÊéíÈô§Âπ≤Êâ∞&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-txt"&gt;ËãπÊûú
Âçé‰∏∫
!Ê∞¥Êûú
!‰ª∑Ê†º
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;‰ΩúÁî®Ôºö&lt;/strong&gt; ÂåÖÂê´ËøáÊª§ËØçÁöÑÊñ∞Èóª‰ºöË¢´&lt;strong&gt;Áõ¥Êé•ÊéíÈô§&lt;/strong&gt;ÔºåÂç≥‰ΩøÂåÖÂê´ÂÖ≥ÈîÆËØç&lt;/p&gt; 
 &lt;h3&gt;üîó ËØçÁªÑÂäüËÉΩ - Á©∫Ë°åÂàÜÈöîÁöÑÈáçË¶Å‰ΩúÁî®&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;Ê†∏ÂøÉËßÑÂàôÔºö&lt;/strong&gt; Áî®&lt;strong&gt;Á©∫Ë°å&lt;/strong&gt;ÂàÜÈöî‰∏çÂêåÁöÑËØçÁªÑÔºåÊØè‰∏™ËØçÁªÑÁã¨Á´ãÁªüËÆ°&lt;/p&gt; 
 &lt;h4&gt;Á§∫‰æãÈÖçÁΩÆÔºö&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-txt"&gt;iPhone
Âçé‰∏∫
OPPO
+ÂèëÂ∏É

AËÇ°
‰∏äËØÅ
Ê∑±ËØÅ
+Ê∂®Ë∑å
!È¢ÑÊµã

‰∏ñÁïåÊùØ
Ê¨ßÊ¥≤ÊùØ
‰∫öÊ¥≤ÊùØ
+ÊØîËµõ
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;ËØçÁªÑËß£ÈáäÂèäÂåπÈÖçÊïàÊûúÔºö&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;Á¨¨1ÁªÑ - ÊâãÊú∫Êñ∞ÂìÅÁ±ªÔºö&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ÂÖ≥ÈîÆËØçÔºöiPhone„ÄÅÂçé‰∏∫„ÄÅOPPO&lt;/li&gt; 
  &lt;li&gt;ÂøÖÈ°ªËØçÔºöÂèëÂ∏É&lt;/li&gt; 
  &lt;li&gt;ÊïàÊûúÔºöÂøÖÈ°ªÂåÖÂê´ÊâãÊú∫ÂìÅÁâåÂêçÔºåÂêåÊó∂ÂåÖÂê´"ÂèëÂ∏É"&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;ÂåπÈÖçÁ§∫‰æãÔºö&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;‚úÖ "iPhone 15Ê≠£ÂºèÂèëÂ∏ÉÂîÆ‰ª∑ÂÖ¨Â∏É" ‚Üê Êúâ"iPhone"+"ÂèëÂ∏É"&lt;/li&gt; 
  &lt;li&gt;‚úÖ "Âçé‰∏∫Mate60Á≥ªÂàóÂèëÂ∏É‰ºöÁõ¥Êí≠" ‚Üê Êúâ"Âçé‰∏∫"+"ÂèëÂ∏É"&lt;/li&gt; 
  &lt;li&gt;‚úÖ "OPPO Find X7ÂèëÂ∏ÉÊó∂Èó¥Á°ÆÂÆö" ‚Üê Êúâ"OPPO"+"ÂèëÂ∏É"&lt;/li&gt; 
  &lt;li&gt;‚ùå "iPhoneÈîÄÈáèÂàõÊñ∞È´ò" ‚Üê Êúâ"iPhone"‰ΩÜÁº∫Â∞ë"ÂèëÂ∏É"&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;Á¨¨2ÁªÑ - ËÇ°Â∏ÇË°åÊÉÖÁ±ªÔºö&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ÂÖ≥ÈîÆËØçÔºöAËÇ°„ÄÅ‰∏äËØÅ„ÄÅÊ∑±ËØÅ&lt;/li&gt; 
  &lt;li&gt;ÂøÖÈ°ªËØçÔºöÊ∂®Ë∑å&lt;/li&gt; 
  &lt;li&gt;ËøáÊª§ËØçÔºöÈ¢ÑÊµã&lt;/li&gt; 
  &lt;li&gt;ÊïàÊûúÔºöÂåÖÂê´ËÇ°Â∏ÇÁõ∏ÂÖ≥ËØçÔºåÂêåÊó∂ÂåÖÂê´"Ê∂®Ë∑å"Ôºå‰ΩÜÊéíÈô§ÂåÖÂê´"È¢ÑÊµã"ÁöÑÂÜÖÂÆπ&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;ÂåπÈÖçÁ§∫‰æãÔºö&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;‚úÖ "AËÇ°‰ªäÊó•Â§ßÂπÖÊ∂®Ë∑åÂàÜÊûê" ‚Üê Êúâ"AËÇ°"+"Ê∂®Ë∑å"&lt;/li&gt; 
  &lt;li&gt;‚úÖ "‰∏äËØÅÊåáÊï∞Ê∂®Ë∑åÂéüÂõ†Ëß£ËØª" ‚Üê Êúâ"‰∏äËØÅ"+"Ê∂®Ë∑å"&lt;/li&gt; 
  &lt;li&gt;‚ùå "‰∏ìÂÆ∂È¢ÑÊµãAËÇ°Ê∂®Ë∑åË∂ãÂäø" ‚Üê Êúâ"AËÇ°"+"Ê∂®Ë∑å"‰ΩÜÂåÖÂê´"È¢ÑÊµã"&lt;/li&gt; 
  &lt;li&gt;‚ùå "AËÇ°Êàê‰∫§ÈáèÂàõÊñ∞È´ò" ‚Üê Êúâ"AËÇ°"‰ΩÜÁº∫Â∞ë"Ê∂®Ë∑å"&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;Á¨¨3ÁªÑ - Ë∂≥ÁêÉËµõ‰∫ãÁ±ªÔºö&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ÂÖ≥ÈîÆËØçÔºö‰∏ñÁïåÊùØ„ÄÅÊ¨ßÊ¥≤ÊùØ„ÄÅ‰∫öÊ¥≤ÊùØ&lt;/li&gt; 
  &lt;li&gt;ÂøÖÈ°ªËØçÔºöÊØîËµõ&lt;/li&gt; 
  &lt;li&gt;ÊïàÊûúÔºöÂøÖÈ°ªÂåÖÂê´ÊùØËµõÂêçÁß∞ÔºåÂêåÊó∂ÂåÖÂê´"ÊØîËµõ"&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;ÂåπÈÖçÁ§∫‰æãÔºö&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;‚úÖ "‰∏ñÁïåÊùØÂ∞èÁªÑËµõÊØîËµõÁªìÊûú" ‚Üê Êúâ"‰∏ñÁïåÊùØ"+"ÊØîËµõ"&lt;/li&gt; 
  &lt;li&gt;‚úÖ "Ê¨ßÊ¥≤ÊùØÂÜ≥ËµõÊØîËµõÊó∂Èó¥" ‚Üê Êúâ"Ê¨ßÊ¥≤ÊùØ"+"ÊØîËµõ"&lt;/li&gt; 
  &lt;li&gt;‚ùå "‰∏ñÁïåÊùØÈó®Á•®ÂºÄÂîÆ" ‚Üê Êúâ"‰∏ñÁïåÊùØ"‰ΩÜÁº∫Â∞ë"ÊØîËµõ"&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;üéØ ÈÖçÁΩÆÊäÄÂ∑ß&lt;/h3&gt; 
 &lt;h4&gt;1. &lt;strong&gt;‰ªéÂÆΩÂà∞‰∏•ÁöÑÈÖçÁΩÆÁ≠ñÁï•&lt;/strong&gt;&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-txt"&gt;# Á¨¨‰∏ÄÊ≠•ÔºöÂÖàÁî®ÂÆΩÊ≥õÂÖ≥ÈîÆËØçÊµãËØï
‰∫∫Â∑•Êô∫ËÉΩ
AI
ChatGPT

# Á¨¨‰∫åÊ≠•ÔºöÂèëÁé∞ËØØÂåπÈÖçÂêéÔºåÂä†ÂÖ•ÂøÖÈ°ªËØçÈôêÂÆö
‰∫∫Â∑•Êô∫ËÉΩ  
AI
ChatGPT
+ÊäÄÊúØ

# Á¨¨‰∏âÊ≠•ÔºöÂèëÁé∞Âπ≤Êâ∞ÂÜÖÂÆπÂêéÔºåÂä†ÂÖ•ËøáÊª§ËØç
‰∫∫Â∑•Êô∫ËÉΩ
AI  
ChatGPT
+ÊäÄÊúØ
!ÂπøÂëä
!ÂüπËÆ≠
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;2. &lt;strong&gt;ÈÅøÂÖçËøáÂ∫¶Â§çÊùÇ&lt;/strong&gt;&lt;/h4&gt; 
 &lt;p&gt;‚ùå &lt;strong&gt;‰∏çÊé®ËçêÔºö&lt;/strong&gt; ‰∏Ä‰∏™ËØçÁªÑÂåÖÂê´Â§™Â§öËØçÊ±á&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-txt"&gt;Âçé‰∏∫
OPPO
ËãπÊûú
‰∏âÊòü
vivo
‰∏ÄÂä†
È≠ÖÊóè
+ÊâãÊú∫
+ÂèëÂ∏É
+ÈîÄÈáè
!ÂÅáË¥ß
!Áª¥‰øÆ
!‰∫åÊâã
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;‚úÖ &lt;strong&gt;Êé®ËçêÔºö&lt;/strong&gt; ÊãÜÂàÜÊàêÂ§ö‰∏™Á≤æÁ°ÆÁöÑËØçÁªÑ&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-txt"&gt;Âçé‰∏∫
OPPO
+Êñ∞ÂìÅ

ËãπÊûú
‰∏âÊòü  
+ÂèëÂ∏É

ÊâãÊú∫
ÈîÄÈáè
+Â∏ÇÂú∫
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;&lt;strong&gt;ÁÉ≠ÁÇπË∂ãÂäøÂàÜÊûê&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;ÂÆûÊó∂ËøΩË∏™Êñ∞ÈóªÁÉ≠Â∫¶ÂèòÂåñÔºåËÆ©‰Ω†‰∏ç‰ªÖÁü•ÈÅì"‰ªÄ‰πàÂú®ÁÉ≠Êêú"ÔºåÊõ¥‰∫ÜËß£"ÁÉ≠ÁÇπÂ¶Ç‰ΩïÊºîÂèò"&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Êó∂Èó¥ËΩ¥ËøΩË∏™&lt;/strong&gt;ÔºöËÆ∞ÂΩïÊØèÊù°Êñ∞Èóª‰ªéÈ¶ñÊ¨°Âá∫Áé∞Âà∞ÊúÄÂêéÂá∫Áé∞ÁöÑÂÆåÊï¥Êó∂Èó¥Ë∑®Â∫¶&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÁÉ≠Â∫¶ÂèòÂåñ&lt;/strong&gt;ÔºöÁªüËÆ°Êñ∞ÈóªÂú®‰∏çÂêåÊó∂Èó¥ÊÆµÁöÑÊéíÂêçÂèòÂåñÂíåÂá∫Áé∞È¢ëÊ¨°&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Êñ∞Â¢ûÊ£ÄÊµã&lt;/strong&gt;ÔºöÂÆûÊó∂ËØÜÂà´Êñ∞Âá∫Áé∞ÁöÑÁÉ≠ÁÇπËØùÈ¢òÔºåÁî®üÜïÊ†áËÆ∞Á¨¨‰∏ÄÊó∂Èó¥ÊèêÈÜí&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÊåÅÁª≠ÊÄßÂàÜÊûê&lt;/strong&gt;ÔºöÂå∫ÂàÜ‰∏ÄÊ¨°ÊÄßÁÉ≠ÁÇπËØùÈ¢òÂíåÊåÅÁª≠ÂèëÈÖµÁöÑÊ∑±Â∫¶Êñ∞Èóª&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ë∑®Âπ≥Âè∞ÂØπÊØî&lt;/strong&gt;ÔºöÂêå‰∏ÄÊñ∞ÈóªÂú®‰∏çÂêåÂπ≥Âè∞ÁöÑÊéíÂêçË°®Áé∞ÔºåÁúãÂá∫Â™í‰ΩìÂÖ≥Ê≥®Â∫¶Â∑ÆÂºÇ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;‰∏çÂÜçÈîôËøáÈáçË¶ÅÊñ∞ÈóªÁöÑÂÆåÊï¥ÂèëÂ±ïËøáÁ®ãÔºå‰ªéËØùÈ¢òËêåËäΩÂà∞È´òÂ≥∞ÁÉ≠ËÆÆÔºåÂÖ®Á®ãÊéåÊè°&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üëâ Êé®ÈÄÅÊ†ºÂºèËØ¥Êòé&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;üìä ÁÉ≠ÁÇπËØçÊ±áÁªüËÆ°&lt;/p&gt; 
 &lt;p&gt;üî• [1/3] AI ChatGPT : 2 Êù°&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;[ÁôæÂ∫¶ÁÉ≠Êêú] üÜï ChatGPT-5Ê≠£ÂºèÂèëÂ∏É [&lt;strong&gt;1&lt;/strong&gt;] - 09Êó∂15ÂàÜ (1Ê¨°)&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;[‰ªäÊó•Â§¥Êù°] AIËäØÁâáÊ¶ÇÂøµËÇ°Êö¥Ê∂® [&lt;strong&gt;3&lt;/strong&gt;] - [08Êó∂30ÂàÜ ~ 10Êó∂45ÂàÜ] (3Ê¨°)&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ&lt;/p&gt; 
 &lt;p&gt;üìà [2/3] ÊØî‰∫öËø™ ÁâπÊñØÊãâ : 2 Êù°&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;[ÂæÆÂçö] üÜï ÊØî‰∫öËø™ÊúàÈîÄÈáèÁ†¥Á∫™ÂΩï [&lt;strong&gt;2&lt;/strong&gt;] - 10Êó∂20ÂàÜ (1Ê¨°)&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;[ÊäñÈü≥] ÁâπÊñØÊãâÈôç‰ª∑‰øÉÈîÄ [&lt;strong&gt;4&lt;/strong&gt;] - [07Êó∂45ÂàÜ ~ 09Êó∂15ÂàÜ] (2Ê¨°)&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ&lt;/p&gt; 
 &lt;p&gt;üìå [3/3] AËÇ° ËÇ°Â∏Ç : 1 Êù°&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;[ÂçéÂ∞îË°óËßÅÈóª] AËÇ°ÂçàÁõòÁÇπËØÑÂàÜÊûê [&lt;strong&gt;5&lt;/strong&gt;] - [11Êó∂30ÂàÜ ~ 12Êó∂00ÂàÜ] (2Ê¨°)&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;üÜï Êú¨Ê¨°Êñ∞Â¢ûÁÉ≠ÁÇπÊñ∞Èóª (ÂÖ± 2 Êù°)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;ÁôæÂ∫¶ÁÉ≠Êêú&lt;/strong&gt; (1 Êù°):&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;ChatGPT-5Ê≠£ÂºèÂèëÂ∏É [&lt;strong&gt;1&lt;/strong&gt;]&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;&lt;strong&gt;ÂæÆÂçö&lt;/strong&gt; (1 Êù°):&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;ÊØî‰∫öËø™ÊúàÈîÄÈáèÁ†¥Á∫™ÂΩï [&lt;strong&gt;2&lt;/strong&gt;]&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;Êõ¥Êñ∞Êó∂Èó¥Ôºö2025-01-15 12:30:15&lt;/p&gt; 
 &lt;h2&gt;&lt;strong&gt;Ê∂àÊÅØÊ†ºÂºèËØ¥Êòé&lt;/strong&gt;&lt;/h2&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Ê†ºÂºèÂÖÉÁ¥†&lt;/th&gt; 
    &lt;th&gt;Á§∫‰æã&lt;/th&gt; 
    &lt;th&gt;Âê´‰πâ&lt;/th&gt; 
    &lt;th&gt;ËØ¥Êòé&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;üî•üìàüìå&lt;/td&gt; 
    &lt;td&gt;üî• [1/3] AI ChatGPT&lt;/td&gt; 
    &lt;td&gt;ÁÉ≠Â∫¶Á≠âÁ∫ß&lt;/td&gt; 
    &lt;td&gt;üî•È´òÁÉ≠Â∫¶(‚â•10Êù°) üìà‰∏≠ÁÉ≠Â∫¶(5-9Êù°) üìåÊôÆÈÄöÁÉ≠Â∫¶(&amp;lt;5Êù°)&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;[Â∫èÂè∑/ÊÄªÊï∞]&lt;/td&gt; 
    &lt;td&gt;[1/3]&lt;/td&gt; 
    &lt;td&gt;ÊéíÂ∫è‰ΩçÁΩÆ&lt;/td&gt; 
    &lt;td&gt;ÂΩìÂâçËØçÁªÑÂú®ÊâÄÊúâÂåπÈÖçËØçÁªÑ‰∏≠ÁöÑÊéíÂêç&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;È¢ëÁéáËØçÁªÑ&lt;/td&gt; 
    &lt;td&gt;AI ChatGPT&lt;/td&gt; 
    &lt;td&gt;ÂÖ≥ÈîÆËØçÁªÑ&lt;/td&gt; 
    &lt;td&gt;ÈÖçÁΩÆÊñá‰ª∂‰∏≠ÁöÑËØçÁªÑÔºåÊ†áÈ¢òÂøÖÈ°ªÂåÖÂê´ÂÖ∂‰∏≠ËØçÊ±á&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;: N Êù°&lt;/td&gt; 
    &lt;td&gt;: 2 Êù°&lt;/td&gt; 
    &lt;td&gt;ÂåπÈÖçÊï∞Èáè&lt;/td&gt; 
    &lt;td&gt;ËØ•ËØçÁªÑÂåπÈÖçÁöÑÊñ∞ÈóªÊÄªÊï∞&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;[Âπ≥Âè∞Âêç]&lt;/td&gt; 
    &lt;td&gt;[ÁôæÂ∫¶ÁÉ≠Êêú]&lt;/td&gt; 
    &lt;td&gt;Êù•Ê∫êÂπ≥Âè∞&lt;/td&gt; 
    &lt;td&gt;Êñ∞ÈóªÊâÄÂ±ûÁöÑÂπ≥Âè∞ÂêçÁß∞&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;üÜï&lt;/td&gt; 
    &lt;td&gt;üÜï ChatGPT-5Ê≠£ÂºèÂèëÂ∏É&lt;/td&gt; 
    &lt;td&gt;Êñ∞Â¢ûÊ†áËÆ∞&lt;/td&gt; 
    &lt;td&gt;Êú¨ËΩÆÊäìÂèñ‰∏≠È¶ñÊ¨°Âá∫Áé∞ÁöÑÁÉ≠ÁÇπ&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;[&lt;strong&gt;Êï∞Â≠ó&lt;/strong&gt;]&lt;/td&gt; 
    &lt;td&gt;[&lt;strong&gt;1&lt;/strong&gt;]&lt;/td&gt; 
    &lt;td&gt;È´òÊéíÂêç&lt;/td&gt; 
    &lt;td&gt;ÊéíÂêç‚â§ÈòàÂÄºÁöÑÁÉ≠ÊêúÔºåÁ∫¢Ëâ≤Âä†Á≤óÊòæÁ§∫&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;[Êï∞Â≠ó]&lt;/td&gt; 
    &lt;td&gt;[7]&lt;/td&gt; 
    &lt;td&gt;ÊôÆÈÄöÊéíÂêç&lt;/td&gt; 
    &lt;td&gt;ÊéíÂêç&amp;gt;ÈòàÂÄºÁöÑÁÉ≠ÊêúÔºåÊôÆÈÄöÊòæÁ§∫&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;- Êó∂Èó¥&lt;/td&gt; 
    &lt;td&gt;- 09Êó∂15ÂàÜ&lt;/td&gt; 
    &lt;td&gt;È¶ñÊ¨°Êó∂Èó¥&lt;/td&gt; 
    &lt;td&gt;ËØ•Êñ∞ÈóªÈ¶ñÊ¨°Ë¢´ÂèëÁé∞ÁöÑÊó∂Èó¥&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;[Êó∂Èó¥~Êó∂Èó¥]&lt;/td&gt; 
    &lt;td&gt;[08Êó∂30ÂàÜ ~ 10Êó∂45ÂàÜ]&lt;/td&gt; 
    &lt;td&gt;ÊåÅÁª≠Êó∂Èó¥&lt;/td&gt; 
    &lt;td&gt;‰ªéÈ¶ñÊ¨°Âá∫Áé∞Âà∞ÊúÄÂêéÂá∫Áé∞ÁöÑÊó∂Èó¥ËåÉÂõ¥&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;(NÊ¨°)&lt;/td&gt; 
    &lt;td&gt;(3Ê¨°)&lt;/td&gt; 
    &lt;td&gt;Âá∫Áé∞È¢ëÁéá&lt;/td&gt; 
    &lt;td&gt;Âú®ÁõëÊéßÊúüÈó¥Âá∫Áé∞ÁöÑÊÄªÊ¨°Êï∞&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Êñ∞Â¢ûÂå∫Âüü&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;üÜï &lt;strong&gt;Êú¨Ê¨°Êñ∞Â¢ûÁÉ≠ÁÇπÊñ∞Èóª&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;Êñ∞ËØùÈ¢òÊ±áÊÄª&lt;/td&gt; 
    &lt;td&gt;ÂçïÁã¨Â±ïÁ§∫Êú¨ËΩÆÊñ∞Âá∫Áé∞ÁöÑÁÉ≠ÁÇπËØùÈ¢ò&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;h3&gt;&lt;strong&gt;‰∏™ÊÄßÂåñÁÉ≠ÁÇπÁÆóÊ≥ï&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;‰∏çÂÜçË¢´ÂêÑ‰∏™Âπ≥Âè∞ÁöÑÁÆóÊ≥ïÁâµÁùÄËµ∞ÔºåTrendRadar ‰ºöÈáçÊñ∞Êï¥ÁêÜÂÖ®ÁΩëÁÉ≠ÊêúÔºö&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ÁúãÈáçÊéíÂêçÈ´òÁöÑÊñ∞Èóª&lt;/strong&gt;ÔºàÂç†60%ÔºâÔºöÂêÑÂπ≥Âè∞ÂâçÂá†ÂêçÁöÑÊñ∞Èóª‰ºòÂÖàÊòæÁ§∫&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÂÖ≥Ê≥®ÊåÅÁª≠Âá∫Áé∞ÁöÑËØùÈ¢ò&lt;/strong&gt;ÔºàÂç†30%ÔºâÔºöÂèçÂ§çÂá∫Áé∞ÁöÑÊñ∞ÈóªÊõ¥ÈáçË¶Å&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ËÄÉËôëÊéíÂêçË¥®Èáè&lt;/strong&gt;ÔºàÂç†10%ÔºâÔºö‰∏ç‰ªÖÂ§öÊ¨°Âá∫Áé∞ÔºåËøòÁªèÂ∏∏ÊéíÂú®ÂâçÂàó&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ÊääÂàÜÊï£Âú®ÂêÑ‰∏™Âπ≥Âè∞ÁöÑÁÉ≠ÊêúÂêàÂπ∂Ëµ∑Êù•ÔºåÊåâÁÖß‰Ω†ÂÖ≥ÂøÉÁöÑÁÉ≠Â∫¶ÈáçÊñ∞ÊéíÂ∫èÔºåËøô‰∏â‰∏™ÊØî‰æãÂèØ‰ª•ÈÄâÊã©ÈÄÇÂêàËá™Â∑±ÁöÑÂú∫ÊôØËøõË°åË∞ÉÊï¥&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üëâ ÁÉ≠ÁÇπÊùÉÈáçË∞ÉÊï¥&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;ÂΩìÂâçÈªòËÆ§ÁöÑÈÖçÁΩÆÊòØÂπ≥Ë°°ÊÄßÈÖçÁΩÆ&lt;/p&gt; 
 &lt;h3&gt;‰∏§‰∏™Ê†∏ÂøÉÂú∫ÊôØ&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;ËøΩÂÆûÊó∂ÁÉ≠ÁÇπÂûã&lt;/strong&gt;Ôºö&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;weight:
  rank_weight: 0.8    # ‰∏ªË¶ÅÁúãÊéíÂêç
  frequency_weight: 0.1  # ‰∏çÂ§™Âú®‰πéÊåÅÁª≠ÊÄß
  hotness_weight: 0.1
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;ÈÄÇÁî®‰∫∫Áæ§&lt;/strong&gt;ÔºöËá™Â™í‰ΩìÂçö‰∏ª„ÄÅËê•ÈîÄ‰∫∫Âëò„ÄÅÊÉ≥Âø´ÈÄü‰∫ÜËß£ÂΩì‰∏ãÊúÄÁÅ´ËØùÈ¢òÁöÑÁî®Êà∑&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;ËøΩÊ∑±Â∫¶ËØùÈ¢òÂûã&lt;/strong&gt;Ôºö&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;weight:
  rank_weight: 0.4    # ÈÄÇÂ∫¶ÁúãÊéíÂêç
  frequency_weight: 0.5  # ÈáçËßÜÂΩìÂ§©ÂÜÖÁöÑÊåÅÁª≠ÁÉ≠Â∫¶
  hotness_weight: 0.1
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;ÈÄÇÁî®‰∫∫Áæ§&lt;/strong&gt;ÔºöÊäïËµÑËÄÖ„ÄÅÁ†îÁ©∂‰∫∫Âëò„ÄÅÊñ∞ÈóªÂ∑•‰ΩúËÄÖ„ÄÅÈúÄË¶ÅÊ∑±Â∫¶ÂàÜÊûêË∂ãÂäøÁöÑÁî®Êà∑&lt;/p&gt; 
 &lt;h3&gt;Ë∞ÉÊï¥ÁöÑÊñπÊ≥ï&lt;/h3&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;strong&gt;‰∏â‰∏™Êï∞Â≠óÂä†Ëµ∑Êù•ÂøÖÈ°ªÁ≠â‰∫é 1.0&lt;/strong&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Âì™‰∏™ÈáçË¶ÅÂ∞±Ë∞ÉÂ§ßÂì™‰∏™&lt;/strong&gt;ÔºöÂú®‰πéÊéíÂêçÂ∞±Ë∞ÉÂ§ß rank_weightÔºåÂú®‰πéÊåÅÁª≠ÊÄßÂ∞±Ë∞ÉÂ§ß frequency_weight&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Âª∫ËÆÆÊØèÊ¨°Âè™Ë∞É 0.1-0.2&lt;/strong&gt;ÔºåËßÇÂØüÊïàÊûú&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;Ê†∏ÂøÉÊÄùË∑ØÔºöËøΩÊ±ÇÈÄüÂ∫¶ÂíåÊó∂ÊïàÊÄßÁöÑÁî®Êà∑ÊèêÈ´òÊéíÂêçÊùÉÈáçÔºåËøΩÊ±ÇÊ∑±Â∫¶ÂíåÁ®≥ÂÆöÊÄßÁöÑÁî®Êà∑ÊèêÈ´òÈ¢ëÊ¨°ÊùÉÈáç„ÄÇ&lt;/p&gt; 
&lt;/details&gt; 
&lt;h3&gt;&lt;strong&gt;Â§öÊ∏†ÈÅìÂÆûÊó∂Êé®ÈÄÅ&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;ÊîØÊåÅ&lt;strong&gt;‰ºÅ‰∏öÂæÆ‰ø°&lt;/strong&gt;(+ ÂæÆ‰ø°Êé®ÈÄÅÊñπÊ°à)„ÄÅ&lt;strong&gt;È£û‰π¶&lt;/strong&gt;„ÄÅ&lt;strong&gt;ÈíâÈíâ&lt;/strong&gt;„ÄÅ&lt;strong&gt;Telegram&lt;/strong&gt;„ÄÅ&lt;strong&gt;ÈÇÆ‰ª∂&lt;/strong&gt;„ÄÅ&lt;strong&gt;ntfy&lt;/strong&gt;ÔºåÊ∂àÊÅØÁõ¥ËææÊâãÊú∫ÂíåÈÇÆÁÆ±&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;Â§öÁ´ØÈÄÇÈÖç&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub Pages&lt;/strong&gt;ÔºöËá™Âä®ÁîüÊàêÁ≤æÁæéÁΩëÈ°µÊä•ÂëäÔºåPC/ÁßªÂä®Á´ØÈÄÇÈÖç&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;DockerÈÉ®ÁΩ≤&lt;/strong&gt;ÔºöÊîØÊåÅÂ§öÊû∂ÊûÑÂÆπÂô®ÂåñËøêË°å&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Êï∞ÊçÆÊåÅ‰πÖÂåñ&lt;/strong&gt;ÔºöHTML/TXTÂ§öÊ†ºÂºèÂéÜÂè≤ËÆ∞ÂΩï‰øùÂ≠ò&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;AI Êô∫ËÉΩÂàÜÊûêÔºàv3.0.0 Êñ∞Â¢ûÔºâ&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Âü∫‰∫é MCP (Model Context Protocol) ÂçèËÆÆÁöÑ AI ÂØπËØùÂàÜÊûêÁ≥ªÁªüÔºåËÆ©‰Ω†Áî®Ëá™ÁÑ∂ËØ≠Ë®ÄÊ∑±Â∫¶ÊåñÊéòÊñ∞ÈóªÊï∞ÊçÆ&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ÂØπËØùÂºèÊü•ËØ¢&lt;/strong&gt;ÔºöÁî®Ëá™ÁÑ∂ËØ≠Ë®ÄÊèêÈóÆÔºåÂ¶Ç"Êü•ËØ¢Êò®Â§©Áü•‰πéÁöÑÁÉ≠ÁÇπ"„ÄÅ"ÂàÜÊûêÊØîÁâπÂ∏ÅÊúÄËøëÁöÑÁÉ≠Â∫¶Ë∂ãÂäø"&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;13 ÁßçÂàÜÊûêÂ∑•ÂÖ∑&lt;/strong&gt;ÔºöÊ∂µÁõñÂü∫Á°ÄÊü•ËØ¢„ÄÅÊô∫ËÉΩÊ£ÄÁ¥¢„ÄÅË∂ãÂäøÂàÜÊûê„ÄÅÊï∞ÊçÆÊ¥ûÂØü„ÄÅÊÉÖÊÑüÂàÜÊûêÁ≠â&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Â§öÂÆ¢Êà∑Á´ØÊîØÊåÅ&lt;/strong&gt;ÔºöCherry StudioÔºàGUI ÈÖçÁΩÆÔºâ„ÄÅClaude Desktop„ÄÅCursor„ÄÅCline Á≠â&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ê∑±Â∫¶ÂàÜÊûêËÉΩÂäõ&lt;/strong&gt;Ôºö 
  &lt;ul&gt; 
   &lt;li&gt;ËØùÈ¢òË∂ãÂäøËøΩË∏™ÔºàÁÉ≠Â∫¶ÂèòÂåñ„ÄÅÁîüÂëΩÂë®Êúü„ÄÅÁàÜÁÅ´Ê£ÄÊµã„ÄÅË∂ãÂäøÈ¢ÑÊµãÔºâ&lt;/li&gt; 
   &lt;li&gt;Ë∑®Âπ≥Âè∞Êï∞ÊçÆÂØπÊØîÔºàÊ¥ªË∑ÉÂ∫¶ÁªüËÆ°„ÄÅÂÖ≥ÈîÆËØçÂÖ±Áé∞Ôºâ&lt;/li&gt; 
   &lt;li&gt;Êô∫ËÉΩÊëòË¶ÅÁîüÊàê„ÄÅÁõ∏‰ººÊñ∞ÈóªÊü•Êâæ„ÄÅÂéÜÂè≤ÂÖ≥ËÅîÊ£ÄÁ¥¢&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ÂëäÂà´ÊâãÂä®ÁøªÈòÖÊï∞ÊçÆÊñá‰ª∂ÔºåAI Âä©ÊâãÂ∏Æ‰Ω†ÁßíÊáÇÊñ∞ÈóªËÉåÂêéÁöÑÊïÖ‰∫ã&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;&lt;strong&gt;Èõ∂ÊäÄÊúØÈó®ÊßõÈÉ®ÁΩ≤&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;GitHub ‰∏ÄÈîÆ Fork Âç≥ÂèØ‰ΩøÁî®ÔºåÊó†ÈúÄÁºñÁ®ãÂü∫Á°Ä„ÄÇ&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;30ÁßíÈÉ®ÁΩ≤Ôºö GitHub PagesÔºàÁΩëÈ°µÊµèËßàÔºâÊîØÊåÅ‰∏ÄÈîÆ‰øùÂ≠òÊàêÂõæÁâáÔºåÈöèÊó∂ÂàÜ‰∫´Áªô‰ªñ‰∫∫&lt;/p&gt; 
 &lt;p&gt;1ÂàÜÈíüÈÉ®ÁΩ≤Ôºö ‰ºÅ‰∏öÂæÆ‰ø°ÔºàÊâãÊú∫ÈÄöÁü•Ôºâ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;üí° ÊèêÁ§∫Ôºö&lt;/strong&gt; ÊÉ≥Ë¶Å&lt;strong&gt;ÂÆûÊó∂Êõ¥Êñ∞&lt;/strong&gt;ÁöÑÁΩëÈ°µÁâàÔºüfork ÂêéÔºåËøõÂÖ•‰Ω†ÁöÑ‰ªìÂ∫ì Settings ‚Üí PagesÔºåÂêØÁî® GitHub Pages„ÄÇ&lt;a href="https://sansan0.github.io/TrendRadar/"&gt;ÊïàÊûúÈ¢ÑËßà&lt;/a&gt;„ÄÇ&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;ÂáèÂ∞ë APP ‰æùËµñ&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;‰ªé"Ë¢´ÁÆóÊ≥ïÊé®ËçêÁªëÊû∂"ÂèòÊàê"‰∏ªÂä®Ëé∑ÂèñËá™Â∑±ÊÉ≥Ë¶ÅÁöÑ‰ø°ÊÅØ"&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ÈÄÇÂêà‰∫∫Áæ§Ôºö&lt;/strong&gt; ÊäïËµÑËÄÖ„ÄÅËá™Â™í‰Ωì‰∫∫„ÄÅ‰ºÅ‰∏öÂÖ¨ÂÖ≥„ÄÅÂÖ≥ÂøÉÊó∂‰∫ãÁöÑÊôÆÈÄöÁî®Êà∑&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ÂÖ∏ÂûãÂú∫ÊôØÔºö&lt;/strong&gt; ËÇ°Â∏ÇÊäïËµÑÁõëÊéß„ÄÅÂìÅÁâåËàÜÊÉÖËøΩË∏™„ÄÅË°å‰∏öÂä®ÊÄÅÂÖ≥Ê≥®„ÄÅÁîüÊ¥ªËµÑËÆØËé∑Âèñ&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;Github Pages ÊïàÊûú(ÊâãÊú∫Á´ØÈÄÇÈÖç„ÄÅÈÇÆÁÆ±Êé®ÈÄÅÊïàÊûú)&lt;/th&gt; 
   &lt;th align="center"&gt;È£û‰π¶Êé®ÈÄÅÊïàÊûú&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/github-pages.png" alt="Github PagesÊïàÊûú" /&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/feishu.jpg" alt="È£û‰π¶Êé®ÈÄÅÊïàÊûú" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üìù Êõ¥Êñ∞Êó•Âøó&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;ÂçáÁ∫ßËØ¥Êòé&lt;/strong&gt;Ôºö&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ÊèêÁ§∫&lt;/strong&gt;Ôºö‰∏çË¶ÅÈÄöËøá &lt;strong&gt;Sync fork&lt;/strong&gt; Êõ¥Êñ∞Êú¨È°πÁõÆ, Âª∫ËÆÆÊü•Áúã„ÄêÂéÜÂè≤Êõ¥Êñ∞„ÄëÔºåÊòéÁ°ÆÂÖ∑‰ΩìÁöÑ„ÄêÂçáÁ∫ßÊñπÂºè„ÄëÂíå„ÄêÂäüËÉΩÂÜÖÂÆπ„Äë&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Â∞èÁâàÊú¨Êõ¥Êñ∞&lt;/strong&gt;Ôºö‰ªé v2.x ÂçáÁ∫ßÂà∞ v2.y, Áî®Êú¨È°πÁõÆÁöÑ &lt;code&gt;main.py&lt;/code&gt; ‰ª£Á†ÅÊõøÊç¢‰Ω† fork ‰ªìÂ∫ì‰∏≠ÁöÑÂØπÂ∫îÊñá‰ª∂&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Â§ßÁâàÊú¨ÂçáÁ∫ß&lt;/strong&gt;Ôºö‰ªé v1.x ÂçáÁ∫ßÂà∞ v2.y, Âª∫ËÆÆÂà†Èô§Áé∞Êúâ fork ÂêéÈáçÊñ∞ forkÔºåËøôÊ†∑Êõ¥ÁúÅÂäõ‰∏îÈÅøÂÖçÈÖçÁΩÆÂÜ≤Á™Å&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;2025/10/26 - mcp-v1.0.1&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;MCP Ê®°ÂùóÊõ¥Êñ∞:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;‰øÆÂ§çÊó•ÊúüÊü•ËØ¢ÂèÇÊï∞‰º†ÈÄíÈîôËØØ&lt;/li&gt; 
 &lt;li&gt;Áªü‰∏ÄÊâÄÊúâÂ∑•ÂÖ∑ÁöÑÊó∂Èó¥ÂèÇÊï∞Ê†ºÂºè&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;2025/10/31 - v3.0.4&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Ëß£ÂÜ≥È£û‰π¶Âõ†Êé®ÈÄÅÂÜÖÂÆπËøáÈïøËÄå‰∫ßÁîüÁöÑÈîôËØØÔºåÂÆûÁé∞‰∫ÜÂàÜÊâπÊé®ÈÄÅ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üëâ ÂéÜÂè≤Êõ¥Êñ∞&lt;/strong&gt;&lt;/summary&gt; 
 &lt;h3&gt;2025/10/23 - v3.0.3&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Êâ©Â§ß ntfy ÈîôËØØ‰ø°ÊÅØÊòæÁ§∫ËåÉÂõ¥&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/10/21 - v3.0.2&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;‰øÆÂ§ç ntfy Êé®ÈÄÅÁºñÁ†ÅÈóÆÈ¢ò&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/10/20 - v3.0.0&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;ÈáçÂ§ßÊõ¥Êñ∞ - AI ÂàÜÊûêÂäüËÉΩ‰∏äÁ∫ø&lt;/strong&gt; ü§ñ&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Ê†∏ÂøÉÂäüËÉΩ&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Êñ∞Â¢ûÂü∫‰∫é MCP (Model Context Protocol) ÁöÑ AI ÂàÜÊûêÊúçÂä°Âô®&lt;/li&gt; 
    &lt;li&gt;ÊîØÊåÅ13ÁßçÊô∫ËÉΩÂàÜÊûêÂ∑•ÂÖ∑ÔºöÂü∫Á°ÄÊü•ËØ¢„ÄÅÊô∫ËÉΩÊ£ÄÁ¥¢„ÄÅÈ´òÁ∫ßÂàÜÊûê„ÄÅÁ≥ªÁªüÁÆ°ÁêÜ&lt;/li&gt; 
    &lt;li&gt;Ëá™ÁÑ∂ËØ≠Ë®Ä‰∫§‰∫íÔºöÈÄöËøáÂØπËØùÊñπÂºèÊü•ËØ¢ÂíåÂàÜÊûêÊñ∞ÈóªÊï∞ÊçÆ&lt;/li&gt; 
    &lt;li&gt;Â§öÂÆ¢Êà∑Á´ØÊîØÊåÅÔºöClaude Desktop„ÄÅCherry Studio„ÄÅCursor„ÄÅCline Á≠â&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;ÂàÜÊûêËÉΩÂäõ&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ËØùÈ¢òË∂ãÂäøÂàÜÊûêÔºàÁÉ≠Â∫¶ËøΩË∏™„ÄÅÁîüÂëΩÂë®Êúü„ÄÅÁàÜÁÅ´Ê£ÄÊµã„ÄÅË∂ãÂäøÈ¢ÑÊµãÔºâ&lt;/li&gt; 
    &lt;li&gt;Êï∞ÊçÆÊ¥ûÂØüÔºàÂπ≥Âè∞ÂØπÊØî„ÄÅÊ¥ªË∑ÉÂ∫¶ÁªüËÆ°„ÄÅÂÖ≥ÈîÆËØçÂÖ±Áé∞Ôºâ&lt;/li&gt; 
    &lt;li&gt;ÊÉÖÊÑüÂàÜÊûê„ÄÅÁõ∏‰ººÊñ∞ÈóªÊü•Êâæ„ÄÅÊô∫ËÉΩÊëòË¶ÅÁîüÊàê&lt;/li&gt; 
    &lt;li&gt;ÂéÜÂè≤Áõ∏ÂÖ≥Êñ∞ÈóªÊ£ÄÁ¥¢„ÄÅÂ§öÊ®°ÂºèÊêúÁ¥¢&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Êõ¥Êñ∞ÊèêÁ§∫&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ËøôÊòØÁã¨Á´ãÁöÑ AI ÂàÜÊûêÂäüËÉΩÔºå‰∏çÂΩ±ÂìçÁé∞ÊúâÁöÑÊé®ÈÄÅÂäüËÉΩ&lt;/li&gt; 
    &lt;li&gt;ÂèØÈÄâÊã©ÊÄß‰ΩøÁî®ÔºåÊó†ÈúÄÂçáÁ∫ßÁé∞ÊúâÈÉ®ÁΩ≤&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/10/15 - v2.4.4&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Êõ¥Êñ∞ÂÜÖÂÆπ&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;‰øÆÂ§ç ntfy Êé®ÈÄÅÁºñÁ†ÅÈóÆÈ¢ò + 1&lt;/li&gt; 
    &lt;li&gt;‰øÆÂ§çÊé®ÈÄÅÊó∂Èó¥Á™óÂè£Âà§Êñ≠ÈóÆÈ¢ò&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Êõ¥Êñ∞ÊèêÁ§∫&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Âª∫ËÆÆ„ÄêÂ∞èÁâàÊú¨ÂçáÁ∫ß„Äë&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/10/10 - v2.4.3&lt;/h3&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;ÊÑüË∞¢ &lt;a href="https://github.com/sansan0/TrendRadar/issues/98"&gt;nidaye996&lt;/a&gt; ÂèëÁé∞ÁöÑ‰ΩìÈ™åÈóÆÈ¢ò&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Êõ¥Êñ∞ÂÜÖÂÆπ&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ÈáçÊûÑ"ÈùôÈªòÊé®ÈÄÅÊ®°Âºè"ÂëΩÂêç‰∏∫"Êé®ÈÄÅÊó∂Èó¥Á™óÂè£ÊéßÂà∂"ÔºåÊèêÂçáÂäüËÉΩÁêÜËß£Â∫¶&lt;/li&gt; 
    &lt;li&gt;ÊòéÁ°ÆÊé®ÈÄÅÊó∂Èó¥Á™óÂè£‰Ωú‰∏∫ÂèØÈÄâÈôÑÂä†ÂäüËÉΩÔºåÂèØ‰∏é‰∏âÁßçÊé®ÈÄÅÊ®°ÂºèÊê≠ÈÖç‰ΩøÁî®&lt;/li&gt; 
    &lt;li&gt;ÊîπËøõÊ≥®ÈáäÂíåÊñáÊ°£ÊèèËø∞Ôºå‰ΩøÂäüËÉΩÂÆö‰ΩçÊõ¥Âä†Ê∏ÖÊô∞&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Êõ¥Êñ∞ÊèêÁ§∫&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Ëøô‰∏™‰ªÖ‰ªÖÊòØÈáçÊûÑÔºåÂèØ‰ª•‰∏çÁî®ÂçáÁ∫ß&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/10/8 - v2.4.2&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Êõ¥Êñ∞ÂÜÖÂÆπ&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;‰øÆÂ§ç ntfy Êé®ÈÄÅÁºñÁ†ÅÈóÆÈ¢ò&lt;/li&gt; 
    &lt;li&gt;‰øÆÂ§çÈÖçÁΩÆÊñá‰ª∂Áº∫Â§±ÈóÆÈ¢ò&lt;/li&gt; 
    &lt;li&gt;‰ºòÂåñ ntfy Êé®ÈÄÅÊïàÊûú&lt;/li&gt; 
    &lt;li&gt;Â¢ûÂä† github page ÂõæÁâáÂàÜÊÆµÂØºÂá∫ÂäüËÉΩ&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Êõ¥Êñ∞ÊèêÁ§∫&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Âª∫ËÆÆ‰ΩøÁî®„ÄêÂ§ßÁâàÊú¨Êõ¥Êñ∞„Äë&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/10/2 - v2.4.0&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;Êñ∞Â¢û ntfy Êé®ÈÄÅÈÄöÁü•&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Ê†∏ÂøÉÂäüËÉΩ&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ÊîØÊåÅ ntfy.sh ÂÖ¨ÂÖ±ÊúçÂä°ÂíåËá™ÊâòÁÆ°ÊúçÂä°Âô®&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;‰ΩøÁî®Âú∫ÊôØ&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ÈÄÇÂêàËøΩÊ±ÇÈöêÁßÅÁöÑÁî®Êà∑ÔºàÊîØÊåÅËá™ÊâòÁÆ°Ôºâ&lt;/li&gt; 
    &lt;li&gt;Ë∑®Âπ≥Âè∞Êé®ÈÄÅÔºàiOS„ÄÅAndroid„ÄÅDesktop„ÄÅWebÔºâ&lt;/li&gt; 
    &lt;li&gt;Êó†ÈúÄÊ≥®ÂÜåË¥¶Âè∑ÔºàÂÖ¨ÂÖ±ÊúçÂä°Âô®Ôºâ&lt;/li&gt; 
    &lt;li&gt;ÂºÄÊ∫êÂÖçË¥πÔºàMIT ÂçèËÆÆÔºâ&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Êõ¥Êñ∞ÊèêÁ§∫&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Âª∫ËÆÆ‰ΩøÁî®„ÄêÂ§ßÁâàÊú¨Êõ¥Êñ∞„Äë&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/09/26 - v2.3.2&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;‰øÆÊ≠£‰∫ÜÈÇÆ‰ª∂ÈÄöÁü•ÈÖçÁΩÆÊ£ÄÊü•Ë¢´ÈÅóÊºèÁöÑÈóÆÈ¢òÔºà&lt;a href="https://github.com/sansan0/TrendRadar/issues/88"&gt;#88&lt;/a&gt;Ôºâ&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;‰øÆÂ§çËØ¥Êòé&lt;/strong&gt;Ôºö&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Ëß£ÂÜ≥‰∫ÜÂç≥‰ΩøÊ≠£Á°ÆÈÖçÁΩÆÈÇÆ‰ª∂ÈÄöÁü•ÔºåÁ≥ªÁªü‰ªçÊèêÁ§∫"Êú™ÈÖçÁΩÆ‰ªª‰Ωïwebhook"ÁöÑÈóÆÈ¢ò&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/09/22 - v2.3.1&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Êñ∞Â¢ûÈÇÆ‰ª∂Êé®ÈÄÅÂäüËÉΩ&lt;/strong&gt;ÔºåÊîØÊåÅÂ∞ÜÁÉ≠ÁÇπÊñ∞ÈóªÊä•ÂëäÂèëÈÄÅÂà∞ÈÇÆÁÆ±&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Êô∫ËÉΩ SMTP ËØÜÂà´&lt;/strong&gt;ÔºöËá™Âä®ËØÜÂà´ Gmail„ÄÅQQÈÇÆÁÆ±„ÄÅOutlook„ÄÅÁΩëÊòìÈÇÆÁÆ±Á≠â 10+ ÁßçÈÇÆÁÆ±ÊúçÂä°ÂïÜÈÖçÁΩÆ&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;HTML Á≤æÁæéÊ†ºÂºè&lt;/strong&gt;ÔºöÈÇÆ‰ª∂ÂÜÖÂÆπÈááÁî®‰∏éÁΩëÈ°µÁâàÁõ∏ÂêåÁöÑ HTML Ê†ºÂºèÔºåÊéíÁâàÁ≤æÁæéÔºåÁßªÂä®Á´ØÈÄÇÈÖç&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;ÊâπÈáèÂèëÈÄÅÊîØÊåÅ&lt;/strong&gt;ÔºöÊîØÊåÅÂ§ö‰∏™Êî∂‰ª∂‰∫∫ÔºåÁî®ÈÄóÂè∑ÂàÜÈöîÂç≥ÂèØÂêåÊó∂ÂèëÈÄÅÁªôÂ§ö‰∫∫&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Ëá™ÂÆö‰πâ SMTP&lt;/strong&gt;ÔºöÂèØËá™ÂÆö‰πâ SMTP ÊúçÂä°Âô®ÂíåÁ´ØÂè£&lt;/li&gt; 
  &lt;li&gt;‰øÆÂ§çDockerÊûÑÂª∫ÁΩëÁªúËøûÊé•ÈóÆÈ¢ò&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;‰ΩøÁî®ËØ¥Êòé&lt;/strong&gt;Ôºö&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ÈÄÇÁî®Âú∫ÊôØÔºöÈÄÇÂêàÈúÄË¶ÅÈÇÆ‰ª∂ÂΩíÊ°£„ÄÅÂõ¢ÈòüÂàÜ‰∫´„ÄÅÂÆöÊó∂Êä•ÂëäÁöÑÁî®Êà∑&lt;/li&gt; 
  &lt;li&gt;ÊîØÊåÅÈÇÆÁÆ±ÔºöGmail„ÄÅQQÈÇÆÁÆ±„ÄÅOutlook/Hotmail„ÄÅ163/126ÈÇÆÁÆ±„ÄÅÊñ∞Êµ™ÈÇÆÁÆ±„ÄÅÊêúÁãêÈÇÆÁÆ±Á≠â&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;Êõ¥Êñ∞ÊèêÁ§∫&lt;/strong&gt;Ôºö&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Ê≠§Ê¨°Êõ¥Êñ∞ÁöÑÂÜÖÂÆπÊØîËæÉÂ§öÔºåÂ¶ÇÊûúÊÉ≥ÂçáÁ∫ßÔºåÂª∫ËÆÆÈááÁî®„ÄêÂ§ßÁâàÊú¨ÂçáÁ∫ß„Äë&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/09/17 - v2.2.0&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Êñ∞Â¢û‰∏ÄÈîÆ‰øùÂ≠òÊñ∞ÈóªÂõæÁâáÂäüËÉΩÔºåËÆ©‰Ω†ËΩªÊùæÂàÜ‰∫´ÂÖ≥Ê≥®ÁöÑÁÉ≠ÁÇπ&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;‰ΩøÁî®ËØ¥Êòé&lt;/strong&gt;Ôºö&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ÈÄÇÁî®Âú∫ÊôØÔºöÂΩì‰Ω†ÊåâÁÖßÊïôÁ®ãÂºÄÂêØ‰∫ÜÁΩëÈ°µÁâàÂäüËÉΩÂêé(GitHub Pages)&lt;/li&gt; 
  &lt;li&gt;‰ΩøÁî®ÊñπÊ≥ïÔºöÁî®ÊâãÊú∫ÊàñÁîµËÑëÊâìÂºÄËØ•ÁΩëÈ°µÈìæÊé•ÔºåÁÇπÂáªÈ°µÈù¢È°∂ÈÉ®ÁöÑ"‰øùÂ≠ò‰∏∫ÂõæÁâá"ÊåâÈíÆ&lt;/li&gt; 
  &lt;li&gt;ÂÆûÈôÖÊïàÊûúÔºöÁ≥ªÁªü‰ºöËá™Âä®Â∞ÜÂΩìÂâçÁöÑÊñ∞ÈóªÊä•ÂëäÂà∂‰ΩúÊàê‰∏ÄÂº†Á≤æÁæéÂõæÁâáÔºå‰øùÂ≠òÂà∞‰Ω†ÁöÑÊâãÊú∫Áõ∏ÂÜåÊàñÁîµËÑëÊ°åÈù¢&lt;/li&gt; 
  &lt;li&gt;ÂàÜ‰∫´‰æøÂà©Ôºö‰Ω†ÂèØ‰ª•Áõ¥Êé•ÊääËøôÂº†ÂõæÁâáÂèëÁªôÊúãÂèã„ÄÅÂèëÂà∞ÊúãÂèãÂúàÔºåÊàñÂàÜ‰∫´Âà∞Â∑•‰ΩúÁæ§ÔºåËÆ©Âà´‰∫∫‰πüËÉΩÁúãÂà∞‰Ω†ÂèëÁé∞ÁöÑÈáçË¶ÅËµÑËÆØ&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/09/13 - v2.1.2&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Ëß£ÂÜ≥ÈíâÈíâÁöÑÊé®ÈÄÅÂÆπÈáèÈôêÂà∂ÂØºËá¥ÁöÑÊñ∞ÈóªÊé®ÈÄÅÂ§±Ë¥•ÈóÆÈ¢ò(ÈááÁî®ÂàÜÊâπÊé®ÈÄÅ)&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/09/04 - v2.1.1&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;‰øÆÂ§çdockerÂú®Êüê‰∫õÊû∂ÊûÑ‰∏≠Êó†Ê≥ïÊ≠£Â∏∏ËøêË°åÁöÑÈóÆÈ¢ò&lt;/li&gt; 
  &lt;li&gt;Ê≠£ÂºèÂèëÂ∏ÉÂÆòÊñπ Docker ÈïúÂÉè wantcat/trendradarÔºåÊîØÊåÅÂ§öÊû∂ÊûÑ&lt;/li&gt; 
  &lt;li&gt;‰ºòÂåñ Docker ÈÉ®ÁΩ≤ÊµÅÁ®ãÔºåÊó†ÈúÄÊú¨Âú∞ÊûÑÂª∫Âç≥ÂèØÂø´ÈÄü‰ΩøÁî®&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/08/30 - v2.1.0&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;Ê†∏ÂøÉÊîπËøõ&lt;/strong&gt;Ôºö&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Êé®ÈÄÅÈÄªËæë‰ºòÂåñ&lt;/strong&gt;Ôºö‰ªé"ÊØèÊ¨°ÊâßË°åÈÉΩÊé®ÈÄÅ"Êîπ‰∏∫"Êó∂Èó¥Á™óÂè£ÂÜÖÂèØÊéßÊé®ÈÄÅ"&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Êó∂Èó¥Á™óÂè£ÊéßÂà∂&lt;/strong&gt;ÔºöÂèØËÆæÂÆöÊé®ÈÄÅÊó∂Èó¥ËåÉÂõ¥ÔºåÈÅøÂÖçÈùûÂ∑•‰ΩúÊó∂Èó¥ÊâìÊâ∞&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Êé®ÈÄÅÈ¢ëÁéáÂèØÈÄâ&lt;/strong&gt;ÔºöÊó∂Èó¥ÊÆµÂÜÖÊîØÊåÅÂçïÊ¨°Êé®ÈÄÅÊàñÂ§öÊ¨°Êé®ÈÄÅ&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;Êõ¥Êñ∞ÊèêÁ§∫&lt;/strong&gt;Ôºö&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Êú¨ÂäüËÉΩÈªòËÆ§ÂÖ≥Èó≠ÔºåÈúÄÊâãÂä®Âú® config.yaml ‰∏≠ÂºÄÂêØÊé®ÈÄÅÊó∂Èó¥Á™óÂè£ÊéßÂà∂&lt;/li&gt; 
  &lt;li&gt;ÂçáÁ∫ßÈúÄÂêåÊó∂Êõ¥Êñ∞ main.py Âíå config.yaml ‰∏§‰∏™Êñá‰ª∂&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/08/27 - v2.0.4&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Êú¨Ê¨°ÁâàÊú¨‰∏çÊòØÂäüËÉΩ‰øÆÂ§çÔºåËÄåÊòØÈáçË¶ÅÊèêÈÜí&lt;/li&gt; 
  &lt;li&gt;ËØ∑Âä°ÂøÖÂ¶•ÂñÑ‰øùÁÆ°Â•Ω webhooksÔºå‰∏çË¶ÅÂÖ¨ÂºÄÔºå‰∏çË¶ÅÂÖ¨ÂºÄÔºå‰∏çË¶ÅÂÖ¨ÂºÄ&lt;/li&gt; 
  &lt;li&gt;Â¶ÇÊûú‰Ω†‰ª• fork ÁöÑÊñπÂºèÂ∞ÜÊú¨È°πÁõÆÈÉ®ÁΩ≤Âú® GitHub ‰∏äÔºåËØ∑Â∞Ü webhooks Â°´ÂÖ• GitHub SecretÔºåËÄåÈùû config.yaml&lt;/li&gt; 
  &lt;li&gt;Â¶ÇÊûú‰Ω†Â∑≤ÁªèÊö¥Èú≤‰∫Ü webhooks ÊàñÂ∞ÜÂÖ∂Â°´ÂÖ•‰∫Ü config.yamlÔºåÂª∫ËÆÆÂà†Èô§ÂêéÈáçÊñ∞ÁîüÊàê&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/08/06 - v2.0.3&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;‰ºòÂåñ github page ÁöÑÁΩëÈ°µÁâàÊïàÊûúÔºåÊñπ‰æøÁßªÂä®Á´Ø‰ΩøÁî®&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/07/28 - v2.0.2&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ÈáçÊûÑ‰ª£Á†Å&lt;/li&gt; 
  &lt;li&gt;Ëß£ÂÜ≥ÁâàÊú¨Âè∑ÂÆπÊòìË¢´ÈÅóÊºè‰øÆÊîπÁöÑÈóÆÈ¢ò&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/07/27 - v2.0.1&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;‰øÆÂ§çÈóÆÈ¢ò&lt;/strong&gt;:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;docker ÁöÑ shell ËÑöÊú¨ÁöÑÊç¢Ë°åÁ¨¶‰∏∫ CRLF ÂØºËá¥ÁöÑÊâßË°åÂºÇÂ∏∏ÈóÆÈ¢ò&lt;/li&gt; 
  &lt;li&gt;frequency_words.txt ‰∏∫Á©∫Êó∂ÔºåÂØºËá¥Êñ∞ÈóªÂèëÈÄÅ‰πü‰∏∫Á©∫ÁöÑÈÄªËæëÈóÆÈ¢ò&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;ul&gt; 
  &lt;li&gt;‰øÆÂ§çÂêéÔºåÂΩì‰Ω†ÈÄâÊã© frequency_words.txt ‰∏∫Á©∫Êó∂ÔºåÂ∞Ü&lt;strong&gt;Êé®ÈÄÅÊâÄÊúâÊñ∞Èóª&lt;/strong&gt;Ôºå‰ΩÜÂèóÈôê‰∫éÊ∂àÊÅØÊé®ÈÄÅÂ§ßÂ∞èÈôêÂà∂ÔºåËØ∑ÂÅöÂ¶Ç‰∏ãË∞ÉÊï¥ 
   &lt;ul&gt; 
    &lt;li&gt;ÊñπÊ°à‰∏ÄÔºöÂÖ≥Èó≠ÊâãÊú∫Êé®ÈÄÅÔºåÂè™ÈÄâÊã© Github Pages Â∏ÉÁΩÆ(ËøôÊòØËÉΩËé∑ÂæóÊúÄÂÆåÊï¥‰ø°ÊÅØÁöÑÊñπÊ°àÔºåÂ∞ÜÊääÊâÄÊúâÂπ≥Âè∞ÁöÑÁÉ≠ÁÇπÊåâÁÖß‰Ω†&lt;strong&gt;Ëá™ÂÆö‰πâÁöÑÁÉ≠ÊêúÁÆóÊ≥ï&lt;/strong&gt;ËøõË°åÈáçÊñ∞ÊéíÂ∫è)&lt;/li&gt; 
    &lt;li&gt;ÊñπÊ°à‰∫åÔºöÂáèÂ∞ëÊé®ÈÄÅÂπ≥Âè∞Ôºå‰ºòÂÖàÈÄâÊã©&lt;strong&gt;‰ºÅ‰∏öÂæÆ‰ø°&lt;/strong&gt;Êàñ&lt;strong&gt;Telegram&lt;/strong&gt;ÔºåËøô‰∏§‰∏™Êé®ÈÄÅÊàëÂÅö‰∫ÜÂàÜÊâπÊé®ÈÄÅÂäüËÉΩ(Âõ†‰∏∫ÂàÜÊâπÊé®ÈÄÅÂΩ±ÂìçÊé®ÈÄÅ‰ΩìÈ™åÔºå‰∏îÂè™ÊúâËøô‰∏§‰∏™Âπ≥Âè∞Âè™Áªô‰∏ÄÁÇπÁÇπÊé®ÈÄÅÂÆπÈáèÔºåÊâÄ‰ª•Êâç‰∏çÂæóÂ∑≤ÂÅö‰∫ÜÂàÜÊâπÊé®ÈÄÅÂäüËÉΩÔºå‰ΩÜËá≥Â∞ëËÉΩ‰øùËØÅËé∑ÂæóÁöÑ‰ø°ÊÅØÂÆåÊï¥)&lt;/li&gt; 
    &lt;li&gt;ÊñπÊ°à‰∏âÔºöÂèØ‰∏éÊñπÊ°à‰∫åÁªìÂêàÔºåÊ®°ÂºèÈÄâÊã© current Êàñ incremental ÂèØÊúâÊïàÂáèÂ∞ë‰∏ÄÊ¨°ÊÄßÊé®ÈÄÅÁöÑÂÜÖÂÆπ&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/07/17 - v2.0.0&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;ÈáçÂ§ßÈáçÊûÑ&lt;/strong&gt;Ôºö&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ÈÖçÁΩÆÁÆ°ÁêÜÈáçÊûÑÔºöÊâÄÊúâÈÖçÁΩÆÁé∞Âú®ÈÄöËøá &lt;code&gt;config/config.yaml&lt;/code&gt; Êñá‰ª∂ÁÆ°ÁêÜÔºàmain.py Êàë‰æùÊóßÊ≤°ÊãÜÂàÜÔºåÊñπ‰æø‰Ω†‰ª¨Â§çÂà∂ÂçáÁ∫ßÔºâ&lt;/li&gt; 
  &lt;li&gt;ËøêË°åÊ®°ÂºèÂçáÁ∫ßÔºöÊîØÊåÅ‰∏âÁßçÊ®°Âºè - &lt;code&gt;daily&lt;/code&gt;ÔºàÂΩìÊó•Ê±áÊÄªÔºâ„ÄÅ&lt;code&gt;current&lt;/code&gt;ÔºàÂΩìÂâçÊ¶úÂçïÔºâ„ÄÅ&lt;code&gt;incremental&lt;/code&gt;ÔºàÂ¢ûÈáèÁõëÊéßÔºâ&lt;/li&gt; 
  &lt;li&gt;Docker ÊîØÊåÅÔºöÂÆåÊï¥ÁöÑ Docker ÈÉ®ÁΩ≤ÊñπÊ°àÔºåÊîØÊåÅÂÆπÂô®ÂåñËøêË°å&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;ÈÖçÁΩÆÊñá‰ª∂ËØ¥Êòé&lt;/strong&gt;Ôºö&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;config/config.yaml&lt;/code&gt; - ‰∏ªÈÖçÁΩÆÊñá‰ª∂ÔºàÂ∫îÁî®ËÆæÁΩÆ„ÄÅÁà¨Ëô´ÈÖçÁΩÆ„ÄÅÈÄöÁü•ÈÖçÁΩÆ„ÄÅÂπ≥Âè∞ÈÖçÁΩÆÁ≠âÔºâ&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;config/frequency_words.txt&lt;/code&gt; - ÂÖ≥ÈîÆËØçÈÖçÁΩÆÔºàÁõëÊéßËØçÊ±áËÆæÁΩÆÔºâ&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;2025/07/09 - v1.4.1&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;ÂäüËÉΩÊñ∞Â¢û&lt;/strong&gt;ÔºöÂ¢ûÂä†Â¢ûÈáèÊé®ÈÄÅ(Âú® main.py Â§¥ÈÉ®ÈÖçÁΩÆ FOCUS_NEW_ONLY)ÔºåËØ•ÂºÄÂÖ≥Âè™ÂÖ≥ÂøÉÊñ∞ËØùÈ¢òËÄåÈùûÊåÅÁª≠ÁÉ≠Â∫¶ÔºåÂè™Âú®ÊúâÊñ∞ÂÜÖÂÆπÊó∂ÊâçÂèëÈÄöÁü•„ÄÇ&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;‰øÆÂ§çÈóÆÈ¢ò&lt;/strong&gt;: Êüê‰∫õÊÉÖÂÜµ‰∏ãÔºåÁî±‰∫éÊñ∞ÈóªÊú¨Ë∫´Âê´ÊúâÁâπÊÆäÁ¨¶Âè∑ÂØºËá¥ÁöÑÂÅ∂ÂèëÊÄßÊéíÁâàÂºÇÂ∏∏„ÄÇ&lt;/p&gt; 
 &lt;h3&gt;2025/06/23 - v1.3.0&lt;/h3&gt; 
 &lt;p&gt;‰ºÅ‰∏öÂæÆ‰ø° Âíå Telegram ÁöÑÊé®ÈÄÅÊ∂àÊÅØÊúâÈïøÂ∫¶ÈôêÂà∂ÔºåÂØπÊ≠§ÊàëÈááÁî®Â∞ÜÊ∂àÊÅØÊãÜÂàÜÊé®ÈÄÅÁöÑÊñπÂºè„ÄÇÂºÄÂèëÊñáÊ°£ËØ¶ËßÅ&lt;a href="https://developer.work.weixin.qq.com/document/path/91770"&gt;‰ºÅ‰∏öÂæÆ‰ø°&lt;/a&gt; Âíå &lt;a href="https://core.telegram.org/bots/api"&gt;Telegram&lt;/a&gt;&lt;/p&gt; 
 &lt;h3&gt;2025/06/21 - v1.2.1&lt;/h3&gt; 
 &lt;p&gt;Âú®Êú¨ÁâàÊú¨‰πãÂâçÁöÑÊóßÁâàÊú¨Ôºå‰∏ç‰ªÖ main.py ÈúÄË¶ÅÂ§çÂà∂ÊõøÊç¢Ôºå crawler.yml ‰πüÈúÄË¶Å‰Ω†Â§çÂà∂ÊõøÊç¢ &lt;a href="https://github.com/sansan0/TrendRadar/raw/master/.github/workflows/crawler.yml"&gt;https://github.com/sansan0/TrendRadar/blob/master/.github/workflows/crawler.yml&lt;/a&gt;&lt;/p&gt; 
 &lt;h3&gt;2025/06/19 - v1.2.0&lt;/h3&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;ÊÑüË∞¢ claude research Êï¥ÁêÜÁöÑÂêÑÂπ≥Âè∞ api ,ËÆ©ÊàëÂø´ÈÄüÂÆåÊàêÂêÑÂπ≥Âè∞ÈÄÇÈÖçÔºàËôΩÁÑ∂‰ª£Á†ÅÊõ¥Â§öÂÜó‰Ωô‰∫Ü~&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;ol&gt; 
  &lt;li&gt;ÊîØÊåÅ telegram Ôºå‰ºÅ‰∏öÂæÆ‰ø°ÔºåÈíâÈíâÊé®ÈÄÅÊ∏†ÈÅì, ÊîØÊåÅÂ§öÊ∏†ÈÅìÈÖçÁΩÆÂíåÂêåÊó∂Êé®ÈÄÅ&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;h3&gt;2025/06/18 - v1.1.0&lt;/h3&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;&lt;strong&gt;200 star‚≠ê&lt;/strong&gt; ‰∫Ü, ÁªßÁª≠ÁªôÂ§ß‰ºôÂÑøÂä©ÂÖ¥~ËøëÊúüÔºåÂú®ÊàëÁöÑ"ÊÄÇÊÅø"‰∏ãÔºåÊå∫Â§ö‰∫∫Âú®ÊàëÂÖ¨‰ºóÂè∑ÁÇπËµûÂàÜ‰∫´Êé®ËçêÂä©Âäõ‰∫ÜÊàëÔºåÊàëÈÉΩÂú®ÂêéÂè∞ÁúãËßÅ‰∫ÜÂÖ∑‰ΩìË¥¶Âè∑ÁöÑÈºìÂä±Êï∞ÊçÆÔºåÂæàÂ§öÈÉΩÊàê‰∫ÜÂ§©‰ΩøËΩÆËÄÅÁ≤âÔºàÊàëÁé©ÂÖ¨‰ºóÂè∑Êâç‰∏Ä‰∏™Â§öÊúàÔºåËôΩÁÑ∂Ê≥®ÂÜåÊòØ‰∏ÉÂÖ´Âπ¥ÂâçÁöÑ‰∫ã‰∫ÜÂìàÂìàÔºåÂ±û‰∫é‰∏äËΩ¶Êó©ÔºåÂèëËΩ¶ÊôöÔºâÔºå‰ΩÜÂõ†‰∏∫‰Ω†‰ª¨Ê≤°ÊúâÁïôË®ÄÊàñÁßÅ‰ø°ÊàëÔºåÊâÄ‰ª•Êàë‰πüÊó†Ê≥ï‰∏Ä‰∏ÄÂõûÂ∫îÂπ∂ÊÑüË∞¢ÊîØÊåÅÔºåÂú®Ê≠§‰∏ÄÂπ∂Ë∞¢Ë∞¢ÔºÅ&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;ol&gt; 
  &lt;li&gt;ÈáçË¶ÅÁöÑÊõ¥Êñ∞ÔºåÂä†‰∫ÜÊùÉÈáçÔºå‰Ω†Áé∞Âú®ÁúãÂà∞ÁöÑÊñ∞ÈóªÈÉΩÊòØÊúÄÁÉ≠ÁÇπÊúÄÊúâÂÖ≥Ê≥®Â∫¶ÁöÑÂá∫Áé∞Âú®ÊúÄ‰∏äÈù¢&lt;/li&gt; 
  &lt;li&gt;Êõ¥Êñ∞ÊñáÊ°£‰ΩøÁî®ÔºåÂõ†‰∏∫ËøëÊúüÊõ¥Êñ∞‰∫ÜÂæàÂ§öÂäüËÉΩÔºåËÄå‰∏î‰πãÂâçÁöÑ‰ΩøÁî®ÊñáÊ°£ÊàëÂÅ∑ÊáíÂÜôÁöÑÁÆÄÂçïÔºàËßÅ‰∏ãÈù¢ÁöÑ ‚öôÔ∏è frequency_words.txt ÈÖçÁΩÆÂÆåÊï¥ÊïôÁ®ãÔºâ&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;h3&gt;2025/06/16 - v1.0.0&lt;/h3&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Â¢ûÂä†‰∫Ü‰∏Ä‰∏™È°πÁõÆÊñ∞ÁâàÊú¨Êõ¥Êñ∞ÊèêÁ§∫ÔºåÈªòËÆ§ÊâìÂºÄÔºåÂ¶ÇË¶ÅÂÖ≥ÊéâÔºåÂèØ‰ª•Âú® main.py ‰∏≠Êää "FEISHU_SHOW_VERSION_UPDATE": True ‰∏≠ÁöÑ True ÊîπÊàê False Âç≥ÂèØ&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;h3&gt;2025/06/13+14&lt;/h3&gt; 
 &lt;ol&gt; 
  &lt;li&gt;ÂéªÊéâ‰∫ÜÂÖºÂÆπ‰ª£Á†ÅÔºå‰πãÂâç fork ÁöÑÂêåÂ≠¶ÔºåÁõ¥Êé•Â§çÂà∂‰ª£Á†Å‰ºöÂú®ÂΩìÂ§©ÊòæÁ§∫ÂºÇÂ∏∏ÔºàÁ¨¨‰∫åÂ§©‰ºöÊÅ¢Â§çÊ≠£Â∏∏Ôºâ&lt;/li&gt; 
  &lt;li&gt;feishu Âíå html Â∫ïÈÉ®Â¢ûÂä†‰∏Ä‰∏™Êñ∞Â¢ûÊñ∞ÈóªÊòæÁ§∫&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;h3&gt;2025/06/09&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;100 star‚≠ê&lt;/strong&gt; ‰∫ÜÔºåÂÜô‰∏™Â∞èÂäüËÉΩÁªôÂ§ß‰ºôÂÑøÂä©Âä©ÂÖ¥ frequency_words.txt Êñá‰ª∂Â¢ûÂä†‰∫Ü‰∏Ä‰∏™„ÄêÂøÖÈ°ªËØç„ÄëÂäüËÉΩÔºå‰ΩøÁî® + Âè∑&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;ÂøÖÈ°ªËØçËØ≠Ê≥ïÂ¶Ç‰∏ãÔºö&lt;br /&gt; ÂîêÂÉßÊàñËÄÖÁå™ÂÖ´ÊàíÂøÖÈ°ªÂú®Ê†áÈ¢òÈáåÂêåÊó∂Âá∫Áé∞ÔºåÊâç‰ºöÊî∂ÂΩïÂà∞Êé®ÈÄÅÊñ∞Èóª‰∏≠&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code&gt;+ÂîêÂÉß
+Áå™ÂÖ´Êàí
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="2"&gt; 
  &lt;li&gt;ËøáÊª§ËØçÁöÑ‰ºòÂÖàÁ∫ßÊõ¥È´òÔºö&lt;br /&gt; Â¶ÇÊûúÊ†áÈ¢ò‰∏≠ËøáÊª§ËØçÂåπÈÖçÂà∞ÂîêÂÉßÂøµÁªèÔºåÈÇ£‰πàÂç≥‰ΩøÂøÖÈ°ªËØçÈáåÊúâÂîêÂÉßÔºå‰πü‰∏çÊòæÁ§∫&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code&gt;+ÂîêÂÉß
!ÂîêÂÉßÂøµÁªè
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;2025/06/02&lt;/h3&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;strong&gt;ÁΩëÈ°µ&lt;/strong&gt;Âíå&lt;strong&gt;È£û‰π¶Ê∂àÊÅØ&lt;/strong&gt;ÊîØÊåÅÊâãÊú∫Áõ¥Êé•Ë∑≥ËΩ¨ËØ¶ÊÉÖÊñ∞Èóª&lt;/li&gt; 
  &lt;li&gt;‰ºòÂåñÊòæÁ§∫ÊïàÊûú + 1&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;h3&gt;2025/05/26&lt;/h3&gt; 
 &lt;ol&gt; 
  &lt;li&gt;È£û‰π¶Ê∂àÊÅØÊòæÁ§∫ÊïàÊûú‰ºòÂåñ&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;table&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td align="center"&gt; ‰ºòÂåñÂâç&lt;br /&gt; &lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/before.jpg" alt="È£û‰π¶Ê∂àÊÅØÁïåÈù¢ - ‰ºòÂåñÂâç" width="400" /&gt; &lt;/td&gt; 
    &lt;td align="center"&gt; ‰ºòÂåñÂêé&lt;br /&gt; &lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/after.jpg" alt="È£û‰π¶Ê∂àÊÅØÁïåÈù¢ - ‰ºòÂåñÂêé" width="400" /&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;h2&gt;üöÄ Âø´ÈÄüÂºÄÂßã&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ÈÖçÁΩÆÂÆåÊàêÂêéÔºåÊñ∞ÈóªÊï∞ÊçÆ‰∏ÄÂ∞èÊó∂ÂêéÊâç‰ºöÊõ¥Êñ∞ÔºåÂ¶ÇÊÉ≥Âä†Âø´ÔºåÂèØÂèÇÁÖß„ÄêÁ¨¨4Ê≠•„ÄëÊâãÂä®ÊµãËØïÈÖçÁΩÆÊïàÊûú&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Fork Êú¨È°πÁõÆ&lt;/strong&gt;Âà∞‰Ω†ÁöÑ GitHub Ë¥¶Êà∑&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;ÁÇπÂáªÊú¨È°µÈù¢Âè≥‰∏äËßíÁöÑ"Fork"ÊåâÈíÆ&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ËÆæÁΩÆ GitHub SecretsÔºàÈÄâÊã©‰Ω†ÈúÄË¶ÅÁöÑÂπ≥Âè∞Ôºâ&lt;/strong&gt;:&lt;/p&gt; &lt;p&gt;Âú®‰Ω† Fork ÂêéÁöÑ‰ªìÂ∫ì‰∏≠ÔºåËøõÂÖ• &lt;code&gt;Settings&lt;/code&gt; &amp;gt; &lt;code&gt;Secrets and variables&lt;/code&gt; &amp;gt; &lt;code&gt;Actions&lt;/code&gt; &amp;gt; &lt;code&gt;New repository secret&lt;/code&gt;ÔºåÁÑ∂ÂêéÊ†πÊçÆÈúÄË¶ÅÈÖçÁΩÆ‰ª•‰∏ã‰ªª‰∏ÄÊàñÂ§ö‰∏™ÈÄöÁü•Âπ≥Âè∞Ôºö&lt;/p&gt; &lt;p&gt;ÂèØ‰ª•ÂêåÊó∂ÈÖçÁΩÆÂ§ö‰∏™Âπ≥Âè∞ÔºåÁ≥ªÁªü‰ºöÂêëÊâÄÊúâÈÖçÁΩÆÁöÑÂπ≥Âè∞ÂèëÈÄÅÈÄöÁü•„ÄÇ&lt;/p&gt; &lt;p&gt;ÊïàÊûúÁ±ª‰ºº‰∏ãÂõæÔºå‰∏Ä‰∏™ name ÂØπÂ∫î‰∏Ä‰∏™ secretÔºå‰øùÂ≠òÂÆåÂ∞±Ë°åÔºå‰Ω†ÈáçÊñ∞ÁºñËæëÁúã‰∏çÂà∞ secret ÊòØÊ≠£Â∏∏ÊÉÖÂÜµ„ÄÇ&lt;/p&gt; &lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/secrets.png" alt="GitHub Secrets" /&gt; 
  &lt;details&gt; 
   &lt;summary&gt; &lt;strong&gt;üëâ ‰ºÅ‰∏öÂæÆ‰ø°Êú∫Âô®‰∫∫&lt;/strong&gt;ÔºàÈÖçÁΩÆÊúÄÁÆÄÂçïÊúÄËøÖÈÄüÔºâ&lt;/summary&gt; 
   &lt;br /&gt; 
   &lt;p&gt;&lt;strong&gt;GitHub Secret ÈÖçÁΩÆÔºö&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ÂêçÁß∞Ôºö&lt;code&gt;WEWORK_WEBHOOK_URL&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;ÂÄºÔºö‰Ω†ÁöÑ‰ºÅ‰∏öÂæÆ‰ø°Êú∫Âô®‰∫∫ Webhook Âú∞ÂùÄ&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;p&gt;&lt;strong&gt;Êú∫Âô®‰∫∫ËÆæÁΩÆÊ≠•È™§Ôºö&lt;/strong&gt;&lt;/p&gt; 
   &lt;h4&gt;ÊâãÊú∫Á´ØËÆæÁΩÆÔºö&lt;/h4&gt; 
   &lt;ol&gt; 
    &lt;li&gt;ÊâìÂºÄ‰ºÅ‰∏öÂæÆ‰ø° App ‚Üí ËøõÂÖ•ÁõÆÊ†áÂÜÖÈÉ®Áæ§ËÅä&lt;/li&gt; 
    &lt;li&gt;ÁÇπÂáªÂè≥‰∏äËßí"‚Ä¶"ÊåâÈíÆ ‚Üí ÈÄâÊã©"Ê∂àÊÅØÊé®ÈÄÅ"&lt;/li&gt; 
    &lt;li&gt;ÁÇπÂáª"Ê∑ªÂä†" ‚Üí ÂêçÁß∞ËæìÂÖ•"TrendRadar"&lt;/li&gt; 
    &lt;li&gt;Â§çÂà∂ Webhook Âú∞ÂùÄÔºåÁÇπÂáª‰øùÂ≠òÔºåÂ§çÂà∂ÁöÑÂÜÖÂÆπÈÖçÁΩÆÂà∞‰∏äÊñπÁöÑ GitHub Secret ‰∏≠&lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;h4&gt;PC Á´ØËÆæÁΩÆÊµÅÁ®ãÁ±ª‰ºº&lt;/h4&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt; &lt;strong&gt;üëâ È£û‰π¶Êú∫Âô®‰∫∫&lt;/strong&gt;ÔºàÊ∂àÊÅØÊòæÁ§∫ÊúÄÂèãÂ•ΩÔºâ&lt;/summary&gt; 
   &lt;br /&gt; 
   &lt;p&gt;&lt;strong&gt;GitHub Secret ÈÖçÁΩÆÔºö&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ÂêçÁß∞Ôºö&lt;code&gt;FEISHU_WEBHOOK_URL&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;ÂÄºÔºö‰Ω†ÁöÑÈ£û‰π¶Êú∫Âô®‰∫∫ Webhook Âú∞ÂùÄ(ËØ•ÈìæÊé•ÂºÄÂ§¥Á±ª‰ºº &lt;a href="https://www.feishu.cn/flow/api/trigger-webhook/"&gt;https://www.feishu.cn/flow/api/trigger-webhook/&lt;/a&gt;********)&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;br /&gt; 
   &lt;p&gt;Êúâ‰∏§‰∏™ÊñπÊ°àÔºå&lt;strong&gt;ÊñπÊ°à‰∏Ä&lt;/strong&gt;ÈÖçÁΩÆÁÆÄÂçïÔºå&lt;strong&gt;ÊñπÊ°à‰∫å&lt;/strong&gt;ÈÖçÁΩÆÂ§çÊùÇ(‰ΩÜÊòØÁ®≥ÂÆöÊé®ÈÄÅ)&lt;/p&gt; 
   &lt;p&gt;ÂÖ∂‰∏≠ÊñπÊ°à‰∏ÄÔºåÁî± &lt;strong&gt;ziventian&lt;/strong&gt;ÂèëÁé∞Âπ∂Êèê‰æõÂª∫ËÆÆÔºåÂú®ËøôÈáåÊÑüË∞¢‰ªñÔºåÈªòËÆ§ÊòØ‰∏™‰∫∫Êé®ÈÄÅÔºå‰πüÂèØ‰ª•ÈÖçÁΩÆÁæ§ÁªÑÊé®ÈÄÅÊìç‰Ωú&lt;a href="https://github.com/sansan0/TrendRadar/issues/97"&gt;#97&lt;/a&gt; Ôºå&lt;/p&gt; 
   &lt;p&gt;&lt;strong&gt;ÊñπÊ°à‰∏ÄÔºö&lt;/strong&gt;&lt;/p&gt; 
   &lt;blockquote&gt; 
    &lt;p&gt;ÂØπÈÉ®ÂàÜ‰∫∫Â≠òÂú®È¢ùÂ§ñÊìç‰ΩúÔºåÂê¶Âàô‰ºöÊä•"Á≥ªÁªüÈîôËØØ"„ÄÇÈúÄË¶ÅÊâãÊú∫Á´ØÊêúÁ¥¢‰∏ãÊú∫Âô®‰∫∫ÔºåÁÑ∂ÂêéÂºÄÂêØÈ£û‰π¶Êú∫Âô®‰∫∫Â∫îÁî®(ËØ•Âª∫ËÆÆÊù•Ëá™‰∫éÁΩëÂèãÔºåÂèØÂèÇËÄÉ)&lt;/p&gt; 
   &lt;/blockquote&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;ÁîµËÑëÊµèËßàÂô®ÊâìÂºÄ &lt;a href="https://botbuilder.feishu.cn/home/my-command"&gt;https://botbuilder.feishu.cn/home/my-command&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;ÁÇπÂáª"Êñ∞Âª∫Êú∫Âô®‰∫∫Êåá‰ª§"&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;ÁÇπÂáª"ÈÄâÊã©Ëß¶ÂèëÂô®"ÔºåÂæÄ‰∏ãÊªëÂä®ÔºåÁÇπÂáª"Webhook Ëß¶Âèë"&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;Ê≠§Êó∂‰Ω†‰ºöÁúãÂà∞"Webhook Âú∞ÂùÄ"ÔºåÊääËøô‰∏™ÈìæÊé•ÂÖàÂ§çÂà∂Âà∞Êú¨Âú∞ËÆ∞‰∫ãÊú¨ÊöÇÂ≠òÔºåÁªßÁª≠Êé•‰∏ãÊù•ÁöÑÊìç‰Ωú&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;"ÂèÇÊï∞"ÈáåÈù¢Êîæ‰∏ä‰∏ãÈù¢ÁöÑÂÜÖÂÆπÔºåÁÑ∂ÂêéÁÇπÂáª"ÂÆåÊàê"&lt;/p&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;pre&gt;&lt;code class="language-json"&gt;{
  "message_type": "text",
  "content": {
    "total_titles": "{{ÂÜÖÂÆπ}}",
    "timestamp": "{{ÂÜÖÂÆπ}}",
    "report_type": "{{ÂÜÖÂÆπ}}",
    "text": "{{ÂÜÖÂÆπ}}"
  }
}
&lt;/code&gt;&lt;/pre&gt; 
   &lt;ol start="6"&gt; 
    &lt;li&gt; &lt;p&gt;ÁÇπÂáª"ÈÄâÊã©Êìç‰Ωú" &amp;gt; "ÈÄöËøáÂÆòÊñπÊú∫Âô®‰∫∫ÂèëÊ∂àÊÅØ"&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;Ê∂àÊÅØÊ†áÈ¢òÂ°´ÂÜô"TrendRadar ÁÉ≠ÁÇπÁõëÊéß"&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;ÊúÄÂÖ≥ÈîÆÁöÑÈÉ®ÂàÜÊù•‰∫ÜÔºåÁÇπÂáª + ÊåâÈíÆÔºåÈÄâÊã©"Webhook Ëß¶Âèë"ÔºåÁÑ∂ÂêéÊåâÁÖß‰∏ãÈù¢ÁöÑÂõæÁâáÊëÜÊîæ&lt;/p&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/image.png" alt="È£û‰π¶Êú∫Âô®‰∫∫ÈÖçÁΩÆÁ§∫‰æã" /&gt;&lt;/p&gt; 
   &lt;ol start="9"&gt; 
    &lt;li&gt;ÈÖçÁΩÆÂÆåÊàêÂêéÔºåÂ∞ÜÁ¨¨ 4 Ê≠•Â§çÂà∂ÁöÑ Webhook Âú∞ÂùÄÈÖçÁΩÆÂà∞ GitHub Secrets ‰∏≠ÁöÑ &lt;code&gt;FEISHU_WEBHOOK_URL&lt;/code&gt;&lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;br /&gt; 
   &lt;p&gt;&lt;strong&gt;ÊñπÊ°à‰∫åÔºö&lt;/strong&gt;&lt;/p&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;ÁîµËÑëÊµèËßàÂô®ÊâìÂºÄ &lt;a href="https://botbuilder.feishu.cn/home/my-app"&gt;https://botbuilder.feishu.cn/home/my-app&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;ÁÇπÂáª"Êñ∞Âª∫Êú∫Âô®‰∫∫Â∫îÁî®"&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;ËøõÂÖ•ÂàõÂª∫ÁöÑÂ∫îÁî®ÂêéÔºåÁÇπÂáª"ÊµÅÁ®ãÊ∂âÂèä" &amp;gt; "ÂàõÂª∫ÊµÅÁ®ã" &amp;gt; "ÈÄâÊã©Ëß¶ÂèëÂô®"&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;ÂæÄ‰∏ãÊªëÂä®ÔºåÁÇπÂáª"Webhook Ëß¶Âèë"&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;Ê≠§Êó∂‰Ω†‰ºöÁúãÂà∞"Webhook Âú∞ÂùÄ"ÔºåÊääËøô‰∏™ÈìæÊé•ÂÖàÂ§çÂà∂Âà∞Êú¨Âú∞ËÆ∞‰∫ãÊú¨ÊöÇÂ≠òÔºåÁªßÁª≠Êé•‰∏ãÊù•ÁöÑÊìç‰Ωú&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;"ÂèÇÊï∞"ÈáåÈù¢Êîæ‰∏ä‰∏ãÈù¢ÁöÑÂÜÖÂÆπÔºåÁÑ∂ÂêéÁÇπÂáª"ÂÆåÊàê"&lt;/p&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;pre&gt;&lt;code class="language-json"&gt;{
  "message_type": "text",
  "content": {
    "total_titles": "{{ÂÜÖÂÆπ}}",
    "timestamp": "{{ÂÜÖÂÆπ}}",
    "report_type": "{{ÂÜÖÂÆπ}}",
    "text": "{{ÂÜÖÂÆπ}}"
  }
}
&lt;/code&gt;&lt;/pre&gt; 
   &lt;ol start="7"&gt; 
    &lt;li&gt; &lt;p&gt;ÁÇπÂáª"ÈÄâÊã©Êìç‰Ωú" &amp;gt; "ÂèëÈÄÅÈ£û‰π¶Ê∂àÊÅØ"ÔºåÂãæÈÄâ "Áæ§Ê∂àÊÅØ"ÔºåÁÑ∂ÂêéÁÇπÂáª‰∏ãÈù¢ÁöÑËæìÂÖ•Ê°ÜÔºåÁÇπÂáª"ÊàëÁÆ°ÁêÜÁöÑÁæ§ÁªÑ"ÔºàÂ¶ÇÊûúÊ≤°ÊúâÁæ§ÁªÑÔºå‰Ω†ÂèØ‰ª•Âú®È£û‰π¶ app ‰∏äÂàõÂª∫Áæ§ÁªÑÔºâ&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;Ê∂àÊÅØÊ†áÈ¢òÂ°´ÂÜô"TrendRadar ÁÉ≠ÁÇπÁõëÊéß"&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;ÊúÄÂÖ≥ÈîÆÁöÑÈÉ®ÂàÜÊù•‰∫ÜÔºåÁÇπÂáª + ÊåâÈíÆÔºåÈÄâÊã©"Webhook Ëß¶Âèë"ÔºåÁÑ∂ÂêéÊåâÁÖß‰∏ãÈù¢ÁöÑÂõæÁâáÊëÜÊîæ&lt;/p&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/image.png" alt="È£û‰π¶Êú∫Âô®‰∫∫ÈÖçÁΩÆÁ§∫‰æã" /&gt;&lt;/p&gt; 
   &lt;ol start="10"&gt; 
    &lt;li&gt;ÈÖçÁΩÆÂÆåÊàêÂêéÔºåÂ∞ÜÁ¨¨ 5 Ê≠•Â§çÂà∂ÁöÑ Webhook Âú∞ÂùÄÈÖçÁΩÆÂà∞ GitHub Secrets ‰∏≠ÁöÑ &lt;code&gt;FEISHU_WEBHOOK_URL&lt;/code&gt;&lt;/li&gt; 
   &lt;/ol&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt; &lt;strong&gt;üëâ ÈíâÈíâÊú∫Âô®‰∫∫&lt;/strong&gt;&lt;/summary&gt; 
   &lt;br /&gt; 
   &lt;p&gt;&lt;strong&gt;GitHub Secret ÈÖçÁΩÆÔºö&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ÂêçÁß∞Ôºö&lt;code&gt;DINGTALK_WEBHOOK_URL&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;ÂÄºÔºö‰Ω†ÁöÑÈíâÈíâÊú∫Âô®‰∫∫ Webhook Âú∞ÂùÄ&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;p&gt;&lt;strong&gt;Êú∫Âô®‰∫∫ËÆæÁΩÆÊ≠•È™§Ôºö&lt;/strong&gt;&lt;/p&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;ÂàõÂª∫Êú∫Âô®‰∫∫Ôºà‰ªÖ PC Á´ØÊîØÊåÅÔºâ&lt;/strong&gt;Ôºö&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;ÊâìÂºÄÈíâÈíâ PC ÂÆ¢Êà∑Á´ØÔºåËøõÂÖ•ÁõÆÊ†áÁæ§ËÅä&lt;/li&gt; 
      &lt;li&gt;ÁÇπÂáªÁæ§ËÆæÁΩÆÂõæÊ†áÔºà‚öôÔ∏èÔºâ‚Üí ÂæÄ‰∏ãÁøªÊâæÂà∞"Êú∫Âô®‰∫∫"ÁÇπÂºÄ&lt;/li&gt; 
      &lt;li&gt;ÈÄâÊã©"Ê∑ªÂä†Êú∫Âô®‰∫∫" ‚Üí "Ëá™ÂÆö‰πâ"&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;ÈÖçÁΩÆÊú∫Âô®‰∫∫&lt;/strong&gt;Ôºö&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;ËÆæÁΩÆÊú∫Âô®‰∫∫ÂêçÁß∞&lt;/li&gt; 
      &lt;li&gt;&lt;strong&gt;ÂÆâÂÖ®ËÆæÁΩÆ&lt;/strong&gt;Ôºö 
       &lt;ul&gt; 
        &lt;li&gt;&lt;strong&gt;Ëá™ÂÆö‰πâÂÖ≥ÈîÆËØç&lt;/strong&gt;ÔºöËÆæÁΩÆ "ÁÉ≠ÁÇπ"&lt;/li&gt; 
       &lt;/ul&gt; &lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;ÂÆåÊàêËÆæÁΩÆ&lt;/strong&gt;Ôºö&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;ÂãæÈÄâÊúçÂä°Êù°Ê¨æÂçèËÆÆ ‚Üí ÁÇπÂáª"ÂÆåÊàê"&lt;/li&gt; 
      &lt;li&gt;Â§çÂà∂Ëé∑ÂæóÁöÑ Webhook URL&lt;/li&gt; 
      &lt;li&gt;Â∞Ü URL ÈÖçÁΩÆÂà∞ GitHub Secrets ‰∏≠ÁöÑ &lt;code&gt;DINGTALK_WEBHOOK_URL&lt;/code&gt;&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;p&gt;&lt;strong&gt;Ê≥®ÊÑè&lt;/strong&gt;ÔºöÁßªÂä®Á´ØÂè™ËÉΩÊé•Êî∂Ê∂àÊÅØÔºåÊó†Ê≥ïÂàõÂª∫Êñ∞Êú∫Âô®‰∫∫„ÄÇ&lt;/p&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt; &lt;strong&gt;üëâ Telegram Bot&lt;/strong&gt;&lt;/summary&gt; 
   &lt;br /&gt; 
   &lt;p&gt;&lt;strong&gt;GitHub Secret ÈÖçÁΩÆÔºö&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ÂêçÁß∞Ôºö&lt;code&gt;TELEGRAM_BOT_TOKEN&lt;/code&gt; - ‰Ω†ÁöÑ Telegram Bot Token&lt;/li&gt; 
    &lt;li&gt;ÂêçÁß∞Ôºö&lt;code&gt;TELEGRAM_CHAT_ID&lt;/code&gt; - ‰Ω†ÁöÑ Telegram Chat ID&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;p&gt;&lt;strong&gt;Êú∫Âô®‰∫∫ËÆæÁΩÆÊ≠•È™§Ôºö&lt;/strong&gt;&lt;/p&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;ÂàõÂª∫Êú∫Âô®‰∫∫&lt;/strong&gt;Ôºö&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;Âú® Telegram ‰∏≠ÊêúÁ¥¢ &lt;code&gt;@BotFather&lt;/code&gt;ÔºàÂ§ßÂ∞èÂÜôÊ≥®ÊÑèÔºåÊúâËìùËâ≤ÂæΩÁ´†ÂãæÂãæÔºåÊúâÁ±ª‰ºº 37849827 monthly usersÔºåËøô‰∏™ÊâçÊòØÂÆòÊñπÁöÑÔºåÊúâ‰∏Ä‰∫õ‰ªøÂÆòÊñπÁöÑË¥¶Âè∑Ê≥®ÊÑèËæ®Âà´Ôºâ&lt;/li&gt; 
      &lt;li&gt;ÂèëÈÄÅ &lt;code&gt;/newbot&lt;/code&gt; ÂëΩ‰ª§ÂàõÂª∫Êñ∞Êú∫Âô®‰∫∫&lt;/li&gt; 
      &lt;li&gt;ËÆæÁΩÆÊú∫Âô®‰∫∫ÂêçÁß∞ÔºàÂøÖÈ°ª‰ª•"bot"ÁªìÂ∞æÔºåÂæàÂÆπÊòìÈÅáÂà∞ÈáçÂ§çÂêçÂ≠óÔºåÊâÄ‰ª•‰Ω†Ë¶ÅÁªûÂ∞ΩËÑëÊ±ÅÊÉ≥‰∏çÂêåÁöÑÂêçÂ≠óÔºâ&lt;/li&gt; 
      &lt;li&gt;Ëé∑Âèñ Bot TokenÔºàÊ†ºÂºèÂ¶ÇÔºö&lt;code&gt;123456789:AAHfiqksKZ8WmR2zSjiQ7_v4TMAKdiHm9T0&lt;/code&gt;Ôºâ&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;Ëé∑Âèñ Chat ID&lt;/strong&gt;Ôºö&lt;/p&gt; &lt;p&gt;&lt;strong&gt;ÊñπÊ≥ï‰∏ÄÔºöÈÄöËøáÂÆòÊñπ API Ëé∑Âèñ&lt;/strong&gt;&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;ÂÖàÂêë‰Ω†ÁöÑÊú∫Âô®‰∫∫ÂèëÈÄÅ‰∏ÄÊù°Ê∂àÊÅØ&lt;/li&gt; 
      &lt;li&gt;ËÆøÈóÆÔºö&lt;code&gt;https://api.telegram.org/bot&amp;lt;‰Ω†ÁöÑBot Token&amp;gt;/getUpdates&lt;/code&gt;&lt;/li&gt; 
      &lt;li&gt;Âú®ËøîÂõûÁöÑ JSON ‰∏≠ÊâæÂà∞ &lt;code&gt;"chat":{"id":Êï∞Â≠ó}&lt;/code&gt; ‰∏≠ÁöÑÊï∞Â≠ó&lt;/li&gt; 
     &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;ÊñπÊ≥ï‰∫åÔºö‰ΩøÁî®Á¨¨‰∏âÊñπÂ∑•ÂÖ∑&lt;/strong&gt;&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;ÊêúÁ¥¢ &lt;code&gt;@userinfobot&lt;/code&gt; Âπ∂ÂèëÈÄÅ &lt;code&gt;/start&lt;/code&gt;&lt;/li&gt; 
      &lt;li&gt;Ëé∑Âèñ‰Ω†ÁöÑÁî®Êà∑ ID ‰Ωú‰∏∫ Chat ID&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;ÈÖçÁΩÆÂà∞ GitHub&lt;/strong&gt;Ôºö&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;&lt;code&gt;TELEGRAM_BOT_TOKEN&lt;/code&gt;ÔºöÂ°´ÂÖ•Á¨¨ 1 Ê≠•Ëé∑ÂæóÁöÑ Bot Token&lt;/li&gt; 
      &lt;li&gt;&lt;code&gt;TELEGRAM_CHAT_ID&lt;/code&gt;ÔºöÂ°´ÂÖ•Á¨¨ 2 Ê≠•Ëé∑ÂæóÁöÑ Chat ID&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt; &lt;strong&gt;üëâ ÈÇÆ‰ª∂Êé®ÈÄÅ&lt;/strong&gt;ÔºàÊîØÊåÅÊâÄÊúâ‰∏ªÊµÅÈÇÆÁÆ±Ôºâ&lt;/summary&gt; 
   &lt;br /&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Ê≥®ÊÑè‰∫ãÈ°πÔºö‰∏∫Èò≤Ê≠¢ÈÇÆ‰ª∂Áæ§ÂèëÂäüËÉΩË¢´&lt;strong&gt;Êª•Áî®&lt;/strong&gt;ÔºåÂΩìÂâçÁöÑÁæ§ÂèëÊòØÊâÄÊúâÊî∂‰ª∂‰∫∫ÈÉΩËÉΩÁúãÂà∞ÂΩºÊ≠§ÁöÑÈÇÆÁÆ±Âú∞ÂùÄÔºåÈÄÇÂêàÁÜü‰∫∫Èó¥‰∫§ÊµÅËµÑËÆØ„ÄÇ&lt;/li&gt; 
    &lt;li&gt;‰ªÖ‰æõÂèÇËÄÉÔºöËØ∑Ê†πÊçÆÂÆûÈôÖÊÉÖÂÜµË∞ÉÊï¥ÔºåÈÇÆÁÆ±ÊñπÈù¢Âπ∂Ê≤°Êúâ‰∏Ä‰∏ÄÈ™åËØÅÔºåÊòØÊåâÁÖß SMTP ÁöÑÊ†áÂáÜÈÖçÁΩÆÁöÑ&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;p&gt;&lt;strong&gt;GitHub Secret ÈÖçÁΩÆÔºö&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ÂêçÁß∞Ôºö&lt;code&gt;EMAIL_FROM&lt;/code&gt; - Âèë‰ª∂‰∫∫ÈÇÆÁÆ±Âú∞ÂùÄ&lt;/li&gt; 
    &lt;li&gt;ÂêçÁß∞Ôºö&lt;code&gt;EMAIL_PASSWORD&lt;/code&gt; - ÈÇÆÁÆ±ÂØÜÁ†ÅÊàñÊéàÊùÉÁ†Å&lt;/li&gt; 
    &lt;li&gt;ÂêçÁß∞Ôºö&lt;code&gt;EMAIL_TO&lt;/code&gt; - Êî∂‰ª∂‰∫∫ÈÇÆÁÆ±Âú∞ÂùÄÔºàÂ§ö‰∏™Êî∂‰ª∂‰∫∫Áî®Ëã±ÊñáÈÄóÂè∑ÂàÜÈöîÔºâ‰πüÂèØ‰ª•Âíå EMAIL_FROM ‰∏ÄÊ†∑ÔºåËá™Â∑±ÂèëÈÄÅÁªôËá™Â∑±&lt;/li&gt; 
    &lt;li&gt;ÂêçÁß∞Ôºö&lt;code&gt;EMAIL_SMTP_SERVER&lt;/code&gt; - SMTPÊúçÂä°Âô®Âú∞ÂùÄÔºàÂèØÈÄâÔºåÁïôÁ©∫ÂàôËá™Âä®ËØÜÂà´Ôºâ&lt;/li&gt; 
    &lt;li&gt;ÂêçÁß∞Ôºö&lt;code&gt;EMAIL_SMTP_PORT&lt;/code&gt; - SMTPÁ´ØÂè£ÔºàÂèØÈÄâÔºåÁïôÁ©∫ÂàôËá™Âä®ËØÜÂà´Ôºâ&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;p&gt;&lt;strong&gt;Â∏∏ËßÅÈÇÆÁÆ±ËÆæÁΩÆÔºö&lt;/strong&gt;&lt;/p&gt; 
   &lt;h4&gt;QQÈÇÆÁÆ±Ôºö&lt;/h4&gt; 
   &lt;ol&gt; 
    &lt;li&gt;ÁôªÂΩï QQÈÇÆÁÆ±ÁΩëÈ°µÁâà ‚Üí ËÆæÁΩÆ ‚Üí Ë¥¶Êà∑&lt;/li&gt; 
    &lt;li&gt;ÂºÄÂêØ POP3/SMTP ÊúçÂä°&lt;/li&gt; 
    &lt;li&gt;ÁîüÊàêÊéàÊùÉÁ†ÅÔºà16‰ΩçÂ≠óÊØçÔºâ&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;EMAIL_PASSWORD&lt;/code&gt; Â°´ÂÜôÊéàÊùÉÁ†ÅÔºåËÄåÈùû QQ ÂØÜÁ†Å&lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;h4&gt;GmailÔºö&lt;/h4&gt; 
   &lt;ol&gt; 
    &lt;li&gt;ÂºÄÂêØ‰∏§Ê≠•È™åËØÅ&lt;/li&gt; 
    &lt;li&gt;ÁîüÊàêÂ∫îÁî®‰∏ìÁî®ÂØÜÁ†Å&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;EMAIL_PASSWORD&lt;/code&gt; Â°´ÂÜôÂ∫îÁî®‰∏ìÁî®ÂØÜÁ†Å&lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;h4&gt;163/126ÈÇÆÁÆ±Ôºö&lt;/h4&gt; 
   &lt;ol&gt; 
    &lt;li&gt;ÁôªÂΩïÁΩëÈ°µÁâà ‚Üí ËÆæÁΩÆ ‚Üí POP3/SMTP/IMAP&lt;/li&gt; 
    &lt;li&gt;ÂºÄÂêØ SMTP ÊúçÂä°&lt;/li&gt; 
    &lt;li&gt;ËÆæÁΩÆÂÆ¢Êà∑Á´ØÊéàÊùÉÁ†Å&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;EMAIL_PASSWORD&lt;/code&gt; Â°´ÂÜôÊéàÊùÉÁ†Å&lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;br /&gt; 
   &lt;p&gt;&lt;strong&gt;È´òÁ∫ßÈÖçÁΩÆ&lt;/strong&gt;Ôºö Â¶ÇÊûúËá™Âä®ËØÜÂà´Â§±Ë¥•ÔºåÂèØÊâãÂä®ÈÖçÁΩÆ SMTPÔºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;code&gt;EMAIL_SMTP_SERVER&lt;/code&gt;ÔºöÂ¶Ç smtp.gmail.com&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;EMAIL_SMTP_PORT&lt;/code&gt;ÔºöÂ¶Ç 587ÔºàTLSÔºâÊàñ 465ÔºàSSLÔºâ&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;br /&gt; 
   &lt;p&gt;&lt;strong&gt;Â§öÊî∂‰ª∂‰∫∫ËÆæÁΩÆ&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;EMAIL_TO="&lt;a href="mailto:user1@example.com"&gt;user1@example.com&lt;/a&gt;,&lt;a href="mailto:user2@example.com"&gt;user2@example.com&lt;/a&gt;,&lt;a href="mailto:user3@example.com"&gt;user3@example.com&lt;/a&gt;"&lt;/li&gt; 
   &lt;/ul&gt; 
  &lt;/details&gt; 
  &lt;details&gt; 
   &lt;summary&gt; &lt;strong&gt;üëâ ntfy Êé®ÈÄÅ&lt;/strong&gt;ÔºàÂºÄÊ∫êÂÖçË¥πÔºåÊîØÊåÅËá™ÊâòÁÆ°Ôºâ&lt;/summary&gt; 
   &lt;br /&gt; 
   &lt;p&gt;&lt;strong&gt;‰∏§Áßç‰ΩøÁî®ÊñπÂºèÔºö&lt;/strong&gt;&lt;/p&gt; 
   &lt;h3&gt;ÊñπÂºè‰∏ÄÔºöÂÖçË¥π‰ΩøÁî®ÔºàÊé®ËçêÊñ∞ÊâãÔºâ üÜì&lt;/h3&gt; 
   &lt;p&gt;&lt;strong&gt;ÁâπÁÇπ&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;‚úÖ Êó†ÈúÄÊ≥®ÂÜåË¥¶Âè∑ÔºåÁ´ãÂç≥‰ΩøÁî®&lt;/li&gt; 
    &lt;li&gt;‚úÖ ÊØèÂ§© 250 Êù°Ê∂àÊÅØÔºàË∂≥Â§ü 90% Áî®Êà∑Ôºâ&lt;/li&gt; 
    &lt;li&gt;‚úÖ Topic ÂêçÁß∞Âç≥"ÂØÜÁ†Å"ÔºàÈúÄÈÄâÊã©‰∏çÊòìÁåúÊµãÁöÑÂêçÁß∞Ôºâ&lt;/li&gt; 
    &lt;li&gt;‚ö†Ô∏è Ê∂àÊÅØÊú™Âä†ÂØÜÔºå‰∏çÈÄÇÂêàÊïèÊÑü‰ø°ÊÅØ, ‰ΩÜÈÄÇÂêàÊàë‰ª¨Ëøô‰∏™È°πÁõÆÁöÑ‰∏çÊïèÊÑü‰ø°ÊÅØ&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;p&gt;&lt;strong&gt;Âø´ÈÄüÂºÄÂßãÔºö&lt;/strong&gt;&lt;/p&gt; 
   &lt;ol&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;‰∏ãËΩΩ ntfy Â∫îÁî®&lt;/strong&gt;Ôºö&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;AndroidÔºö&lt;a href="https://play.google.com/store/apps/details?id=io.heckel.ntfy"&gt;Google Play&lt;/a&gt; / &lt;a href="https://f-droid.org/en/packages/io.heckel.ntfy/"&gt;F-Droid&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;iOSÔºö&lt;a href="https://apps.apple.com/us/app/ntfy/id1625396347"&gt;App Store&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;Ê°åÈù¢ÔºöËÆøÈóÆ &lt;a href="https://ntfy.sh"&gt;ntfy.sh&lt;/a&gt;&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;ËÆ¢ÈòÖ‰∏ªÈ¢ò&lt;/strong&gt;ÔºàÈÄâÊã©‰∏Ä‰∏™ÈöæÁåúÁöÑÂêçÁß∞ÔºâÔºö&lt;/p&gt; &lt;pre&gt;&lt;code&gt;Âª∫ËÆÆÊ†ºÂºèÔºötrendradar-{‰Ω†ÁöÑÂêçÂ≠óÁº©ÂÜô}-{ÈöèÊú∫Êï∞Â≠ó}

‰∏çËÉΩ‰ΩøÁî®‰∏≠Êñá

‚úÖ Â•Ω‰æãÂ≠êÔºötrendradar-zs-8492
‚ùå Âùè‰æãÂ≠êÔºönews„ÄÅalertsÔºàÂ§™ÂÆπÊòìË¢´ÁåúÂà∞Ôºâ
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;ÈÖçÁΩÆ GitHub Secret&lt;/strong&gt;Ôºö&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt;&lt;code&gt;NTFY_TOPIC&lt;/code&gt;ÔºöÂ°´ÂÜô‰Ω†ÂàöÊâçËÆ¢ÈòÖÁöÑ‰∏ªÈ¢òÂêçÁß∞&lt;/li&gt; 
      &lt;li&gt;&lt;code&gt;NTFY_SERVER_URL&lt;/code&gt;ÔºöÁïôÁ©∫ÔºàÈªòËÆ§‰ΩøÁî® ntfy.shÔºâ&lt;/li&gt; 
      &lt;li&gt;&lt;code&gt;NTFY_TOKEN&lt;/code&gt;ÔºöÁïôÁ©∫&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;ÊµãËØï&lt;/strong&gt;Ôºö&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;curl -d "ÊµãËØïÊ∂àÊÅØ" ntfy.sh/‰Ω†ÁöÑ‰∏ªÈ¢òÂêçÁß∞
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;/ol&gt; 
   &lt;hr /&gt; 
   &lt;h3&gt;ÊñπÂºè‰∫åÔºöËá™ÊâòÁÆ°ÔºàÂÆåÂÖ®ÈöêÁßÅÊéßÂà∂Ôºâ üîí&lt;/h3&gt; 
   &lt;p&gt;&lt;strong&gt;ÈÄÇÂêà‰∫∫Áæ§&lt;/strong&gt;ÔºöÊúâÊúçÂä°Âô®„ÄÅËøΩÊ±ÇÂÆåÂÖ®ÈöêÁßÅ„ÄÅÊäÄÊúØËÉΩÂäõÂº∫&lt;/p&gt; 
   &lt;p&gt;&lt;strong&gt;‰ºòÂäø&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;‚úÖ ÂÆåÂÖ®ÂºÄÊ∫êÔºàApache 2.0 + GPLv2Ôºâ&lt;/li&gt; 
    &lt;li&gt;‚úÖ Êï∞ÊçÆÂÆåÂÖ®Ëá™‰∏ªÊéßÂà∂&lt;/li&gt; 
    &lt;li&gt;‚úÖ Êó†‰ªª‰ΩïÈôêÂà∂&lt;/li&gt; 
    &lt;li&gt;‚úÖ Èõ∂Ë¥πÁî®&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;p&gt;&lt;strong&gt;Docker ‰∏ÄÈîÆÈÉ®ÁΩ≤&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d \
  --name ntfy \
  -p 80:80 \
  -v /var/cache/ntfy:/var/cache/ntfy \
  binwiederhier/ntfy \
  serve --cache-file /var/cache/ntfy/cache.db
&lt;/code&gt;&lt;/pre&gt; 
   &lt;p&gt;&lt;strong&gt;ÈÖçÁΩÆ TrendRadar&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;pre&gt;&lt;code class="language-yaml"&gt;NTFY_SERVER_URL: https://ntfy.yourdomain.com
NTFY_TOPIC: trendradar-alerts  # Ëá™ÊâòÁÆ°ÂèØÁî®ÁÆÄÂçïÂêçÁß∞
NTFY_TOKEN: tk_your_token  # ÂèØÈÄâÔºöÂêØÁî®ËÆøÈóÆÊéßÂà∂
&lt;/code&gt;&lt;/pre&gt; 
   &lt;p&gt;&lt;strong&gt;Âú®Â∫îÁî®‰∏≠ËÆ¢ÈòÖ&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ÁÇπÂáª"Use another server"&lt;/li&gt; 
    &lt;li&gt;ËæìÂÖ•‰Ω†ÁöÑÊúçÂä°Âô®Âú∞ÂùÄ&lt;/li&gt; 
    &lt;li&gt;ËæìÂÖ•‰∏ªÈ¢òÂêçÁß∞&lt;/li&gt; 
    &lt;li&gt;ÔºàÂèØÈÄâÔºâËæìÂÖ•ÁôªÂΩïÂá≠ÊçÆ&lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;hr /&gt; 
   &lt;p&gt;&lt;strong&gt;Â∏∏ËßÅÈóÆÈ¢òÔºö&lt;/strong&gt;&lt;/p&gt; 
   &lt;details&gt; 
    &lt;summary&gt;&lt;strong&gt;Q1: ÂÖçË¥πÁâàÂ§üÁî®ÂêóÔºü&lt;/strong&gt;&lt;/summary&gt; 
    &lt;p&gt;ÊØèÂ§© 250 Êù°Ê∂àÊÅØÂØπÂ§ßÂ§öÊï∞Áî®Êà∑Ë∂≥Â§ü„ÄÇÊåâ 30 ÂàÜÈíüÊäìÂèñ‰∏ÄÊ¨°ËÆ°ÁÆóÔºåÊØèÂ§©Á∫¶ 48 Ê¨°Êé®ÈÄÅÔºåÂÆåÂÖ®Â§üÁî®„ÄÇ&lt;/p&gt; 
   &lt;/details&gt; 
   &lt;details&gt; 
    &lt;summary&gt;&lt;strong&gt;Q2: Topic ÂêçÁß∞ÁúüÁöÑÂÆâÂÖ®ÂêóÔºü&lt;/strong&gt;&lt;/summary&gt; 
    &lt;p&gt;Â¶ÇÊûú‰Ω†ÈÄâÊã©ÈöèÊú∫ÁöÑ„ÄÅË∂≥Â§üÈïøÁöÑÂêçÁß∞ÔºàÂ¶Ç &lt;code&gt;trendradar-zs-8492-news&lt;/code&gt;ÔºâÔºåÊö¥ÂäõÁ†¥Ëß£Âá†‰πé‰∏çÂèØËÉΩÔºö&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;ntfy Êúâ‰∏•Ê†ºÁöÑÈÄüÁéáÈôêÂà∂Ôºà1 Áßí 1 Ê¨°ËØ∑Ê±ÇÔºâ&lt;/li&gt; 
     &lt;li&gt;64 ‰∏™Â≠óÁ¨¶ÈÄâÊã©ÔºàA-Z, a-z, 0-9, _, -Ôºâ&lt;/li&gt; 
     &lt;li&gt;10 ‰ΩçÈöèÊú∫Â≠óÁ¨¶‰∏≤Êúâ 64^10 ÁßçÂèØËÉΩÊÄßÔºàÈúÄË¶ÅÊï∞Âπ¥ÊâçËÉΩÁ†¥Ëß£Ôºâ&lt;/li&gt; 
    &lt;/ul&gt; 
   &lt;/details&gt; 
   &lt;hr /&gt; 
   &lt;p&gt;&lt;strong&gt;Êé®ËçêÈÄâÊã©Ôºö&lt;/strong&gt;&lt;/p&gt; 
   &lt;table&gt; 
    &lt;thead&gt; 
     &lt;tr&gt; 
      &lt;th&gt;Áî®Êà∑Á±ªÂûã&lt;/th&gt; 
      &lt;th&gt;Êé®ËçêÊñπÊ°à&lt;/th&gt; 
      &lt;th&gt;ÁêÜÁî±&lt;/th&gt; 
     &lt;/tr&gt; 
    &lt;/thead&gt; 
    &lt;tbody&gt; 
     &lt;tr&gt; 
      &lt;td&gt;ÊôÆÈÄöÁî®Êà∑&lt;/td&gt; 
      &lt;td&gt;ÊñπÂºè‰∏ÄÔºàÂÖçË¥πÔºâ&lt;/td&gt; 
      &lt;td&gt;ÁÆÄÂçïÂø´ÈÄüÔºåÂ§üÁî®&lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td&gt;ÊäÄÊúØÁî®Êà∑&lt;/td&gt; 
      &lt;td&gt;ÊñπÂºè‰∫åÔºàËá™ÊâòÁÆ°Ôºâ&lt;/td&gt; 
      &lt;td&gt;ÂÆåÂÖ®ÊéßÂà∂ÔºåÊó†ÈôêÂà∂&lt;/td&gt; 
     &lt;/tr&gt; 
     &lt;tr&gt; 
      &lt;td&gt;È´òÈ¢ëÁî®Êà∑&lt;/td&gt; 
      &lt;td&gt;ÊñπÂºè‰∏âÔºà‰ªòË¥πÔºâ&lt;/td&gt; 
      &lt;td&gt;Ëøô‰∏™Ëá™Â∑±ÂéªÂÆòÁΩëÁúãÂêß&lt;/td&gt; 
     &lt;/tr&gt; 
    &lt;/tbody&gt; 
   &lt;/table&gt; 
   &lt;p&gt;&lt;strong&gt;Áõ∏ÂÖ≥ÈìæÊé•Ôºö&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://docs.ntfy.sh/"&gt;ntfy ÂÆòÊñπÊñáÊ°£&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://docs.ntfy.sh/install/"&gt;Ëá™ÊâòÁÆ°ÊïôÁ®ã&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://github.com/binwiederhier/ntfy"&gt;GitHub ‰ªìÂ∫ì&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; 
  &lt;/details&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ÈÖçÁΩÆËØ¥ÊòéÔºö&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Êé®ÈÄÅËÆæÁΩÆ&lt;/strong&gt;ÔºöÂú® &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/config/config.yaml"&gt;config/config.yaml&lt;/a&gt; ‰∏≠ÈÖçÁΩÆÊé®ÈÄÅÊ®°ÂºèÂíåÈÄöÁü•ÈÄâÈ°π&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;ÂÖ≥ÈîÆËØçËÆæÁΩÆ&lt;/strong&gt;ÔºöÂú® &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/config/frequency_words.txt"&gt;config/frequency_words.txt&lt;/a&gt; ‰∏≠Ê∑ªÂä†‰Ω†ÂÖ≥ÂøÉÁöÑÂÖ≥ÈîÆËØç&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Êé®ÈÄÅÈ¢ëÁéáË∞ÉÊï¥&lt;/strong&gt;ÔºöÂú® &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/.github/workflows/crawler.yml"&gt;.github/workflows/crawler.yml&lt;/a&gt; ËØ∑Ë∞®ÊÖéË∞ÉÊï¥ÔºåÂà´Ë¥™ÂøÉ&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;Ê≥®ÊÑè&lt;/strong&gt;ÔºöÂª∫ËÆÆÂè™Ë∞ÉÊï¥ÊñáÊ°£‰∏≠ÊòéÁ°ÆËØ¥ÊòéÁöÑÈÖçÁΩÆÈ°πÔºåÂÖ∂‰ªñÈÄâÈ°π‰∏ªË¶Å‰æõ‰ΩúËÄÖÂºÄÂèëÊó∂ÊµãËØï‰ΩøÁî®&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ÊâãÂä®ÊµãËØïÊñ∞ÈóªÊé®ÈÄÅ&lt;/strong&gt;Ôºö&lt;/p&gt; &lt;p&gt;ÊàëËøôÈáåÊòØÊãøÊàëÁöÑÈ°πÁõÆ‰∏æ‰æãÔºå‰Ω†Ë¶ÅÂéª‰Ω†&lt;strong&gt;fork&lt;/strong&gt;ÁöÑÈ°πÁõÆÂÅöÊµãËØï&lt;/p&gt; 
  &lt;ol&gt; 
   &lt;li&gt;&lt;strong&gt;ËøõÂÖ• Actions&lt;/strong&gt;Ôºö&lt;a href="https://github.com/sansan0/TrendRadar/actions"&gt;https://github.com/sansan0/TrendRadar/actions&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;ÊâæÂà∞ "Hot News Crawler" ÁöÑÁÇπËøõÂéªÔºåÂ¶ÇÊûúÁúã‰∏çÂà∞ËØ•Â≠óÊ†∑ÔºåÈÇ£‰πàÂèÇÁÖß&lt;a href="https://github.com/sansan0/TrendRadar/issues/109"&gt;#109&lt;/a&gt;Ëß£ÂÜ≥&lt;/li&gt; 
   &lt;li&gt;ÁÇπÂáª "Run workflow" ÊåâÈíÆËøêË°åÔºåÁ≠âÂæÖ 1 ÂàÜÈíüÂ∑¶Âè≥Êï∞ÊçÆÂà∞‰Ω†ÊâãÊú∫‰∏ä&lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;üê≥ Docker ÈÉ®ÁΩ≤&lt;/h2&gt; 
&lt;h4&gt;ÊñπÂºè‰∏ÄÔºöÂø´ÈÄü‰ΩìÈ™åÔºà‰∏ÄË°åÂëΩ‰ª§Ôºâ&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;Linux/macOS Á≥ªÁªüÔºö&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ÂàõÂª∫ÈÖçÁΩÆÁõÆÂΩïÂπ∂‰∏ãËΩΩÈÖçÁΩÆÊñá‰ª∂
mkdir -p config output
wget https://raw.githubusercontent.com/sansan0/TrendRadar/master/config/config.yaml -P config/
wget https://raw.githubusercontent.com/sansan0/TrendRadar/master/config/frequency_words.txt -P config/
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;ÊàñËÄÖ&lt;strong&gt;ÊâãÂä®ÂàõÂª∫&lt;/strong&gt;Ôºö&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Âú®ÂΩìÂâçÁõÆÂΩïÂàõÂª∫ &lt;code&gt;config&lt;/code&gt; Êñá‰ª∂Â§π&lt;/li&gt; 
 &lt;li&gt;‰∏ãËΩΩÈÖçÁΩÆÊñá‰ª∂Ôºö 
  &lt;ul&gt; 
   &lt;li&gt;ËÆøÈóÆ &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/config/config.yaml"&gt;https://raw.githubusercontent.com/sansan0/TrendRadar/master/config/config.yaml&lt;/a&gt; ‚Üí Âè≥ÈîÆ"Âè¶Â≠ò‰∏∫" ‚Üí ‰øùÂ≠òÂà∞ &lt;code&gt;config\config.yaml&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;ËÆøÈóÆ &lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/config/frequency_words.txt"&gt;https://raw.githubusercontent.com/sansan0/TrendRadar/master/config/frequency_words.txt&lt;/a&gt; ‚Üí Âè≥ÈîÆ"Âè¶Â≠ò‰∏∫" ‚Üí ‰øùÂ≠òÂà∞ &lt;code&gt;config\frequency_words.txt&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;ÂÆåÊàêÂêéÁöÑÁõÆÂΩïÁªìÊûÑÂ∫îËØ•ÊòØÔºö&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;ÂΩìÂâçÁõÆÂΩï/
‚îî‚îÄ‚îÄ config/
    ‚îú‚îÄ‚îÄ config.yaml
    ‚îî‚îÄ‚îÄ frequency_words.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d --name trend-radar \
  -v ./config:/app/config:ro \
  -v ./output:/app/output \
  -e FEISHU_WEBHOOK_URL="‰Ω†ÁöÑÈ£û‰π¶webhook" \
  -e DINGTALK_WEBHOOK_URL="‰Ω†ÁöÑÈíâÈíâwebhook" \
  -e WEWORK_WEBHOOK_URL="‰Ω†ÁöÑ‰ºÅ‰∏öÂæÆ‰ø°webhook" \
  -e TELEGRAM_BOT_TOKEN="‰Ω†ÁöÑtelegram_bot_token" \
  -e TELEGRAM_CHAT_ID="‰Ω†ÁöÑtelegram_chat_id" \
  -e EMAIL_FROM="‰Ω†ÁöÑÂèë‰ª∂ÈÇÆÁÆ±" \
  -e EMAIL_PASSWORD="‰Ω†ÁöÑÈÇÆÁÆ±ÂØÜÁ†ÅÊàñÊéàÊùÉÁ†Å" \
  -e EMAIL_TO="Êî∂‰ª∂‰∫∫ÈÇÆÁÆ±" \
  -e CRON_SCHEDULE="*/30 * * * *" \
  -e RUN_MODE="cron" \
  -e IMMEDIATE_RUN="true" \
  wantcat/trendradar:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;ÊñπÂºè‰∫åÔºö‰ΩøÁî® docker-composeÔºàÊé®ËçêÔºâ&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;ÂàõÂª∫È°πÁõÆÁõÆÂΩïÂíåÈÖçÁΩÆ&lt;/strong&gt;: &lt;pre&gt;&lt;code class="language-bash"&gt;# ÂàõÂª∫ÁõÆÂΩïÁªìÊûÑ
mkdir -p trendradar/{config,docker}
cd trendradar

# ‰∏ãËΩΩÈÖçÁΩÆÊñá‰ª∂Ê®°Êùø
wget https://raw.githubusercontent.com/sansan0/TrendRadar/master/config/config.yaml -P config/
wget https://raw.githubusercontent.com/sansan0/TrendRadar/master/config/frequency_words.txt -P config/

# ‰∏ãËΩΩ docker-compose ÈÖçÁΩÆ
wget https://raw.githubusercontent.com/sansan0/TrendRadar/master/docker/.env
wget https://raw.githubusercontent.com/sansan0/TrendRadar/master/docker/docker-compose.yml
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;ÂÆåÊàêÂêéÁöÑÁõÆÂΩïÁªìÊûÑÂ∫îËØ•ÊòØÔºö&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;ÂΩìÂâçÁõÆÂΩï/
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ config.yaml
‚îÇ   ‚îî‚îÄ‚îÄ frequency_words.txt
‚îî‚îÄ‚îÄ docker/
    ‚îú‚îÄ‚îÄ .env
    ‚îî‚îÄ‚îÄ docker-compose.yml
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ÈÖçÁΩÆÊñá‰ª∂ËØ¥Êòé&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;config/config.yaml&lt;/code&gt; - Â∫îÁî®‰∏ªÈÖçÁΩÆÔºàÊä•ÂëäÊ®°Âºè„ÄÅÊé®ÈÄÅËÆæÁΩÆÁ≠âÔºâ&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;config/frequency_words.txt&lt;/code&gt; - ÂÖ≥ÈîÆËØçÈÖçÁΩÆÔºàËÆæÁΩÆ‰Ω†ÂÖ≥ÂøÉÁöÑÁÉ≠ÁÇπËØçÊ±áÔºâ&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;.env&lt;/code&gt; - ÁéØÂ¢ÉÂèòÈáèÈÖçÁΩÆÔºàwebhook URLs ÂíåÂÆöÊó∂‰ªªÂä°Ôºâ&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ÂêØÂä®ÊúçÂä°&lt;/strong&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# ÊãâÂèñÊúÄÊñ∞ÈïúÂÉèÂπ∂ÂêØÂä®
docker-compose pull
docker-compose up -d
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Êü•ÁúãËøêË°åÁä∂ÊÄÅ&lt;/strong&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# Êü•ÁúãÊó•Âøó
docker logs -f trend-radar

# Êü•ÁúãÂÆπÂô®Áä∂ÊÄÅ
docker ps | grep trend-radar
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;ÊñπÂºè‰∏âÔºöÊú¨Âú∞ÊûÑÂª∫ÔºàÂºÄÂèëËÄÖÈÄâÈ°πÔºâ&lt;/h4&gt; 
&lt;p&gt;Â¶ÇÊûúÈúÄË¶ÅËá™ÂÆö‰πâ‰øÆÊîπ‰ª£Á†ÅÊàñÊûÑÂª∫Ëá™Â∑±ÁöÑÈïúÂÉèÔºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ÂÖãÈöÜÈ°πÁõÆ
git clone https://github.com/sansan0/TrendRadar.git
cd TrendRadar

# ‰øÆÊîπÈÖçÁΩÆÊñá‰ª∂
vim config/config.yaml
vim config/frequency_words.txt

# ‰ΩøÁî®ÊûÑÂª∫ÁâàÊú¨ÁöÑ docker-compose
cd docker
cp docker-compose-build.yml docker-compose.yml

# ÊûÑÂª∫Âπ∂ÂêØÂä®
docker-compose build
docker-compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;ÈïúÂÉèÊõ¥Êñ∞&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ÊñπÂºè‰∏ÄÔºöÊâãÂä®Êõ¥Êñ∞
docker pull wantcat/trendradar:latest
docker-compose down
docker-compose up -d

# ÊñπÂºè‰∫åÔºö‰ΩøÁî® docker-compose Êõ¥Êñ∞
docker-compose pull
docker-compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;ÊúçÂä°ÁÆ°ÁêÜÂëΩ‰ª§&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Êü•ÁúãËøêË°åÁä∂ÊÄÅ
docker exec -it trend-radar python manage.py status

# ÊâãÂä®ÊâßË°å‰∏ÄÊ¨°Áà¨Ëô´
docker exec -it trend-radar python manage.py run

# Êü•ÁúãÂÆûÊó∂Êó•Âøó
docker exec -it trend-radar python manage.py logs

# ÊòæÁ§∫ÂΩìÂâçÈÖçÁΩÆ
docker exec -it trend-radar python manage.py config

# ÊòæÁ§∫ËæìÂá∫Êñá‰ª∂
docker exec -it trend-radar python manage.py files

# Êü•ÁúãÂ∏ÆÂä©‰ø°ÊÅØ
docker exec -it trend-radar python manage.py help

# ÈáçÂêØÂÆπÂô®
docker restart trend-radar

# ÂÅúÊ≠¢ÂÆπÂô®
docker stop trend-radar

# Âà†Èô§ÂÆπÂô®Ôºà‰øùÁïôÊï∞ÊçÆÔºâ
docker rm trend-radar
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Êï∞ÊçÆÊåÅ‰πÖÂåñ&lt;/h4&gt; 
&lt;p&gt;ÁîüÊàêÁöÑÊä•ÂëäÂíåÊï∞ÊçÆÈªòËÆ§‰øùÂ≠òÂú® &lt;code&gt;./output&lt;/code&gt; ÁõÆÂΩï‰∏ãÔºåÂç≥‰ΩøÂÆπÂô®ÈáçÂêØÊàñÂà†Èô§ÔºåÊï∞ÊçÆ‰πü‰ºö‰øùÁïô„ÄÇ&lt;/p&gt; 
&lt;h4&gt;ÊïÖÈöúÊéíÊü•&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Ê£ÄÊü•ÂÆπÂô®Áä∂ÊÄÅ
docker inspect trend-radar

# Êü•ÁúãÂÆπÂô®Êó•Âøó
docker logs --tail 100 trend-radar

# ËøõÂÖ•ÂÆπÂô®Ë∞ÉËØï
docker exec -it trend-radar /bin/bash

# È™åËØÅÈÖçÁΩÆÊñá‰ª∂
docker exec -it trend-radar ls -la /app/config/
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ü§ñ AI Êô∫ËÉΩÂàÜÊûêÈÉ®ÁΩ≤&lt;/h2&gt; 
&lt;p&gt;TrendRadar v3.0.0 Êñ∞Â¢û‰∫ÜÂü∫‰∫é &lt;strong&gt;MCP (Model Context Protocol)&lt;/strong&gt; ÁöÑ AI ÂàÜÊûêÂäüËÉΩÔºåËÆ©‰Ω†ÂèØ‰ª•ÈÄöËøáËá™ÁÑ∂ËØ≠Ë®Ä‰∏éÊñ∞ÈóªÊï∞ÊçÆÂØπËØùÔºåËøõË°åÊ∑±Â∫¶ÂàÜÊûê„ÄÇ‰ΩøÁî® &lt;strong&gt;AI ÂäüËÉΩ&lt;/strong&gt; ÁöÑÊúÄ‰Ω≥ÂâçÊèêÊòØÂ∑≤‰ΩøÁî®Êú¨È°πÁõÆËá≥Â∞ëËøêË°å‰∏ÄÂ§©(ÁßØÁ¥ØÊñ∞ÈóªÊï∞ÊçÆ)&lt;/p&gt; 
&lt;h3&gt;1. Âø´ÈÄüÈÉ®ÁΩ≤&lt;/h3&gt; 
&lt;p&gt;Cherry Studio Êèê‰æõ GUI ÈÖçÁΩÆÁïåÈù¢Ôºå 5 ÂàÜÈíüÂø´ÈÄüÈÉ®ÁΩ≤Ôºå Â§çÊùÇÁöÑÈÉ®ÂàÜÊòØ‰∏ÄÈîÆÂÆâË£ÖÁöÑ„ÄÇ&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ÂõæÊñáÈÉ®ÁΩ≤ÊïôÁ®ã&lt;/strong&gt;ÔºöÁé∞Â∑≤Êõ¥Êñ∞Âà∞ÊàëÁöÑ&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#%E9%97%AE%E9%A2%98%E7%AD%94%E7%96%91%E4%B8%8E1%E5%85%83%E7%82%B9%E8%B5%9E"&gt;ÂÖ¨‰ºóÂè∑&lt;/a&gt;ÔºåÂõûÂ§ç "mcp" Âç≥ÂèØ&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ËØ¶ÁªÜÈÉ®ÁΩ≤ÊïôÁ®ã&lt;/strong&gt;Ôºö&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/README-Cherry-Studio.md"&gt;README-Cherry-Studio.md&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;2. Â≠¶‰π†‰∏é AI ÂØπËØùÁöÑÂßøÂäø&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;ËØ¶ÁªÜÂØπËØùÊïôÁ®ã&lt;/strong&gt;Ôºö&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/README-MCP-FAQ.md"&gt;README-MCP-FAQ.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ÊèêÈóÆÊïàÊûú&lt;/strong&gt;Ôºö&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ÂÆûÈôÖ‰∏çÂª∫ËÆÆ‰∏ÄÊ¨°ÊÄßÈóÆÂ§ö‰∏™ÈóÆÈ¢ò„ÄÇÂ¶ÇÊûú‰Ω†ÈÄâÊã©ÁöÑ ai Ê®°ÂûãËøû‰∏ãÂõæÁöÑÊåâÈ°∫Â∫èË∞ÉÁî®ÈÉΩÊó†Ê≥ïÂÅöÂà∞ÔºåÂª∫ËÆÆÊç¢‰∏Ä‰∏™„ÄÇ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/ai2.png" alt="mcp ‰ΩøÁî®ÊïàÊûúÂõæ2" width="600" /&gt; 
&lt;h2&gt;üîå MCP ÂÆ¢Êà∑Á´Ø&lt;/h2&gt; 
&lt;p&gt;TrendRadar MCP ÊúçÂä°ÊîØÊåÅÊ†áÂáÜÁöÑ Model Context Protocol (MCP) ÂçèËÆÆÔºåÂèØ‰ª•Êé•ÂÖ•ÂêÑÁßçÊîØÊåÅ MCP ÁöÑ AI ÂÆ¢Êà∑Á´ØËøõË°åÊô∫ËÉΩÂàÜÊûê„ÄÇ&lt;/p&gt; 
&lt;h3&gt;ÊîØÊåÅÁöÑÂÆ¢Êà∑Á´Ø&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Ê≥®ÊÑè‰∫ãÈ°π&lt;/strong&gt;Ôºö&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Â∞Ü &lt;code&gt;/path/to/TrendRadar&lt;/code&gt; ÊõøÊç¢‰∏∫‰Ω†ÁöÑÈ°πÁõÆÂÆûÈôÖË∑ØÂæÑ&lt;/li&gt; 
 &lt;li&gt;Windows Ë∑ØÂæÑ‰ΩøÁî®ÂèåÂèçÊñúÊù†Ôºö&lt;code&gt;C:\\Users\\YourName\\TrendRadar&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;‰øùÂ≠òÂêéËÆ∞ÂæóÈáçÂêØ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;üëâ Claude Desktop&lt;/b&gt;&lt;/summary&gt; 
 &lt;h4&gt;ÈÖçÁΩÆÊñá‰ª∂ÊñπÂºè&lt;/h4&gt; 
 &lt;p&gt;ÁºñËæë Claude Desktop ÁöÑ MCP ÈÖçÁΩÆÊñá‰ª∂Ôºö&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Windows&lt;/strong&gt;Ôºö &lt;code&gt;%APPDATA%\Claude\claude_desktop_config.json&lt;/code&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Mac&lt;/strong&gt;Ôºö &lt;code&gt;~/Library/Application Support/Claude/claude_desktop_config.json&lt;/code&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;ÈÖçÁΩÆÂÜÖÂÆπ&lt;/strong&gt;Ôºö&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "trendradar": {
      "command": "uv",
      "args": [
        "--directory",
        "/path/to/TrendRadar",
        "run",
        "python",
        "-m",
        "mcp_server.server"
      ],
      "env": {},
      "disabled": false,
      "alwaysAllow": []
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;üëâ Cursor&lt;/b&gt;&lt;/summary&gt; 
 &lt;h4&gt;ÊñπÂºè‰∏ÄÔºöHTTP Ê®°ÂºèÔºàÊé®ËçêÔºâ&lt;/h4&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;ÂêØÂä® HTTP ÊúçÂä°&lt;/strong&gt;Ôºö&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# Windows
start-http.bat

# Mac/Linux
./start-http.sh
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;ÈÖçÁΩÆ Cursor&lt;/strong&gt;Ôºö&lt;/p&gt; &lt;p&gt;&lt;strong&gt;È°πÁõÆÁ∫ßÈÖçÁΩÆ&lt;/strong&gt;ÔºàÊé®ËçêÔºâÔºö Âú®È°πÁõÆÊ†πÁõÆÂΩïÂàõÂª∫ &lt;code&gt;.cursor/mcp.json&lt;/code&gt;Ôºö&lt;/p&gt; &lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "trendradar": {
      "url": "http://localhost:3333/mcp",
      "description": "TrendRadar Êñ∞ÈóªÁÉ≠ÁÇπËÅöÂêàÂàÜÊûê"
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;ÂÖ®Â±ÄÈÖçÁΩÆ&lt;/strong&gt;Ôºö Âú®Áî®Êà∑ÁõÆÂΩïÂàõÂª∫ &lt;code&gt;~/.cursor/mcp.json&lt;/code&gt;ÔºàÂêåÊ†∑ÂÜÖÂÆπÔºâ&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;‰ΩøÁî®Ê≠•È™§&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;‰øùÂ≠òÈÖçÁΩÆÊñá‰ª∂ÂêéÈáçÂêØ Cursor&lt;/li&gt; 
    &lt;li&gt;Âú®ËÅäÂ§©ÁïåÈù¢ÁöÑ "Available Tools" ‰∏≠Êü•ÁúãÂ∑≤ËøûÊé•ÁöÑÂ∑•ÂÖ∑&lt;/li&gt; 
    &lt;li&gt;ÂºÄÂßã‰ΩøÁî®Ôºö&lt;code&gt;ÊêúÁ¥¢‰ªäÂ§©ÁöÑ"AI"Áõ∏ÂÖ≥Êñ∞Èóª&lt;/code&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;h4&gt;ÊñπÂºè‰∫åÔºöSTDIO Ê®°Âºè&lt;/h4&gt; 
 &lt;p&gt;ÂàõÂª∫ &lt;code&gt;.cursor/mcp.json&lt;/code&gt;Ôºö&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "trendradar": {
      "command": "uv",
      "args": [
        "--directory",
        "/path/to/TrendRadar",
        "run",
        "python",
        "-m",
        "mcp_server.server"
      ]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;üëâ VSCode (Cline/Continue)&lt;/b&gt;&lt;/summary&gt; 
 &lt;h4&gt;Cline ÈÖçÁΩÆ&lt;/h4&gt; 
 &lt;p&gt;Âú® Cline ÁöÑ MCP ËÆæÁΩÆ‰∏≠Ê∑ªÂä†Ôºö&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;HTTP Ê®°Âºè&lt;/strong&gt;ÔºàÊé®ËçêÔºâÔºö&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "trendradar": {
    "url": "http://localhost:3333/mcp",
    "type": "streamableHttp",
    "autoApprove": [],
    "disabled": false
  }
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;STDIO Ê®°Âºè&lt;/strong&gt;Ôºö&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "trendradar": {
    "command": "uv",
    "args": [
      "--directory",
      "/path/to/TrendRadar",
      "run",
      "python",
      "-m",
      "mcp_server.server"
    ],
    "type": "stdio",
    "disabled": false
  }
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;Continue ÈÖçÁΩÆ&lt;/h4&gt; 
 &lt;p&gt;ÁºñËæë &lt;code&gt;~/.continue/config.json&lt;/code&gt;Ôºö&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "experimental": {
    "modelContextProtocolServers": [
      {
        "transport": {
          "type": "stdio",
          "command": "uv",
          "args": [
            "--directory",
            "/path/to/TrendRadar",
            "run",
            "python",
            "-m",
            "mcp_server.server"
          ]
        }
      }
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;‰ΩøÁî®Á§∫‰æã&lt;/strong&gt;Ôºö&lt;/p&gt; 
 &lt;pre&gt;&lt;code&gt;ÂàÜÊûêÊúÄËøë7Â§©"ÁâπÊñØÊãâ"ÁöÑÁÉ≠Â∫¶ÂèòÂåñË∂ãÂäø
ÁîüÊàê‰ªäÂ§©ÁöÑÁÉ≠ÁÇπÊëòË¶ÅÊä•Âëä
ÊêúÁ¥¢"ÊØîÁâπÂ∏Å"Áõ∏ÂÖ≥Êñ∞ÈóªÂπ∂ÂàÜÊûêÊÉÖÊÑüÂÄæÂêë
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;üëâ Claude Code CLI&lt;/b&gt;&lt;/summary&gt; 
 &lt;h4&gt;HTTP Ê®°ÂºèÈÖçÁΩÆ&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# 1. ÂêØÂä® HTTP ÊúçÂä°
# Windows: start-http.bat
# Mac/Linux: ./start-http.sh

# 2. Ê∑ªÂä† MCP ÊúçÂä°Âô®
claude mcp add --transport http trendradar http://localhost:3333/mcp

# 3. È™åËØÅËøûÊé•ÔºàÁ°Æ‰øùÊúçÂä°Â∑≤ÂêØÂä®Ôºâ
claude mcp list
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;‰ΩøÁî®Á§∫‰æã&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Êü•ËØ¢Êñ∞Èóª
claude "ÊêúÁ¥¢‰ªäÂ§©Áü•‰πéÁöÑÁÉ≠ÁÇπÊñ∞ÈóªÔºåÂâç10Êù°"

# Ë∂ãÂäøÂàÜÊûê
claude "ÂàÜÊûê'‰∫∫Â∑•Êô∫ËÉΩ'Ëøô‰∏™ËØùÈ¢òÊúÄËøë‰∏ÄÂë®ÁöÑÁÉ≠Â∫¶Ë∂ãÂäø"

# Êï∞ÊçÆÂØπÊØî
claude "ÂØπÊØîÁü•‰πéÂíåÂæÆÂçöÂπ≥Âè∞ÂØπ'ÊØîÁâπÂ∏Å'ÁöÑÂÖ≥Ê≥®Â∫¶"
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;üëâ MCP Inspector&lt;/b&gt;ÔºàË∞ÉËØïÂ∑•ÂÖ∑Ôºâ&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;MCP Inspector ÊòØÂÆòÊñπË∞ÉËØïÂ∑•ÂÖ∑ÔºåÁî®‰∫éÊµãËØï MCP ËøûÊé•Ôºö&lt;/p&gt; 
 &lt;h4&gt;‰ΩøÁî®Ê≠•È™§&lt;/h4&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;ÂêØÂä® TrendRadar HTTP ÊúçÂä°&lt;/strong&gt;Ôºö&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# Windows
start-http.bat

# Mac/Linux
./start-http.sh
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;ÂêØÂä® MCP Inspector&lt;/strong&gt;Ôºö&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;npx @modelcontextprotocol/inspector
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Âú®ÊµèËßàÂô®‰∏≠ËøûÊé•&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ËÆøÈóÆÔºö&lt;code&gt;http://localhost:3333/mcp&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;ÊµãËØï "Ping Server" ÂäüËÉΩÈ™åËØÅËøûÊé•&lt;/li&gt; 
    &lt;li&gt;Ê£ÄÊü• "List Tools" ÊòØÂê¶ËøîÂõû 13 ‰∏™Â∑•ÂÖ∑Ôºö 
     &lt;ul&gt; 
      &lt;li&gt;Âü∫Á°ÄÊü•ËØ¢Ôºöget_latest_news, get_news_by_date, get_trending_topics&lt;/li&gt; 
      &lt;li&gt;Êô∫ËÉΩÊ£ÄÁ¥¢Ôºösearch_news, search_related_news_history&lt;/li&gt; 
      &lt;li&gt;È´òÁ∫ßÂàÜÊûêÔºöanalyze_topic_trend, analyze_data_insights, analyze_sentiment, find_similar_news, generate_summary_report&lt;/li&gt; 
      &lt;li&gt;Á≥ªÁªüÁÆ°ÁêÜÔºöget_current_config, get_system_status, trigger_crawl&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;üëâ ÂÖ∂‰ªñÊîØÊåÅ MCP ÁöÑÂÆ¢Êà∑Á´Ø&lt;/b&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;‰ªª‰ΩïÊîØÊåÅ Model Context Protocol ÁöÑÂÆ¢Êà∑Á´ØÈÉΩÂèØ‰ª•ËøûÊé• TrendRadarÔºö&lt;/p&gt; 
 &lt;h4&gt;HTTP Ê®°ÂºèÔºàÊé®ËçêÔºâ&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;ÊúçÂä°Âú∞ÂùÄ&lt;/strong&gt;Ôºö&lt;code&gt;http://localhost:3333/mcp&lt;/code&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Âü∫Êú¨ÈÖçÁΩÆÊ®°Êùø&lt;/strong&gt;Ôºö&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "name": "trendradar",
  "url": "http://localhost:3333/mcp",
  "type": "http",
  "description": "Êñ∞ÈóªÁÉ≠ÁÇπËÅöÂêàÂàÜÊûê"
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;STDIO Ê®°Âºè&lt;/h4&gt; 
 &lt;p&gt;&lt;strong&gt;Âü∫Êú¨ÈÖçÁΩÆÊ®°Êùø&lt;/strong&gt;Ôºö&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "name": "trendradar",
  "command": "uv",
  "args": [
    "--directory",
    "/path/to/TrendRadar",
    "run",
    "python",
    "-m",
    "mcp_server.server"
  ],
  "type": "stdio"
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Ê≥®ÊÑè‰∫ãÈ°π&lt;/strong&gt;Ôºö&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ÊõøÊç¢ &lt;code&gt;/path/to/TrendRadar&lt;/code&gt; ‰∏∫ÂÆûÈôÖÈ°πÁõÆË∑ØÂæÑ&lt;/li&gt; 
  &lt;li&gt;Windows Ë∑ØÂæÑ‰ΩøÁî®ÂèçÊñúÊù†ËΩ¨‰πâÔºö&lt;code&gt;C:\\Users\\...&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;Á°Æ‰øùÂ∑≤ÂÆåÊàêÈ°πÁõÆ‰æùËµñÂÆâË£ÖÔºàËøêË°åËøá setup ËÑöÊú¨Ôºâ&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;‚òïÈóÆÈ¢òÁ≠îÁñë‰∏é1ÂÖÉÁÇπËµû&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ÂøÉÊÑèÂà∞Â∞±Ë°åÔºåÊî∂Âà∞ÁöÑ&lt;strong&gt;ÁÇπËµû&lt;/strong&gt;Áî®‰∫éÊèêÈ´òÂºÄÂèëËÄÖÂºÄÊ∫êÁöÑÁßØÊûÅÊÄß„ÄÇ&lt;strong&gt;ÁÇπËµû&lt;/strong&gt;Â∑≤Êî∂ÂΩï‰∫é&lt;strong&gt;Ëá¥Ë∞¢ÂêçÂçï&lt;/strong&gt;&lt;br /&gt; ÊàëÂèëÁé∞Â§ßÂÆ∂ÈÉΩÂæàÂñÑ‰∫éÈù†Ëá™Â∑±Ëß£ÂÜ≥ÈóÆÈ¢òÔºåËøôÁßçÂ∞ùËØïÂÄºÂæóÈºìÂä±Ôºå‰ΩÜÂ¶ÇÊûúË¢´ÈóÆÈ¢òÂç°‰ΩèÂ§™‰πÖÔºåÂª∫ËÆÆÊèêÈóÆÊàñËÄÖÁïôË®Ä„ÄÇËøôÊ†∑ÊàëÊó¢ËÉΩÂ∏ÆÂà∞&lt;strong&gt;‰Ω†&lt;/strong&gt;Ôºå‰πüËÉΩÂ∏ÆÂà∞&lt;strong&gt;Êõ¥Â§öÊé¢Á¥¢‰∏≠ÁöÑÂ∞è‰ºô‰º¥&lt;/strong&gt;~~&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub Issues&lt;/strong&gt;ÔºöÈÄÇÂêàÈíàÂØπÊÄßÂº∫ÁöÑËß£Á≠î„ÄÇÊèêÈóÆÊó∂ËØ∑Êèê‰æõÂÆåÊï¥‰ø°ÊÅØÔºàÊà™Âõæ„ÄÅÈîôËØØÊó•Âøó„ÄÅÁ≥ªÁªüÁéØÂ¢ÉÁ≠âÔºâ„ÄÇ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÂÖ¨‰ºóÂè∑‰∫§ÊµÅ&lt;/strong&gt;ÔºöÈÄÇÂêàÂø´ÈÄüÂí®ËØ¢„ÄÇÂª∫ËÆÆ‰ºòÂÖàÂú®Áõ∏ÂÖ≥ÊñáÁ´†‰∏ãÁöÑÂÖ¨ÂÖ±ÁïôË®ÄÂå∫‰∫§ÊµÅÔºåÂ¶ÇÁßÅ‰ø°ÔºåËØ∑ÊñáÊòéÁ§ºË≤åÁî®ËØ≠üòâ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;ÂÖ¨‰ºóÂè∑ÂÖ≥Ê≥®&lt;/th&gt; 
   &lt;th align="center"&gt;ÂæÆ‰ø°ÁÇπËµû&lt;/th&gt; 
   &lt;th align="center"&gt;ÊîØ‰ªòÂÆùÁÇπËµû&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/weixin.png" width="300" title="Á°ÖÂü∫Ëå∂Ê∞¥Èó¥" /&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;img src="https://cdn-1258574687.cos.ap-shanghai.myqcloud.com/img/%2F2025%2F07%2F17%2F2ae0a88d98079f7e876c2b4dc85233c6-9e8025.JPG" width="300" title="ÂæÆ‰ø°ÊîØ‰ªò" /&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;img src="https://cdn-1258574687.cos.ap-shanghai.myqcloud.com/img/%2F2025%2F07%2F17%2F1ed4f20ab8e35be51f8e84c94e6e239b4-fe4947.JPG" width="300" title="ÊîØ‰ªòÂÆùÊîØ‰ªò" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Â∏∏ËßÅÈóÆÈ¢ò&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;üëâ Q1: HTTP ÊúçÂä°Êó†Ê≥ïÂêØÂä®Ôºü&lt;/b&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;Ê£ÄÊü•Ê≠•È™§&lt;/strong&gt;Ôºö&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;Á°ÆËÆ§Á´ØÂè£ 3333 Êú™Ë¢´Âç†Áî®Ôºö&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# Windows
netstat -ano | findstr :3333

# Mac/Linux
lsof -i :3333
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Ê£ÄÊü•È°πÁõÆ‰æùËµñÊòØÂê¶ÂÆâË£ÖÔºö&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# ÈáçÊñ∞ËøêË°åÂÆâË£ÖËÑöÊú¨
# Windows: setup-windows.bat ÊàñËÄÖ setup-windows-en.bat
# Mac/Linux: ./setup-mac.sh
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Êü•ÁúãËØ¶ÁªÜÈîôËØØÊó•ÂøóÔºö&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;uv run python -m mcp_server.server --transport http --port 3333
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Â∞ùËØïËá™ÂÆö‰πâÁ´ØÂè£:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;uv run python -m mcp_server.server --transport http --port 33333
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;üëâ Q2: ÂÆ¢Êà∑Á´ØÊó†Ê≥ïËøûÊé•Âà∞ MCP ÊúçÂä°Ôºü&lt;/b&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;Ëß£ÂÜ≥ÊñπÊ°à&lt;/strong&gt;Ôºö&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;STDIO Ê®°Âºè&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Á°ÆËÆ§ UV Ë∑ØÂæÑÊ≠£Á°ÆÔºàËøêË°å &lt;code&gt;which uv&lt;/code&gt; Êàñ &lt;code&gt;where uv&lt;/code&gt;Ôºâ&lt;/li&gt; 
    &lt;li&gt;Á°ÆËÆ§È°πÁõÆË∑ØÂæÑÊ≠£Á°Æ‰∏îÊó†‰∏≠ÊñáÂ≠óÁ¨¶&lt;/li&gt; 
    &lt;li&gt;Êü•ÁúãÂÆ¢Êà∑Á´ØÈîôËØØÊó•Âøó&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;HTTP Ê®°Âºè&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Á°ÆËÆ§ÊúçÂä°Â∑≤ÂêØÂä®ÔºàËÆøÈóÆ &lt;code&gt;http://localhost:3333/mcp&lt;/code&gt;Ôºâ&lt;/li&gt; 
    &lt;li&gt;Ê£ÄÊü•Èò≤ÁÅ´Â¢ôËÆæÁΩÆ&lt;/li&gt; 
    &lt;li&gt;Â∞ùËØï‰ΩøÁî® 127.0.0.1 Êõø‰ª£ localhost&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;ÈÄöÁî®Ê£ÄÊü•&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;ÈáçÂêØÂÆ¢Êà∑Á´ØÂ∫îÁî®&lt;/li&gt; 
    &lt;li&gt;Êü•Áúã MCP ÊúçÂä°Êó•Âøó&lt;/li&gt; 
    &lt;li&gt;‰ΩøÁî® MCP Inspector ÊµãËØïËøûÊé•&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;üëâ Q3: Â∑•ÂÖ∑Ë∞ÉÁî®Â§±Ë¥•ÊàñËøîÂõûÈîôËØØÔºü&lt;/b&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;ÂèØËÉΩÂéüÂõ†&lt;/strong&gt;Ôºö&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Êï∞ÊçÆ‰∏çÂ≠òÂú®&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Á°ÆËÆ§Â∑≤ËøêË°åËøáÁà¨Ëô´ÔºàÊúâ output ÁõÆÂΩïÊï∞ÊçÆÔºâ&lt;/li&gt; 
    &lt;li&gt;Ê£ÄÊü•Êü•ËØ¢Êó•ÊúüËåÉÂõ¥ÊòØÂê¶ÊúâÊï∞ÊçÆ&lt;/li&gt; 
    &lt;li&gt;Êü•Áúã output ÁõÆÂΩïÁöÑÂèØÁî®Êó•Êúü&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;ÂèÇÊï∞ÈîôËØØ&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Ê£ÄÊü•Êó•ÊúüÊ†ºÂºèÔºö&lt;code&gt;YYYY-MM-DD&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;Á°ÆËÆ§Âπ≥Âè∞ ID Ê≠£Á°ÆÔºö&lt;code&gt;zhihu&lt;/code&gt;, &lt;code&gt;weibo&lt;/code&gt; Á≠â&lt;/li&gt; 
    &lt;li&gt;Êü•ÁúãÂ∑•ÂÖ∑ÊñáÊ°£‰∏≠ÁöÑÂèÇÊï∞ËØ¥Êòé&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;ÈÖçÁΩÆÈóÆÈ¢ò&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Á°ÆËÆ§ &lt;code&gt;config/config.yaml&lt;/code&gt; Â≠òÂú®&lt;/li&gt; 
    &lt;li&gt;Á°ÆËÆ§ &lt;code&gt;config/frequency_words.txt&lt;/code&gt; Â≠òÂú®&lt;/li&gt; 
    &lt;li&gt;Ê£ÄÊü•ÈÖçÁΩÆÊñá‰ª∂Ê†ºÂºèÊòØÂê¶Ê≠£Á°Æ&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;h3&gt;È°πÁõÆÁõ∏ÂÖ≥&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;4 ÁØáÊñáÁ´†&lt;/strong&gt;Ôºö&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s/KYEPfTPVzZNWFclZh4am_g"&gt;ÂèØÂú®ËØ•ÊñáÁ´†‰∏ãÊñπÁïôË®ÄÔºåÊñπ‰æøÈ°πÁõÆ‰ΩúËÄÖÁî®ÊâãÊú∫Á≠îÁñë&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s/jzn0vLiQFX408opcfpPPxQ"&gt;2‰∏™ÊúàÁ†¥ 1000 starÔºåÊàëÁöÑGitHubÈ°πÁõÆÊé®ÂπøÂÆûÊàòÁªèÈ™å&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s/C8evK-U7onG1sTTdwdW2zg"&gt;github fork ËøêË°åÊú¨È°πÁõÆÁöÑÊ≥®ÊÑè‰∫ãÈ°π &lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mp.weixin.qq.com/s/8ghyfDAtQZjLrnWTQabYOQ"&gt;Âü∫‰∫éÊú¨È°πÁõÆÔºåÂ¶Ç‰ΩïÂºÄÂ±ïÂÖ¨‰ºóÂè∑ÊàñËÄÖÊñ∞ÈóªËµÑËÆØÁ±ªÊñáÁ´†ÂÜô‰Ωú&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;AI ÂºÄÂèë&lt;/strong&gt;Ôºö&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;Â¶ÇÊûú‰Ω†ÊúâÂ∞è‰ºóÈúÄÊ±ÇÔºåÂÆåÂÖ®ÂèØ‰ª•Âü∫‰∫éÊàëÁöÑÈ°πÁõÆËá™Ë°åÂºÄÂèëÔºåÈõ∂ÁºñÁ®ãÂü∫Á°ÄÁöÑ‰πüÂèØ‰ª•ËØïËØï&lt;/li&gt; 
 &lt;li&gt;ÊàëÊâÄÊúâÁöÑÂºÄÊ∫êÈ°πÁõÆÊàñÂ§öÊàñÂ∞ëÈÉΩ‰ΩøÁî®‰∫ÜËá™Â∑±ÂÜôÁöÑ&lt;strong&gt;AIËæÖÂä©ËΩØ‰ª∂&lt;/strong&gt;Êù•ÊèêÂçáÂºÄÂèëÊïàÁéáÔºåËøôÊ¨æÂ∑•ÂÖ∑Â∑≤ÂºÄÊ∫ê&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ê†∏ÂøÉÂäüËÉΩ&lt;/strong&gt;ÔºöËøÖÈÄüÁ≠õÈÄâÈ°πÁõÆ‰ª£Á†ÅÂñÇÁªôAIÔºå‰Ω†Âè™ÈúÄË¶ÅË°•ÂÖÖ‰∏™‰∫∫ÈúÄÊ±ÇÂç≥ÂèØ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;È°πÁõÆÂú∞ÂùÄ&lt;/strong&gt;Ôºö&lt;a href="https://github.com/sansan0/ai-code-context-helper"&gt;https://github.com/sansan0/ai-code-context-helper&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ÂÖ∂‰ΩôÈ°πÁõÆ&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;üìç ÊØõ‰∏ªÂ∏≠Ë∂≥ËøπÂú∞Âõæ - ‰∫§‰∫íÂºèÂä®ÊÄÅÂ±ïÁ§∫1893-1976Âπ¥ÂÆåÊï¥ËΩ®Ëøπ„ÄÇÊ¨¢ËøéËØ∏‰ΩçÂêåÂøóË¥°ÁåÆÊï∞ÊçÆ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sansan0/mao-map"&gt;https://github.com/sansan0/mao-map&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ÂìîÂì©ÂìîÂì©(bilibili)ËØÑËÆ∫Âå∫Êï∞ÊçÆÂèØËßÜÂåñÂàÜÊûêËΩØ‰ª∂&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sansan0/bilibili-comment-analyzer"&gt;https://github.com/sansan0/bilibili-comment-analyzer&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üëâ ÂæÆ‰ø°Êé®ÈÄÅÈÄöÁü•ÊñπÊ°à&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;Áî±‰∫éËØ•ÊñπÊ°àÊòØÂü∫‰∫é‰ºÅ‰∏öÂæÆ‰ø°ÁöÑÊèí‰ª∂Êú∫Âà∂ÔºåÊé®ÈÄÅÊ†∑Âºè‰πüÂçÅÂàÜ‰∏çÂêåÔºåÊâÄ‰ª•Áõ∏ÂÖ≥ÂÆûÁé∞ÊàëÊöÇÊó∂‰∏çÂáÜÂ§áÁ∫≥ÂÖ•ÂΩìÂâçÈ°πÁõÆ&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt;fork Ëøô‰ΩçÂÖÑÂè∞ÁöÑÈ°πÁõÆ &lt;a href="https://github.com/jayzqj/TrendRadar"&gt;https://github.com/jayzqj/TrendRadar&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;ÂÆåÊàê‰∏äÊñπÁöÑ‰ºÅ‰∏öÂæÆ‰ø°Êé®ÈÄÅËÆæÁΩÆ&lt;/li&gt; 
  &lt;li&gt;ÊåâÁÖß‰∏ãÈù¢ÂõæÁâáÊìç‰Ωú&lt;/li&gt; 
  &lt;li&gt;ÈÖçÁΩÆÂ•ΩÂêéÔºåÊâãÊú∫‰∏äÁöÑ‰ºÅ‰∏öÂæÆ‰ø° app Âà†Èô§Êéâ‰πüÊ≤°‰∫ã&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;img src="https://raw.githubusercontent.com/sansan0/TrendRadar/master/_image/wework.png" title="github" /&gt; 
&lt;/details&gt; 
&lt;h3&gt;Êú¨È°πÁõÆÊµÅÁ®ãÂõæ&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-mermaid"&gt;flowchart TD
    A[üë§ Áî®Êà∑ÂºÄÂßã] --&amp;gt; B{üöÄ ÈÄâÊã©ÈÉ®ÁΩ≤ÊñπÂºè}
    
    B --&amp;gt;|‰∫ëÁ´ØÈÉ®ÁΩ≤| C1[üç¥ Fork È°πÁõÆÂà∞ GitHub]
    B --&amp;gt;|Êú¨Âú∞ÈÉ®ÁΩ≤| C2[üê≥ Docker ÈÉ®ÁΩ≤]
    
    C1 --&amp;gt; D[‚öôÔ∏è ÈÖçÁΩÆÈÄöÁü•Ê∏†ÈÅì&amp;lt;br/&amp;gt;ÂèØÂêåÊó∂ÈÖçÁΩÆÂ§ö‰∏™]
    C2 --&amp;gt; D
    
    D --&amp;gt; E[ÈÄâÊã©ÈÄöÁü•ÊñπÂºèÔºö&amp;lt;br/&amp;gt;üì±‰ºÅ‰∏öÂæÆ‰ø° üí¨È£û‰π¶ üîîÈíâÈíâ&amp;lt;br/&amp;gt;üìüTelegram üìßÈÇÆ‰ª∂]
    
    E --&amp;gt; F[üîë Â°´ÂÜôÈÄöÁü•ÂèÇÊï∞&amp;lt;br/&amp;gt;GitHub Secrets ÊàñÁéØÂ¢ÉÂèòÈáè]
    
    F --&amp;gt; G[üìù ÈÖçÁΩÆÂÖ≥ÈîÆËØç&amp;lt;br/&amp;gt;config/frequency_words.txt&amp;lt;br/&amp;gt;ÊôÆÈÄöËØç/ÂøÖÈ°ªËØç+/ËøáÊª§ËØç!]
    
    G --&amp;gt; H[üéØ ÈÄâÊã©ËøêË°åÊ®°Âºè&amp;lt;br/&amp;gt;config/config.yaml]
    
    H --&amp;gt; H1[üìã daily - ÂΩìÊó•Ê±áÊÄª&amp;lt;br/&amp;gt;ÂÆöÊó∂Êé®ÈÄÅÊâÄÊúâÂåπÈÖçÊñ∞Èóª]
    H --&amp;gt; H2[üì∞ current - ÂΩìÂâçÊ¶úÂçï&amp;lt;br/&amp;gt;ÂÆöÊó∂Êé®ÈÄÅÊúÄÊñ∞Ê¶úÂçï]
    H --&amp;gt; H3[üìà incremental - Â¢ûÈáèÁõëÊéß&amp;lt;br/&amp;gt;‰ªÖÊé®ÈÄÅÊñ∞Â¢ûÂÜÖÂÆπ]
    
    H1 --&amp;gt; I[ÂèØÈÄâÔºöÊé®ÈÄÅÊó∂Èó¥Á™óÂè£ÊéßÂà∂&amp;lt;br/&amp;gt;‚è∞ ÈôêÂà∂Êé®ÈÄÅÊó∂Èó¥ËåÉÂõ¥]
    H2 --&amp;gt; I
    H3 --&amp;gt; I
    
    I --&amp;gt; J[‚úÖ ÈÖçÁΩÆÂÆåÊàê]
    
    J --&amp;gt; K[ü§ñ Á≥ªÁªüËá™Âä®ËøêË°å]
    
    K --&amp;gt; L[üï∑Ô∏è Áà¨Âèñ11+Âπ≥Âè∞ÁÉ≠ÁÇπ]
    L --&amp;gt; M[üîç ÂÖ≥ÈîÆËØçÁ≠õÈÄâ]
    M --&amp;gt; N[‚öñÔ∏è ÊùÉÈáçÁÆóÊ≥ïÊéíÂ∫è&amp;lt;br/&amp;gt;ÊéíÂêç60% + È¢ëÊ¨°30% + ÁÉ≠Â∫¶10%]
    N --&amp;gt; O[üìä ÁîüÊàêÊä•Âëä&amp;lt;br/&amp;gt;HTMLÁΩëÈ°µ + Êé®ÈÄÅÊ∂àÊÅØ]
    O --&amp;gt; P[üì± Â§öÊ∏†ÈÅìÊé®ÈÄÅÈÄöÁü•]
    
    P --&amp;gt; Q[üéâ ÊåÅÁª≠Êé•Êî∂Á≤æÂáÜÊé®ÈÄÅ&amp;lt;br/&amp;gt;ÂëäÂà´‰ø°ÊÅØËøáËΩΩ]
    
    style A fill:#e3f2fd
    style B fill:#f3e5f5
    style D fill:#fff3e0
    style F fill:#fff9c4
    style G fill:#e8f5e9
    style H fill:#e0f2f1
    style I fill:#fce4ec
    style O fill:#e1bee7
    style Q fill:#c8e6c9
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#sansan0/TrendRadar&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=sansan0/TrendRadar&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üìÑ ËÆ∏ÂèØËØÅ&lt;/h2&gt; 
&lt;p&gt;GPL-3.0 License&lt;/p&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/sansan0/TrendRadar/master/#trendradar"&gt;üîù ÂõûÂà∞È°∂ÈÉ®&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Skyvern-AI/skyvern</title>
      <link>https://github.com/Skyvern-AI/skyvern</link>
      <description>&lt;p&gt;Automate browser based workflows with AI&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; &lt;a href="https://www.skyvern.com"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="fern/images/skyvern_logo.png" /&gt; 
   &lt;img height="120" src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/skyvern_logo_blackbg.png" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;br /&gt; &lt;/h1&gt; 
&lt;p align="center"&gt; üêâ Automate Browser-based workflows using LLMs and Computer Vision üêâ &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.skyvern.com/"&gt;&lt;img src="https://img.shields.io/badge/Website-blue?logo=googlechrome&amp;amp;logoColor=black" /&gt;&lt;/a&gt; &lt;a href="https://www.skyvern.com/docs/"&gt;&lt;img src="https://img.shields.io/badge/Docs-yellow?logo=gitbook&amp;amp;logoColor=black" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/fG2XXEuQX3"&gt;&lt;img src="https://img.shields.io/discord/1212486326352617534?logo=discord&amp;amp;label=discord" /&gt;&lt;/a&gt; 
 &lt;!-- &lt;a href="https://pepy.tech/project/skyvern" target="_blank"&gt;&lt;img src="https://static.pepy.tech/badge/skyvern" alt="Total Downloads"/&gt;&lt;/a&gt; --&gt; &lt;a href="https://github.com/skyvern-ai/skyvern"&gt;&lt;img src="https://img.shields.io/github/stars/skyvern-ai/skyvern" /&gt;&lt;/a&gt; &lt;a href="https://github.com/Skyvern-AI/skyvern/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/skyvern-ai/skyvern" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/skyvernai"&gt;&lt;img src="https://img.shields.io/twitter/follow/skyvernai?style=social" /&gt;&lt;/a&gt; &lt;a href="https://www.linkedin.com/company/95726232"&gt;&lt;img src="https://img.shields.io/badge/Follow%20 on%20LinkedIn-8A2BE2?logo=linkedin" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.skyvern.com"&gt;Skyvern&lt;/a&gt; automates browser-based workflows using LLMs and computer vision. It provides a simple API endpoint to fully automate manual workflows on a large number of websites, replacing brittle or unreliable automation solutions.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/geico_shu_recording_cropped.gif" /&gt; &lt;/p&gt; 
&lt;p&gt;Traditional approaches to browser automations required writing custom scripts for websites, often relying on DOM parsing and XPath-based interactions which would break whenever the website layouts changed.&lt;/p&gt; 
&lt;p&gt;Instead of only relying on code-defined XPath interactions, Skyvern relies on Vision LLMs to learn and interact with the websites.&lt;/p&gt; 
&lt;h1&gt;How it works&lt;/h1&gt; 
&lt;p&gt;Skyvern was inspired by the Task-Driven autonomous agent design popularized by &lt;a href="https://github.com/yoheinakajima/babyagi"&gt;BabyAGI&lt;/a&gt; and &lt;a href="https://github.com/Significant-Gravitas/AutoGPT"&gt;AutoGPT&lt;/a&gt; -- with one major bonus: we give Skyvern the ability to interact with websites using browser automation libraries like &lt;a href="https://playwright.dev/"&gt;Playwright&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Skyvern uses a swarm of agents to comprehend a website, and plan and execute its actions:&lt;/p&gt; 
&lt;picture&gt; 
 &lt;source media="(prefers-color-scheme: dark)" srcset="fern/images/skyvern_2_0_system_diagram.png" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/skyvern_2_0_system_diagram.png" /&gt; 
&lt;/picture&gt; 
&lt;p&gt;This approach has a few advantages:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Skyvern can operate on websites it's never seen before, as it's able to map visual elements to actions necessary to complete a workflow, without any customized code&lt;/li&gt; 
 &lt;li&gt;Skyvern is resistant to website layout changes, as there are no pre-determined XPaths or other selectors our system is looking for while trying to navigate&lt;/li&gt; 
 &lt;li&gt;Skyvern is able to take a single workflow and apply it to a large number of websites, as it's able to reason through the interactions necessary to complete the workflow&lt;/li&gt; 
 &lt;li&gt;Skyvern leverages LLMs to reason through interactions to ensure we can cover complex situations. Examples include: 
  &lt;ol&gt; 
   &lt;li&gt;If you wanted to get an auto insurance quote from Geico, the answer to a common question "Were you eligible to drive at 18?" could be inferred from the driver receiving their license at age 16&lt;/li&gt; 
   &lt;li&gt;If you were doing competitor analysis, it's understanding that an Arnold Palmer 22 oz can at 7/11 is almost definitely the same product as a 23 oz can at Gopuff (even though the sizes are slightly different, which could be a rounding error!)&lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;A detailed technical report can be found &lt;a href="https://www.skyvern.com/blog/skyvern-2-0-state-of-the-art-web-navigation-with-85-8-on-webvoyager-eval/"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Demo&lt;/h1&gt; 
&lt;!-- Redo demo --&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/5cab4668-e8e2-4982-8551-aab05ff73a7f"&gt;https://github.com/user-attachments/assets/5cab4668-e8e2-4982-8551-aab05ff73a7f&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Performance &amp;amp; Evaluation&lt;/h1&gt; 
&lt;p&gt;Skyvern has SOTA performance on the &lt;a href="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/webbench.ai"&gt;WebBench benchmark&lt;/a&gt; with a 64.4% accuracy. The technical report + evaluation can be found &lt;a href="https://www.skyvern.com/blog/web-bench-a-new-way-to-compare-ai-browser-agents/"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/performance/webbench_overall.png" /&gt; &lt;/p&gt; 
&lt;h2&gt;Performance on WRITE tasks (eg filling out forms, logging in, downloading files, etc)&lt;/h2&gt; 
&lt;p&gt;Skyvern is the best performing agent on WRITE tasks (eg filling out forms, logging in, downloading files, etc), which is primarily used for RPA (Robotic Process Automation) adjacent tasks.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/performance/webbench_write.png" /&gt; &lt;/p&gt; 
&lt;h1&gt;Quickstart&lt;/h1&gt; 
&lt;h2&gt;Skyvern Cloud&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://app.skyvern.com"&gt;Skyvern Cloud&lt;/a&gt; is a managed cloud version of Skyvern that allows you to run Skyvern without worrying about the infrastructure. It allows you to run multiple Skyvern instances in parallel and comes bundled with anti-bot detection mechanisms, proxy network, and CAPTCHA solvers.&lt;/p&gt; 
&lt;p&gt;If you'd like to try it out, navigate to &lt;a href="https://app.skyvern.com"&gt;app.skyvern.com&lt;/a&gt; and create an account.&lt;/p&gt; 
&lt;h2&gt;Install &amp;amp; Run&lt;/h2&gt; 
&lt;p&gt;Dependencies needed:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.python.org/downloads/"&gt;Python 3.11.x&lt;/a&gt;, works with 3.12, not ready yet for 3.13&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://nodejs.org/en/download/"&gt;NodeJS &amp;amp; NPM&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Additionally, for Windows:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://rustup.rs/"&gt;Rust&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;VS Code with C++ dev tools and Windows SDK&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;1. Install Skyvern&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install skyvern
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. Run Skyvern&lt;/h3&gt; 
&lt;p&gt;This is most helpful for first time run (db setup, db migrations etc).&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;skyvern quickstart
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;3. Run task&lt;/h3&gt; 
&lt;h4&gt;UI (Recommended)&lt;/h4&gt; 
&lt;p&gt;Start the Skyvern service and UI (when DB is up and running)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;skyvern run all
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Go to &lt;a href="http://localhost:8080"&gt;http://localhost:8080&lt;/a&gt; and use the UI to run a task&lt;/p&gt; 
&lt;h4&gt;Code&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from skyvern import Skyvern

skyvern = Skyvern()
task = await skyvern.run_task(prompt="Find the top post on hackernews today")
print(task)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Skyvern starts running the task in a browser that pops up and closes it when the task is done. You will be able to view the task from &lt;a href="http://localhost:8080/history"&gt;http://localhost:8080/history&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;You can also run a task on different targets:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from skyvern import Skyvern

# Run on Skyvern Cloud
skyvern = Skyvern(api_key="SKYVERN API KEY")

# Local Skyvern service
skyvern = Skyvern(base_url="http://localhost:8000", api_key="LOCAL SKYVERN API KEY")

task = await skyvern.run_task(prompt="Find the top post on hackernews today")
print(task)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Advanced Usage&lt;/h2&gt; 
&lt;h3&gt;Control your own browser (Chrome)&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;‚ö†Ô∏è WARNING: Since &lt;a href="https://developer.chrome.com/blog/remote-debugging-port"&gt;Chrome 136&lt;/a&gt;, Chrome refuses any CDP connect to the browser using the default user_data_dir. In order to use your browser data, Skyvern copies your default user_data_dir to &lt;code&gt;./tmp/user_data_dir&lt;/code&gt; the first time connecting to your local browser. ‚ö†Ô∏è&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol&gt; 
 &lt;li&gt;Just With Python Code&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from skyvern import Skyvern

# The path to your Chrome browser. This example path is for Mac.
browser_path = "/Applications/Google Chrome.app/Contents/MacOS/Google Chrome"
skyvern = Skyvern(
    base_url="http://localhost:8000",
    api_key="YOUR_API_KEY",
    browser_path=browser_path,
)
task = await skyvern.run_task(
    prompt="Find the top post on hackernews today",
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;With Skyvern Service&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Add two variables to your .env file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# The path to your Chrome browser. This example path is for Mac.
CHROME_EXECUTABLE_PATH="/Applications/Google Chrome.app/Contents/MacOS/Google Chrome"
BROWSER_TYPE=cdp-connect
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Restart Skyvern service &lt;code&gt;skyvern run all&lt;/code&gt; and run the task through UI or code&lt;/p&gt; 
&lt;h3&gt;Run Skyvern with any remote browser&lt;/h3&gt; 
&lt;p&gt;Grab the cdp connection url and pass it to Skyvern&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from skyvern import Skyvern

skyvern = Skyvern(cdp_url="your cdp connection url")
task = await skyvern.run_task(
    prompt="Find the top post on hackernews today",
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Get consistent output schema from your run&lt;/h3&gt; 
&lt;p&gt;You can do this by adding the &lt;code&gt;data_extraction_schema&lt;/code&gt; parameter:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from skyvern import Skyvern

skyvern = Skyvern()
task = await skyvern.run_task(
    prompt="Find the top post on hackernews today",
    data_extraction_schema={
        "type": "object",
        "properties": {
            "title": {
                "type": "string",
                "description": "The title of the top post"
            },
            "url": {
                "type": "string",
                "description": "The URL of the top post"
            },
            "points": {
                "type": "integer",
                "description": "Number of points the post has received"
            }
        }
    }
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Helpful commands to debug issues&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Launch the Skyvern Server Separately*
skyvern run server

# Launch the Skyvern UI
skyvern run ui

# Check status of the Skyvern service
skyvern status

# Stop the Skyvern service
skyvern stop all

# Stop the Skyvern UI
skyvern stop ui

# Stop the Skyvern Server Separately
skyvern stop server
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Docker Compose setup&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Make sure you have &lt;a href="https://www.docker.com/products/docker-desktop/"&gt;Docker Desktop&lt;/a&gt; installed and running on your machine&lt;/li&gt; 
 &lt;li&gt;Make sure you don't have postgres running locally (Run &lt;code&gt;docker ps&lt;/code&gt; to check)&lt;/li&gt; 
 &lt;li&gt;Clone the repository and navigate to the root directory&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;skyvern init llm&lt;/code&gt; to generate a &lt;code&gt;.env&lt;/code&gt; file. This will be copied into the Docker image.&lt;/li&gt; 
 &lt;li&gt;Fill in the LLM provider key on the &lt;a href="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/docker-compose.yml"&gt;docker-compose.yml&lt;/a&gt;. &lt;em&gt;If you want to run Skyvern on a remote server, make sure you set the correct server ip for the UI container in &lt;a href="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/docker-compose.yml"&gt;docker-compose.yml&lt;/a&gt;.&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;Run the following command via the commandline: &lt;pre&gt;&lt;code class="language-bash"&gt; docker compose up -d
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Navigate to &lt;code&gt;http://localhost:8080&lt;/code&gt; in your browser to start using the UI&lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt; Only one Postgres container can run on port 5432 at a time. If you switch from the CLI-managed Postgres to Docker Compose, you must first remove the original container:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;docker rm -f postgresql-container
&lt;/code&gt;&lt;/pre&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;If you encounter any database related errors while using Docker to run Skyvern, check which Postgres container is running with &lt;code&gt;docker ps&lt;/code&gt;.&lt;/p&gt; 
&lt;h1&gt;Skyvern Features&lt;/h1&gt; 
&lt;h2&gt;Skyvern Tasks&lt;/h2&gt; 
&lt;p&gt;Tasks are the fundamental building block inside Skyvern. Each task is a single request to Skyvern, instructing it to navigate through a website and accomplish a specific goal.&lt;/p&gt; 
&lt;p&gt;Tasks require you to specify a &lt;code&gt;url&lt;/code&gt;, &lt;code&gt;prompt&lt;/code&gt;, and can optionally include a &lt;code&gt;data schema&lt;/code&gt; (if you want the output to conform to a specific schema) and &lt;code&gt;error codes&lt;/code&gt; (if you want Skyvern to stop running in specific situations).&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/skyvern_2_0_screenshot.png" /&gt; &lt;/p&gt; 
&lt;h2&gt;Skyvern Workflows&lt;/h2&gt; 
&lt;p&gt;Workflows are a way to chain multiple tasks together to form a cohesive unit of work.&lt;/p&gt; 
&lt;p&gt;For example, if you wanted to download all invoices newer than January 1st, you could create a workflow that first navigated to the invoices page, then filtered down to only show invoices newer than January 1st, extracted a list of all eligible invoices, and iterated through each invoice to download it.&lt;/p&gt; 
&lt;p&gt;Another example is if you wanted to automate purchasing products from an e-commerce store, you could create a workflow that first navigated to the desired product, then added it to a cart. Second, it would navigate to the cart and validate the cart state. Finally, it would go through the checkout process to purchase the items.&lt;/p&gt; 
&lt;p&gt;Supported workflow features include:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Browser Task&lt;/li&gt; 
 &lt;li&gt;Browser Action&lt;/li&gt; 
 &lt;li&gt;Data Extraction&lt;/li&gt; 
 &lt;li&gt;Validation&lt;/li&gt; 
 &lt;li&gt;For Loops&lt;/li&gt; 
 &lt;li&gt;File parsing&lt;/li&gt; 
 &lt;li&gt;Sending emails&lt;/li&gt; 
 &lt;li&gt;Text Prompts&lt;/li&gt; 
 &lt;li&gt;HTTP Request Block&lt;/li&gt; 
 &lt;li&gt;Custom Code Block&lt;/li&gt; 
 &lt;li&gt;Uploading files to block storage&lt;/li&gt; 
 &lt;li&gt;(Coming soon) Conditionals&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/block_example_v2.png" /&gt; &lt;/p&gt; 
&lt;h2&gt;Livestreaming&lt;/h2&gt; 
&lt;p&gt;Skyvern allows you to livestream the viewport of the browser to your local machine so that you can see exactly what Skyvern is doing on the web. This is useful for debugging and understanding how Skyvern is interacting with a website, and intervening when necessary&lt;/p&gt; 
&lt;h2&gt;Form Filling&lt;/h2&gt; 
&lt;p&gt;Skyvern is natively capable of filling out form inputs on websites. Passing in information via the &lt;code&gt;navigation_goal&lt;/code&gt; will allow Skyvern to comprehend the information and fill out the form accordingly.&lt;/p&gt; 
&lt;h2&gt;Data Extraction&lt;/h2&gt; 
&lt;p&gt;Skyvern is also capable of extracting data from a website.&lt;/p&gt; 
&lt;p&gt;You can also specify a &lt;code&gt;data_extraction_schema&lt;/code&gt; directly within the main prompt to tell Skyvern exactly what data you'd like to extract from the website, in jsonc format. Skyvern's output will be structured in accordance to the supplied schema.&lt;/p&gt; 
&lt;h2&gt;File Downloading&lt;/h2&gt; 
&lt;p&gt;Skyvern is also capable of downloading files from a website. All downloaded files are automatically uploaded to block storage (if configured), and you can access them via the UI.&lt;/p&gt; 
&lt;h2&gt;Authentication&lt;/h2&gt; 
&lt;p&gt;Skyvern supports a number of different authentication methods to make it easier to automate tasks behind a login. If you'd like to try it out, please reach out to us &lt;a href="mailto:founders@skyvern.com"&gt;via email&lt;/a&gt; or &lt;a href="https://discord.gg/fG2XXEuQX3"&gt;discord&lt;/a&gt;.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/secure_password_task_example.png" /&gt; &lt;/p&gt; 
&lt;h3&gt;üîê 2FA Support (TOTP)&lt;/h3&gt; 
&lt;p&gt;Skyvern supports a number of different 2FA methods to allow you to automate workflows that require 2FA.&lt;/p&gt; 
&lt;p&gt;Examples include:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;QR-based 2FA (e.g. Google Authenticator, Authy)&lt;/li&gt; 
 &lt;li&gt;Email based 2FA&lt;/li&gt; 
 &lt;li&gt;SMS based 2FA&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;üîê Learn more about 2FA support &lt;a href="https://www.skyvern.com/docs/credentials/totp"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Password Manager Integrations&lt;/h3&gt; 
&lt;p&gt;Skyvern currently supports the following password manager integrations:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Bitwarden&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; 1Password&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; LastPass&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Model Context Protocol (MCP)&lt;/h2&gt; 
&lt;p&gt;Skyvern supports the Model Context Protocol (MCP) to allow you to use any LLM that supports MCP.&lt;/p&gt; 
&lt;p&gt;See the MCP documentation &lt;a href="https://github.com/Skyvern-AI/skyvern/raw/main/integrations/mcp/README.md"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Zapier / Make.com / N8N Integration&lt;/h2&gt; 
&lt;p&gt;Skyvern supports Zapier, Make.com, and N8N to allow you to connect your Skyvern workflows to other apps.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.skyvern.com/docs/integrations/zapier"&gt;Zapier&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.skyvern.com/docs/integrations/make.com"&gt;Make.com&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.skyvern.com/docs/integrations/n8n"&gt;N8N&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;üîê Learn more about 2FA support &lt;a href="https://www.skyvern.com/docs/credentials/totp"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Real-world examples of Skyvern&lt;/h1&gt; 
&lt;p&gt;We love to see how Skyvern is being used in the wild. Here are some examples of how Skyvern is being used to automate workflows in the real world. Please open PRs to add your own examples!&lt;/p&gt; 
&lt;h2&gt;Invoice Downloading on many different websites&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://meetings.hubspot.com/skyvern/demo"&gt;Book a demo to see it live&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/invoice_downloading.gif" /&gt; &lt;/p&gt; 
&lt;h2&gt;Automate the job application process&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://app.skyvern.com/tasks/create/job_application"&gt;üí° See it in action&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/job_application_demo.gif" /&gt; &lt;/p&gt; 
&lt;h2&gt;Automate materials procurement for a manufacturing company&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://app.skyvern.com/tasks/create/finditparts"&gt;üí° See it in action&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/finditparts_recording_crop.gif" /&gt; &lt;/p&gt; 
&lt;h2&gt;Navigating to government websites to register accounts or fill out forms&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://app.skyvern.com/tasks/create/california_edd"&gt;üí° See it in action&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/edd_services.gif" /&gt; &lt;/p&gt; 
&lt;!-- Add example of delaware entity lookups x2 --&gt; 
&lt;h2&gt;Filling out random contact us forms&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://app.skyvern.com/tasks/create/contact_us_forms"&gt;üí° See it in action&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/contact_forms.gif" /&gt; &lt;/p&gt; 
&lt;h2&gt;Retrieving insurance quotes from insurance providers in any language&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://app.skyvern.com/tasks/create/bci_seguros"&gt;üí° See it in action&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/bci_seguros_recording.gif" /&gt; &lt;/p&gt; 
&lt;p&gt;&lt;a href="https://app.skyvern.com/tasks/create/geico"&gt;üí° See it in action&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/geico_shu_recording_cropped.gif" /&gt; &lt;/p&gt; 
&lt;h1&gt;Contributor Setup&lt;/h1&gt; 
&lt;p&gt;Make sure to have &lt;a href="https://docs.astral.sh/uv/getting-started/installation/"&gt;uv&lt;/a&gt; installed.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Run this to create your virtual environment (&lt;code&gt;.venv&lt;/code&gt;) &lt;pre&gt;&lt;code class="language-bash"&gt;uv sync --group dev
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Perform initial server configuration &lt;pre&gt;&lt;code class="language-bash"&gt;uv run skyvern quickstart
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Navigate to &lt;code&gt;http://localhost:8080&lt;/code&gt; in your browser to start using the UI &lt;em&gt;The Skyvern CLI supports Windows, WSL, macOS, and Linux environments.&lt;/em&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h1&gt;Documentation&lt;/h1&gt; 
&lt;p&gt;More extensive documentation can be found on our &lt;a href="https://www.skyvern.com/docs"&gt;üìï docs page&lt;/a&gt;. Please let us know if something is unclear or missing by opening an issue or reaching out to us &lt;a href="mailto:founders@skyvern.com"&gt;via email&lt;/a&gt; or &lt;a href="https://discord.gg/fG2XXEuQX3"&gt;discord&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Supported LLMs&lt;/h1&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Provider&lt;/th&gt; 
   &lt;th&gt;Supported Models&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenAI&lt;/td&gt; 
   &lt;td&gt;gpt4-turbo, gpt-4o, gpt-4o-mini&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Anthropic&lt;/td&gt; 
   &lt;td&gt;Claude 3 (Haiku, Sonnet, Opus), Claude 3.5 (Sonnet)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Azure OpenAI&lt;/td&gt; 
   &lt;td&gt;Any GPT models. Better performance with a multimodal llm (azure/gpt4-o)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;AWS Bedrock&lt;/td&gt; 
   &lt;td&gt;Anthropic Claude 3 (Haiku, Sonnet, Opus), Claude 3.5 (Sonnet)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Gemini&lt;/td&gt; 
   &lt;td&gt;Gemini 2.5 Pro and flash, Gemini 2.0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ollama&lt;/td&gt; 
   &lt;td&gt;Run any locally hosted model via &lt;a href="https://github.com/ollama/ollama"&gt;Ollama&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenRouter&lt;/td&gt; 
   &lt;td&gt;Access models through &lt;a href="https://openrouter.ai"&gt;OpenRouter&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenAI-compatible&lt;/td&gt; 
   &lt;td&gt;Any custom API endpoint that follows OpenAI's API format (via &lt;a href="https://docs.litellm.ai/docs/providers/openai_compatible"&gt;liteLLM&lt;/a&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Environment Variables&lt;/h4&gt; 
&lt;h5&gt;OpenAI&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ENABLE_OPENAI&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Register OpenAI models&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OpenAI API Key&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;sk-1234567890&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_API_BASE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OpenAI API Base, optional&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;https://openai.api.base&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_ORGANIZATION&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OpenAI Organization ID, optional&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;your-org-id&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Recommended &lt;code&gt;LLM_KEY&lt;/code&gt;: &lt;code&gt;OPENAI_GPT4O&lt;/code&gt;, &lt;code&gt;OPENAI_GPT4O_MINI&lt;/code&gt;, &lt;code&gt;OPENAI_GPT4_1&lt;/code&gt;, &lt;code&gt;OPENAI_O4_MINI&lt;/code&gt;, &lt;code&gt;OPENAI_O3&lt;/code&gt;&lt;/p&gt; 
&lt;h5&gt;Anthropic&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ENABLE_ANTHROPIC&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Register Anthropic models&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ANTHROPIC_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Anthropic API key&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;sk-1234567890&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Recommended&lt;code&gt;LLM_KEY&lt;/code&gt;: &lt;code&gt;ANTHROPIC_CLAUDE3.5_SONNET&lt;/code&gt;, &lt;code&gt;ANTHROPIC_CLAUDE3.7_SONNET&lt;/code&gt;, &lt;code&gt;ANTHROPIC_CLAUDE4_OPUS&lt;/code&gt;, &lt;code&gt;ANTHROPIC_CLAUDE4_SONNET&lt;/code&gt;&lt;/p&gt; 
&lt;h5&gt;Azure OpenAI&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ENABLE_AZURE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Register Azure OpenAI models&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AZURE_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Azure deployment API key&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;sk-1234567890&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AZURE_DEPLOYMENT&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Azure OpenAI Deployment Name&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;skyvern-deployment&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AZURE_API_BASE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Azure deployment api base url&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;https://skyvern-deployment.openai.azure.com/&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AZURE_API_VERSION&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Azure API Version&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;2024-02-01&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Recommended &lt;code&gt;LLM_KEY&lt;/code&gt;: &lt;code&gt;AZURE_OPENAI&lt;/code&gt;&lt;/p&gt; 
&lt;h5&gt;AWS Bedrock&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ENABLE_BEDROCK&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Register AWS Bedrock models. To use AWS Bedrock, you need to make sure your &lt;a href="https://github.com/boto/boto3?tab=readme-ov-file#using-boto3"&gt;AWS configurations&lt;/a&gt; are set up correctly first.&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Recommended &lt;code&gt;LLM_KEY&lt;/code&gt;: &lt;code&gt;BEDROCK_ANTHROPIC_CLAUDE3.7_SONNET_INFERENCE_PROFILE&lt;/code&gt;, &lt;code&gt;BEDROCK_ANTHROPIC_CLAUDE4_OPUS_INFERENCE_PROFILE&lt;/code&gt;, &lt;code&gt;BEDROCK_ANTHROPIC_CLAUDE4_SONNET_INFERENCE_PROFILE&lt;/code&gt;&lt;/p&gt; 
&lt;h5&gt;Gemini&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ENABLE_GEMINI&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Register Gemini models&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;GEMINI_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Gemini API Key&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;your_google_gemini_api_key&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Recommended &lt;code&gt;LLM_KEY&lt;/code&gt;: &lt;code&gt;GEMINI_2.5_PRO_PREVIEW&lt;/code&gt;, &lt;code&gt;GEMINI_2.5_FLASH_PREVIEW&lt;/code&gt;&lt;/p&gt; 
&lt;h5&gt;Ollama&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ENABLE_OLLAMA&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Register local models via Ollama&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OLLAMA_SERVER_URL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;URL for your Ollama server&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;http://host.docker.internal:11434&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OLLAMA_MODEL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Ollama model name to load&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;qwen2.5:7b-instruct&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Recommended &lt;code&gt;LLM_KEY&lt;/code&gt;: &lt;code&gt;OLLAMA&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Note: Ollama does not support vision yet.&lt;/p&gt; 
&lt;h5&gt;OpenRouter&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ENABLE_OPENROUTER&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Register OpenRouter models&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENROUTER_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OpenRouter API key&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;sk-1234567890&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENROUTER_MODEL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OpenRouter model name&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;mistralai/mistral-small-3.1-24b-instruct&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENROUTER_API_BASE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OpenRouter API base URL&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;https://api.openrouter.ai/v1&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Recommended &lt;code&gt;LLM_KEY&lt;/code&gt;: &lt;code&gt;OPENROUTER&lt;/code&gt;&lt;/p&gt; 
&lt;h5&gt;OpenAI-Compatible&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ENABLE_OPENAI_COMPATIBLE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Register a custom OpenAI-compatible API endpoint&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_COMPATIBLE_MODEL_NAME&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Model name for OpenAI-compatible endpoint&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;yi-34b&lt;/code&gt;, &lt;code&gt;gpt-3.5-turbo&lt;/code&gt;, &lt;code&gt;mistral-large&lt;/code&gt;, etc.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_COMPATIBLE_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;API key for OpenAI-compatible endpoint&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;sk-1234567890&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_COMPATIBLE_API_BASE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Base URL for OpenAI-compatible endpoint&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;https://api.together.xyz/v1&lt;/code&gt;, &lt;code&gt;http://localhost:8000/v1&lt;/code&gt;, etc.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_COMPATIBLE_API_VERSION&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;API version for OpenAI-compatible endpoint, optional&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;2023-05-15&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_COMPATIBLE_MAX_TOKENS&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Maximum tokens for completion, optional&lt;/td&gt; 
   &lt;td&gt;Integer&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;4096&lt;/code&gt;, &lt;code&gt;8192&lt;/code&gt;, etc.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_COMPATIBLE_TEMPERATURE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Temperature setting, optional&lt;/td&gt; 
   &lt;td&gt;Float&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;0.0&lt;/code&gt;, &lt;code&gt;0.5&lt;/code&gt;, &lt;code&gt;0.7&lt;/code&gt;, etc.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_COMPATIBLE_SUPPORTS_VISION&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Whether model supports vision, optional&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Supported LLM Key: &lt;code&gt;OPENAI_COMPATIBLE&lt;/code&gt;&lt;/p&gt; 
&lt;h5&gt;General LLM Configuration&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;LLM_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The name of the model you want to use&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;See supported LLM keys above&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;SECONDARY_LLM_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The name of the model for mini agents skyvern runs with&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;See supported LLM keys above&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;LLM_CONFIG_MAX_TOKENS&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Override the max tokens used by the LLM&lt;/td&gt; 
   &lt;td&gt;Integer&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;128000&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h1&gt;Feature Roadmap&lt;/h1&gt; 
&lt;p&gt;This is our planned roadmap for the next few months. If you have any suggestions or would like to see a feature added, please don't hesitate to reach out to us &lt;a href="mailto:founders@skyvern.com"&gt;via email&lt;/a&gt; or &lt;a href="https://discord.gg/fG2XXEuQX3"&gt;discord&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Open Source&lt;/strong&gt; - Open Source Skyvern's core codebase&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Workflow support&lt;/strong&gt; - Allow support to chain multiple Skyvern calls together&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Improved context&lt;/strong&gt; - Improve Skyvern's ability to understand content around interactable elements by introducing feeding relevant label context through the text prompt&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Cost Savings&lt;/strong&gt; - Improve Skyvern's stability and reduce the cost of running Skyvern by optimizing the context tree passed into Skyvern&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Self-serve UI&lt;/strong&gt; - Deprecate the Streamlit UI in favour of a React-based UI component that allows users to kick off new jobs in Skyvern&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Workflow UI Builder&lt;/strong&gt; - Introduce a UI to allow users to build and analyze workflows visually&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Chrome Viewport streaming&lt;/strong&gt; - Introduce a way to live-stream the Chrome viewport to the user's browser (as a part of the self-serve UI)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Past Runs UI&lt;/strong&gt; - Deprecate the Streamlit UI in favour of a React-based UI that allows you to visualize past runs and their results&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Auto workflow builder ("Observer") mode&lt;/strong&gt; - Allow Skyvern to auto-generate workflows as it's navigating the web to make it easier to build new workflows&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Prompt Caching&lt;/strong&gt; - Introduce a caching layer to the LLM calls to dramatically reduce the cost of running Skyvern (memorize past actions and repeat them!)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Web Evaluation Dataset&lt;/strong&gt; - Integrate Skyvern with public benchmark tests to track the quality of our models over time&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;Improved Debug mode&lt;/strong&gt; - Allow Skyvern to plan its actions and get "approval" before running them, allowing you to debug what it's doing and more easily iterate on the prompt&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;Chrome Extension&lt;/strong&gt; - Allow users to interact with Skyvern through a Chrome extension (incl voice mode, saving tasks, etc.)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;Skyvern Action Recorder&lt;/strong&gt; - Allow Skyvern to watch a user complete a task and then automatically generate a workflow for it&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;Interactable Livestream&lt;/strong&gt; - Allow users to interact with the livestream in real-time to intervene when necessary (such as manually submitting sensitive forms)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;Integrate LLM Observability tools&lt;/strong&gt; - Integrate LLM Observability tools to allow back-testing prompt changes with specific data sets + visualize the performance of Skyvern over time&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Langchain Integration&lt;/strong&gt; - Create langchain integration in langchain_community to use Skyvern as a "tool".&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Contributing&lt;/h1&gt; 
&lt;p&gt;We welcome PRs and suggestions! Don't hesitate to open a PR/issue or to reach out to us &lt;a href="mailto:founders@skyvern.com"&gt;via email&lt;/a&gt; or &lt;a href="https://discord.gg/fG2XXEuQX3"&gt;discord&lt;/a&gt;. Please have a look at our &lt;a href="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/CONTRIBUTING.md"&gt;contribution guide&lt;/a&gt; and &lt;a href="https://github.com/skyvern-ai/skyvern/issues?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22"&gt;"Help Wanted" issues&lt;/a&gt; to get started!&lt;/p&gt; 
&lt;p&gt;If you want to chat with the skyvern repository to get a high level overview of how it is structured, how to build off it, and how to resolve usage questions, check out &lt;a href="https://sage.storia.ai?utm_source=github&amp;amp;utm_medium=referral&amp;amp;utm_campaign=skyvern-readme"&gt;Code Sage&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Telemetry&lt;/h1&gt; 
&lt;p&gt;By Default, Skyvern collects basic usage statistics to help us understand how Skyvern is being used. If you would like to opt-out of telemetry, please set the &lt;code&gt;SKYVERN_TELEMETRY&lt;/code&gt; environment variable to &lt;code&gt;false&lt;/code&gt;.&lt;/p&gt; 
&lt;h1&gt;License&lt;/h1&gt; 
&lt;p&gt;Skyvern's open source repository is supported via a managed cloud. All of the core logic powering Skyvern is available in this open source repository licensed under the &lt;a href="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/LICENSE"&gt;AGPL-3.0 License&lt;/a&gt;, with the exception of anti-bot measures available in our managed cloud offering.&lt;/p&gt; 
&lt;p&gt;If you have any questions or concerns around licensing, please &lt;a href="mailto:support@skyvern.com"&gt;contact us&lt;/a&gt; and we would be happy to help.&lt;/p&gt; 
&lt;h1&gt;Star History&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#Skyvern-AI/skyvern&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=Skyvern-AI/skyvern&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>topoteretes/cognee</title>
      <link>https://github.com/topoteretes/cognee</link>
      <description>&lt;p&gt;Memory for AI Agents in 6 lines of code&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a href="https://github.com/topoteretes/cognee"&gt; &lt;img src="https://raw.githubusercontent.com/topoteretes/cognee/refs/heads/dev/assets/cognee-logo-transparent.png" alt="Cognee Logo" height="60" /&gt; &lt;/a&gt; 
 &lt;br /&gt; 
 &lt;p&gt;Cognee - Accurate and Persistent AI Memory&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;a href="https://www.youtube.com/watch?v=1bezuvLwJmw&amp;amp;t=2s"&gt;Demo&lt;/a&gt; . &lt;a href="https://docs.cognee.ai/"&gt;Docs&lt;/a&gt; . &lt;a href="https://cognee.ai"&gt;Learn More&lt;/a&gt; ¬∑ &lt;a href="https://discord.gg/NQPKmU5CCg"&gt;Join Discord&lt;/a&gt; ¬∑ &lt;a href="https://www.reddit.com/r/AIMemory/"&gt;Join r/AIMemory&lt;/a&gt; . &lt;a href="https://github.com/topoteretes/cognee-community"&gt;Community Plugins &amp;amp; Add-ons&lt;/a&gt; &lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://GitHub.com/topoteretes/cognee/network/"&gt;&lt;img src="https://img.shields.io/github/forks/topoteretes/cognee.svg?style=social&amp;amp;label=Fork&amp;amp;maxAge=2592000" alt="GitHub forks" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/topoteretes/cognee/stargazers/"&gt;&lt;img src="https://img.shields.io/github/stars/topoteretes/cognee.svg?style=social&amp;amp;label=Star&amp;amp;maxAge=2592000" alt="GitHub stars" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/topoteretes/cognee/commit/"&gt;&lt;img src="https://badgen.net/github/commits/topoteretes/cognee" alt="GitHub commits" /&gt;&lt;/a&gt; &lt;a href="https://github.com/topoteretes/cognee/tags/"&gt;&lt;img src="https://badgen.net/github/tag/topoteretes/cognee" alt="GitHub tag" /&gt;&lt;/a&gt; &lt;a href="https://pepy.tech/project/cognee"&gt;&lt;img src="https://static.pepy.tech/badge/cognee" alt="Downloads" /&gt;&lt;/a&gt; &lt;a href="https://github.com/topoteretes/cognee/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/topoteretes/cognee?colorA=00C586&amp;amp;colorB=000000" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://github.com/topoteretes/cognee/graphs/contributors"&gt;&lt;img src="https://img.shields.io/github/contributors/topoteretes/cognee?colorA=00C586&amp;amp;colorB=000000" alt="Contributors" /&gt;&lt;/a&gt; &lt;a href="https://github.com/sponsors/topoteretes"&gt;&lt;img src="https://img.shields.io/badge/Sponsor-‚ù§Ô∏è-ff69b4.svg" alt="Sponsor" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt; &lt;a href="https://www.producthunt.com/posts/cognee?embed=true&amp;amp;utm_source=badge-top-post-badge&amp;amp;utm_medium=badge&amp;amp;utm_souce=badge-cognee" target="_blank" style="display:inline-block; margin-right:10px;"&gt; &lt;img src="https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?post_id=946346&amp;amp;theme=light&amp;amp;period=daily&amp;amp;t=1744472480704" alt="cognee - Memory for AI Agents  in 5 lines of code | Product Hunt" width="250" height="54" /&gt; &lt;/a&gt; &lt;a href="https://trendshift.io/repositories/13955" target="_blank" style="display:inline-block;"&gt; &lt;img src="https://trendshift.io/api/badge/repositories/13955" alt="topoteretes%2Fcognee | Trendshift" width="250" height="55" /&gt; &lt;/a&gt; &lt;/p&gt; 
 &lt;p&gt;Use your data to build personalized and dynamic memory for AI Agents. Cognee lets you replace RAG with scalable and modular ECL (Extract, Cognify, Load) pipelines.&lt;/p&gt; 
 &lt;p align="center"&gt; üåê Available Languages : 
  &lt;!-- Keep these links. Translations will automatically update with the README. --&gt; &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=de"&gt;Deutsch&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=es"&gt;Espa√±ol&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=fr"&gt;Fran√ßais&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=ja"&gt;Êó•Êú¨Ë™û&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=ko"&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=pt"&gt;Portugu√™s&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=ru"&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=zh"&gt;‰∏≠Êñá&lt;/a&gt; &lt;/p&gt; 
 &lt;div style="text-align: center"&gt; 
  &lt;img src="https://raw.githubusercontent.com/topoteretes/cognee/refs/heads/main/assets/cognee_benefits.png" alt="Why cognee?" width="50%" /&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h2&gt;About Cognee&lt;/h2&gt; 
&lt;p&gt;Cognee is an open-source tool and platform that transforms your raw data into persistent and dynamic AI memory for Agents. It combines vector search with graph databases to make your documents both searchable by meaning and connected by relationships.&lt;/p&gt; 
&lt;p&gt;You can use Cognee in two ways:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://docs.cognee.ai/getting-started/installation"&gt;Self-host Cognee Open Source&lt;/a&gt;, which stores all data locally by default.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://platform.cognee.ai/"&gt;Connect to Cognee Cloud&lt;/a&gt;, and get the same OSS stack on managed infrastructure for easier development and productionization.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Cognee Open Source (self-hosted):&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Interconnects any type of data ‚Äî including past conversations, files, images, and audio transcriptions&lt;/li&gt; 
 &lt;li&gt;Replaces traditional RAG systems with a unified memory layer built on graphs and vectors&lt;/li&gt; 
 &lt;li&gt;Reduces developer effort and infrastructure cost while improving quality and precision&lt;/li&gt; 
 &lt;li&gt;Provides Pythonic data pipelines for ingestion from 30+ data sources&lt;/li&gt; 
 &lt;li&gt;Offers high customizability through user-defined tasks, modular pipelines, and built-in search endpoints&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Cognee Cloud (managed):&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Hosted web UI dashboard&lt;/li&gt; 
 &lt;li&gt;Automatic version updates&lt;/li&gt; 
 &lt;li&gt;Resource usage analytics&lt;/li&gt; 
 &lt;li&gt;GDPR compliant, enterprise-grade security&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Basic Usage &amp;amp; Feature Guide&lt;/h2&gt; 
&lt;p&gt;To learn more, &lt;a href="https://colab.research.google.com/drive/12Vi9zID-M3fpKpKiaqDBvkk98ElkRPWy?usp=sharing"&gt;check out this short, end-to-end Colab walkthrough&lt;/a&gt; of Cognee's core features.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://colab.research.google.com/drive/12Vi9zID-M3fpKpKiaqDBvkk98ElkRPWy?usp=sharing"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open In Colab" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;p&gt;Let‚Äôs try Cognee in just a few lines of code. For detailed setup and configuration, see the &lt;a href="https://docs.cognee.ai/getting-started/installation#environment-configuration"&gt;Cognee Docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Python 3.10 to 3.13&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Step 1: Install Cognee&lt;/h3&gt; 
&lt;p&gt;You can install Cognee with &lt;strong&gt;pip&lt;/strong&gt;, &lt;strong&gt;poetry&lt;/strong&gt;, &lt;strong&gt;uv&lt;/strong&gt;, or your preferred Python package manager.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv pip install cognee
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Step 2: Configure the LLM&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import os
os.environ["LLM_API_KEY"] = "YOUR OPENAI_API_KEY"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively, create a &lt;code&gt;.env&lt;/code&gt; file using our &lt;a href="https://github.com/topoteretes/cognee/raw/main/.env.template"&gt;template&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To integrate other LLM providers, see our &lt;a href="https://docs.cognee.ai/setup-configuration/llm-providers"&gt;LLM Provider Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Step 3: Run the Pipeline&lt;/h3&gt; 
&lt;p&gt;Cognee will take your documents, generate a knowledge graph from them and then query the graph based on combined relationships.&lt;/p&gt; 
&lt;p&gt;Now, run a minimal pipeline:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import cognee
import asyncio


async def main():
    # Add text to cognee
    await cognee.add("Cognee turns documents into AI memory.")

    # Generate the knowledge graph
    await cognee.cognify()

    # Add memory algorithms to the graph
    await cognee.memify()

    # Query the knowledge graph
    results = await cognee.search("What does Cognee do?")

    # Display the results
    for result in results:
        print(result)


if __name__ == '__main__':
    asyncio.run(main())

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;As you can see, the output is generated from the document we previously stored in Cognee:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;  Cognee turns documents into AI memory.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Use the Cognee CLI&lt;/h3&gt; 
&lt;p&gt;As an alternative, you can get started with these essential commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cognee-cli add "Cognee turns documents into AI memory."

cognee-cli cognify

cognee-cli search "What does Cognee do?"
cognee-cli delete --all

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To open the local UI, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cognee-cli -ui
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Demos &amp;amp; Examples&lt;/h2&gt; 
&lt;p&gt;See Cognee in action:&lt;/p&gt; 
&lt;h3&gt;Persistent Agent Memory&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/e113b628-7212-4a2b-b288-0be39a93a1c3"&gt;Cognee Memory for LangGraph Agents&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Simple GraphRAG&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/f2186b2e-305a-42b0-9c2d-9f4473f15df8"&gt;Watch Demo&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Cognee with Ollama&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/39672858-f774-4136-b957-1e2de67b8981"&gt;Watch Demo&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Community &amp;amp; Support&lt;/h2&gt; 
&lt;h3&gt;Contributing&lt;/h3&gt; 
&lt;p&gt;We welcome contributions from the community! Your input helps make Cognee better for everyone. See &lt;a href="https://raw.githubusercontent.com/topoteretes/cognee/main/CONTRIBUTING.md"&gt;&lt;code&gt;CONTRIBUTING.md&lt;/code&gt;&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h3&gt;Code of Conduct&lt;/h3&gt; 
&lt;p&gt;We're committed to fostering an inclusive and respectful community. Read our &lt;a href="https://github.com/topoteretes/cognee/raw/main/CODE_OF_CONDUCT.md"&gt;Code of Conduct&lt;/a&gt; for guidelines.&lt;/p&gt; 
&lt;h2&gt;Research &amp;amp; Citation&lt;/h2&gt; 
&lt;p&gt;We recently published a research paper on optimizing knowledge graphs for LLM reasoning:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{markovic2025optimizinginterfaceknowledgegraphs,
      title={Optimizing the Interface Between Knowledge Graphs and LLMs for Complex Reasoning},
      author={Vasilije Markovic and Lazar Obradovic and Laszlo Hajdu and Jovan Pavlovic},
      year={2025},
      eprint={2505.24478},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2505.24478},
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>microsoft/agent-lightning</title>
      <link>https://github.com/microsoft/agent-lightning</link>
      <description>&lt;p&gt;The absolute trainer to light up AI agents.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/microsoft/agent-lightning/main/docs/assets/readme-banner.svg?sanitize=true" alt="Agent-lightning-banner" style="width:600px" /&gt; &lt;/p&gt; 
&lt;h1&gt;Agent Lightning‚ö°&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/microsoft/agent-lightning/actions/workflows/tests-full.yml"&gt;&lt;img src="https://github.com/microsoft/agent-lightning/actions/workflows/tests-full.yml/badge.svg?sanitize=true" alt="Test" /&gt;&lt;/a&gt; &lt;a href="https://microsoft.github.io/agent-lightning/"&gt;&lt;img src="https://img.shields.io/badge/GitHub%20Pages-Documentation-blue" alt="Documentation" /&gt;&lt;/a&gt; &lt;a href="https://badge.fury.io/py/agentlightning"&gt;&lt;img src="https://badge.fury.io/py/agentlightning.svg?sanitize=true" alt="PyPI version" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/microsoft/agent-lightning/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-MIT-blue.svg?sanitize=true" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/microsoft/agent-lightning"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/RYk7CdvDR7"&gt;&lt;img src="https://img.shields.io/badge/Discord-Join-5865F2?logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;The absolute trainer to light up AI agents.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Join our &lt;a href="https://discord.gg/RYk7CdvDR7"&gt;Discord community&lt;/a&gt; to connect with other users and contributors.&lt;/p&gt; 
&lt;h2&gt;‚ö° Core Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Turn your agent into an optimizable beast with &lt;strong&gt;ZERO CODE CHANGE&lt;/strong&gt; (almost)! üí§&lt;/li&gt; 
 &lt;li&gt;Build with &lt;strong&gt;ANY&lt;/strong&gt; agent framework (LangChain, OpenAI Agent SDK, AutoGen, CrewAI, Microsoft Agent Framework...); or even WITHOUT agent framework (Python OpenAI). You name it! ü§ñ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Selectively&lt;/strong&gt; optimize one or more agents in a multi-agent system. üéØ&lt;/li&gt; 
 &lt;li&gt;Embraces &lt;strong&gt;Algorithms&lt;/strong&gt; like Reinforcement Learning, Automatic Prompt Optimization, Supervised Fine-tuning and more. ü§ó&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Read more on our &lt;a href="https://microsoft.github.io/agent-lightning/"&gt;documentation website&lt;/a&gt;.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/microsoft/agent-lightning/main/docs/assets/readme-diff.svg?sanitize=true" alt="Agent-Lightning Core Quickstart" style="width:100%" /&gt; &lt;/p&gt; 
&lt;h2&gt;‚ö° Installation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install agentlightning
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Please refer to our &lt;a href="https://microsoft.github.io/agent-lightning/stable/tutorials/installation/"&gt;installation guide&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;p&gt;To start using Agent-lightning, check out our &lt;a href="https://microsoft.github.io/agent-lightning/"&gt;documentation&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/microsoft/agent-lightning/main/examples"&gt;examples&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;‚ö° Articles&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;11/4/2025 &lt;a href="https://medium.com/@yugez/tuning-any-ai-agent-with-tinker-agent-lightning-part-1-1d8c9a397f0e"&gt;Tuning ANY AI agent with Tinker ‚úï Agent-lightning&lt;/a&gt; Medium. See also &lt;a href="https://medium.com/@yugez/tuning-any-ai-agent-with-tinker-agent-lightning-part-2-332c5437f0dc"&gt;Part 2&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;10/22/2025 &lt;a href="https://blog.vllm.ai/2025/10/22/agent-lightning.html"&gt;No More Retokenization Drift: Returning Token IDs via the OpenAI Compatible API Matters in Agent RL&lt;/a&gt; vLLM blog. See also &lt;a href="https://zhuanlan.zhihu.com/p/1965067274642785725"&gt;Zhihu writeup&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;8/11/2025 &lt;a href="https://medium.com/@yugez/training-ai-agents-to-write-and-self-correct-sql-with-reinforcement-learning-571ed31281ad"&gt;Training AI Agents to Write and Self-correct SQL with Reinforcement Learning&lt;/a&gt; Medium.&lt;/li&gt; 
 &lt;li&gt;8/5/2025 &lt;a href="https://arxiv.org/abs/2508.03680"&gt;Agent Lightning: Train ANY AI Agents with Reinforcement Learning&lt;/a&gt; arXiv paper.&lt;/li&gt; 
 &lt;li&gt;7/26/2025 &lt;a href="https://www.reddit.com/r/LocalLLaMA/comments/1m9m670/we_discovered_an_approach_to_train_any_ai_agent/"&gt;We discovered an approach to train any AI agent with RL, with (almost) zero code changes.&lt;/a&gt; Reddit.&lt;/li&gt; 
 &lt;li&gt;6/6/2025 &lt;a href="https://www.microsoft.com/en-us/research/project/agent-lightning/"&gt;Agent Lightning - Microsoft Research&lt;/a&gt; Project page.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;‚ö° Community Projects&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/af-74413592/DeepWerewolf"&gt;DeepWerewolf&lt;/a&gt; ‚Äî A case study of agent RL training for the Chinese Werewolf game built with AgentScope and Agent Lightning.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://agentflow.stanford.edu/"&gt;AgentFlow&lt;/a&gt; ‚Äî A modular multi-agent framework that combines planner, executor, verifier, and generator agents with the Flow-GRPO algorithm to tackle long-horizon, sparse-reward tasks.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;‚ö° Architecture&lt;/h2&gt; 
&lt;p&gt;Agent Lightning keeps the moving parts to a minimum so you can focus on your idea, not the plumbing. Your agent continues to run as usual; you can still use any agent framework you like; you drop in the lightweight &lt;code&gt;agl.emit_xxx()&lt;/code&gt; helper, or let the tracer collect every prompt, tool call, and reward. Those events become structured spans that flow into the LightningStore, a central hub that keeps tasks, resources, and traces in sync.&lt;/p&gt; 
&lt;p&gt;On the other side of the store sits the algorithm you choose, or write yourself. The algorithm reads spans, learns from them, and posts updated resources such as refined prompt templates or new policy weights. The Trainer ties it all together: it streams datasets to runners, ferries resources between the store and the algorithm, and updates the inference engine when improvements land. You can either stop there, or simply let the same loop keep turning.&lt;/p&gt; 
&lt;p&gt;No rewrites, no lock-in, just a clear path from first rollout to steady improvement.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/microsoft/agent-lightning/main/docs/assets/readme-architecture.svg?sanitize=true" alt="Agent-lightning Architecture" style="width:100%" /&gt; &lt;/p&gt; 
&lt;h2&gt;‚ö° CI Status&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Workflow&lt;/th&gt; 
   &lt;th&gt;Status&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CPU Tests&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/microsoft/agent-lightning/actions/workflows/tests.yml"&gt;&lt;img src="https://github.com/microsoft/agent-lightning/actions/workflows/tests.yml/badge.svg?sanitize=true" alt="tests workflow status" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GPU Tests&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/microsoft/agent-lightning/actions/workflows/tests-full.yml"&gt;&lt;img src="https://github.com/microsoft/agent-lightning/actions/workflows/tests-full.yml/badge.svg?sanitize=true" alt="tests-full workflow status" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Examples Integration&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/microsoft/agent-lightning/actions/workflows/badge-examples.yml"&gt;&lt;img src="https://github.com/microsoft/agent-lightning/actions/workflows/badge-examples.yml/badge.svg?sanitize=true" alt="examples summary workflow status" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Latest Dependency Compatibility&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/microsoft/agent-lightning/actions/workflows/badge-latest.yml"&gt;&lt;img src="https://github.com/microsoft/agent-lightning/actions/workflows/badge-latest.yml/badge.svg?sanitize=true" alt="latest summary workflow status" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Legacy Examples Compatibility&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/microsoft/agent-lightning/actions/workflows/examples-compat.yml"&gt;&lt;img src="https://github.com/microsoft/agent-lightning/actions/workflows/examples-compat.yml/badge.svg?sanitize=true" alt="examples compatibility workflow status" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;‚ö° Citation&lt;/h2&gt; 
&lt;p&gt;If you find Agent Lightning useful in your research or projects, please cite our paper:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{luo2025agentlightningtrainai,
      title={Agent Lightning: Train ANY AI Agents with Reinforcement Learning},
      author={Xufang Luo and Yuge Zhang and Zhiyuan He and Zilong Wang and Siyun Zhao and Dongsheng Li and Luna K. Qiu and Yuqing Yang},
      year={2025},
      eprint={2508.03680},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2508.03680},
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;‚ö° Contributing&lt;/h2&gt; 
&lt;p&gt;This project welcomes contributions and suggestions. Start by reading the &lt;a href="https://raw.githubusercontent.com/microsoft/agent-lightning/main/docs/community/contributing.md"&gt;Contributing Guide&lt;/a&gt; for environment setup, branching conventions, and pull request expectations. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit &lt;a href="https://cla.opensource.microsoft.com"&gt;https://cla.opensource.microsoft.com&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.&lt;/p&gt; 
&lt;p&gt;This project has adopted the &lt;a href="https://opensource.microsoft.com/codeofconduct/"&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;. For more information see the &lt;a href="https://opensource.microsoft.com/codeofconduct/faq/"&gt;Code of Conduct FAQ&lt;/a&gt; or contact &lt;a href="mailto:opencode@microsoft.com"&gt;opencode@microsoft.com&lt;/a&gt; with any additional questions or comments.&lt;/p&gt; 
&lt;h2&gt;‚ö° Trademarks&lt;/h2&gt; 
&lt;p&gt;This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow &lt;a href="https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general"&gt;Microsoft's Trademark &amp;amp; Brand Guidelines&lt;/a&gt;. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party's policies.&lt;/p&gt; 
&lt;h2&gt;‚ö° Responsible AI&lt;/h2&gt; 
&lt;p&gt;This project has been evaluated and certified to comply with the Microsoft Responsible AI Standard. The team will continue to monitor and maintain the repository, addressing any severe issues, including potential harms, if they arise.&lt;/p&gt; 
&lt;h2&gt;‚ö° License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the MIT License. See the &lt;a href="https://raw.githubusercontent.com/microsoft/agent-lightning/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>dbeaver/dbeaver</title>
      <link>https://github.com/dbeaver/dbeaver</link>
      <description>&lt;p&gt;Free universal database tool and SQL client&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://twitter.com/dbeaver_news"&gt;&lt;img src="https://img.shields.io/twitter/url/https/twitter.com/dbeaver_news.svg?style=social&amp;amp;label=Follow%20%40dbeaver_news" alt="Twitter URL" /&gt;&lt;/a&gt; &lt;a href="https://app.codacy.com/gh/dbeaver/dbeaver/dashboard?utm_source=gh&amp;amp;utm_medium=referral&amp;amp;utm_content=&amp;amp;utm_campaign=Badge_grade"&gt;&lt;img src="https://app.codacy.com/project/badge/Grade/fa0bb9cf5a904c7d87424f8f6351ba92" alt="Codacy Badge" /&gt;&lt;/a&gt; &lt;a href="http://www.apache.org/licenses/LICENSE-2.0"&gt;&lt;img src="https://img.shields.io/github/license/cronn-de/jira-sync.svg?sanitize=true" alt="Apache 2.0" /&gt;&lt;/a&gt; &lt;a href="https://github.com/dbeaver/dbeaver/issues?q=is%3Aissue+is%3Aopen+label%3A%22wait%20for%20review%22"&gt;&lt;img src="https://img.shields.io/github/issues/dbeaver/dbeaver/wait%20for%20review" alt="Tickets in review" /&gt;&lt;/a&gt; &lt;img src="https://github.com/dbeaver/dbeaver/wiki/images/dbeaver-icon-64x64.png" align="right" /&gt;&lt;/p&gt; 
&lt;h1&gt;DBeaver&lt;/h1&gt; 
&lt;p&gt;Free multi-platform database tool for developers, SQL programmers, database administrators and analysts.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Has a lot of &lt;a href="https://github.com/dbeaver/dbeaver/wiki"&gt;features&lt;/a&gt; including schema editor, SQL editor, data editor, AI integration, ER diagrams, data export/import/migration, SQL execution plans, database administration tools, database dashboards, Spatial data viewer, proxy and SSH tunnelling, custom database drivers editor, etc.&lt;/li&gt; 
 &lt;li&gt;Out of the box supports more than &lt;a href="https://raw.githubusercontent.com/dbeaver/dbeaver/devel/#supported-databases"&gt;100 database drivers&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Supports any database which has JDBC or ODBC driver (basically - almost all existing databases).&lt;/li&gt; 
 &lt;li&gt;Supports smart AI completion and code generation with OpenAI or Copilot&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://dbeaver.io/product/dbeaver-sql-editor.png"&gt;&lt;img src="https://dbeaver.io/product/dbeaver-sql-editor.png" width="400" /&gt;&lt;/a&gt; &lt;a href="https://dbeaver.io/product/dbeaver-gis-viewer.png"&gt;&lt;img src="https://dbeaver.io/product/dbeaver-gis-viewer.png" width="400" /&gt;&lt;/a&gt; &lt;a href="https://dbeaver.io/product/dbeaver-data-editor.png"&gt;&lt;img src="https://dbeaver.io/product/dbeaver-data-editor.png" width="400" /&gt;&lt;/a&gt; &lt;a href="https://dbeaver.io/product/dbeaver-erd.png"&gt;&lt;img src="https://dbeaver.io/product/dbeaver-erd.png" width="400" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Download&lt;/h2&gt; 
&lt;p&gt;You can download prebuilt binaries from &lt;a href="https://dbeaver.io/download" target="_blank"&gt;official website&lt;/a&gt; or directly from &lt;a href="https://github.com/dbeaver/dbeaver/releases"&gt;GitHub releases&lt;/a&gt;.&lt;br /&gt; You can also download &lt;a href="https://dbeaver.io/files/ea" target="_blank"&gt;Early Access&lt;/a&gt; version. We publish daily.&lt;/p&gt; 
&lt;h2&gt;Running&lt;/h2&gt; 
&lt;p&gt;Just run an installer (or unzip an archive) and run &lt;code&gt;dbeaver&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Note: DBeaver needs Java to run. &lt;a href="https://adoptium.net/temurin/releases/?package=jre" target="_blank"&gt;OpenJDK 21&lt;/a&gt; is included in all DBeaver distributions. You can change default JDK version by replacing directory &lt;code&gt;jre&lt;/code&gt; in dbeaver installation folder.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://dbeaver.com/docs/dbeaver/"&gt;Full product documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dbeaver/dbeaver/wiki"&gt;WIKI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dbeaver/dbeaver/issues"&gt;Issue tracker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dbeaver/dbeaver/wiki/Build-from-sources"&gt;Building from sources&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Architecture&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;DBeaver is written mostly on Java. However, it also uses a set of native OS-specific components for desktop UI, high performance database drivers and networking.&lt;/li&gt; 
 &lt;li&gt;Basic frameworks: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/OSGi"&gt;OSGI&lt;/a&gt; platform for plugins and dependency management. Community version consists of 130+ plugins.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/eclipse-platform/eclipse.platform.ui/raw/master/docs/Rich_Client_Platform.md"&gt;Eclipse RCP&lt;/a&gt; platform for rich user interface build.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Java_Database_Connectivity"&gt;JDBC&lt;/a&gt; for basic database connectivity API.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/JSQLParser/JSqlParser"&gt;JSQLParser&lt;/a&gt; and &lt;a href="https://github.com/antlr/antlr4"&gt;Antlr4&lt;/a&gt; for SQL grammar and semantic parser.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;For networking and additional functionality we use wide range of open source libraries such as &lt;a href="https://github.com/hierynomus/sshj"&gt;SSHJ&lt;/a&gt;, &lt;a href="https://github.com/apache/poi"&gt;Apache POI&lt;/a&gt;, &lt;a href="https://github.com/jfree/jfreechart"&gt;JFreeChart&lt;/a&gt;, &lt;a href="https://github.com/locationtech/jts"&gt;JTS&lt;/a&gt;, &lt;a href="https://github.com/apache/commons-jexl"&gt;Apache JEXL&lt;/a&gt; etc.&lt;/li&gt; 
 &lt;li&gt;We separate model plugins from desktop UI plugins. This allows us to use the same set of "back-end" plugins in both DBeaver and &lt;a href="https://github.com/dbeaver/cloudbeaver"&gt;CloudBeaver&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Dependencies: being an OSGI application we use P2 repositories for third party dependencies. For additional Maven dependencies we use our own &lt;a href="https://github.com/dbeaver/dbeaver-deps-ce"&gt;DBeaver P2 repo&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Supported databases&lt;/h2&gt; 
&lt;h3&gt;Community version&lt;/h3&gt; 
&lt;p&gt;Out of the box DBeaver supports following database drivers: MySQL, MariaDB, Oracle, DB2, PostgreSQL, SQL Server, Sybase, Apache Hive, Drill, Presto, Trino, Phoenix, Exasol, Informix, Teradata, Vertica, Netezza, Firebird, Derby, H2, H2GIS, WMI, Snowflake, Greenplum, Redshift, Athena, SAP HANA, MaxDB, NuoDB, MS Access, SQLite, CSV, DBF, Firebird, TimescaleDB, Yellowbrick, CockroachDB, OrientDB, MonetDB, Google BigQuery, Google Spanner, Apache Hive/Impala/Spark, Apache Ignite, MapD, Azure SQL, CrateDB, Elasticsearch, Ocient, Ingres, OmniSci, Yugabyte, IRIS, Data Virtuality, Denodo, Virtuoso, Machbase, DuckDB, Babelfish, OceanBase, Salesforce, EnterpriseDB, Apache Druid, Apache Kylin, Databricks, OpenSearch, TiDB, TDEngine, Materialize, JDBCX, Dameng, Altibase, StarRocks, CUBRID, GaussDB, DolphinDB, LibSQL, GBase 8s, Databend, Cloudberry, Teiid, Kingbase.&lt;/p&gt; 
&lt;h3&gt;PRO versions&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://dbeaver.com/download/"&gt;Commercial versions&lt;/a&gt; extends functionality of many popular drivers and also support non-JDBC datasources such as: ODBC, MongoDB, Cassandra, Couchbase, CouchDB, Redis, InfluxDB, Firestore, BigTable, DynamoDB, Kafka KSQL, Neo4j, AWS Neptune, AWS Timestream, Azure CosmosDB, Yugabyte, Salesforce, etc.&lt;br /&gt; Also, we support flat files as databases: CSV, XLSX, Json, XML, Parquet.&lt;br /&gt; You can find the list of all databases supported in commercial versions &lt;a href="https://dbeaver.com/databases/"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Feedback&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;For bug reports and feature requests - please &lt;a href="https://github.com/dbeaver/dbeaver/issues"&gt;create a ticket&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;To promote &lt;a href="https://github.com/dbeaver/dbeaver/issues?q=is%3Aissue+is%3Aopen+sort%3Areactions-%2B1-desc+label%3A%22wait+for+votes%22"&gt;a ticket&lt;/a&gt; to a higher priority - please vote for it with üëç under the ticket description.&lt;/li&gt; 
 &lt;li&gt;If you have any questions, ideas, etc - please &lt;a href="https://github.com/dbeaver/dbeaver/discussions"&gt;start a discussion&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Pull requests are welcome. See our &lt;a href="https://github.com/dbeaver/dbeaver/wiki/Contribute-your-code"&gt;guide for contributors&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Visit &lt;a href="https://dbeaver.com"&gt;https://dbeaver.com&lt;/a&gt; for more information.&lt;/li&gt; 
 &lt;li&gt;Follow us on &lt;a href="https://x.com/dbeaver_news/"&gt;X&lt;/a&gt; and watch educational video on &lt;a href="https://www.youtube.com/@DBeaver_video"&gt;YouTube&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Thanks for using DBeaver! Star if you like it.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contribution: help the Beaver!&lt;/h2&gt; 
&lt;p&gt;Hooray, we have reached 40k+ stars on GitHub and continue to grow!&lt;br /&gt; That's really cool, and we are glad that you like DBeaver.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;We are actively looking for new source code contributors. We have added labels ‚ÄúGood first issue‚Äù and ‚ÄúHelp wanted‚Äù to some tickets. If you want to be a part of our development team, just be brave and take a ticket. &lt;a href="https://dbeaver.com/help-dbeaver/"&gt;We are happy to reward&lt;/a&gt; our most active contributors every major sprint.&lt;/li&gt; 
 &lt;li&gt;You can buy &lt;a href="https://dbeaver.com/buy/"&gt;one of our commercial versions&lt;/a&gt;. They include NoSQL databases support, additional extensions, and official online support. Also, licensed users have priorities in bug fixes and the development of new features.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Thank you!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dbeaver/dbeaver/graphs/contributors"&gt;DBeaver Team&lt;/a&gt; (contributors)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;a href="https://github.com/dbeaver/cloudbeaver/"&gt;&lt;img src="https://github.com/dbeaver/cloudbeaver/wiki/images/cloudbeaver-logo.png" width="250" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/dbeaver/cloudbeaver"&gt;CloudBeaver&lt;/a&gt; is a web-based database management tool built on the DBeaver platform. It brings the capabilities of DBeaver to the browser, enabling database management from any device with an internet connection and eliminating the need for local installation. Supporting any database, CloudBeaver incorporates most of DBeaver's features and includes advanced access management for secure collaboration. Designed with a user-friendly interface, CloudBeaver simplifies complex database operations and is suitable for both individual developers and organizations. Its scalable architecture accommodates various needs, making it a convenient solution for managing databases anytime and anywhere through web-based accessibility.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>