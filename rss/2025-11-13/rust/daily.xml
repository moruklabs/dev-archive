<rss version="2.0">
  <channel>
    <title>GitHub Rust Daily Trending</title>
    <description>Daily Trending of Rust in GitHub</description>
    <pubDate>Wed, 12 Nov 2025 01:42:33 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>openai/codex</title>
      <link>https://github.com/openai/codex</link>
      <description>&lt;p&gt;Lightweight coding agent that runs in your terminal&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt;&lt;code&gt;npm i -g @openai/codex&lt;/code&gt;&lt;br /&gt;or &lt;code&gt;brew install --cask codex&lt;/code&gt;&lt;/p&gt; 
&lt;p align="center"&gt;&lt;strong&gt;Codex CLI&lt;/strong&gt; is a coding agent from OpenAI that runs locally on your computer. &lt;br /&gt; &lt;br /&gt;If you want Codex in your code editor (VS Code, Cursor, Windsurf), &lt;a href="https://developers.openai.com/codex/ide"&gt;install in your IDE&lt;/a&gt; &lt;br /&gt;If you are looking for the &lt;em&gt;cloud-based agent&lt;/em&gt; from OpenAI, &lt;strong&gt;Codex Web&lt;/strong&gt;, go to &lt;a href="https://chatgpt.com/codex"&gt;chatgpt.com/codex&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/openai/codex/main/.github/codex-cli-splash.png" alt="Codex CLI splash" width="80%" /&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;h3&gt;Installing and running Codex CLI&lt;/h3&gt; 
&lt;p&gt;Install globally with your preferred package manager. If you use npm:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;npm install -g @openai/codex
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively, if you use Homebrew:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;brew install --cask codex
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then simply run &lt;code&gt;codex&lt;/code&gt; to get started:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;codex
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you're running into upgrade issues with Homebrew, see the &lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/faq.md#brew-upgrade-codex-isnt-upgrading-me"&gt;FAQ entry on brew upgrade codex&lt;/a&gt;.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;You can also go to the &lt;a href="https://github.com/openai/codex/releases/latest"&gt;latest GitHub Release&lt;/a&gt; and download the appropriate binary for your platform.&lt;/summary&gt; 
 &lt;p&gt;Each GitHub Release contains many executables, but in practice, you likely want one of these:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;macOS 
   &lt;ul&gt; 
    &lt;li&gt;Apple Silicon/arm64: &lt;code&gt;codex-aarch64-apple-darwin.tar.gz&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;x86_64 (older Mac hardware): &lt;code&gt;codex-x86_64-apple-darwin.tar.gz&lt;/code&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Linux 
   &lt;ul&gt; 
    &lt;li&gt;x86_64: &lt;code&gt;codex-x86_64-unknown-linux-musl.tar.gz&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;arm64: &lt;code&gt;codex-aarch64-unknown-linux-musl.tar.gz&lt;/code&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;Each archive contains a single entry with the platform baked into the name (e.g., &lt;code&gt;codex-x86_64-unknown-linux-musl&lt;/code&gt;), so you likely want to rename it to &lt;code&gt;codex&lt;/code&gt; after extracting it.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h3&gt;Using Codex with your ChatGPT plan&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/openai/codex/main/.github/codex-cli-login.png" alt="Codex CLI login" width="80%" /&gt; &lt;/p&gt; 
&lt;p&gt;Run &lt;code&gt;codex&lt;/code&gt; and select &lt;strong&gt;Sign in with ChatGPT&lt;/strong&gt;. We recommend signing into your ChatGPT account to use Codex as part of your Plus, Pro, Team, Edu, or Enterprise plan. &lt;a href="https://help.openai.com/en/articles/11369540-codex-in-chatgpt"&gt;Learn more about what's included in your ChatGPT plan&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can also use Codex with an API key, but this requires &lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/authentication.md#usage-based-billing-alternative-use-an-openai-api-key"&gt;additional setup&lt;/a&gt;. If you previously used an API key for usage-based billing, see the &lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/authentication.md#migrating-from-usage-based-billing-api-key"&gt;migration steps&lt;/a&gt;. If you're having trouble with login, please comment on &lt;a href="https://github.com/openai/codex/issues/1243"&gt;this issue&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Model Context Protocol (MCP)&lt;/h3&gt; 
&lt;p&gt;Codex can access MCP servers. To configure them, refer to the &lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/config.md#mcp_servers"&gt;config docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Configuration&lt;/h3&gt; 
&lt;p&gt;Codex CLI supports a rich set of configuration options, with preferences stored in &lt;code&gt;~/.codex/config.toml&lt;/code&gt;. For full configuration options, see &lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/config.md"&gt;Configuration&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Docs &amp;amp; FAQ&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/getting-started.md"&gt;&lt;strong&gt;Getting started&lt;/strong&gt;&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/getting-started.md#cli-usage"&gt;CLI usage&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/slash_commands.md"&gt;Slash Commands&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/getting-started.md#running-with-a-prompt-as-input"&gt;Running with a prompt as input&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/getting-started.md#example-prompts"&gt;Example prompts&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/prompts.md"&gt;Custom prompts&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/getting-started.md#memory-with-agentsmd"&gt;Memory with AGENTS.md&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/config.md"&gt;&lt;strong&gt;Configuration&lt;/strong&gt;&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/example-config.md"&gt;Example config&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/sandbox.md"&gt;&lt;strong&gt;Sandbox &amp;amp; approvals&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/authentication.md"&gt;&lt;strong&gt;Authentication&lt;/strong&gt;&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/authentication.md#forcing-a-specific-auth-method-advanced"&gt;Auth methods&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/authentication.md#connecting-on-a-headless-machine"&gt;Login on a "Headless" machine&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Automating Codex&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/openai/codex-action"&gt;GitHub Action&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/sdk/typescript/README.md"&gt;TypeScript SDK&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/exec.md"&gt;Non-interactive mode (&lt;code&gt;codex exec&lt;/code&gt;)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/advanced.md"&gt;&lt;strong&gt;Advanced&lt;/strong&gt;&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/advanced.md#tracing--verbose-logging"&gt;Tracing / verbose logging&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/advanced.md#model-context-protocol-mcp"&gt;Model Context Protocol (MCP)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/zdr.md"&gt;&lt;strong&gt;Zero data retention (ZDR)&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/contributing.md"&gt;&lt;strong&gt;Contributing&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/install.md"&gt;&lt;strong&gt;Install &amp;amp; build&lt;/strong&gt;&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/install.md#system-requirements"&gt;System Requirements&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/install.md#dotslash"&gt;DotSlash&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/install.md#build-from-source"&gt;Build from source&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/faq.md"&gt;&lt;strong&gt;FAQ&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/open-source-fund.md"&gt;&lt;strong&gt;Open source fund&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This repository is licensed under the &lt;a href="https://raw.githubusercontent.com/openai/codex/main/LICENSE"&gt;Apache-2.0 License&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>uutils/coreutils</title>
      <link>https://github.com/uutils/coreutils</link>
      <description>&lt;p&gt;Cross-platform Rust rewrite of the GNU coreutils&lt;/p&gt;&lt;hr&gt;&lt;div class="oranda-hide"&gt; 
 &lt;div align="center"&gt; 
  &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/uutils/coreutils/main/docs/src/logo.svg?sanitize=true" alt="uutils logo" /&gt;&lt;/p&gt; 
  &lt;h1&gt;uutils coreutils&lt;/h1&gt; 
  &lt;p&gt;&lt;a href="https://crates.io/crates/coreutils"&gt;&lt;img src="https://img.shields.io/crates/v/coreutils.svg?sanitize=true" alt="Crates.io" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/wQVJbvJ"&gt;&lt;img src="https://img.shields.io/badge/discord-join-7289DA.svg?logo=discord&amp;amp;longCache=true&amp;amp;style=flat" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://github.com/uutils/coreutils/raw/main/LICENSE"&gt;&lt;img src="http://img.shields.io/badge/license-MIT-blue.svg?sanitize=true" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://deps.rs/repo/github/uutils/coreutils"&gt;&lt;img src="https://deps.rs/repo/github/uutils/coreutils/status.svg?sanitize=true" alt="dependency status" /&gt;&lt;/a&gt;&lt;/p&gt; 
  &lt;p&gt;&lt;a href="https://codecov.io/gh/uutils/coreutils"&gt;&lt;img src="https://codecov.io/gh/uutils/coreutils/branch/main/graph/badge.svg?sanitize=true" alt="CodeCov" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/badge/MSRV-1.85.0-brightgreen" alt="MSRV" /&gt; &lt;a href="https://hosted.weblate.org/projects/rust-coreutils/"&gt;&lt;img src="https://hosted.weblate.org/widget/rust-coreutils/svg-badge.svg?sanitize=true" alt="Weblate" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;hr /&gt; 
&lt;/div&gt; 
&lt;p&gt;uutils coreutils is a cross-platform reimplementation of the GNU coreutils in &lt;a href="http://www.rust-lang.org"&gt;Rust&lt;/a&gt;. While all programs have been implemented, some options might be missing or different behavior might be experienced.&lt;/p&gt; 
&lt;div class="oranda-hide"&gt; 
 &lt;p&gt;To install it:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;cargo install coreutils
~/.cargo/bin/coreutils
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;!-- markdownlint-disable-next-line MD026 --&gt; 
&lt;h2&gt;Goals&lt;/h2&gt; 
&lt;p&gt;uutils coreutils aims to be a drop-in replacement for the GNU utils. Differences with GNU are treated as bugs.&lt;/p&gt; 
&lt;p&gt;Our key objectives include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Matching GNU's output (stdout and error code) exactly&lt;/li&gt; 
 &lt;li&gt;Better error messages&lt;/li&gt; 
 &lt;li&gt;Providing comprehensive internationalization support (UTF-8)&lt;/li&gt; 
 &lt;li&gt;Improved performances&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/uutils/coreutils/main/docs/src/extensions.md"&gt;Extensions&lt;/a&gt; when relevant (example: --progress)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;uutils aims to work on as many platforms as possible, to be able to use the same utils on Linux, macOS, Windows and other platforms. This ensures, for example, that scripts can be easily transferred between platforms.&lt;/p&gt; 
&lt;div class="oranda-hide"&gt; 
 &lt;h2&gt;Documentation&lt;/h2&gt; 
 &lt;p&gt;uutils has both user and developer documentation available:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://uutils.github.io/coreutils/docs/"&gt;User Manual&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://docs.rs/crate/coreutils/"&gt;Developer Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;Both can also be generated locally, the instructions for that can be found in the &lt;a href="https://github.com/uutils/uutils.github.io"&gt;coreutils docs&lt;/a&gt; repository.&lt;/p&gt; 
 &lt;p&gt;Use &lt;a href="https://hosted.weblate.org/projects/rust-coreutils/"&gt;weblate/rust-coreutils&lt;/a&gt; to translate the Rust coreutils into your language.&lt;/p&gt; 
 &lt;!-- ANCHOR: build (this mark is needed for mdbook) --&gt; 
 &lt;h2&gt;Requirements&lt;/h2&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Rust (&lt;code&gt;cargo&lt;/code&gt;, &lt;code&gt;rustc&lt;/code&gt;)&lt;/li&gt; 
  &lt;li&gt;GNU Make (optional)&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Rust Version&lt;/h3&gt; 
 &lt;p&gt;uutils follows Rust's release channels and is tested against stable, beta and nightly. The current Minimum Supported Rust Version (MSRV) is &lt;code&gt;1.85.0&lt;/code&gt;.&lt;/p&gt; 
 &lt;h2&gt;Building&lt;/h2&gt; 
 &lt;p&gt;There are currently two methods to build the uutils binaries: either Cargo or GNU Make.&lt;/p&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;Building the full package, including all documentation, requires both Cargo and GNU Make on a Unix platform.&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;p&gt;For either method, we first need to fetch the repository:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;git clone https://github.com/uutils/coreutils
cd coreutils
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;Cargo&lt;/h3&gt; 
 &lt;p&gt;Building uutils using Cargo is easy because the process is the same as for every other Rust program:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;cargo build --release
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;This command builds the most portable common core set of uutils into a multicall (BusyBox-type) binary, named 'coreutils', on most Rust-supported platforms.&lt;/p&gt; 
 &lt;p&gt;Additional platform-specific uutils are often available. Building these expanded sets of uutils for a platform (on that platform) is as simple as specifying it as a feature:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;cargo build --release --features macos
# or ...
cargo build --release --features windows
# or ...
cargo build --release --features unix
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;To build SELinux-specific features, including &lt;code&gt;chcon&lt;/code&gt; and &lt;code&gt;runcon&lt;/code&gt;, ensure that &lt;code&gt;libselinux&lt;/code&gt; and &lt;code&gt;libclang&lt;/code&gt; are installed on your system. Then, run the following command:&lt;/p&gt; 
 &lt;pre&gt;&lt;code&gt;cargo build --release --features unix,feat_selinux
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;If you don't want to build every utility available on your platform into the final binary, you can also specify which ones you want to build manually. For example:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;cargo build --features "base32 cat echo rm" --no-default-features
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;If you want to build the utilities as individual binaries, that is also possible:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;cargo build --release --bins --workspace --exclude coreutils --exclude uu_runcon --exclude uu_chcon
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Each utility is contained in its own package within the main repository, named "uu_UTILNAME". To build selected individual utilities, use the &lt;code&gt;--package&lt;/code&gt; [aka &lt;code&gt;-p&lt;/code&gt;] option. For example:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;cargo build -p uu_base32 -p uu_cat -p uu_echo -p uu_rm
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;GNU Make&lt;/h3&gt; 
 &lt;p&gt;Building using &lt;code&gt;make&lt;/code&gt; is a simple process as well.&lt;/p&gt; 
 &lt;p&gt;To simply build all available utilities:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;make
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;In release mode:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;make PROFILE=release
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;To build all but a few of the available utilities:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;make SKIP_UTILS='UTILITY_1 UTILITY_2'
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;To build only a few of the available utilities:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;make UTILS='UTILITY_1 UTILITY_2'
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h2&gt;Installation&lt;/h2&gt; 
 &lt;h3&gt;Install with Cargo&lt;/h3&gt; 
 &lt;p&gt;Likewise, installing can simply be done using:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;cargo install --path . --locked
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;This command will install uutils into Cargo's &lt;em&gt;bin&lt;/em&gt; folder (&lt;em&gt;e.g.&lt;/em&gt; &lt;code&gt;$HOME/.cargo/bin&lt;/code&gt;).&lt;/p&gt; 
 &lt;p&gt;This does not install files necessary for shell completion or manpages. For manpages or shell completion to work, use &lt;code&gt;GNU Make&lt;/code&gt; or see &lt;code&gt;Manually install shell completions&lt;/code&gt;/&lt;code&gt;Manually install manpages&lt;/code&gt;.&lt;/p&gt; 
 &lt;h3&gt;Install with GNU Make&lt;/h3&gt; 
 &lt;p&gt;To install all available utilities:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;make install
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;To install using &lt;code&gt;sudo&lt;/code&gt; switch &lt;code&gt;-E&lt;/code&gt; must be used:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;sudo -E make install
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;To install all but a few of the available utilities:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;make SKIP_UTILS='UTILITY_1 UTILITY_2' install
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;To install only a few of the available utilities:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;make UTILS='UTILITY_1 UTILITY_2' install
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;To install every program with a prefix (e.g. uu-echo uu-cat):&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;make PROG_PREFIX=PREFIX_GOES_HERE install
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;To install the multicall binary:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;make MULTICALL=y install
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Set install parent directory (default value is /usr/local):&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;# DESTDIR is also supported
make PREFIX=/my/path install
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Installing with &lt;code&gt;make&lt;/code&gt; installs shell completions for all installed utilities for &lt;code&gt;bash&lt;/code&gt;, &lt;code&gt;fish&lt;/code&gt; and &lt;code&gt;zsh&lt;/code&gt;. Completions for &lt;code&gt;elvish&lt;/code&gt; and &lt;code&gt;powershell&lt;/code&gt; can also be generated; See &lt;code&gt;Manually install shell completions&lt;/code&gt;.&lt;/p&gt; 
 &lt;p&gt;To skip installation of completions and manpages:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;make COMPLETIONS=n MANPAGES=n install
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;Manually install shell completions&lt;/h3&gt; 
 &lt;p&gt;The &lt;code&gt;uudoc&lt;/code&gt; binary generates completions for the &lt;code&gt;bash&lt;/code&gt;, &lt;code&gt;elvish&lt;/code&gt;, &lt;code&gt;fish&lt;/code&gt;, &lt;code&gt;powershell&lt;/code&gt; and &lt;code&gt;zsh&lt;/code&gt; shells to stdout.&lt;/p&gt; 
 &lt;p&gt;Install &lt;code&gt;uudoc&lt;/code&gt; by&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;cargo install --bin uudoc --features uudoc --path .
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Then use the installed binary:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;uudoc completion &amp;lt;utility&amp;gt; &amp;lt;shell&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;So, to install completions for &lt;code&gt;ls&lt;/code&gt; on &lt;code&gt;bash&lt;/code&gt; to &lt;code&gt;/usr/local/share/bash-completion/completions/ls&lt;/code&gt;, run:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;uudoc completion ls bash &amp;gt; /usr/local/share/bash-completion/completions/ls.bash
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Completion for prefixed &lt;code&gt;cp&lt;/code&gt; with &lt;code&gt;uu-&lt;/code&gt; on &lt;code&gt;zsh&lt;/code&gt; is generated by&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;env PROG_PREFIX=uu- uudoc completion cp zsh
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;Manually install manpages&lt;/h3&gt; 
 &lt;p&gt;To generate manpages, the syntax is:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;uudoc manpage &amp;lt;utility&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;So, to install the manpage for &lt;code&gt;ls&lt;/code&gt; to &lt;code&gt;/usr/local/share/man/man1/ls.1&lt;/code&gt; run:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;uudoc manpage ls &amp;gt; /usr/local/share/man/man1/ls.1
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h2&gt;Un-installation&lt;/h2&gt; 
 &lt;p&gt;Un-installation differs depending on how you have installed uutils. If you used Cargo to install, use Cargo to uninstall. If you used GNU Make to install, use Make to uninstall.&lt;/p&gt; 
 &lt;h3&gt;Uninstall with Cargo&lt;/h3&gt; 
 &lt;p&gt;To uninstall uutils:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;cargo uninstall coreutils
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;Uninstall with GNU Make&lt;/h3&gt; 
 &lt;p&gt;To uninstall all utilities:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;make uninstall
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;To uninstall every program with a set prefix:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;make PROG_PREFIX=PREFIX_GOES_HERE uninstall
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;To uninstall the multicall binary:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;make MULTICALL=y uninstall
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;To uninstall from a custom parent directory:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;# DESTDIR is also supported
make PREFIX=/my/path uninstall
&lt;/code&gt;&lt;/pre&gt; 
 &lt;!-- ANCHOR_END: build (this mark is needed for mdbook) --&gt; 
 &lt;h2&gt;GNU test suite compatibility&lt;/h2&gt; 
 &lt;p&gt;Below is the evolution of how many GNU tests uutils passes. A more detailed breakdown of the GNU test results of the main branch can be found &lt;a href="https://uutils.github.io/coreutils/docs/test_coverage.html"&gt;in the user manual&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;See &lt;a href="https://github.com/orgs/uutils/projects/1"&gt;https://github.com/orgs/uutils/projects/1&lt;/a&gt; for the main meta bugs (many are missing).&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://github.com/uutils/coreutils-tracking/raw/main/gnu-results.svg?raw=true" alt="Evolution over time" /&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;!-- close oranda-hide div --&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;To contribute to uutils, please see &lt;a href="https://raw.githubusercontent.com/uutils/coreutils/main/CONTRIBUTING.md"&gt;CONTRIBUTING&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;uutils is licensed under the MIT License - see the &lt;code&gt;LICENSE&lt;/code&gt; file for details&lt;/p&gt; 
&lt;p&gt;GNU Coreutils is licensed under the GPL 3.0 or later.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>erebe/wstunnel</title>
      <link>https://github.com/erebe/wstunnel</link>
      <description>&lt;p&gt;Tunnel all your traffic over Websocket or HTTP2 - Bypass firewalls/DPI - Static binary available&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://github.com/erebe/wstunnel/raw/main/docs/logo_wstunnel.png" alt="wstunnel logo" height="400" /&gt; &lt;/p&gt; 
&lt;p align="right"&gt; &lt;a href="https://ko-fi.com/P5P4QCHMO"&gt;&lt;img src="https://ko-fi.com/img/githubbutton_sm.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;br /&gt; &lt;/p&gt; 
&lt;h2&gt;Summary&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/erebe/wstunnel/main/#description"&gt;Description&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/erebe/wstunnel/main/#demo"&gt;Demo server&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/erebe/wstunnel/main/#cmd"&gt;Command line&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/erebe/wstunnel/main/#examples"&gt;Examples&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/erebe/wstunnel/main/#release"&gt;Release&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/erebe/wstunnel/main/#note"&gt;Note&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/erebe/wstunnel/main/#bench"&gt;Benchmark&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/erebe/wstunnel/main/#build"&gt;How to build&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Description &lt;a name="description"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Most of the time when you are using a public network, you are behind some kind of firewall or proxy. One of their purpose is to constrain you to only use certain kind of protocols and consult only a subset of the web. Nowadays, the most widespread protocol is http and is de facto allowed by third party equipment.&lt;/p&gt; 
&lt;p&gt;Wstunnel uses the websocket protocol which is compatible with http in order to bypass firewalls and proxies. Wstunnel allows you to tunnel whatever traffic you want and access whatever resources/site you need.&lt;/p&gt; 
&lt;p&gt;My inspiration came from &lt;a href="https://www.npmjs.com/package/wstunnel"&gt;this project&lt;/a&gt; but as I don't want to install npm and nodejs to use this tool, I remade it in &lt;del&gt;Haskell&lt;/del&gt; Rust and improved it.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;What to expect:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Easy to use&lt;/li&gt; 
 &lt;li&gt;Good error messages and debug information&lt;/li&gt; 
 &lt;li&gt;Static forward (reverse) tunneling (TCP, UDP, Unix socket, Stdio)&lt;/li&gt; 
 &lt;li&gt;Dynamic (reverse) tunneling (Socks5 proxy, HTTP proxy and Transparent Proxy)&lt;/li&gt; 
 &lt;li&gt;Support for using http proxy (when behind one) as gateway&lt;/li&gt; 
 &lt;li&gt;Support of proxy protocol&lt;/li&gt; 
 &lt;li&gt;Support for tls/https server with certificates auto-reload (with embedded self-signed certificate, or your own)&lt;/li&gt; 
 &lt;li&gt;Support of mTLS with certificates auto-reload - &lt;a href="https://github.com/erebe/wstunnel/raw/main/docs/using_mtls.md"&gt;documentation here&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Support IPv6&lt;/li&gt; 
 &lt;li&gt;Support for Websocket and HTTP2 as transport protocol (websocket is more performant)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Standalone binaries&lt;/strong&gt; (so just cp it where you want) &lt;a href="https://github.com/erebe/wstunnel/releases"&gt;here&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Sponsors &lt;a name="sponsors"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Part of Wstunnel development has been sponsored by&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://serviceplanet.nl"&gt; &lt;img width="200" height="100" src="https://github.com/erebe/wstunnel/raw/main/docs/logo_serviceplanet.png" alt="service planet logo" /&gt; &lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Note &lt;a name="note"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;v7.0.0 is a complete rewrite of wstunnel in Rust and is not compatible with previous version. Previous code in Haskell can be found on branch &lt;a href="https://github.com/erebe/wstunnel/tree/haskell"&gt;https://github.com/erebe/wstunnel/tree/haskell&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;What to expect from previous version:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;More throughput and less jitter due to Haskell GC. Most of you will not care, as it was performant enough already. But you can now saturate a gigabit ethernet card with a single connection&lt;/li&gt; 
 &lt;li&gt;Command line is more homogeneous/has better UX. All tunnel can be specified multiple times&lt;/li&gt; 
 &lt;li&gt;Tunnel protocol tries to look like normal traffic, to avoid being flagged&lt;/li&gt; 
 &lt;li&gt;Support of reverse tunneling&lt;/li&gt; 
 &lt;li&gt;New bug, it is a rewrite (╯'□')╯︵ ┻━┻ ¯\&lt;em&gt;(ツ)&lt;/em&gt;/¯&lt;/li&gt; 
 &lt;li&gt;Mainly for me to ease the maintenance of the project. I don't do a lot of haskell nowadays and it was harder for me to keep maintening the project over time, as I get lost in touch of the Haskell ecosystem and new release.&lt;/li&gt; 
 &lt;li&gt;Armv7 build (aka raspberry pi), as new version of GHC (Haskell compiler) dropped its support&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Demo server &lt;a name="demo"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;If you just want to try out that you can bypass your proxy/firewall. You can give it a try with wstunnel demo server.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# In a terminal start wstunnel client
# You can set as tls-sni-override whatever domain you want. The tunnel is the only one that is going to be allowed. 
wstunnel client -L 'tcp://4443:localhost:444?proxy_protocol' -P demo --tls-sni-override=google.fr wss://49.13.58.9

# on another terminal, run curl and it should return you this greetings
curl -k https://localhost:4443
&amp;gt; Memento mori !
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Command line &lt;a name="cmd"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;Usage: wstunnel client [OPTIONS] &amp;lt;ws[s]|http[s]://wstunnel.server.com[:port]&amp;gt;

Arguments:
  &amp;lt;ws[s]|http[s]://wstunnel.server.com[:port]&amp;gt;
          Address of the wstunnel server
          You can either use websocket or http2 as transport protocol. Use websocket if you are unsure.
          Example: For websocket with TLS wss://wstunnel.example.com or without ws://wstunnel.example.com
                   For http2 with TLS https://wstunnel.example.com or without http://wstunnel.example.com
          
          *WARNING* HTTP2 as transport protocol is harder to make it works because:
            - If you are behind a (reverse) proxy/CDN they are going to buffer the whole request before forwarding it to the server
              Obviously, this is not going to work for tunneling traffic
            - if you have wstunnel behind a reverse proxy, most of them (i.e: nginx) are going to turn http2 request into http1
              This is not going to work, because http1 does not support streaming naturally
          The only way to make it works with http2 is to have wstunnel directly exposed to the internet without any reverse proxy in front of it

Options:
  -L, --local-to-remote &amp;lt;{tcp,udp,socks5,stdio,unix}://[BIND:]PORT:HOST:PORT&amp;gt;
          Listen on local and forwards traffic from remote. Can be specified multiple times
          examples:
          'tcp://1212:google.com:443'      =&amp;gt;       listen locally on tcp on port 1212 and forward to google.com on port 443
          'tcp://2:n.lan:4?proxy_protocol' =&amp;gt;       listen locally on tcp on port 2 and forward to n.lan on port 4
                                                    Send a proxy protocol header v2 when establishing connection to n.lan
          
          'udp://1212:1.1.1.1:53'          =&amp;gt;       listen locally on udp on port 1212 and forward to cloudflare dns 1.1.1.1 on port 53
          'udp://1212:1.1.1.1:53?timeout_sec=10'    timeout_sec on udp force close the tunnel after 10sec. Set it to 0 to disable the timeout [default: 30]
          
          'socks5://[::1]:1212'            =&amp;gt;       listen locally with socks5 on port 1212 and forward dynamically requested tunnel
          'socks5://[::1]:1212?login=admin&amp;amp;password=admin' =&amp;gt; listen locally with socks5 on port 1212 and only accept connection with login=admin and password=admin
          
          'http://[::1]:1212'              =&amp;gt;       start a http proxy on port 1212 and forward dynamically requested tunnel
          'http://[::1]:1212?login=admin&amp;amp;password=admin' =&amp;gt; start a http proxy on port 1212 and only accept connection with login=admin and password=admin

          'tproxy+tcp://[::1]:1212'        =&amp;gt;       listen locally on tcp on port 1212 as a *transparent proxy* and forward dynamically requested tunnel
          'tproxy+udp://[::1]:1212?timeout_sec=10'  listen locally on udp on port 1212 as a *transparent proxy* and forward dynamically requested tunnel
                                                    linux only and requires sudo/CAP_NET_ADMIN
          
          'stdio://google.com:443'         =&amp;gt;       listen for data from stdio, mainly for `ssh -o ProxyCommand="wstunnel client --log-lvl=off -L stdio://%h:%p ws://localhost:8080" my-server`
          
          'unix:///tmp/wstunnel.sock:g.com:443' =&amp;gt;  listen for data from unix socket of path /tmp/wstunnel.sock and forward to g.com:443

  -R, --remote-to-local &amp;lt;{tcp,udp,socks5,unix}://[BIND:]PORT:HOST:PORT&amp;gt;
          Listen on remote and forwards traffic from local. Can be specified multiple times. Only tcp is supported
          examples:
          'tcp://1212:google.com:443'      =&amp;gt;     listen on server for incoming tcp cnx on port 1212 and forward to google.com on port 443 from local machine
          'udp://1212:1.1.1.1:53'          =&amp;gt;     listen on server for incoming udp on port 1212 and forward to cloudflare dns 1.1.1.1 on port 53 from local machine
          'socks5://[::1]:1212'            =&amp;gt;     listen on server for incoming socks5 request on port 1212 and forward dynamically request from local machine
          'http://[::1]:1212'              =&amp;gt;     listen on server for incoming http proxy request on port 1212 and forward dynamically request from local machine (login/password is supported)
          'unix://wstunnel.sock:g.com:443' =&amp;gt;     listen on server for incoming data from unix socket of path wstunnel.sock and forward to g.com:443 from local machine

      --no-color &amp;lt;NO_COLOR&amp;gt;
          Disable color output in logs
          
          [env: NO_COLOR=]

      --socket-so-mark &amp;lt;INT&amp;gt;
          (linux only) Mark network packet with SO_MARK sockoption with the specified value.
          You need to use {root, sudo, capabilities} to run wstunnel when using this option

  -c, --connection-min-idle &amp;lt;INT&amp;gt;
          Client will maintain a pool of open connection to the server, in order to speed up the connection process.
          This option set the maximum number of connection that will be kept open.
          This is useful if you plan to create/destroy a lot of tunnel (i.e: with socks5 to navigate with a browser)
          It will avoid the latency of doing tcp + tls handshake with the server
          
          [default: 0]

      --nb-worker-threads &amp;lt;INT&amp;gt;
          *WARNING* The flag does nothing, you need to set the env variable *WARNING*
          Control the number of threads that will be used.
          By default, it is equal the number of cpus
          
          [env: TOKIO_WORKER_THREADS=]

      --log-lvl &amp;lt;LOG_LEVEL&amp;gt;
          Control the log verbosity. i.e: TRACE, DEBUG, INFO, WARN, ERROR, OFF
          for more details: https://docs.rs/tracing-subscriber/latest/tracing_subscriber/filter/struct.EnvFilter.html#example-syntax
          
          [env: RUST_LOG=]
          [default: INFO]

      --tls-sni-override &amp;lt;DOMAIN_NAME&amp;gt;
          Domain name that will be used as SNI during TLS handshake
          Warning: If you are behind a CDN (i.e: Cloudflare) you must set this domain also in the http HOST header.
                   or it will be flagged as fishy and your request rejected

      --tls-sni-disable
          Disable sending SNI during TLS handshake
          Warning: Most reverse proxies rely on it

      --tls-ech-enable
          Enable ECH (encrypted sni) during TLS handshake to wstunnel server.
          Warning: Ech DNS config is not refreshed over time. It is retrieved only once at startup of the program

      --tls-verify-certificate
          Enable TLS certificate verification.
          Disabled by default. The client will happily connect to any server with self-signed certificate.

  -p, --http-proxy &amp;lt;USER:PASS@HOST:PORT&amp;gt;
          If set, will use this http proxy to connect to the server
          
          [env: HTTP_PROXY=]

      --http-proxy-login &amp;lt;LOGIN&amp;gt;
          If set, will use this login to connect to the http proxy. Override the one from --http-proxy
          
          [env: WSTUNNEL_HTTP_PROXY_LOGIN=]

      --http-proxy-password &amp;lt;PASSWORD&amp;gt;
          If set, will use this password to connect to the http proxy. Override the one from --http-proxy
          
          [env: WSTUNNEL_HTTP_PROXY_PASSWORD=]

  -P, --http-upgrade-path-prefix &amp;lt;HTTP_UPGRADE_PATH_PREFIX&amp;gt;
          Use a specific prefix that will show up in the http path during the upgrade request.
          Useful if you need to route requests server side but don't have vhosts
          
          [env: WSTUNNEL_HTTP_UPGRADE_PATH_PREFIX=]
          [default: v1]

      --http-upgrade-credentials &amp;lt;USER[:PASS]&amp;gt;
          Pass authorization header with basic auth credentials during the upgrade request.
          If you need more customization, you can use the http_headers option.

      --websocket-ping-frequency-sec &amp;lt;seconds&amp;gt;
          Frequency at which the client will send websocket ping to the server.
          
          [default: 30]

      --websocket-mask-frame
          Enable the masking of websocket frames. Default is false
          Enable this option only if you use unsecure (non TLS) websocket server, and you see some issues. Otherwise, it is just overhead.

  -H, --http-headers &amp;lt;HEADER_NAME: HEADER_VALUE&amp;gt;
          Send custom headers in the upgrade request
          Can be specified multiple time

      --http-headers-file &amp;lt;FILE_PATH&amp;gt;
          Send custom headers in the upgrade request reading them from a file.
          It overrides http_headers specified from command line.
          File is read everytime and file format must contain lines with `HEADER_NAME: HEADER_VALUE`

      --tls-certificate &amp;lt;FILE_PATH&amp;gt;
          [Optional] Certificate (pem) to present to the server when connecting over TLS (HTTPS).
          Used when the server requires clients to authenticate themselves with a certificate (i.e. mTLS).
          The certificate will be automatically reloaded if it changes

      --tls-private-key &amp;lt;FILE_PATH&amp;gt;
          [Optional] The private key for the corresponding certificate used with mTLS.
          The certificate will be automatically reloaded if it changes

      --dns-resolver &amp;lt;DNS_RESOLVER&amp;gt;
          Dns resolver to use to lookup ips of domain name. Can be specified multiple time
          Example:
           dns://1.1.1.1 for using udp
           dns+https://1.1.1.1?sni=cloudflare-dns.com for using dns over HTTPS
           dns+tls://8.8.8.8?sni=dns.google for using dns over TLS
          For Dns over HTTPS/TLS if an HTTP proxy is configured, it will be used also
          To use libc resolver, use
          system://0.0.0.0

          **WARN** On windows you may want to specify explicitly the DNS resolver to avoid excessive DNS queries
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code&gt;SERVER
Usage: wstunnel server [OPTIONS] &amp;lt;ws[s]://0.0.0.0[:port]&amp;gt;

Arguments:
  &amp;lt;ws[s]://0.0.0.0[:port]&amp;gt;
          Address of the wstunnel server to bind to
          Example: With TLS wss://0.0.0.0:8080 or without ws://[::]:8080
          
          The server is capable of detecting by itself if the request is websocket or http2. So you don't need to specify it.

Options:
      --socket-so-mark &amp;lt;INT&amp;gt;
          (linux only) Mark network packet with SO_MARK sockoption with the specified value.
          You need to use {root, sudo, capabilities} to run wstunnel when using this option

      --websocket-ping-frequency-sec &amp;lt;seconds&amp;gt;
          Frequency at which the server will send websocket ping to client.

      --no-color &amp;lt;NO_COLOR&amp;gt;
          Disable color output in logs
          
          [env: NO_COLOR=]

      --websocket-mask-frame
          Enable the masking of websocket frames. Default is false
          Enable this option only if you use unsecure (non TLS) websocket server, and you see some issues. Otherwise, it is just overhead.

      --nb-worker-threads &amp;lt;INT&amp;gt;
          *WARNING* The flag does nothing, you need to set the env variable *WARNING*
          Control the number of threads that will be used.
          By default, it is equal the number of cpus
          
          [env: TOKIO_WORKER_THREADS=]

      --restrict-to &amp;lt;DEST:PORT&amp;gt;
          Server will only accept connection from the specified tunnel information.
          Can be specified multiple time
          Example: --restrict-to "google.com:443" --restrict-to "localhost:22"

      --dns-resolver &amp;lt;DNS_RESOLVER&amp;gt;
          Dns resolver to use to lookup ips of domain name
          This option is not going to work if you use transparent proxy
          Can be specified multiple time
          Example:
           dns://1.1.1.1 for using udp
           dns+https://1.1.1.1?sni=loudflare-dns.com for using dns over HTTPS
           dns+tls://8.8.8.8?sni=dns.google for using dns over TLS
          To use libc resolver, use
          system://0.0.0.0

      --log-lvl &amp;lt;LOG_LEVEL&amp;gt;
          Control the log verbosity. i.e: TRACE, DEBUG, INFO, WARN, ERROR, OFF
          for more details: https://docs.rs/tracing-subscriber/latest/tracing_subscriber/filter/struct.EnvFilter.html#example-syntax
          
          [env: RUST_LOG=]
          [default: INFO]

  -r, --restrict-http-upgrade-path-prefix &amp;lt;RESTRICT_HTTP_UPGRADE_PATH_PREFIX&amp;gt;
          Server will only accept connection from if this specific path prefix is used during websocket upgrade.
          Useful if you specify in the client a custom path prefix, and you want the server to only allow this one.
          The path prefix act as a secret to authenticate clients
          Disabled by default. Accept all path prefix. Can be specified multiple time
          
          [env: WSTUNNEL_RESTRICT_HTTP_UPGRADE_PATH_PREFIX=]

      --restrict-config &amp;lt;RESTRICT_CONFIG&amp;gt;
          Path to the location of the restriction yaml config file.
          Restriction file is automatically reloaded if it changes

      --tls-certificate &amp;lt;FILE_PATH&amp;gt;
          [Optional] Use custom certificate (pem) instead of the default embedded self-signed certificate.
          The certificate will be automatically reloaded if it changes

      --tls-private-key &amp;lt;FILE_PATH&amp;gt;
          [Optional] Use a custom tls key (pem, ec, rsa) that the server will use instead of the default embedded one
          The private key will be automatically reloaded if it changes

      --tls-client-ca-certs &amp;lt;FILE_PATH&amp;gt;
          [Optional] Enables mTLS (client authentication with certificate). Argument must be PEM file
          containing one or more certificates of CA's of which the certificate of clients needs to be signed with.
          The ca will be automatically reloaded if it changes
          
    -p, --http-proxy &amp;lt;USER:PASS@HOST:PORT&amp;gt;
          If set, will use this http proxy to connect to the client

          [env: HTTP_PROXY=]

      --http-proxy-login &amp;lt;LOGIN&amp;gt;
          If set, will use this login to connect to the http proxy. Override the one from --http-proxy

          [env: WSTUNNEL_HTTP_PROXY_LOGIN=]

      --http-proxy-password &amp;lt;PASSWORD&amp;gt;
          If set, will use this password to connect to the http proxy. Override the one from --http-proxy

          [env: WSTUNNEL_HTTP_PROXY_PASSWORD=]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Release &lt;a name="release"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Static binaries are available in &lt;a href="https://github.com/erebe/wstunnel/releases"&gt;release section&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;docker image are available at &lt;a href="https://github.com/erebe/wstunnel/pkgs/container/wstunnel"&gt;https://github.com/erebe/wstunnel/pkgs/container/wstunnel&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker pull ghcr.io/erebe/wstunnel:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Examples &lt;a name="examples"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/erebe/wstunnel/main/#syntax"&gt;Understand command line syntax&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/erebe/wstunnel/main/#simple"&gt;Simplest one with socks5 - Good for browsing internet&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/erebe/wstunnel/main/#ssh"&gt;Proxy SSH&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/erebe/wstunnel/main/#corporate"&gt;Bypass a corporate proxy&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/erebe/wstunnel/main/#wireguard"&gt;Proxy Wireguard traffic&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/erebe/wstunnel/main/#android"&gt;Android&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/erebe/wstunnel/main/#tproxy"&gt;Proxy easily any traffic with transparent proxy (linux only)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/erebe/wstunnel/main/#reverse"&gt;Reverse tunneling&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/erebe/wstunnel/main/#secure"&gt;How to secure access of your wstunnel server&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/erebe/wstunnel/main/#http2"&gt;Use HTTP2 instead of websocket for transport protocol&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/erebe/wstunnel/main/#stealth"&gt;Maximize your stealthiness/Make your traffic discrete&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Understand command line syntax &lt;a name="syntax"&gt;&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Wstunnel command line mimic ssh tunnel syntax. You can take reference to &lt;a href="https://iximiuz.com/en/posts/ssh-tunnels/"&gt;this article&lt;/a&gt;, or this diagram to understand &lt;img src="https://iximiuz.com/ssh-tunnels/ssh-tunnels.png" /&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Simplest one &lt;a name="simple"&gt;&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;On your remote host, start the wstunnel's server by typing this command in your terminal&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;wstunnel server wss://[::]:8080
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will create a websocket server listening on any interface on port 8080. On the client side use this command to forward traffic through the websocket tunnel&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;wstunnel client -L socks5://127.0.0.1:8888 --connection-min-idle 5 wss://myRemoteHost:8080
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This command will create a socks5 server listening on port 8888 of the loopback interface and will forward traffic dynamically. &lt;code&gt;connection-min-idle 10&lt;/code&gt; is going an optimization to create a pool of 10 connection connected to the server, to speed-up the establishement of new tunnels.&lt;/p&gt; 
&lt;p&gt;With firefox you can setup a proxy using this tunnel, by setting in networking preferences 127.0.0.1:8888 and selecting socks5 proxy. Be sure to check the option &lt;code&gt;Proxy DNS when using SOCKS v5&lt;/code&gt; for the server to resolve DNS name and not your local machine.&lt;/p&gt; 
&lt;p&gt;or with curl&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -x socks5h://127.0.0.1:8888 http://google.com/
#Please note h after the 5, it is to avoid curl resolving DNS name locally
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h3&gt;As proxy command for SSH &lt;a name="ssh"&gt;&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;You can specify &lt;code&gt;stdio&lt;/code&gt; as source port on the client side if you wish to use wstunnel as part of a proxy command for ssh&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;ssh -o ProxyCommand="wstunnel client --log-lvl=off -L stdio://%h:%p ws://myRemoteHost:8080" my-server
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h3&gt;When behind a corporate proxy &lt;a name="corporate"&gt;&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;An other useful example is when you want to bypass an http proxy (a corporate proxy for example) The most reliable way to do it is to use wstunnel as described below&lt;/p&gt; 
&lt;p&gt;Start your wstunnel server with tls activated&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;wstunnel server wss://[::]:443 --restrict-to 127.0.0.1:22
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The server will listen on any interface using port 443 (https) and restrict traffic to be forwarded only to the ssh daemon.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Be aware that the server will use self signed certificate with weak cryptographic algorithm. It was made in order to add the least possible overhead while still being compliant with tls.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Do not rely on wstunnel to protect your privacy, if it is one of your concerns, you should only forwards traffic that is already secure by design (ie: https or vpn traffic)&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Now on the client side start the client with&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;wstunnel client -L tcp://9999:127.0.0.1:22 -p http://mycorporateproxy:8080 wss://myRemoteHost:443
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;It will start a tcp server on port 9999 that will contact the corporate proxy, negotiate a tls connection with the remote host and forward traffic to the ssh daemon on the remote host.&lt;/p&gt; 
&lt;p&gt;You may now access your server from your local machine on ssh by using&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;ssh -p 9999 login@127.0.0.1
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Wireguard and wstunnel &lt;a name="wireguard"&gt;&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;You can find a full &lt;a href="https://community.hetzner.com/tutorials/obfuscating-wireguard-using-wstunnel"&gt;tutorial&lt;/a&gt; that explain how to setup wstunnel and wireguard at &lt;a href="https://community.hetzner.com/tutorials/obfuscating-wireguard-using-wstunnel"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;For a quick explanation see below.&lt;/p&gt; 
&lt;p&gt;You have a working wireguard client configuration called &lt;code&gt;wg0.conf&lt;/code&gt;. Let's say&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;[Interface]
Address = 10.200.0.2/32, fd00:cafe::2/128
PrivateKey = xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx=

[Peer]
PublicKey = 9iicV7Stdl/U0RH1BNf3VvlVjaa4Eus6QPEfEz6cR0c=
AllowedIPs = 0.0.0.0/0, ::/0
Endpoint = my.server.com:51820
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Start wstunnel server on my.server.com like this&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;wstunnel server --restrict-to localhost:51820 wss://[::]:443
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;on your local machine start the client like this&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;wstunnel client -L 'udp://51820:localhost:51820?timeout_sec=0' wss://my.server.com:443
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;change your wireguard client config to something&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;[Interface]
Address = 10.200.0.2/32, fd00:cafe::2/128
PrivateKey = xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx=
# Replace by a dns your server has access to
dns = 8.8.8.8
# https://github.com/nitred/nr-wg-mtu-finder to find best mtu for you
MTU = 1400 

[Peer]
PublicKey = 9iicV7Stdl/U0RH1BNf3VvlVjaa4Eus6QPEfEz6cR0c=
AllowedIPs = 0.0.0.0/0, ::/0
# Should target port where wstunnel client is listenning to
Endpoint = localhost:51820
# Should not be necessary if you enable wstunnel client websocket ping
PersistentKeepalive = 20
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Add a default route to your server, as your AllowedIps are catch-all, it is to avoid the traffic looping.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;sudo ip route add ip.of.my.server.com dev eth0 via 192.168.0.1
# replace eth0 (interface) and 192.168.0.1 (router gateway) by the one given by `ip route get ip.of.my.server.com` 
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;start your wireguard, and it should be working&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;sudo wg-quick up wg0
ping 10.200.0.1 # ping another ip of your vpn network
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;FAQ&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Disable default udp tunnel timeout that will auto-close it after 30sec. &lt;code&gt;i.e: udp://1212:127.0.0.1:5201?timeout_sec=0&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;If you see some throughput issue, be sure to lower the MTU of your wireguard interface (you can do it via config file) to something like 1300 or you will endup fragmenting udp packet (due to overhead of other layer) which is always causing issues&lt;/li&gt; 
 &lt;li&gt;If wstunnel cannot connect to server while wireguard is on, be sure you have added a static route via your main gateway for the ip of wstunnel server. Else if you forward all the traffic without putting a static route, you will endup looping your traffic wireguard interface -&amp;gt; wstunnel client -&amp;gt; wireguard interface&lt;/li&gt; 
 &lt;li&gt;If you have trouble making it works on windows, please check this issue &lt;a href="https://github.com/erebe/wstunnel/issues/252"&gt;https://github.com/erebe/wstunnel/issues/252&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Android &lt;a name="android"&gt;&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;You can use the android binary and use termux to run it on your phone.&lt;/p&gt; 
&lt;p&gt;If you want a guide regarding how to use wstunnel on Android, you can follow this &lt;a href="https://community.hetzner.com/tutorials/obfuscating-wireguard-using-wstunnel"&gt;guide&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Transparent proxy (linux only) &lt;a name="tproxy"&gt;&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Transparent proxy allows to easily proxy any program. Start wstunnel with&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;sudo wstunnel client -L 'tproxy+tcp://1080' -L 'tproxy+udp://1080' wss://my.server.com:443
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;use this project to route traffic seamlessly &lt;a href="https://github.com/NOBLES5E/cproxy"&gt;https://github.com/NOBLES5E/cproxy&lt;/a&gt;. It works with any program&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;cproxy --port 1080 --mode tproxy -- curl https://google.com
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can even start a new shell, were all your commands will be proxyfied&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;cproxy --port 1080 --mode tproxy -- bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Reverse tunneling &lt;a name="reverse"&gt;&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Start wstunnel with&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;sudo wstunnel client -R 'tcp://[::]:8000:localhost:8000' wss://my.server.com:443
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In another terminal, start a simple webserver on your local machine&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;python3 -m http.server
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;From your my.server.com machine/network you can now do&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;curl http://localhost:8000
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h3&gt;How to secure the access of your wstunnel server &lt;a name="secure"&gt;&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Generate a secret, let's say &lt;code&gt;h3GywpDrP6gJEdZ6xbJbZZVFmvFZDCa4KcRd&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Now start you server with the following command&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;wstunnel server --restrict-http-upgrade-path-prefix h3GywpDrP6gJEdZ6xbJbZZVFmvFZDCa4KcRd  wss://[::]:443 
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;And start your client with&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;wstunnel client --http-upgrade-path-prefix h3GywpDrP6gJEdZ6xbJbZZVFmvFZDCa4KcRd ... wss://myRemoteHost
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Now your wstunnel server, will only accept connection if the client specify the correct path prefix during the upgrade request.&lt;/p&gt; 
&lt;p&gt;If you need more customization, you can use a config file to specify specific rules with &lt;code&gt;--restrict-config&lt;/code&gt;. You can find examples of restriction rules &lt;a href="https://github.com/erebe/wstunnel/raw/main/restrictions.yaml"&gt;there&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Use HTTP2 instead of websocket for the transport protocol &lt;a name="http2"&gt;&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Use this only if websocket is blocked by your firewall/proxy. Otherwise, it is less performant than websocket.&lt;/p&gt; 
&lt;p&gt;Start your wstunnel server as usual with&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;wstunnel server wss://[::]:8080
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;On the client the only difference is to specify https:// instead of wss://&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;wstunnel client -L socks5://127.0.0.1:8888 https://myRemoteHost:8080
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;WARNING&lt;/strong&gt; HTTP2 as transport protocol is harder to make it works because:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;If you are behind a (reverse) proxy/CDN they may buffer the whole request before forwarding it to the server. Cloudflare is doing that, and obviously, this is not going to work for tunneling traffic&lt;/li&gt; 
 &lt;li&gt;if you have wstunnel behind a reverse proxy, most of them (i.e: nginx) are going to turn http2 request into http1 This is not going to work, because http1 does not support streaming naturally&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The only way to make it works with HTTP2 is to have wstunnel server directly exposed to the internet without any reverse proxy in front of it&lt;/p&gt; 
&lt;p&gt;In addition, you may also want to play with the request headers (i.e: content-length and content-type) to make it looks like normal traffic to bypass your firewall/proxy. Some firewall may not like to see request with content-length not set, or with content-type set to application/octet-stream&lt;/p&gt; 
&lt;h3&gt;Maximize your stealthiness/Make your traffic discrete &lt;a name="stealth"&gt;&lt;/a&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Use wstunnel with TLS activated (wss://) and use your own certificate 
  &lt;ul&gt; 
   &lt;li&gt;Embedded certificate is self-signed and are the same for everyone, so can be easily fingerprinted/flagged&lt;/li&gt; 
   &lt;li&gt;Use valid certificate (i.e: with Let's Encrypt), self-signed certificate are suspicious&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Use a custom http path prefix (see &lt;code&gt;--http-upgrade-path-prefix&lt;/code&gt; option) 
  &lt;ul&gt; 
   &lt;li&gt;To avoid having the same url than every other wstunnel user&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Change your tls-sni-override to a domain is known to be allowed (i.e: google.com, baidu.com, etc...) 
  &lt;ul&gt; 
   &lt;li&gt;this will not work if your wstunnel server is behind a reverse proxy (i.e: Nginx, Cloudflare, HAProxy, ...)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Benchmark &lt;a name="bench"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://github.com/erebe/wstunnel/assets/854278/6e3580b0-c4f8-449e-881e-64d1df56b0ce" alt="image" /&gt;&lt;/p&gt; 
&lt;h2&gt;How to Build &lt;a name="build"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Install the Rust &lt;a href="https://www.rust-lang.org/tools/install"&gt;https://www.rust-lang.org/tools/install&lt;/a&gt; or if you are a believer&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;and run those commands at the root of the project&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;cargo build --package wstunnel-cli
target/debug/wstunnel ...
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>Eventual-Inc/Daft</title>
      <link>https://github.com/Eventual-Inc/Daft</link>
      <description>&lt;p&gt;Distributed query engine providing simple and reliable data processing for any modality and scale&lt;/p&gt;&lt;hr&gt;&lt;p&gt;|Banner|&lt;/p&gt; 
&lt;p&gt;|CI| |PyPI| |Latest Tag| |Coverage| |Slack|&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;Website &amp;lt;https://www.daft.ai&amp;gt;&lt;/code&gt;_ • &lt;code&gt;Docs &amp;lt;https://docs.daft.ai&amp;gt;&lt;/code&gt;_ • &lt;code&gt;Installation &amp;lt;https://docs.daft.ai/en/stable/install/&amp;gt;&lt;/code&gt;_ • &lt;code&gt;Daft Quickstart &amp;lt;https://docs.daft.ai/en/stable/quickstart/&amp;gt;&lt;/code&gt;_ • &lt;code&gt;Community and Support &amp;lt;https://github.com/Eventual-Inc/Daft/discussions&amp;gt;&lt;/code&gt;_&lt;/p&gt; 
&lt;h1&gt;Daft: Unified Engine for Data Analytics, Engineering &amp;amp; ML/AI&lt;/h1&gt; 
&lt;p&gt;|TrendShift|&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;Daft &amp;lt;https://www.daft.ai&amp;gt;&lt;/code&gt;_ is a distributed query engine for large-scale data processing using Python or SQL, implemented in Rust.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Familiar interactive API:&lt;/strong&gt; Lazy Python Dataframe for rapid and interactive iteration, or SQL for analytical queries&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Focus on the what:&lt;/strong&gt; Powerful Query Optimizer that rewrites queries to be as efficient as possible&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Data Catalog integrations:&lt;/strong&gt; Integration with data catalogs (AWS Glue, Unity Catalog) and table formats like Apache Iceberg&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Rich multimodal type-system:&lt;/strong&gt; Supports multimodal types such as Images, URLs, Tensors and more&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Seamless Interchange&lt;/strong&gt;: Built on the &lt;code&gt;Apache Arrow &amp;lt;https://arrow.apache.org/docs/index.html&amp;gt;&lt;/code&gt;_ In-Memory Format&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Built for the cloud:&lt;/strong&gt; &lt;code&gt;Record-setting &amp;lt;https://www.daft.ai/blog/announcing-daft-02&amp;gt;&lt;/code&gt;_ I/O performance for integrations with S3 cloud storage&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;About Daft&lt;/code&gt;_&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;Getting Started&lt;/code&gt;_&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;Benchmarks&lt;/code&gt;_&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;Contributing&lt;/code&gt;_&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;Telemetry&lt;/code&gt;_&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;Related Projects&lt;/code&gt;_&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;License&lt;/code&gt;_&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;About Daft&lt;/h2&gt; 
&lt;p&gt;Daft was designed with the following principles in mind:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Any Data&lt;/strong&gt;: Beyond the usual strings/numbers/dates, Daft columns can also hold complex or nested multimodal data such as Images, Embeddings and Python objects efficiently with its Arrow based memory representation. Ingestion and basic transformations of multimodal data is extremely easy and performant in Daft.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Interactive Computing&lt;/strong&gt;: Daft is built for the interactive developer experience through notebooks or REPLs - intelligent caching/query optimizations accelerates your experimentation and data exploration.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Distributed Computing&lt;/strong&gt;: Some workloads can quickly outgrow your local laptop's computational resources - Daft integrates natively with &lt;code&gt;Ray &amp;lt;https://www.ray.io&amp;gt;&lt;/code&gt;_ for running dataframes on large clusters of machines with thousands of CPUs/GPUs.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;Installation ^^^^^^^^^^^^&lt;/p&gt; 
&lt;p&gt;Install Daft with &lt;code&gt;pip install daft&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;For more advanced installations (e.g. installing from source or with extra dependencies such as Ray and AWS utilities), please see our &lt;code&gt;Installation Guide &amp;lt;https://docs.daft.ai/en/stable/install/&amp;gt;&lt;/code&gt;_&lt;/p&gt; 
&lt;p&gt;Quickstart ^^^^^^^^^^&lt;/p&gt; 
&lt;p&gt;Check out our &lt;code&gt;quickstart &amp;lt;https://docs.daft.ai/en/stable/quickstart/&amp;gt;&lt;/code&gt;_!&lt;/p&gt; 
&lt;p&gt;In this example, we load images from an AWS S3 bucket's URLs and resize each image in the dataframe:&lt;/p&gt; 
&lt;p&gt;.. code:: python&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;import daft

# Load a dataframe from filepaths in an S3 bucket
df = daft.from_glob_path("s3://daft-public-data/laion-sample-images/*")

# 1. Download column of image URLs as a column of bytes
# 2. Decode the column of bytes into a column of images
df = df.with_column("image", df["path"].url.download().image.decode())

# Resize each image into 32x32
df = df.with_column("resized", df["image"].image.resize(32, 32))

df.show(3)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;|Quickstart Image|&lt;/p&gt; 
&lt;h2&gt;Benchmarks&lt;/h2&gt; 
&lt;p&gt;|Benchmark Image|&lt;/p&gt; 
&lt;p&gt;To see the full benchmarks, detailed setup, and logs, check out our &lt;code&gt;benchmarking page. &amp;lt;https://docs.daft.ai/en/stable/benchmarks&amp;gt;&lt;/code&gt;_&lt;/p&gt; 
&lt;p&gt;More Resources ^^^^^^^^^^^^^^&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;Daft Quickstart &amp;lt;https://docs.daft.ai/en/stable/quickstart/&amp;gt;&lt;/code&gt;_ - learn more about Daft's full range of capabilities including dataloading from URLs, joins, user-defined functions (UDF), groupby, aggregations and more.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;Examples &amp;lt;https://docs.daft.ai/en/stable/examples/&amp;gt;&lt;/code&gt;_ - see Daft in action with use cases across text, images, audio, and more&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;User Guide &amp;lt;https://docs.daft.ai/en/stable/&amp;gt;&lt;/code&gt;_ - take a deep-dive into each topic within Daft&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;API Reference &amp;lt;https://docs.daft.ai/en/stable/api/&amp;gt;&lt;/code&gt;_ - API reference for public classes/functions of Daft&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;SQL Reference &amp;lt;https://docs.daft.ai/en/stable/sql/&amp;gt;&lt;/code&gt;_ - Daft SQL reference&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We &amp;lt;3 developers! To start contributing to Daft, please read &lt;code&gt;CONTRIBUTING.md &amp;lt;https://github.com/Eventual-Inc/Daft/blob/main/CONTRIBUTING.md&amp;gt;&lt;/code&gt;_. This document describes the development lifecycle and toolchain for working on Daft. It also details how to add new functionality to the core engine and expose it through a Python API.&lt;/p&gt; 
&lt;p&gt;Here's a list of &lt;code&gt;good first issues &amp;lt;https://github.com/Eventual-Inc/Daft/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22&amp;gt;&lt;/code&gt;_ to get yourself warmed up with Daft. Comment in the issue to pick it up, and feel free to ask any questions!&lt;/p&gt; 
&lt;h2&gt;Telemetry&lt;/h2&gt; 
&lt;p&gt;To help improve Daft, we collect non-identifiable data via Scarf (&lt;a href="https://scarf.sh"&gt;https://scarf.sh&lt;/a&gt;).&lt;/p&gt; 
&lt;p&gt;To disable this behavior, set the environment variable &lt;code&gt;DO_NOT_TRACK=true&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;The data that we collect is:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Non-identifiable:&lt;/strong&gt; Events are keyed by a session ID which is generated on import of Daft&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Metadata-only:&lt;/strong&gt; We do not collect any of our users’ proprietary code or data&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;For development only:&lt;/strong&gt; We do not buy or sell any user data&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Please see our &lt;code&gt;documentation &amp;lt;https://docs.daft.ai/en/stable/resources/telemetry/&amp;gt;&lt;/code&gt;_ for more details.&lt;/p&gt; 
&lt;p&gt;.. image:: &lt;a href="https://static.scarf.sh/a.png?x-pxid=31f8d5ba-7e09-4d75-8895-5252bbf06cf6"&gt;https://static.scarf.sh/a.png?x-pxid=31f8d5ba-7e09-4d75-8895-5252bbf06cf6&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Related Projects&lt;/h2&gt; 
&lt;p&gt;+---------------------------------------------------+-----------------+---------------+-------------+-----------------+-----------------------------+-------------+ | Engine | Query Optimizer | Multimodal | Distributed | Arrow Backed | Vectorized Execution Engine | Out-of-core | +===================================================+=================+===============+=============+=================+=============================+=============+ | Daft | Yes | Yes | Yes | Yes | Yes | Yes | +---------------------------------------------------+-----------------+---------------+-------------+-----------------+-----------------------------+-------------+ | &lt;code&gt;Pandas &amp;lt;https://github.com/pandas-dev/pandas&amp;gt;&lt;/code&gt;_ | No | Python object | No | optional &amp;gt;= 2.0 | Some(Numpy) | No | +---------------------------------------------------+-----------------+---------------+-------------+-----------------+-----------------------------+-------------+ | &lt;code&gt;Polars &amp;lt;https://github.com/pola-rs/polars&amp;gt;&lt;/code&gt;_ | Yes | Python object | No | Yes | Yes | Yes | +---------------------------------------------------+-----------------+---------------+-------------+-----------------+-----------------------------+-------------+ | &lt;code&gt;Modin &amp;lt;https://github.com/modin-project/modin&amp;gt;&lt;/code&gt;_ | Yes | Python object | Yes | No | Some(Pandas) | Yes | +---------------------------------------------------+-----------------+---------------+-------------+-----------------+-----------------------------+-------------+ | &lt;code&gt;Ray Data &amp;lt;https://github.com/ray-project/ray&amp;gt;&lt;/code&gt;_ | No | Yes | Yes | Yes | Some(PyArrow) | Yes | +---------------------------------------------------+-----------------+---------------+-------------+-----------------+-----------------------------+-------------+ | &lt;code&gt;PySpark &amp;lt;https://github.com/apache/spark&amp;gt;&lt;/code&gt;_ | Yes | No | Yes | Pandas UDF/IO | Pandas UDF | Yes | +---------------------------------------------------+-----------------+---------------+-------------+-----------------+-----------------------------+-------------+ | &lt;code&gt;Dask DF &amp;lt;https://github.com/dask/dask&amp;gt;&lt;/code&gt;_ | No | Python object | Yes | No | Some(Pandas) | Yes | +---------------------------------------------------+-----------------+---------------+-------------+-----------------+-----------------------------+-------------+&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Daft has an Apache 2.0 license - please see the LICENSE file.&lt;/p&gt; 
&lt;p&gt;.. |Quickstart Image| image:: &lt;a href="https://github.com/Eventual-Inc/Daft/assets/17691182/dea2f515-9739-4f3e-ac58-cd96d51e44a8"&gt;https://github.com/Eventual-Inc/Daft/assets/17691182/dea2f515-9739-4f3e-ac58-cd96d51e44a8&lt;/a&gt; :alt: Dataframe code to load a folder of images from AWS S3 and create thumbnails :height: 256&lt;/p&gt; 
&lt;p&gt;.. |Benchmark Image| image:: &lt;a href="https://raw.githubusercontent.com/Eventual-Inc/Daft/refs/heads/main/assets/benchmark.png"&gt;https://raw.githubusercontent.com/Eventual-Inc/Daft/refs/heads/main/assets/benchmark.png&lt;/a&gt; :alt: AI Benchmarks&lt;/p&gt; 
&lt;p&gt;.. |Banner| image:: &lt;a href="https://daft.ai/images/diagram.png"&gt;https://daft.ai/images/diagram.png&lt;/a&gt; :target: &lt;a href="https://www.daft.ai"&gt;https://www.daft.ai&lt;/a&gt; :alt: Daft dataframes can load any data such as PDF documents, images, protobufs, csv, parquet and audio files into a table dataframe structure for easy querying&lt;/p&gt; 
&lt;p&gt;.. |CI| image:: &lt;a href="https://github.com/Eventual-Inc/Daft/actions/workflows/pr-test-suite.yml/badge.svg"&gt;https://github.com/Eventual-Inc/Daft/actions/workflows/pr-test-suite.yml/badge.svg&lt;/a&gt; :target: &lt;a href="https://github.com/Eventual-Inc/Daft/actions/workflows/pr-test-suite.yml?query=branch:main"&gt;https://github.com/Eventual-Inc/Daft/actions/workflows/pr-test-suite.yml?query=branch:main&lt;/a&gt; :alt: GitHub Actions tests&lt;/p&gt; 
&lt;p&gt;.. |PyPI| image:: &lt;a href="https://img.shields.io/pypi/v/daft.svg?label=pip&amp;amp;logo=PyPI&amp;amp;logoColor=white"&gt;https://img.shields.io/pypi/v/daft.svg?label=pip&amp;amp;logo=PyPI&amp;amp;logoColor=white&lt;/a&gt; :target: &lt;a href="https://pypi.org/project/daft"&gt;https://pypi.org/project/daft&lt;/a&gt; :alt: PyPI&lt;/p&gt; 
&lt;p&gt;.. |Latest Tag| image:: &lt;a href="https://img.shields.io/github/v/tag/Eventual-Inc/Daft?label=latest&amp;amp;logo=GitHub"&gt;https://img.shields.io/github/v/tag/Eventual-Inc/Daft?label=latest&amp;amp;logo=GitHub&lt;/a&gt; :target: &lt;a href="https://github.com/Eventual-Inc/Daft/tags"&gt;https://github.com/Eventual-Inc/Daft/tags&lt;/a&gt; :alt: latest tag&lt;/p&gt; 
&lt;p&gt;.. |Coverage| image:: &lt;a href="https://codecov.io/gh/Eventual-Inc/Daft/branch/main/graph/badge.svg?token=J430QVFE89"&gt;https://codecov.io/gh/Eventual-Inc/Daft/branch/main/graph/badge.svg?token=J430QVFE89&lt;/a&gt; :target: &lt;a href="https://codecov.io/gh/Eventual-Inc/Daft"&gt;https://codecov.io/gh/Eventual-Inc/Daft&lt;/a&gt; :alt: Coverage&lt;/p&gt; 
&lt;p&gt;.. |Slack| image:: &lt;a href="https://img.shields.io/badge/slack-@distdata-purple.svg?logo=slack"&gt;https://img.shields.io/badge/slack-@distdata-purple.svg?logo=slack&lt;/a&gt; :target: &lt;a href="https://join.slack.com/t/dist-data/shared_invite/zt-2e77olvxw-uyZcPPV1SRchhi8ah6ZCtg"&gt;https://join.slack.com/t/dist-data/shared_invite/zt-2e77olvxw-uyZcPPV1SRchhi8ah6ZCtg&lt;/a&gt; :alt: slack community&lt;/p&gt; 
&lt;p&gt;.. |TrendShift| image:: &lt;a href="https://trendshift.io/api/badge/repositories/8239"&gt;https://trendshift.io/api/badge/repositories/8239&lt;/a&gt; :target: &lt;a href="https://trendshift.io/repositories/8239"&gt;https://trendshift.io/repositories/8239&lt;/a&gt; :alt: Eventual-Inc/Daft | Trendshift :width: 250px :height: 55px&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>TabbyML/tabby</title>
      <link>https://github.com/TabbyML/tabby</link>
      <description>&lt;p&gt;Self-hosted AI coding assistant&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;h1&gt;🐾 Tabby&lt;/h1&gt; 
 &lt;p&gt;&lt;a href="https://tabby.tabbyml.com/docs/welcome/"&gt;📚 Docs&lt;/a&gt; • &lt;a href="https://links.tabbyml.com/join-slack"&gt;💬 Slack&lt;/a&gt; • &lt;a href="https://tabby.tabbyml.com/docs/roadmap/"&gt;🗺️ Roadmap&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/TabbyML/tabby/releases/latest"&gt;&lt;img src="https://shields.io/github/v/release/TabbyML/tabby" alt="latest release" /&gt;&lt;/a&gt; &lt;a href="https://makeapullrequest.com"&gt;&lt;img src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square" alt="PRs Welcome" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/tabbyml/tabby"&gt;&lt;img src="https://img.shields.io/docker/pulls/tabbyml/tabby" alt="Docker pulls" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/TabbyML/tabby"&gt;&lt;img src="https://codecov.io/gh/TabbyML/tabby/graph/badge.svg?token=WYVVH8MKK3" alt="codecov" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TabbyML/tabby/main/README.md"&gt;English&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/TabbyML/tabby/main/README-zh.md"&gt;简体中文&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/TabbyML/tabby/main/README-ja.md"&gt;日本語&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;Tabby is a self-hosted AI coding assistant, offering an open-source and on-premises alternative to GitHub Copilot. It boasts several key features:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Self-contained, with no need for a DBMS or cloud service.&lt;/li&gt; 
 &lt;li&gt;OpenAPI interface, easy to integrate with existing infrastructure (e.g Cloud IDE).&lt;/li&gt; 
 &lt;li&gt;Supports consumer-grade GPUs.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="center"&gt; &lt;a target="_blank" href="https://tabby.tabbyml.com"&gt;&lt;img alt="Open Live Demo" src="https://img.shields.io/badge/OPEN_LIVE_DEMO-blue?logo=xcode&amp;amp;style=for-the-badge&amp;amp;logoColor=green" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;img alt="Demo" src="https://user-images.githubusercontent.com/388154/230440226-9bc01d05-9f57-478b-b04d-81184eba14ca.gif" /&gt; &lt;/p&gt; 
&lt;h2&gt;🔥 What's New&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;07/02/2025&lt;/strong&gt; &lt;a href="https://github.com/TabbyML/tabby/releases/tag/v0.30.0"&gt;v0.30&lt;/a&gt; supports indexing GitLab Merge Request as Context!&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;05/25/2025&lt;/strong&gt; 💡Interested in joining &lt;a href="https://links.tabbyml.com/pochi-github-readme"&gt;Agent&lt;/a&gt; private preview? DM in &lt;a href="https://x.com/getpochi"&gt;X&lt;/a&gt; for early waitlist approval!🎫&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;05/20/2025&lt;/strong&gt; Enhance Tabby with your own documentation📃 through REST APIs in &lt;a href="https://github.com/TabbyML/tabby/releases/tag/v0.29.0"&gt;v0.29&lt;/a&gt;! 🎉&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;05/01/2025&lt;/strong&gt; &lt;a href="https://github.com/TabbyML/tabby/releases/tag/v0.28.0"&gt;v0.28&lt;/a&gt; transforming Answer Engine messages into persistent, shareable Pages&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;03/31/2025&lt;/strong&gt; &lt;a href="https://github.com/TabbyML/tabby/releases/tag/v0.27.0"&gt;v0.27&lt;/a&gt; released with a richer &lt;code&gt;@&lt;/code&gt; menu in the chat side panel.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;02/05/2025&lt;/strong&gt; LDAP Authentication and better notification for background jobs coming in Tabby &lt;a href="https://github.com/TabbyML/tabby/releases/tag/v0.24.0"&gt;v0.24.0&lt;/a&gt;!✨&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;02/04/2025&lt;/strong&gt; &lt;a href="https://marketplace.visualstudio.com/items/TabbyML.vscode-tabby/changelog"&gt;VSCode 1.20.0&lt;/a&gt; upgrade! @-mention files to add them as chat context, and edit inline with a new right-click option are available!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;Archived&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;01/10/2025&lt;/strong&gt; Tabby &lt;a href="https://github.com/TabbyML/tabby/releases/tag/v0.23.0"&gt;v0.23.0&lt;/a&gt; featuring enhanced code browser experience and chat side panel improvements!&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;12/24/2024&lt;/strong&gt; Introduce &lt;strong&gt;Notification Box&lt;/strong&gt; in Tabby &lt;a href="https://github.com/TabbyML/tabby/releases/tag/v0.22.0"&gt;v0.22.0&lt;/a&gt;!&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;12/06/2024&lt;/strong&gt; Llamafile deployment integration and enhanced Answer Engine user experience are coming in Tabby &lt;a href="https://github.com/TabbyML/tabby/releases/tag/v0.21.0"&gt;v0.21.0&lt;/a&gt;!🚀&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;11/10/2024&lt;/strong&gt; Switching between different backend chat models is supported in Answer Engine with Tabby &lt;a href="https://github.com/TabbyML/tabby/releases/tag/v0.20.0"&gt;v0.20.0&lt;/a&gt;!&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;10/30/2024&lt;/strong&gt; Tabby &lt;a href="https://github.com/TabbyML/tabby/releases/tag/v0.19.0"&gt;v0.19.0&lt;/a&gt; featuring recent shared threads on the main page to improve their discoverability.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;07/09/2024&lt;/strong&gt; 🎉Announce &lt;a href="https://tabby.tabbyml.com/blog/2024/07/09/tabby-codestral/"&gt;Codestral integration in Tabby&lt;/a&gt;!&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;07/05/2024&lt;/strong&gt; Tabby &lt;a href="https://github.com/TabbyML/tabby/releases/tag/v0.13.0"&gt;v0.13.0&lt;/a&gt; introduces &lt;em&gt;&lt;strong&gt;Answer Engine&lt;/strong&gt;&lt;/em&gt;, a central knowledge engine for internal engineering teams. It seamlessly integrates with dev team's internal data, delivering reliable and precise answers to empower developers.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;06/13/2024&lt;/strong&gt; &lt;a href="https://marketplace.visualstudio.com/items/TabbyML.vscode-tabby/changelog"&gt;VSCode 1.7&lt;/a&gt; marks a significant milestone with a versatile Chat experience throughout your coding experience. Come and they the latest &lt;strong&gt;chat in side-panel&lt;/strong&gt; and &lt;strong&gt;editing via chat command&lt;/strong&gt;!&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;06/10/2024&lt;/strong&gt; Latest 📃blogpost drop on &lt;a href="https://tabby.tabbyml.com/blog/2024/06/11/rank-fusion-in-tabby-code-completion/"&gt;an enhanced code context understanding&lt;/a&gt; in Tabby!&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;06/06/2024&lt;/strong&gt; Tabby &lt;a href="https://github.com/TabbyML/tabby/releases/tag/v0.12.0"&gt;v0.12.0&lt;/a&gt; release brings 🔗&lt;strong&gt;seamless integrations&lt;/strong&gt; (Gitlab SSO, Self-hosted GitHub/GitLab, etc.), to ⚙️&lt;strong&gt;flexible configurations&lt;/strong&gt; (HTTP API integration) and 🌐&lt;strong&gt;expanded capabilities&lt;/strong&gt; (repo-context in Code Browser)!&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;05/22/2024&lt;/strong&gt; Tabby &lt;a href="https://marketplace.visualstudio.com/items?itemName=TabbyML.vscode-tabby"&gt;VSCode 1.6&lt;/a&gt; comes with &lt;strong&gt;multiple choices&lt;/strong&gt; in inline completion, and the &lt;strong&gt;auto-generated commit messages&lt;/strong&gt;🐱💻!&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;05/11/2024&lt;/strong&gt; &lt;a href="https://github.com/TabbyML/tabby/releases/tag/v0.11.0"&gt;v0.11.0&lt;/a&gt; brings significant enterprise upgrades, including 📊&lt;strong&gt;storage usage&lt;/strong&gt; stats, 🔗&lt;strong&gt;GitHub &amp;amp; GitLab&lt;/strong&gt; integration, 📋&lt;strong&gt;Activities&lt;/strong&gt; page, and the long-awaited 🤖&lt;strong&gt;Ask Tabby&lt;/strong&gt; feature!&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;04/22/2024&lt;/strong&gt; &lt;a href="https://github.com/TabbyML/tabby/releases/tag/v0.10.0"&gt;v0.10.0&lt;/a&gt; released, featuring the latest &lt;strong&gt;Reports&lt;/strong&gt; tab with team-wise analytics for Tabby usage.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;04/19/2024&lt;/strong&gt; 📣 Tabby now incorporates &lt;a href="https://github.com/TabbyML/tabby/pull/1844"&gt;locally relevant snippets&lt;/a&gt;(declarations from local LSP, and recently modified code) for code completion!&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;04/17/2024&lt;/strong&gt; CodeGemma and CodeQwen model series have now been added to the &lt;a href="https://tabby.tabbyml.com/docs/models/"&gt;official registry&lt;/a&gt;!&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;03/20/2024&lt;/strong&gt; &lt;a href="https://github.com/TabbyML/tabby/releases/tag/v0.9.1"&gt;v0.9&lt;/a&gt; released, highlighting a full feature admin UI.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;12/23/2023&lt;/strong&gt; Seamlessly &lt;a href="https://tabby.tabbyml.com/docs/installation/skypilot/"&gt;deploy Tabby on any cloud&lt;/a&gt; with &lt;a href="https://skypilot.readthedocs.io/en/latest/serving/sky-serve.html"&gt;SkyServe&lt;/a&gt; 🛫 from SkyPilot.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;12/15/2023&lt;/strong&gt; &lt;a href="https://github.com/TabbyML/tabby/releases/tag/v0.7.0"&gt;v0.7.0&lt;/a&gt; released with team management and secured access!&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;10/15/2023&lt;/strong&gt; RAG-based code completion is enabled by detail in &lt;a href="https://github.com/TabbyML/tabby/releases/tag/v0.3.0"&gt;v0.3.0&lt;/a&gt;🎉! Check out the &lt;a href="https://tabby.tabbyml.com/blog/2023/10/16/repository-context-for-code-completion/"&gt;blogpost&lt;/a&gt; explaining how Tabby utilizes repo-level context to get even smarter!&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;11/27/2023&lt;/strong&gt; &lt;a href="https://github.com/TabbyML/tabby/releases/tag/v0.6.0"&gt;v0.6.0&lt;/a&gt; released!&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;11/09/2023&lt;/strong&gt; &lt;a href="https://github.com/TabbyML/tabby/releases/tag/v0.5.5"&gt;v0.5.5&lt;/a&gt; released! With a redesign of UI + performance improvement.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;10/24/2023&lt;/strong&gt; ⛳️ Major updates for Tabby IDE plugins across &lt;a href="https://tabby.tabbyml.com/docs/extensions"&gt;VSCode/Vim/IntelliJ&lt;/a&gt;!&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;10/04/2023&lt;/strong&gt; Check out the &lt;a href="https://tabby.tabbyml.com/docs/models/"&gt;model directory&lt;/a&gt; for the latest models supported by Tabby.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;09/18/2023&lt;/strong&gt; Apple's M1/M2 Metal inference support has landed in &lt;a href="https://github.com/TabbyML/tabby/releases/tag/v0.1.1"&gt;v0.1.1&lt;/a&gt;!&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;08/31/2023&lt;/strong&gt; Tabby's first stable release &lt;a href="https://github.com/TabbyML/tabby/releases/tag/v0.0.1"&gt;v0.0.1&lt;/a&gt; 🥳.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;08/28/2023&lt;/strong&gt; Experimental support for the &lt;a href="https://github.com/TabbyML/tabby/issues/370"&gt;CodeLlama 7B&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;08/24/2023&lt;/strong&gt; Tabby is now on &lt;a href="https://plugins.jetbrains.com/plugin/22379-tabby"&gt;JetBrains Marketplace&lt;/a&gt;!&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;👋 Getting Started&lt;/h2&gt; 
&lt;p&gt;You can find our documentation &lt;a href="https://tabby.tabbyml.com/docs/getting-started"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;📚 &lt;a href="https://tabby.tabbyml.com/docs/installation/"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;💻 &lt;a href="https://tabby.tabbyml.com/docs/extensions/"&gt;IDE/Editor Extensions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;⚙️ &lt;a href="https://tabby.tabbyml.com/docs/configuration"&gt;Configuration&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Run Tabby in 1 Minute&lt;/h3&gt; 
&lt;p&gt;The easiest way to start a Tabby server is by using the following Docker command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -it \
  --gpus all -p 8080:8080 -v $HOME/.tabby:/data \
  tabbyml/tabby \
  serve --model StarCoder-1B --device cuda --chat-model Qwen2-1.5B-Instruct
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For additional options (e.g inference type, parallelism), please refer to the &lt;a href="https://tabbyml.github.io/tabby"&gt;documentation page&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;🤝 Contributing&lt;/h2&gt; 
&lt;p&gt;Full guide at &lt;a href="https://github.com/TabbyML/tabby/raw/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;;&lt;/p&gt; 
&lt;h3&gt;Get the Code&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone --recurse-submodules https://github.com/TabbyML/tabby
cd tabby
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you have already cloned the repository, you could run the &lt;code&gt;git submodule update --recursive --init&lt;/code&gt; command to fetch all submodules.&lt;/p&gt; 
&lt;h3&gt;Build&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Set up the Rust environment by following this &lt;a href="https://www.rust-lang.org/learn/get-started"&gt;tutorial&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Install the required dependencies:&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# For MacOS
brew install protobuf

# For Ubuntu / Debian
apt install protobuf-compiler libopenblas-dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Install useful tools:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# For Ubuntu
apt install make sqlite3 graphviz
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;Now, you can build Tabby by running the command &lt;code&gt;cargo build&lt;/code&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Start Hacking!&lt;/h3&gt; 
&lt;p&gt;... and don't forget to submit a &lt;a href="https://github.com/TabbyML/tabby/compare"&gt;Pull Request&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;🌍 Community&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;🎤 &lt;a href="https://twitter.com/Tabby_ML"&gt;Twitter / X&lt;/a&gt; - engage with TabbyML for all things possible&lt;/li&gt; 
 &lt;li&gt;📚 &lt;a href="https://www.linkedin.com/company/tabbyml/"&gt;LinkedIn&lt;/a&gt; - follow for the latest from the community&lt;/li&gt; 
 &lt;li&gt;💌 &lt;a href="https://newsletter.tabbyml.com/archive"&gt;Newsletter&lt;/a&gt; - subscribe to unlock Tabby insights and secrets&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;🔆 Activity&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://repobeats.axiom.co/api/embed/e4ef0fbd12e586ef9ea7d72d1fb4f5c5b88d78d5.svg?sanitize=true" alt="Git Repository Activity" title="Repobeats analytics image" /&gt;&lt;/p&gt; 
&lt;h3&gt;🌟 Star History&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#tabbyml/tabby&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=tabbyml/tabby&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>librespot-org/librespot</title>
      <link>https://github.com/librespot-org/librespot</link>
      <description>&lt;p&gt;Open Source Spotify client library&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://github.com/librespot-org/librespot/actions"&gt;&lt;img src="https://github.com/librespot-org/librespot/workflows/build/badge.svg?sanitize=true" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://gitter.im/librespot-org/spotify-connect-resources"&gt;&lt;img src="https://badges.gitter.im/librespot-org/librespot.png" alt="Gitter chat" /&gt;&lt;/a&gt; &lt;a href="https://crates.io/crates/librespot"&gt;&lt;img src="https://img.shields.io/crates/v/librespot.svg?sanitize=true" alt="Crates.io" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Current maintainers are &lt;a href="https://github.com/orgs/librespot-org/people"&gt;listed on GitHub&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;librespot&lt;/h1&gt; 
&lt;p&gt;&lt;em&gt;librespot&lt;/em&gt; is an open source client library for Spotify. It enables applications to use Spotify's service to control and play music via various backends, and to act as a Spotify Connect receiver. It is an alternative to the official and &lt;a href="https://pyspotify.mopidy.com/en/latest/#libspotify-s-deprecation"&gt;now deprecated&lt;/a&gt; closed-source &lt;code&gt;libspotify&lt;/code&gt;. Additionally, it will provide extra features which are not available in the official library.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Note: librespot only works with Spotify Premium. This will remain the case. We will not support any features to make librespot compatible with free accounts, such as limited skips and adverts.&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;Quick start&lt;/h2&gt; 
&lt;p&gt;We're available on &lt;a href="https://crates.io/crates/librespot"&gt;crates.io&lt;/a&gt; as the &lt;em&gt;librespot&lt;/em&gt; package. Simply run &lt;code&gt;cargo install librespot&lt;/code&gt; to install librespot on your system. Check the wiki for more info and possible &lt;a href="https://github.com/librespot-org/librespot/wiki/Options"&gt;usage options&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;After installation, you can run librespot from the CLI using a command such as &lt;code&gt;librespot -n "Librespot Speaker" -b 160&lt;/code&gt; to create a speaker called &lt;em&gt;Librespot Speaker&lt;/em&gt; serving 160 kbps audio.&lt;/p&gt; 
&lt;h2&gt;This fork&lt;/h2&gt; 
&lt;p&gt;As the origin by &lt;a href="https://github.com/plietar/"&gt;plietar&lt;/a&gt; is no longer actively maintained, this organisation and repository have been set up so that the project may be maintained and upgraded in the future.&lt;/p&gt; 
&lt;h1&gt;Documentation&lt;/h1&gt; 
&lt;p&gt;Documentation is currently a work in progress, contributions are welcome!&lt;/p&gt; 
&lt;p&gt;There is some brief documentation on how the protocol works in the &lt;a href="https://github.com/librespot-org/librespot/tree/master/docs"&gt;docs&lt;/a&gt; folder.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/librespot-org/librespot/raw/master/COMPILING.md"&gt;COMPILING.md&lt;/a&gt; contains detailed instructions on setting up a development environment, and compiling librespot. More general usage and compilation information is available on the &lt;a href="https://github.com/librespot-org/librespot/wiki"&gt;wiki&lt;/a&gt;. &lt;a href="https://github.com/librespot-org/librespot/raw/master/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; also contains our contributing guidelines.&lt;/p&gt; 
&lt;p&gt;If you wish to learn more about how librespot works overall, the best way is to simply read the code, and ask any questions you have in our &lt;a href="https://gitter.im/librespot-org/spotify-connect-resources"&gt;Gitter Room&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Issues &amp;amp; Discussions&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;We have recently started using Github discussions for general questions and feature requests, as they are a more natural medium for such cases, and allow for upvoting to prioritize feature development. Check them out &lt;a href="https://github.com/librespot-org/librespot/discussions"&gt;here&lt;/a&gt;. Bugs and issues with the underlying library should still be reported as issues.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;If you run into a bug when using librespot, please search the existing issues before opening a new one. Chances are, we've encountered it before, and have provided a resolution. If not, please open a new one, and where possible, include the backtrace librespot generates on crashing, along with anything we can use to reproduce the issue, e.g. the Spotify URI of the song that caused the crash.&lt;/p&gt; 
&lt;h1&gt;Building&lt;/h1&gt; 
&lt;p&gt;A quick walkthrough of the build process is outlined below, while a detailed compilation guide can be found &lt;a href="https://github.com/librespot-org/librespot/raw/master/COMPILING.md"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Additional Dependencies&lt;/h2&gt; 
&lt;p&gt;We recently switched to using &lt;a href="https://github.com/tomaka/rodio"&gt;Rodio&lt;/a&gt; for audio playback by default, hence for macOS and Windows, you should just be able to clone and build librespot (with the command below). For Linux, you will need to run the additional commands below, depending on your distro.&lt;/p&gt; 
&lt;p&gt;On Debian/Ubuntu, the following command will install these dependencies:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;sudo apt-get install build-essential libasound2-dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;On Fedora systems, the following command will install these dependencies:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;sudo dnf install alsa-lib-devel make gcc
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;librespot currently offers the following selection of &lt;a href="https://github.com/librespot-org/librespot/wiki/Audio-Backends"&gt;audio backends&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Rodio (default)
ALSA
GStreamer
PortAudio
PulseAudio
JACK
JACK over Rodio
SDL
Pipe
Subprocess
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Please check &lt;a href="https://raw.githubusercontent.com/librespot-org/librespot/dev/COMPILING.md"&gt;COMPILING.md&lt;/a&gt; for detailed information on TLS, audio, and discovery backend dependencies, or the &lt;a href="https://github.com/librespot-org/librespot/wiki/Compiling#general-dependencies"&gt;Compiling&lt;/a&gt; entry on the wiki for additional backend specific dependencies.&lt;/p&gt; 
&lt;p&gt;Once you've installed the dependencies and cloned this repository you can build &lt;em&gt;librespot&lt;/em&gt; with the default features using Cargo.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;cargo build --release
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;By default, this builds with native-tls (system TLS), rodio audio backend, and libmdns discovery. See &lt;a href="https://raw.githubusercontent.com/librespot-org/librespot/dev/COMPILING.md"&gt;COMPILING.md&lt;/a&gt; for information on selecting different TLS, audio, and discovery backends.&lt;/p&gt; 
&lt;h1&gt;Packages&lt;/h1&gt; 
&lt;p&gt;librespot is also available via official package system on various operating systems such as Linux, FreeBSD, NetBSD. &lt;a href="https://repology.org/project/librespot/versions"&gt;Repology&lt;/a&gt; offers a good overview.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://repology.org/project/librespot/versions"&gt;&lt;img src="https://repology.org/badge/vertical-allrepos/librespot.svg?sanitize=true" alt="Packaging status" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;A sample program implementing a headless Spotify Connect receiver is provided. Once you've built &lt;em&gt;librespot&lt;/em&gt;, run it using :&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;target/release/librespot --name DEVICENAME
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The above is a minimal example. Here is a more fully fledged one:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;target/release/librespot -n "Librespot" -b 320 -c ./cache --enable-volume-normalisation --initial-volume 75 --device-type avr
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The above command will create a receiver named &lt;code&gt;Librespot&lt;/code&gt;, with bitrate set to 320 kbps, initial volume at 75%, with volume normalisation enabled, and the device displayed in the app as an Audio/Video Receiver. A folder named &lt;code&gt;cache&lt;/code&gt; will be created/used in the current directory, and be used to cache audio data and credentials.&lt;/p&gt; 
&lt;p&gt;A full list of runtime options is available &lt;a href="https://github.com/librespot-org/librespot/wiki/Options"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Please Note: When using the cache feature, an authentication blob is stored for your account in the cache directory. For security purposes, we recommend that you set directory permissions on the cache directory to &lt;code&gt;700&lt;/code&gt;.&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;Contact&lt;/h2&gt; 
&lt;p&gt;Come and hang out on gitter if you need help or want to offer some: &lt;a href="https://gitter.im/librespot-org/spotify-connect-resources"&gt;https://gitter.im/librespot-org/spotify-connect-resources&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Disclaimer&lt;/h2&gt; 
&lt;p&gt;Using this code to connect to Spotify's API is probably forbidden by them. Use at your own risk.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Everything in this repository is licensed under the MIT license.&lt;/p&gt; 
&lt;h2&gt;Related Projects&lt;/h2&gt; 
&lt;p&gt;This is a non exhaustive list of projects that either use or have modified librespot. If you'd like to include yours, submit a PR.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/librespot-org/librespot-golang"&gt;librespot-golang&lt;/a&gt; - A golang port of librespot.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/marcelveldt/plugin.audio.spotify"&gt;plugin.audio.spotify&lt;/a&gt; - A Kodi plugin for Spotify.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dtcooper/raspotify"&gt;raspotify&lt;/a&gt; - A Spotify Connect client that mostly Just Works™&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Spotifyd/spotifyd"&gt;Spotifyd&lt;/a&gt; - A stripped down librespot UNIX daemon.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nicokaiser/rpi-audio-receiver"&gt;rpi-audio-receiver&lt;/a&gt; - easy Raspbian install scripts for Spotifyd, Bluetooth, Shairport and other audio receivers&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/badfortrains/spotcontrol"&gt;Spotcontrol&lt;/a&gt; - A golang implementation of a Spotify Connect controller. No Playback functionality.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/devgianlu/librespot-java"&gt;librespot-java&lt;/a&gt; - A Java port of librespot.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hrkfdn/ncspot"&gt;ncspot&lt;/a&gt; - Cross-platform ncurses Spotify client.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xMordax/ansible-role-librespot/tree/master"&gt;ansible-role-librespot&lt;/a&gt; - Ansible role that will build, install and configure Librespot.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xou816/spot"&gt;Spot&lt;/a&gt; - Gtk/Rust native Spotify client for the GNOME desktop.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/badaix/snapcast"&gt;Snapcast&lt;/a&gt; - synchronised multi-room audio player that uses librespot as its source for Spotify content&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mupibox.de/"&gt;MuPiBox&lt;/a&gt; - Portable music box for Spotify and local media based on Raspberry Pi. Operated via touchscreen. Suitable for children and older people.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ropieee.org"&gt;RoPieee&lt;/a&gt; - An easy-to-use Raspberry Pi image for network audio streaming solutions.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>zensical/zensical</title>
      <link>https://github.com/zensical/zensical</link>
      <description>&lt;p&gt;A modern static site generator by the creators of Material for MkDocs&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/zensical/zensical/master/.github/assets/zensical-dark.png" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/zensical/zensical/master/.github/assets/zensical.png" /&gt; 
  &lt;img alt="Zensical" src="https://raw.githubusercontent.com/zensical/zensical/master/.github/assets/zensical.png" width="290" height="240" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;strong&gt; A modern static site generator built by the creators of &lt;a href="https://github.com/squidfunk/mkdocs-material/"&gt;Material for MkDocs&lt;/a&gt; &lt;/strong&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/zensical/zensical/actions"&gt;&lt;img src="https://github.com/zensical/zensical/actions/workflows/build.yml/badge.svg?sanitize=true" alt="Build" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/zensical"&gt;&lt;img src="https://img.shields.io/pypi/v/zensical.svg?sanitize=true" alt="Python Package Index" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://zensical.org/"&gt;&lt;strong&gt;Home&lt;/strong&gt;&lt;/a&gt; · &lt;a href="https://zensical.org/docs/get-started/"&gt;&lt;strong&gt;Get started&lt;/strong&gt;&lt;/a&gt; · &lt;a href="https://zensical.org/compatibility/"&gt;&lt;strong&gt;Compatibility&lt;/strong&gt;&lt;/a&gt; · &lt;a href="https://zensical.org/about/roadmap/"&gt;&lt;strong&gt;Roadmap&lt;/strong&gt;&lt;/a&gt; · &lt;a href="https://zensical.org/about/newsletter/"&gt;&lt;strong&gt;Newsletter&lt;/strong&gt;&lt;/a&gt; · &lt;a href="https://zensical.org/spark/"&gt;&lt;strong&gt;Zensical Spark&lt;/strong&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; Write your documentation in Markdown and create a professional static site for your Open Source or commercial project in minutes – searchable, customizable, more than 60 languages, for all devices. &lt;/p&gt; 
&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/zensical/zensical/master/.github/assets/screenshot-dark.png" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/zensical/zensical/master/.github/assets/screenshot.png" /&gt; 
  &lt;img alt="Zensical" src="https://raw.githubusercontent.com/zensical/zensical/master/.github/assets/screenshot.png" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;em&gt; Visit our documentation at &lt;a href="https://zensical.org/docs/"&gt;zensical.org/docs/&lt;/a&gt;. &lt;/em&gt; &lt;/p&gt;</description>
    </item>
    
    <item>
      <title>launchbadge/sqlx</title>
      <link>https://github.com/launchbadge/sqlx</link>
      <description>&lt;p&gt;🧰 The Rust SQL Toolkit. An async, pure Rust SQL crate featuring compile-time checked queries without a DSL. Supports PostgreSQL, MySQL, and SQLite.&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt;SQLx&lt;/h1&gt; 
&lt;div align="center"&gt; 
 &lt;strong&gt; 🧰 The Rust SQL Toolkit &lt;/strong&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;div align="center"&gt; 
 &lt;!-- Github Actions --&gt; 
 &lt;a href="https://github.com/launchbadge/sqlx/actions/workflows/sqlx.yml?query=branch%3Amain"&gt; &lt;img src="https://img.shields.io/github/actions/workflow/status/launchbadge/sqlx/sqlx.yml?branch=main&amp;amp;style=flat-square" alt="actions status" /&gt;&lt;/a&gt; 
 &lt;!-- Version --&gt; 
 &lt;a href="https://crates.io/crates/sqlx"&gt; &lt;img src="https://img.shields.io/crates/v/sqlx.svg?style=flat-square" alt="Crates.io version" /&gt;&lt;/a&gt; 
 &lt;!-- Discord --&gt; 
 &lt;a href="https://discord.gg/uuruzJ7"&gt; &lt;img src="https://img.shields.io/discord/665528275556106240?style=flat-square" alt="chat" /&gt;&lt;/a&gt; 
 &lt;!-- Docs --&gt; 
 &lt;a href="https://docs.rs/sqlx"&gt; &lt;img src="https://img.shields.io/badge/docs-latest-blue.svg?style=flat-square" alt="docs.rs docs" /&gt;&lt;/a&gt; 
 &lt;!-- Downloads --&gt; 
 &lt;a href="https://crates.io/crates/sqlx"&gt; &lt;img src="https://img.shields.io/crates/d/sqlx.svg?style=flat-square" alt="Download" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;h4&gt; &lt;a href="https://raw.githubusercontent.com/launchbadge/sqlx/main/#install"&gt; Install &lt;/a&gt; &lt;span&gt; | &lt;/span&gt; &lt;a href="https://raw.githubusercontent.com/launchbadge/sqlx/main/#usage"&gt; Usage &lt;/a&gt; &lt;span&gt; | &lt;/span&gt; &lt;a href="https://docs.rs/sqlx"&gt; Docs &lt;/a&gt; &lt;span&gt; | &lt;/span&gt; &lt;a href="https://github.com/launchbadge/sqlx/wiki/Ecosystem"&gt; Ecosystem &lt;/a&gt; &lt;span&gt; | &lt;/span&gt; &lt;a href="https://discord.gg/uuruzJ7"&gt; Discord &lt;/a&gt; &lt;/h4&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;div align="center"&gt; 
 &lt;small&gt;Built with ❤️ by &lt;a href="https://launchbadge.com"&gt;The LaunchBadge team&lt;/a&gt;&lt;/small&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;div align="center"&gt; 
 &lt;h5&gt;Have a question? Be sure to &lt;a href="https://raw.githubusercontent.com/launchbadge/sqlx/main/FAQ.md"&gt;check the FAQ first!&lt;/a&gt;&lt;/h5&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;p&gt;SQLx is an async, pure Rust&lt;sub&gt;†&lt;/sub&gt; SQL crate featuring compile-time checked queries without a DSL.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Truly Asynchronous&lt;/strong&gt;. Built from the ground-up using async/await for maximum concurrency.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Compile-time checked queries&lt;/strong&gt; (if you want). See &lt;a href="https://raw.githubusercontent.com/launchbadge/sqlx/main/#sqlx-is-not-an-orm"&gt;SQLx is not an ORM&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Database Agnostic&lt;/strong&gt;. Support for &lt;a href="http://postgresql.org/"&gt;PostgreSQL&lt;/a&gt;, &lt;a href="https://www.mysql.com/"&gt;MySQL&lt;/a&gt;, &lt;a href="https://www.mariadb.org/"&gt;MariaDB&lt;/a&gt;, &lt;a href="https://sqlite.org/"&gt;SQLite&lt;/a&gt;.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://www.microsoft.com/en-us/sql-server"&gt;MSSQL&lt;/a&gt; was supported prior to version 0.7, but has been removed pending a full rewrite of the driver as part of our &lt;a href="https://github.com/launchbadge/sqlx/discussions/1616"&gt;SQLx Pro initiative&lt;/a&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Pure Rust&lt;/strong&gt;. The Postgres and MySQL/MariaDB drivers are written in pure Rust using &lt;strong&gt;zero&lt;/strong&gt; unsafe&lt;sub&gt;††&lt;/sub&gt; code.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Runtime Agnostic&lt;/strong&gt;. Works on different runtimes (&lt;a href="https://github.com/async-rs/async-std"&gt;&lt;code&gt;async-std&lt;/code&gt;&lt;/a&gt; / &lt;a href="https://github.com/tokio-rs/tokio"&gt;&lt;code&gt;tokio&lt;/code&gt;&lt;/a&gt; / &lt;a href="https://github.com/actix/actix-net"&gt;&lt;code&gt;actix&lt;/code&gt;&lt;/a&gt;) and TLS backends (&lt;a href="https://crates.io/crates/native-tls"&gt;&lt;code&gt;native-tls&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://crates.io/crates/rustls"&gt;&lt;code&gt;rustls&lt;/code&gt;&lt;/a&gt;).&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;small&gt;&lt;small&gt;&lt;/small&gt;&lt;/small&gt;&lt;/p&gt;
&lt;small&gt;&lt;small&gt; &lt;p&gt;† The SQLite driver uses the libsqlite3 C library as SQLite is an embedded database (the only way we could be pure Rust for SQLite is by porting &lt;em&gt;all&lt;/em&gt; of SQLite to Rust).&lt;/p&gt; &lt;p&gt;†† SQLx uses &lt;code&gt;#![forbid(unsafe_code)]&lt;/code&gt; unless the &lt;code&gt;sqlite&lt;/code&gt; feature is enabled. The SQLite driver directly invokes the SQLite3 API via &lt;code&gt;libsqlite3-sys&lt;/code&gt;, which requires &lt;code&gt;unsafe&lt;/code&gt;.&lt;/p&gt; &lt;/small&gt;&lt;/small&gt;
&lt;p&gt;&lt;small&gt;&lt;small&gt;&lt;/small&gt;&lt;/small&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Cross-platform. Being native Rust, SQLx will compile anywhere Rust is supported.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Built-in connection pooling with &lt;code&gt;sqlx::Pool&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Row streaming. Data is read asynchronously from the database and decoded on demand.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Automatic statement preparation and caching. When using the high-level query API (&lt;code&gt;sqlx::query&lt;/code&gt;), statements are prepared and cached per connection.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Simple (unprepared) query execution including fetching results into the same &lt;code&gt;Row&lt;/code&gt; types used by the high-level API. Supports batch execution and returns results from all statements.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Transport Layer Security (TLS) where supported (&lt;a href="https://www.mysql.com/"&gt;MySQL&lt;/a&gt;, &lt;a href="https://www.mariadb.org/"&gt;MariaDB&lt;/a&gt; and &lt;a href="http://postgresql.org/"&gt;PostgreSQL&lt;/a&gt;).&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Asynchronous notifications using &lt;code&gt;LISTEN&lt;/code&gt; and &lt;code&gt;NOTIFY&lt;/code&gt; for &lt;a href="http://postgresql.org/"&gt;PostgreSQL&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Nested transactions with support for save points.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;Any&lt;/code&gt; database driver for changing the database driver at runtime. An &lt;code&gt;AnyPool&lt;/code&gt; connects to the driver indicated by the URL scheme.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Install&lt;/h2&gt; 
&lt;p&gt;SQLx is compatible with the &lt;a href="https://github.com/async-rs/async-std"&gt;&lt;code&gt;async-std&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://github.com/tokio-rs/tokio"&gt;&lt;code&gt;tokio&lt;/code&gt;&lt;/a&gt;, and &lt;a href="https://github.com/actix/actix-net"&gt;&lt;code&gt;actix&lt;/code&gt;&lt;/a&gt; runtimes; and, the &lt;a href="https://crates.io/crates/native-tls"&gt;&lt;code&gt;native-tls&lt;/code&gt;&lt;/a&gt; and &lt;a href="https://crates.io/crates/rustls"&gt;&lt;code&gt;rustls&lt;/code&gt;&lt;/a&gt; TLS backends. When adding the dependency, you must choose a runtime feature that is &lt;code&gt;runtime&lt;/code&gt; + &lt;code&gt;tls&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# Cargo.toml
[dependencies]
# PICK ONE OF THE FOLLOWING:

# tokio (no TLS)
sqlx = { version = "0.8", features = [ "runtime-tokio" ] }
# tokio + native-tls
sqlx = { version = "0.8", features = [ "runtime-tokio", "tls-native-tls" ] }
# tokio + rustls with ring and WebPKI CA certificates
sqlx = { version = "0.8", features = [ "runtime-tokio", "tls-rustls-ring-webpki" ] }
# tokio + rustls with ring and platform's native CA certificates
sqlx = { version = "0.8", features = [ "runtime-tokio", "tls-rustls-ring-native-roots" ] }
# tokio + rustls with aws-lc-rs
sqlx = { version = "0.8", features = [ "runtime-tokio", "tls-rustls-aws-lc-rs" ] }

# async-std (no TLS)
sqlx = { version = "0.8", features = [ "runtime-async-std" ] }
# async-std + native-tls
sqlx = { version = "0.8", features = [ "runtime-async-std", "tls-native-tls" ] }
# async-std + rustls with ring and WebPKI CA certificates
sqlx = { version = "0.8", features = [ "runtime-async-std", "tls-rustls-ring-webpki" ] }
# async-std + rustls with ring and platform's native CA certificates
sqlx = { version = "0.8", features = [ "runtime-async-std", "tls-rustls-ring-native-roots" ] }
# async-std + rustls with aws-lc-rs
sqlx = { version = "0.8", features = [ "runtime-async-std", "tls-rustls-aws-lc-rs" ] }
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Cargo Feature Flags&lt;/h4&gt; 
&lt;p&gt;For backward-compatibility reasons, the runtime and TLS features can either be chosen together as a single feature, or separately.&lt;/p&gt; 
&lt;p&gt;For forward compatibility, you should use the separate runtime and TLS features as the combination features may be removed in the future.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;runtime-async-std&lt;/code&gt;: Use the &lt;code&gt;async-std&lt;/code&gt; runtime without enabling a TLS backend.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;runtime-tokio&lt;/code&gt;: Use the &lt;code&gt;tokio&lt;/code&gt; runtime without enabling a TLS backend.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Actix-web is fully compatible with Tokio and so a separate runtime feature is no longer needed.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;tls-native-tls&lt;/code&gt;: Use the &lt;code&gt;native-tls&lt;/code&gt; TLS backend (OpenSSL on *nix, SChannel on Windows, Secure Transport on macOS).&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;tls-rustls&lt;/code&gt;: Use the &lt;code&gt;rustls&lt;/code&gt; TLS backend (cross-platform backend, only supports TLS 1.2 and 1.3).&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;postgres&lt;/code&gt;: Add support for the Postgres database server.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;mysql&lt;/code&gt;: Add support for the MySQL/MariaDB database server.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;mssql&lt;/code&gt;: Add support for the MSSQL database server.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;sqlite&lt;/code&gt;: Add support for the self-contained &lt;a href="https://sqlite.org/"&gt;SQLite&lt;/a&gt; database engine with SQLite bundled and statically-linked.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;sqlite-unbundled&lt;/code&gt;: The same as above (&lt;code&gt;sqlite&lt;/code&gt;), but link SQLite from the system instead of the bundled version.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Allows updating SQLite independently of SQLx or using forked versions.&lt;/li&gt; 
   &lt;li&gt;You must have SQLite installed on the system or provide a path to the library at build time. See &lt;a href="https://github.com/rusqlite/rusqlite?tab=readme-ov-file#notes-on-building-rusqlite-and-libsqlite3-sys"&gt;the &lt;code&gt;rusqlite&lt;/code&gt; README&lt;/a&gt; for details.&lt;/li&gt; 
   &lt;li&gt;May result in link errors if the SQLite version is too old. Version &lt;code&gt;3.20.0&lt;/code&gt; or newer is recommended.&lt;/li&gt; 
   &lt;li&gt;Can increase build time due to the use of bindgen.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;sqlite-preupdate-hook&lt;/code&gt;: enables SQLite's &lt;a href="https://sqlite.org/c3ref/preupdate_count.html"&gt;preupdate hook&lt;/a&gt; API.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Exposed as a separate feature because it's generally not enabled by default.&lt;/li&gt; 
   &lt;li&gt;Using this feature with &lt;code&gt;sqlite-unbundled&lt;/code&gt; may cause linker failures if the system SQLite version does not support it.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;any&lt;/code&gt;: Add support for the &lt;code&gt;Any&lt;/code&gt; database driver, which can proxy to a database driver at runtime.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;derive&lt;/code&gt;: Add support for the derive family macros, those are &lt;code&gt;FromRow&lt;/code&gt;, &lt;code&gt;Type&lt;/code&gt;, &lt;code&gt;Encode&lt;/code&gt;, &lt;code&gt;Decode&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;macros&lt;/code&gt;: Add support for the &lt;code&gt;query*!&lt;/code&gt; macros, which allows compile-time checked queries.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;migrate&lt;/code&gt;: Add support for the migration management and &lt;code&gt;migrate!&lt;/code&gt; macro, which allow compile-time embedded migrations.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;uuid&lt;/code&gt;: Add support for UUID.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;chrono&lt;/code&gt;: Add support for date and time types from &lt;code&gt;chrono&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;time&lt;/code&gt;: Add support for date and time types from &lt;code&gt;time&lt;/code&gt; crate (alternative to &lt;code&gt;chrono&lt;/code&gt;, which is preferred by &lt;code&gt;query!&lt;/code&gt; macro, if both enabled)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;bstr&lt;/code&gt;: Add support for &lt;code&gt;bstr::BString&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;bigdecimal&lt;/code&gt;: Add support for &lt;code&gt;NUMERIC&lt;/code&gt; using the &lt;code&gt;bigdecimal&lt;/code&gt; crate.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;rust_decimal&lt;/code&gt;: Add support for &lt;code&gt;NUMERIC&lt;/code&gt; using the &lt;code&gt;rust_decimal&lt;/code&gt; crate.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;ipnet&lt;/code&gt;: Add support for &lt;code&gt;INET&lt;/code&gt; and &lt;code&gt;CIDR&lt;/code&gt; (in postgres) using the &lt;code&gt;ipnet&lt;/code&gt; crate.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;ipnetwork&lt;/code&gt;: Add support for &lt;code&gt;INET&lt;/code&gt; and &lt;code&gt;CIDR&lt;/code&gt; (in postgres) using the &lt;code&gt;ipnetwork&lt;/code&gt; crate.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;json&lt;/code&gt;: Add support for &lt;code&gt;JSON&lt;/code&gt; and &lt;code&gt;JSONB&lt;/code&gt; (in postgres) using the &lt;code&gt;serde_json&lt;/code&gt; crate.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Offline mode is now always enabled. See &lt;a href="https://raw.githubusercontent.com/launchbadge/sqlx/main/sqlx-cli/README.md#enable-building-in-offline-mode-with-query"&gt;sqlx-cli/README.md&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;SQLx is not an ORM!&lt;/h2&gt; 
&lt;p&gt;SQLx supports &lt;strong&gt;compile-time checked queries&lt;/strong&gt;. It does not, however, do this by providing a Rust API or DSL (domain-specific language) for building queries. Instead, it provides macros that take regular SQL as input and ensure that it is valid for your database. The way this works is that SQLx connects to your development DB at compile time to have the database itself verify (and return some info on) your SQL queries. This has some potentially surprising implications:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Since SQLx never has to parse the SQL string itself, any syntax that the development DB accepts can be used (including things added by database extensions)&lt;/li&gt; 
 &lt;li&gt;Due to the different amount of information databases let you retrieve about queries, the extent of SQL verification you get from the query macros depends on the database&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;If you are looking for an (asynchronous) ORM,&lt;/strong&gt; you can check out our new &lt;a href="https://github.com/launchbadge/sqlx/wiki/Ecosystem#orms"&gt;Ecosystem wiki page&lt;/a&gt;!&lt;/p&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;See the &lt;code&gt;examples/&lt;/code&gt; folder for more in-depth usage.&lt;/p&gt; 
&lt;h3&gt;Quickstart&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;use sqlx::postgres::PgPoolOptions;
// use sqlx::mysql::MySqlPoolOptions;
// etc.

#[async_std::main] // Requires the `attributes` feature of `async-std`
// or #[tokio::main]
// or #[actix_web::main]
async fn main() -&amp;gt; Result&amp;lt;(), sqlx::Error&amp;gt; {
    // Create a connection pool
    //  for MySQL/MariaDB, use MySqlPoolOptions::new()
    //  for SQLite, use SqlitePoolOptions::new()
    //  etc.
    let pool = PgPoolOptions::new()
        .max_connections(5)
        .connect("postgres://postgres:password@localhost/test").await?;

    // Make a simple query to return the given parameter (use a question mark `?` instead of `$1` for MySQL/MariaDB)
    let row: (i64,) = sqlx::query_as("SELECT $1")
        .bind(150_i64)
        .fetch_one(&amp;amp;pool).await?;

    assert_eq!(row.0, 150);

    Ok(())
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Connecting&lt;/h3&gt; 
&lt;p&gt;A single connection can be established using any of the database connection types and calling &lt;code&gt;connect()&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;use sqlx::Connection;

let conn = SqliteConnection::connect("sqlite::memory:").await?;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Generally, you will want to instead create a connection pool (&lt;code&gt;sqlx::Pool&lt;/code&gt;) for the application to regulate how many server-side connections it's using.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;let pool = MySqlPool::connect("mysql://user:pass@host/database").await?;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Querying&lt;/h3&gt; 
&lt;p&gt;In SQL, queries can be separated into prepared (parameterized) or unprepared (simple). Prepared queries have their query plan &lt;em&gt;cached&lt;/em&gt;, use a binary mode of communication (lower bandwidth and faster decoding), and utilize parameters to avoid SQL injection. Unprepared queries are simple and intended only for use where a prepared statement will not work, such as various database commands (e.g., &lt;code&gt;PRAGMA&lt;/code&gt; or &lt;code&gt;SET&lt;/code&gt; or &lt;code&gt;BEGIN&lt;/code&gt;).&lt;/p&gt; 
&lt;p&gt;SQLx supports all operations with both types of queries. In SQLx, a &lt;code&gt;&amp;amp;str&lt;/code&gt; is treated as an unprepared query, and a &lt;code&gt;Query&lt;/code&gt; or &lt;code&gt;QueryAs&lt;/code&gt; struct is treated as a prepared query.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;// low-level, Executor trait
conn.execute("BEGIN").await?; // unprepared, simple query
conn.execute(sqlx::query("DELETE FROM table")).await?; // prepared, cached query
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;We should prefer to use the high-level &lt;code&gt;query&lt;/code&gt; interface whenever possible. To make this easier, there are finalizers on the type to avoid the need to wrap with an executor.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;sqlx::query("DELETE FROM table").execute(&amp;amp;mut conn).await?;
sqlx::query("DELETE FROM table").execute(&amp;amp;pool).await?;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;code&gt;execute&lt;/code&gt; query finalizer returns the number of affected rows, if any, and drops all received results. In addition, there are &lt;code&gt;fetch&lt;/code&gt;, &lt;code&gt;fetch_one&lt;/code&gt;, &lt;code&gt;fetch_optional&lt;/code&gt;, and &lt;code&gt;fetch_all&lt;/code&gt; to receive results.&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;Query&lt;/code&gt; type returned from &lt;code&gt;sqlx::query&lt;/code&gt; will return &lt;code&gt;Row&amp;lt;'conn&amp;gt;&lt;/code&gt; from the database. Column values can be accessed by ordinal or by name with &lt;code&gt;row.get()&lt;/code&gt;. As the &lt;code&gt;Row&lt;/code&gt; retains an immutable borrow on the connection, only one &lt;code&gt;Row&lt;/code&gt; may exist at a time.&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;fetch&lt;/code&gt; query finalizer returns a stream-like type that iterates through the rows in the result sets.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;// provides `try_next`
use futures_util::TryStreamExt;
// provides `try_get`
use sqlx::Row;

let mut rows = sqlx::query("SELECT * FROM users WHERE email = ?")
    .bind(email)
    .fetch(&amp;amp;mut conn);

while let Some(row) = rows.try_next().await? {
    // map the row into a user-defined domain type
    let email: &amp;amp;str = row.try_get("email")?;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To assist with mapping the row into a domain type, one of two idioms may be used:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;let mut stream = sqlx::query("SELECT * FROM users")
    .map(|row: PgRow| {
        // map the row into a user-defined domain type
    })
    .fetch(&amp;amp;mut conn);
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;#[derive(sqlx::FromRow)]
struct User { name: String, id: i64 }

let mut stream = sqlx::query_as::&amp;lt;_, User&amp;gt;("SELECT * FROM users WHERE email = ? OR name = ?")
    .bind(user_email)
    .bind(user_name)
    .fetch(&amp;amp;mut conn);
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Instead of a stream of results, we can use &lt;code&gt;fetch_one&lt;/code&gt; or &lt;code&gt;fetch_optional&lt;/code&gt; to request one required or optional result from the database.&lt;/p&gt; 
&lt;h3&gt;Compile-time verification&lt;/h3&gt; 
&lt;p&gt;We can use the macro, &lt;code&gt;sqlx::query!&lt;/code&gt; to achieve compile-time syntactic and semantic verification of the SQL, with an output to an anonymous record type where each SQL column is a Rust field (using raw identifiers where needed).&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;let countries = sqlx::query!(
        "
SELECT country, COUNT(*) as count
FROM users
GROUP BY country
WHERE organization = ?
        ",
        organization
    )
    .fetch_all(&amp;amp;pool) // -&amp;gt; Vec&amp;lt;{ country: String, count: i64 }&amp;gt;
    .await?;

// countries[0].country
// countries[0].count
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Differences from &lt;code&gt;query()&lt;/code&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;The input (or bind) parameters must be given all at once (and they are compile-time validated to be the right number and the right type).&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;The output type is an anonymous record. In the above example the type would be similar to:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-rust"&gt;{ country: String, count: i64 }
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;The &lt;code&gt;DATABASE_URL&lt;/code&gt; environment variable must be set at build time to a database which it can prepare queries against; the database does not have to contain any data but must be the same kind (MySQL, Postgres, etc.) and have the same schema as the database you will be connecting to at runtime.&lt;/p&gt; &lt;p&gt;For convenience, you can use &lt;a href="https://github.com/dotenv-rs/dotenv#examples"&gt;a &lt;code&gt;.env&lt;/code&gt; file&lt;/a&gt;&lt;sup&gt;1&lt;/sup&gt; to set DATABASE_URL so that you don't have to pass it every time:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;DATABASE_URL=mysql://localhost/my_database
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The biggest downside to &lt;code&gt;query!()&lt;/code&gt; is that the output type cannot be named (due to Rust not officially supporting anonymous records). To address that, there is a &lt;code&gt;query_as!()&lt;/code&gt; macro that is mostly identical except that you can name the output type.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;// no traits are needed
struct Country { country: String, count: i64 }

let countries = sqlx::query_as!(Country,
        "
SELECT country, COUNT(*) as count
FROM users
GROUP BY country
WHERE organization = ?
        ",
        organization
    )
    .fetch_all(&amp;amp;pool) // -&amp;gt; Vec&amp;lt;Country&amp;gt;
    .await?;

// countries[0].country
// countries[0].count
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To avoid the need of having a development database around to compile the project even when no modifications (to the database-accessing parts of the code) are done, you can enable "offline mode" to cache the results of the SQL query analysis using the &lt;code&gt;sqlx&lt;/code&gt; command-line tool. See &lt;a href="https://raw.githubusercontent.com/launchbadge/sqlx/main/sqlx-cli/README.md#enable-building-in-offline-mode-with-query"&gt;sqlx-cli/README.md&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Compile-time verified queries do quite a bit of work at compile time. Incremental actions like &lt;code&gt;cargo check&lt;/code&gt; and &lt;code&gt;cargo build&lt;/code&gt; can be significantly faster when using an optimized build by putting the following in your &lt;code&gt;Cargo.toml&lt;/code&gt; (More information in the &lt;a href="https://doc.rust-lang.org/cargo/reference/profiles.html"&gt;Profiles section&lt;/a&gt; of The Cargo Book)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;[profile.dev.package.sqlx-macros]
opt-level = 3
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;sup&gt;1&lt;/sup&gt; The &lt;code&gt;dotenv&lt;/code&gt; crate itself appears abandoned as of &lt;a href="https://github.com/dotenv-rs/dotenv/issues/74"&gt;December 2021&lt;/a&gt; so we now use the &lt;code&gt;dotenvy&lt;/code&gt; crate instead. The file format is the same.&lt;/p&gt; 
&lt;h2&gt;Safety&lt;/h2&gt; 
&lt;p&gt;This crate uses &lt;code&gt;#![forbid(unsafe_code)]&lt;/code&gt; to ensure everything is implemented in 100% Safe Rust.&lt;/p&gt; 
&lt;p&gt;If the &lt;code&gt;sqlite&lt;/code&gt; feature is enabled, this is downgraded to &lt;code&gt;#![deny(unsafe_code)]&lt;/code&gt; with &lt;code&gt;#![allow(unsafe_code)]&lt;/code&gt; on the &lt;code&gt;sqlx::sqlite&lt;/code&gt; module. There are several places where we interact with the C SQLite API. We try to document each call for the invariants we're assuming. We absolutely welcome auditing of, and feedback on, our unsafe code usage.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Licensed under either of&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Apache License, Version 2.0 (&lt;a href="https://raw.githubusercontent.com/launchbadge/sqlx/main/LICENSE-APACHE"&gt;LICENSE-APACHE&lt;/a&gt; or &lt;a href="http://www.apache.org/licenses/LICENSE-2.0"&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;MIT license (&lt;a href="https://raw.githubusercontent.com/launchbadge/sqlx/main/LICENSE-MIT"&gt;LICENSE-MIT&lt;/a&gt; or &lt;a href="http://opensource.org/licenses/MIT"&gt;http://opensource.org/licenses/MIT&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;at your option.&lt;/p&gt; 
&lt;h2&gt;Contribution&lt;/h2&gt; 
&lt;p&gt;Unless you explicitly state otherwise, any Contribution intentionally submitted for inclusion in the work by you, as defined in the Apache-2.0 license, shall be dual licensed as above, without any additional terms or conditions.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>regolith-labs/ore</title>
      <link>https://github.com/regolith-labs/ore</link>
      <description>&lt;p&gt;It's time to mine.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ORE&lt;/h1&gt; 
&lt;p&gt;ORE is a crypto mining protocol.&lt;/p&gt; 
&lt;h2&gt;API&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/regolith-labs/ore/master/api/src/consts.rs"&gt;&lt;code&gt;Consts&lt;/code&gt;&lt;/a&gt; –&amp;nbsp;Program constants.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/regolith-labs/ore/master/api/src/error.rs"&gt;&lt;code&gt;Error&lt;/code&gt;&lt;/a&gt; –&amp;nbsp;Custom program errors.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/regolith-labs/ore/master/api/src/error.rs"&gt;&lt;code&gt;Event&lt;/code&gt;&lt;/a&gt; –&amp;nbsp;Custom program events.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/regolith-labs/ore/master/api/src/instruction.rs"&gt;&lt;code&gt;Instruction&lt;/code&gt;&lt;/a&gt; –&amp;nbsp;Declared instructions and arguments.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Instructions&lt;/h2&gt; 
&lt;h4&gt;Mining&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/regolith-labs/ore/master/program/src/automate.rs"&gt;&lt;code&gt;Automate&lt;/code&gt;&lt;/a&gt; - Configures a new automation.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/regolith-labs/ore/master/program/src/checkpoint.rs"&gt;&lt;code&gt;Checkpoint&lt;/code&gt;&lt;/a&gt; - Checkpoints rewards from an prior round.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/regolith-labs/ore/master/program/src/claim_ore.rs"&gt;&lt;code&gt;ClaimORE&lt;/code&gt;&lt;/a&gt; - Claims ORE mining rewards.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/regolith-labs/ore/master/program/src/claim_sol.rs"&gt;&lt;code&gt;ClaimSOL&lt;/code&gt;&lt;/a&gt; - Claims SOL mining rewards.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/regolith-labs/ore/master/program/src/deploy.rs"&gt;&lt;code&gt;Deploy&lt;/code&gt;&lt;/a&gt; – Deploys SOL to claim space on the board.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/regolith-labs/ore/master/program/src/initialize.rs"&gt;&lt;code&gt;Initialize&lt;/code&gt;&lt;/a&gt; - Initializes program variables.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/regolith-labs/ore/master/program/src/log.rs"&gt;&lt;code&gt;Log&lt;/code&gt;&lt;/a&gt; – Logs non-truncatable event data.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/regolith-labs/ore/master/program/src/reset.rs"&gt;&lt;code&gt;Reset&lt;/code&gt;&lt;/a&gt; - Resets the board for a new round.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/regolith-labs/ore/master/program/src/reset.rs"&gt;&lt;code&gt;Reset&lt;/code&gt;&lt;/a&gt; - Resets the board for a new round.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Staking&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/regolith-labs/ore/master/program/src/deposit.rs"&gt;&lt;code&gt;Deposit&lt;/code&gt;&lt;/a&gt; - Deposits ORE into a stake account.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/regolith-labs/ore/master/program/src/withdraw.rs"&gt;&lt;code&gt;Withdraw&lt;/code&gt;&lt;/a&gt; - Withdraws ORE from a stake account.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/regolith-labs/ore/master/program/src/claim_seeker.rs"&gt;&lt;code&gt;ClaimSeeker&lt;/code&gt;&lt;/a&gt; - Claims a Seeker genesis token.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/regolith-labs/ore/master/program/src/claim_yield.rs"&gt;&lt;code&gt;ClaimYield&lt;/code&gt;&lt;/a&gt; - Claims staking yield.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Admin&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/regolith-labs/ore/master/program/src/bury.rs"&gt;&lt;code&gt;Bury&lt;/code&gt;&lt;/a&gt; - Executes a buy-and-bury transaction.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/regolith-labs/ore/master/program/src/wrap.rs"&gt;&lt;code&gt;Wrap&lt;/code&gt;&lt;/a&gt; - Wraps SOL in the treasury for swap transactions.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/regolith-labs/ore/master/program/src/set_admin.rs"&gt;&lt;code&gt;SetAdmin&lt;/code&gt;&lt;/a&gt; - Re-assigns the admin authority.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/regolith-labs/ore/master/program/src/set_admin.rs"&gt;&lt;code&gt;SetFeeCollector&lt;/code&gt;&lt;/a&gt; - Updates the fee collection address.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/regolith-labs/ore/master/program/src/set_admin.rs"&gt;&lt;code&gt;SetFeeRate&lt;/code&gt;&lt;/a&gt; - Updates the fee charged per swap.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;State&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/regolith-labs/ore/master/api/src/state/automation.rs"&gt;&lt;code&gt;Automation&lt;/code&gt;&lt;/a&gt; - Tracks automation configs.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/regolith-labs/ore/master/api/src/state/board.rs"&gt;&lt;code&gt;Board&lt;/code&gt;&lt;/a&gt; - Tracks the current round number and timestamps.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/regolith-labs/ore/master/api/src/state/config.rs"&gt;&lt;code&gt;Config&lt;/code&gt;&lt;/a&gt; - Global program configs.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/regolith-labs/ore/master/api/src/state/miner.rs"&gt;&lt;code&gt;Miner&lt;/code&gt;&lt;/a&gt; - Tracks a miner's game state.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/regolith-labs/ore/master/api/src/state/round.rs"&gt;&lt;code&gt;Round&lt;/code&gt;&lt;/a&gt; - Tracks the game state of a given round.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/regolith-labs/ore/master/api/src/state/seeker.rs"&gt;&lt;code&gt;Seeker&lt;/code&gt;&lt;/a&gt; - Tracks whether a Seeker token has been claimed.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/regolith-labs/ore/master/api/src/state/stake.rs"&gt;&lt;code&gt;Stake&lt;/code&gt;&lt;/a&gt; - Manages a user's staking activity.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/regolith-labs/ore/master/api/src/state/treasury.rs"&gt;&lt;code&gt;Treasury&lt;/code&gt;&lt;/a&gt; - Mints, burns, and escrows ORE tokens.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Tests&lt;/h2&gt; 
&lt;p&gt;To run the test suite, use the Solana toolchain:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;cargo test-sbf
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For line coverage, use llvm-cov:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;cargo llvm-cov
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>PyO3/maturin</title>
      <link>https://github.com/PyO3/maturin</link>
      <description>&lt;p&gt;Build and publish crates with pyo3, cffi and uniffi bindings as well as rust binaries as python packages&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Maturin&lt;/h1&gt; 
&lt;p&gt;&lt;em&gt;formerly pyo3-pack&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://maturin.rs"&gt;&lt;img src="https://img.shields.io/badge/user-guide-brightgreen?logo=readthedocs&amp;amp;style=flat-square" alt="Maturin User Guide" /&gt;&lt;/a&gt; &lt;a href="https://crates.io/crates/maturin"&gt;&lt;img src="https://img.shields.io/crates/v/maturin.svg?logo=rust&amp;amp;style=flat-square" alt="Crates.io" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/maturin"&gt;&lt;img src="https://img.shields.io/pypi/v/maturin.svg?logo=python&amp;amp;style=flat-square" alt="PyPI" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/33kcChzH7f"&gt;&lt;img src="https://img.shields.io/discord/1209263839632424990?logo=discord&amp;amp;style=flat-square" alt="discord server" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Build and publish crates with &lt;a href="https://maturin.rs/bindings"&gt;pyo3, cffi and uniffi bindings&lt;/a&gt; as well as rust binaries as python packages with minimal configuration. It supports building wheels for python 3.8+ on Windows, Linux, macOS and FreeBSD, can upload them to &lt;a href="https://pypi.org/"&gt;pypi&lt;/a&gt; and has basic PyPy and GraalPy support.&lt;/p&gt; 
&lt;p&gt;Check out the &lt;a href="https://maturin.rs/"&gt;User Guide&lt;/a&gt;!&lt;/p&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;You can either download binaries from the &lt;a href="https://github.com/PyO3/maturin/releases/latest"&gt;latest release&lt;/a&gt; or install it with &lt;a href="https://pypa.github.io/pipx/"&gt;pipx&lt;/a&gt; or &lt;a href="https://github.com/astral-sh/uv"&gt;uv&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# pipx
pipx install maturin
# uv
uv tool install maturin
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;&lt;code&gt;pip install maturin&lt;/code&gt; should also work if you don't want to use pipx.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;There are four main commands:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;maturin new&lt;/code&gt; creates a new cargo project with maturin configured.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;maturin publish&lt;/code&gt; builds the crate into python packages and publishes them to pypi.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;maturin build&lt;/code&gt; builds the wheels and stores them in a folder (&lt;code&gt;target/wheels&lt;/code&gt; by default), but doesn't upload them. It's recommended to publish packages with &lt;a href="https://github.com/astral-sh/uv"&gt;uv&lt;/a&gt; using &lt;code&gt;uv publish&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;maturin develop&lt;/code&gt; builds the crate and installs it as a python module directly in the current virtualenv. Note that while &lt;code&gt;maturin develop&lt;/code&gt; is faster, it doesn't support all the feature that running &lt;code&gt;pip install&lt;/code&gt; after &lt;code&gt;maturin build&lt;/code&gt; supports.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;maturin doesn't need extra configuration files and doesn't clash with an existing setuptools-rust configuration. You can even integrate it with testing tools such as &lt;a href="https://tox.readthedocs.io/en/latest/"&gt;tox&lt;/a&gt;. There are examples for the different bindings in the &lt;code&gt;test-crates&lt;/code&gt; folder.&lt;/p&gt; 
&lt;p&gt;The name of the package will be the name of the cargo project, i.e. the name field in the &lt;code&gt;[package]&lt;/code&gt; section of &lt;code&gt;Cargo.toml&lt;/code&gt;. The name of the module, which you are using when importing, will be the &lt;code&gt;name&lt;/code&gt; value in the &lt;code&gt;[lib]&lt;/code&gt; section (which defaults to the name of the package). For binaries, it's simply the name of the binary generated by cargo.&lt;/p&gt; 
&lt;p&gt;When using &lt;code&gt;maturin build&lt;/code&gt; and &lt;code&gt;maturin develop&lt;/code&gt; commands, you can compile a performance-optimized program by adding the &lt;code&gt;-r&lt;/code&gt; or &lt;code&gt;--release&lt;/code&gt; flag.&lt;/p&gt; 
&lt;h2&gt;Python packaging basics&lt;/h2&gt; 
&lt;p&gt;Python packages come in two formats: A built form called wheel and source distributions (sdist), both of which are archives. A wheel can be compatible with any python version, interpreter (cpython and pypy, mainly), operating system and hardware architecture (for pure python wheels), can be limited to a specific platform and architecture (e.g. when using ctypes or cffi) or to a specific python interpreter and version on a specific architecture and operating system (e.g. with pyo3).&lt;/p&gt; 
&lt;p&gt;When using &lt;code&gt;pip install&lt;/code&gt; on a package, pip tries to find a matching wheel and install that. If it doesn't find one, it downloads the source distribution and builds a wheel for the current platform, which requires the right compilers to be installed. Installing a wheel is much faster than installing a source distribution as building wheels is generally slow.&lt;/p&gt; 
&lt;p&gt;When you publish a package to be installable with &lt;code&gt;pip install&lt;/code&gt;, you upload it to &lt;a href="https://pypi.org/"&gt;pypi&lt;/a&gt;, the official package repository. For testing, you can use &lt;a href="https://test.pypi.org/"&gt;test pypi&lt;/a&gt; instead, which you can use with &lt;code&gt;pip install --index-url https://test.pypi.org/simple/&lt;/code&gt;. Note that for &lt;a href="https://raw.githubusercontent.com/PyO3/maturin/main/#manylinux-and-auditwheel"&gt;publishing for linux&lt;/a&gt;, you need to use the manylinux docker container or zig, while for publishing from your repository you can use the &lt;a href="https://github.com/PyO3/maturin-action"&gt;PyO3/maturin-action&lt;/a&gt; github action.&lt;/p&gt; 
&lt;h2&gt;Mixed rust/python projects&lt;/h2&gt; 
&lt;p&gt;To create a mixed rust/python project, create a folder with your module name (i.e. &lt;code&gt;lib.name&lt;/code&gt; in Cargo.toml) next to your Cargo.toml and add your python sources there:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;my-project
├── Cargo.toml
├── my_project
│&amp;nbsp;&amp;nbsp; ├── __init__.py
│&amp;nbsp;&amp;nbsp; └── bar.py
├── pyproject.toml
├── README.md
└── src
 &amp;nbsp;&amp;nbsp; └── lib.rs
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can specify a different python source directory in &lt;code&gt;pyproject.toml&lt;/code&gt; by setting &lt;code&gt;tool.maturin.python-source&lt;/code&gt;, for example&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;pyproject.toml&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;[tool.maturin]
python-source = "python"
module-name = "my_project._lib_name"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;then the project structure would look like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;my-project
├── Cargo.toml
├── python
│   └── my_project
│       ├── __init__.py
│       └── bar.py
├── pyproject.toml
├── README.md
└── src
 &amp;nbsp;&amp;nbsp; └── lib.rs
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;This structure is recommended to avoid &lt;a href="https://github.com/PyO3/maturin/issues/490"&gt;a common &lt;code&gt;ImportError&lt;/code&gt; pitfall&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;maturin will add the native extension as a module in your python folder. When using develop, maturin will copy the native library and for cffi also the glue code to your python folder. You should add those files to your gitignore.&lt;/p&gt; 
&lt;p&gt;With cffi you can do &lt;code&gt;from .my_project import lib&lt;/code&gt; and then use &lt;code&gt;lib.my_native_function&lt;/code&gt;, with pyo3 you can directly &lt;code&gt;from .my_project import my_native_function&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Example layout with pyo3 after &lt;code&gt;maturin develop&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;my-project
├── Cargo.toml
├── my_project
│&amp;nbsp;&amp;nbsp; ├── __init__.py
│&amp;nbsp;&amp;nbsp; ├── bar.py
│&amp;nbsp;&amp;nbsp; └── _lib_name.cpython-36m-x86_64-linux-gnu.so
├── README.md
└── src
 &amp;nbsp;&amp;nbsp; └── lib.rs
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When doing this also be sure to set the module name in your code to match the last part of &lt;code&gt;module-name&lt;/code&gt; (don't include the package path):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;#[pymodule]
#[pyo3(name="_lib_name")]
fn my_lib_name(m: &amp;amp;Bound&amp;lt;'_, PyModule&amp;gt;) -&amp;gt; PyResult&amp;lt;()&amp;gt; {
    m.add_class::&amp;lt;MyPythonRustClass&amp;gt;()?;
    Ok(())
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Python metadata&lt;/h2&gt; 
&lt;p&gt;maturin supports &lt;a href="https://www.python.org/dev/peps/pep-0621/"&gt;PEP 621&lt;/a&gt;, you can specify python package metadata in &lt;code&gt;pyproject.toml&lt;/code&gt;. maturin merges metadata from &lt;code&gt;Cargo.toml&lt;/code&gt; and &lt;code&gt;pyproject.toml&lt;/code&gt;, &lt;code&gt;pyproject.toml&lt;/code&gt; takes precedence over &lt;code&gt;Cargo.toml&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;To specify python dependencies, add a list &lt;code&gt;dependencies&lt;/code&gt; in a &lt;code&gt;[project]&lt;/code&gt; section in the &lt;code&gt;pyproject.toml&lt;/code&gt;. This list is equivalent to &lt;code&gt;install_requires&lt;/code&gt; in setuptools:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;[project]
name = "my-project"
dependencies = ["flask~=1.1.0", "toml&amp;gt;=0.10.2,&amp;lt;0.11.0"]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can add so called console scripts, which are shell commands that execute some function in your program in the &lt;code&gt;[project.scripts]&lt;/code&gt; section. The keys are the script names while the values are the path to the function in the format &lt;code&gt;some.module.path:class.function&lt;/code&gt;, where the &lt;code&gt;class&lt;/code&gt; part is optional. The function is called with no arguments. Example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;[project.scripts]
get_42 = "my_project:DummyClass.get_42"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also specify &lt;a href="https://pypi.org/classifiers/"&gt;trove classifiers&lt;/a&gt; in your &lt;code&gt;pyproject.toml&lt;/code&gt; under &lt;code&gt;project.classifiers&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;[project]
name = "my-project"
classifiers = ["Programming Language :: Python"]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Source distribution&lt;/h2&gt; 
&lt;p&gt;maturin supports building through &lt;code&gt;pyproject.toml&lt;/code&gt;. To use it, create a &lt;code&gt;pyproject.toml&lt;/code&gt; next to your &lt;code&gt;Cargo.toml&lt;/code&gt; with the following content:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;[build-system]
requires = ["maturin&amp;gt;=1.0,&amp;lt;2.0"]
build-backend = "maturin"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If a &lt;code&gt;pyproject.toml&lt;/code&gt; with a &lt;code&gt;[build-system]&lt;/code&gt; entry is present, maturin can build a source distribution of your package when &lt;code&gt;--sdist&lt;/code&gt; is specified. The source distribution will contain the same files as &lt;code&gt;cargo package&lt;/code&gt;. To only build a source distribution, pass &lt;code&gt;--interpreter&lt;/code&gt; without any values.&lt;/p&gt; 
&lt;p&gt;You can then e.g. install your package with &lt;code&gt;pip install .&lt;/code&gt;. With &lt;code&gt;pip install . -v&lt;/code&gt; you can see the output of cargo and maturin.&lt;/p&gt; 
&lt;p&gt;You can use the options &lt;code&gt;compatibility&lt;/code&gt;, &lt;code&gt;skip-auditwheel&lt;/code&gt;, &lt;code&gt;bindings&lt;/code&gt;, &lt;code&gt;strip&lt;/code&gt; and common Cargo build options such as &lt;code&gt;features&lt;/code&gt; under &lt;code&gt;[tool.maturin]&lt;/code&gt; the same way you would when running maturin directly. The &lt;code&gt;bindings&lt;/code&gt; key is required for cffi and bin projects as those can't be automatically detected. Currently, all builds are in release mode (see &lt;a href="https://discuss.python.org/t/pep-517-debug-vs-release-builds/1924"&gt;this thread&lt;/a&gt; for details).&lt;/p&gt; 
&lt;p&gt;For a non-manylinux build with cffi bindings you could use the following:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;[build-system]
requires = ["maturin&amp;gt;=1.0,&amp;lt;2.0"]
build-backend = "maturin"

[tool.maturin]
bindings = "cffi"
compatibility = "linux"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;code&gt;manylinux&lt;/code&gt; option is also accepted as an alias of &lt;code&gt;compatibility&lt;/code&gt; for backward compatibility with old version of maturin.&lt;/p&gt; 
&lt;p&gt;To include arbitrary files in the sdist for use during compilation specify &lt;code&gt;include&lt;/code&gt; as an array of &lt;code&gt;path&lt;/code&gt; globs with &lt;code&gt;format&lt;/code&gt; set to &lt;code&gt;sdist&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;[tool.maturin]
include = [{ path = "path/**/*", format = "sdist" }]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;There's a &lt;code&gt;maturin sdist&lt;/code&gt; command for only building a source distribution as workaround for &lt;a href="https://github.com/pypa/pip/issues/6041"&gt;pypa/pip#6041&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Manylinux and auditwheel&lt;/h2&gt; 
&lt;p&gt;For portability reasons, native python modules on linux must only dynamically link a set of very few libraries which are installed basically everywhere, hence the name manylinux. The pypa offers special docker images and a tool called &lt;a href="https://github.com/pypa/auditwheel/"&gt;auditwheel&lt;/a&gt; to ensure compliance with the &lt;a href="https://peps.python.org/pep-0599/#the-manylinux2014-policy"&gt;manylinux rules&lt;/a&gt;. If you want to publish widely usable wheels for linux pypi, &lt;strong&gt;you need to use a manylinux docker image or build with zig&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;The Rust compiler since version 1.64 &lt;a href="https://blog.rust-lang.org/2022/08/01/Increasing-glibc-kernel-requirements.html"&gt;requires at least glibc 2.17&lt;/a&gt;, so you need to use at least manylinux2014. For publishing, we recommend enforcing the same manylinux version as the image with the manylinux flag, e.g. use &lt;code&gt;--manylinux 2014&lt;/code&gt; if you are building in &lt;code&gt;quay.io/pypa/manylinux2014_x86_64&lt;/code&gt;. The &lt;a href="https://github.com/PyO3/maturin-action"&gt;PyO3/maturin-action&lt;/a&gt; github action already takes care of this if you set e.g. &lt;code&gt;manylinux: 2014&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;maturin contains a reimplementation of auditwheel automatically checks the generated library and gives the wheel the proper platform tag. If your system's glibc is too new or you link other shared libraries, it will assign the &lt;code&gt;linux&lt;/code&gt; tag. You can also manually disable those checks and directly use native linux target with &lt;code&gt;--manylinux off&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;For full manylinux compliance you need to compile in a CentOS docker container. The &lt;a href="https://ghcr.io/pyo3/maturin"&gt;pyo3/maturin&lt;/a&gt; image is based on the manylinux2014 image, and passes arguments to the &lt;code&gt;maturin&lt;/code&gt; binary. You can use it like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;docker run --rm -v $(pwd):/io ghcr.io/pyo3/maturin build --release  # or other maturin arguments
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that this image is very basic and only contains python, maturin and stable rust. If you need additional tools, you can run commands inside the manylinux container. See &lt;a href="https://github.com/konstin/complex-manylinux-maturin-docker"&gt;konstin/complex-manylinux-maturin-docker&lt;/a&gt; for a small educational example or &lt;a href="https://github.com/nanoporetech/fast-ctc-decode/raw/b226ea0f2b2f4f474eff47349703d57d2ea4801b/.github/workflows/publish.yml"&gt;nanoporetech/fast-ctc-decode&lt;/a&gt; for a real world setup.&lt;/p&gt; 
&lt;p&gt;maturin itself is manylinux compliant when compiled for the musl target.&lt;/p&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/agg-python-bindings"&gt;agg-python-bindings&lt;/a&gt; - A Python Library that binds to Asciinema Agg terminal record renderer and Avt terminal emulator&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/apache/arrow-ballista-python"&gt;ballista-python&lt;/a&gt; - A Python library that binds to Apache Arrow distributed query engine Ballista&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/shenxiangzhuang/bleuscore"&gt;bleuscore&lt;/a&gt; - A BLEU score calculation library, written in pure Rust&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/john-parton/chardetng-py"&gt;chardetng-py&lt;/a&gt; - Python binding for the chardetng character encoding detector.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sfu-db/connector-x/tree/main/connectorx-python"&gt;connector-x&lt;/a&gt; - ConnectorX enables you to load data from databases into Python in the fastest and most memory efficient way&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/apache/arrow-datafusion-python"&gt;datafusion-python&lt;/a&gt; - a Python library that binds to Apache Arrow in-memory query engine DataFusion&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/delta-io/delta-rs/tree/main/python"&gt;deltalake-python&lt;/a&gt; - Native Delta Lake Python binding based on delta-rs with Pandas integration&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/apache/incubator-opendal/tree/main/bindings/python"&gt;opendal&lt;/a&gt; - OpenDAL Python Binding to access data freely&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ijl/orjson"&gt;orjson&lt;/a&gt; - A fast, correct JSON library for Python&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pola-rs/polars/tree/master/py-polars"&gt;polars&lt;/a&gt; - Fast multi-threaded DataFrame library in Rust | Python | Node.js&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pydantic/pydantic-core"&gt;pydantic-core&lt;/a&gt; - Core validation logic for pydantic written in Rust&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/milesgranger/pyrus-cramjam"&gt;pyrus-cramjam&lt;/a&gt; - Thin Python wrapper to de/compression algorithms in Rust&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kitao/pyxel"&gt;pyxel&lt;/a&gt; - A retro game engine for Python&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/roapi/roapi"&gt;roapi&lt;/a&gt; - ROAPI automatically spins up read-only APIs for static datasets without requiring you to write a single line of code&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sansyrox/robyn"&gt;robyn&lt;/a&gt; - A fast and extensible async python web server with a Rust runtime&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/charliermarsh/ruff"&gt;ruff&lt;/a&gt; - An extremely fast Python linter, written in Rust&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/0x676e67/rnet"&gt;rnet&lt;/a&gt; - Asynchronous Python HTTP Client with Black Magic&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rahmadafandi/rustpy-xlsxwriter"&gt;rustpy-xlsxwriter&lt;/a&gt;: A high-performance Python library for generating Excel files, utilizing the &lt;a href="https://github.com/jmcnamara/rust_xlsxwriter"&gt;rust_xlsxwriter&lt;/a&gt; crate for efficient data handling.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/quickwit-oss/tantivy-py"&gt;tantivy-py&lt;/a&gt; - Python bindings for Tantivy&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/clflushopt/tpchgen-rs/tree/main/tpchgen-cli"&gt;tpchgen-cli&lt;/a&gt; - Python CLI binding for &lt;code&gt;tpchgen&lt;/code&gt;, a blazing fast TPC-H benchmark data generator built in pure Rust with zero dependencies.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/samuelcolvin/watchfiles"&gt;watchfiles&lt;/a&gt; - Simple, modern and high performance file watching and code reload in python&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/webonnx/wonnx/tree/master/wonnx-py"&gt;wonnx&lt;/a&gt; - Wonnx is a GPU-accelerated ONNX inference run-time written 100% in Rust&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Everyone is welcomed to contribute to maturin! There are many ways to support the project, such as:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;help maturin users with issues on GitHub and Gitter&lt;/li&gt; 
 &lt;li&gt;improve documentation&lt;/li&gt; 
 &lt;li&gt;write features and bugfixes&lt;/li&gt; 
 &lt;li&gt;publish blogs and examples of how to use maturin&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Our &lt;a href="https://github.com/PyO3/maturin/raw/main/guide/src/contributing.md"&gt;contributing notes&lt;/a&gt; have more resources if you wish to volunteer time for maturin and are searching where to start.&lt;/p&gt; 
&lt;p&gt;If you don't have time to contribute yourself but still wish to support the project's future success, some of our maintainers have GitHub sponsorship pages:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sponsors/messense"&gt;messense&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Licensed under either of:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Apache License, Version 2.0, (&lt;a href="https://github.com/PyO3/maturin/raw/main/license-apache"&gt;LICENSE-APACHE&lt;/a&gt; or &lt;a href="http://www.apache.org/licenses/LICENSE-2.0"&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;MIT license (&lt;a href="https://github.com/PyO3/maturin/raw/main/license-mit"&gt;LICENSE-MIT&lt;/a&gt; or &lt;a href="http://opensource.org/licenses/MIT"&gt;http://opensource.org/licenses/MIT&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;at your option.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>solana-labs/solana</title>
      <link>https://github.com/solana-labs/solana</link>
      <description>&lt;p&gt;Web-Scale Blockchain for fast, secure, scalable, decentralized apps and marketplaces.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;PLEASE READ: This repo is now a public archive&lt;/h1&gt; 
&lt;p&gt;This repo still exists in archived form, feel free to fork any reference implementations it still contains.&lt;/p&gt; 
&lt;p&gt;See Agave, the Solana validator implementation from Anza: &lt;a href="https://github.com/anza-xyz/agave"&gt;https://github.com/anza-xyz/agave&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p align="center"&gt; &lt;a href="https://solana.com"&gt; &lt;img alt="Solana" src="https://i.imgur.com/IKyzQ6T.png" width="250" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;a href="https://crates.io/crates/solana-core"&gt;&lt;img src="https://img.shields.io/crates/v/solana-core.svg?sanitize=true" alt="Solana crate" /&gt;&lt;/a&gt; &lt;a href="https://docs.rs/solana-core"&gt;&lt;img src="https://docs.rs/solana-core/badge.svg?sanitize=true" alt="Solana documentation" /&gt;&lt;/a&gt; &lt;a href="https://buildkite.com/solana-labs/solana/builds?branch=master"&gt;&lt;img src="https://badge.buildkite.com/8cc350de251d61483db98bdfc895b9ea0ac8ffa4a32ee850ed.svg?branch=master" alt="Build status" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/solana-labs/solana"&gt;&lt;img src="https://codecov.io/gh/solana-labs/solana/branch/master/graph/badge.svg?sanitize=true" alt="codecov" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Building&lt;/h1&gt; 
&lt;h2&gt;&lt;strong&gt;1. Install rustc, cargo and rustfmt.&lt;/strong&gt;&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ curl https://sh.rustup.rs -sSf | sh
$ source $HOME/.cargo/env
$ rustup component add rustfmt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When building the master branch, please make sure you are using the latest stable rust version by running:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ rustup update
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When building a specific release branch, you should check the rust version in &lt;code&gt;ci/rust-version.sh&lt;/code&gt; and if necessary, install that version by running:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ rustup install VERSION
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that if this is not the latest rust version on your machine, cargo commands may require an &lt;a href="https://rust-lang.github.io/rustup/overrides.html"&gt;override&lt;/a&gt; in order to use the correct version.&lt;/p&gt; 
&lt;p&gt;On Linux systems you may need to install libssl-dev, pkg-config, zlib1g-dev, protobuf etc.&lt;/p&gt; 
&lt;p&gt;On Ubuntu:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ sudo apt-get update
$ sudo apt-get install libssl-dev libudev-dev pkg-config zlib1g-dev llvm clang cmake make libprotobuf-dev protobuf-compiler
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;On Fedora:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ sudo dnf install openssl-devel systemd-devel pkg-config zlib-devel llvm clang cmake make protobuf-devel protobuf-compiler perl-core
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;&lt;strong&gt;2. Download the source code.&lt;/strong&gt;&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ git clone https://github.com/solana-labs/solana.git
$ cd solana
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;&lt;strong&gt;3. Build.&lt;/strong&gt;&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ ./cargo build
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;Testing&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;Run the test suite:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ ./cargo test
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Starting a local testnet&lt;/h3&gt; 
&lt;p&gt;Start your own testnet locally, instructions are in the &lt;a href="https://docs.solanalabs.com/clusters/benchmark"&gt;online docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Accessing the remote development cluster&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;devnet&lt;/code&gt; - stable public cluster for development accessible via devnet.solana.com. Runs 24/7. Learn more about the &lt;a href="https://docs.solanalabs.com/clusters"&gt;public clusters&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Benchmarking&lt;/h1&gt; 
&lt;p&gt;First, install the nightly build of rustc. &lt;code&gt;cargo bench&lt;/code&gt; requires the use of the unstable features only available in the nightly build.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ rustup install nightly
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run the benchmarks:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ cargo +nightly bench
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;Release Process&lt;/h1&gt; 
&lt;p&gt;The release process for this project is described &lt;a href="https://raw.githubusercontent.com/solana-labs/solana/master/RELEASE.md"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Code coverage&lt;/h1&gt; 
&lt;p&gt;To generate code coverage statistics:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ scripts/coverage.sh
$ open target/cov/lcov-local/index.html
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Why coverage? While most see coverage as a code quality metric, we see it primarily as a developer productivity metric. When a developer makes a change to the codebase, presumably it's a &lt;em&gt;solution&lt;/em&gt; to some problem. Our unit-test suite is how we encode the set of &lt;em&gt;problems&lt;/em&gt; the codebase solves. Running the test suite should indicate that your change didn't &lt;em&gt;infringe&lt;/em&gt; on anyone else's solutions. Adding a test &lt;em&gt;protects&lt;/em&gt; your solution from future changes. Say you don't understand why a line of code exists, try deleting it and running the unit-tests. The nearest test failure should tell you what problem was solved by that code. If no test fails, go ahead and submit a Pull Request that asks, "what problem is solved by this code?" On the other hand, if a test does fail and you can think of a better way to solve the same problem, a Pull Request with your solution would most certainly be welcome! Likewise, if rewriting a test can better communicate what code it's protecting, please send us that patch!&lt;/p&gt; 
&lt;h1&gt;Disclaimer&lt;/h1&gt; 
&lt;p&gt;All claims, content, designs, algorithms, estimates, roadmaps, specifications, and performance measurements described in this project are done with the Solana Labs, Inc. (“SL”) good faith efforts. It is up to the reader to check and validate their accuracy and truthfulness. Furthermore, nothing in this project constitutes a solicitation for investment.&lt;/p&gt; 
&lt;p&gt;Any content produced by SL or developer resources that SL provides are for educational and inspirational purposes only. SL does not encourage, induce or sanction the deployment, integration or use of any such applications (including the code comprising the Solana blockchain protocol) in violation of applicable laws or regulations and hereby prohibits any such deployment, integration or use. This includes the use of any such applications by the reader (a) in violation of export control or sanctions laws of the United States or any other applicable jurisdiction, (b) if the reader is located in or ordinarily resident in a country or territory subject to comprehensive sanctions administered by the U.S. Office of Foreign Assets Control (OFAC), or (c) if the reader is or is working on behalf of a Specially Designated National (SDN) or a person subject to similar blocking or denied party prohibitions.&lt;/p&gt; 
&lt;p&gt;The reader should be aware that U.S. export control and sanctions laws prohibit U.S. persons (and other persons that are subject to such laws) from transacting with persons in certain countries and territories or that are on the SDN list. Accordingly, there is a risk to individuals that other persons using any of the code contained in this repo, or a derivation thereof, may be sanctioned persons and that transactions with such persons would be a violation of U.S. export controls and sanctions law.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>aws/amazon-q-developer-cli</title>
      <link>https://github.com/aws/amazon-q-developer-cli</link>
      <description>&lt;p&gt;✨ Agentic chat experience in your terminal. Build applications using natural language.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Amazon Q CLI&lt;/h1&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;macOS&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;DMG&lt;/strong&gt;: &lt;a href="https://desktop-release.q.us-east-1.amazonaws.com/latest/Amazon%20Q.dmg"&gt;Download now&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;HomeBrew&lt;/strong&gt;: &lt;code&gt;brew install --cask amazon-q &lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Linux&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/command-line-installing.html#command-line-installing-ubuntu"&gt;Ubuntu/Debian&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/command-line-installing.html#command-line-installing-appimage"&gt;AppImage&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/command-line-installing.html#command-line-installing-alternative-linux"&gt;Alternative Linux builds&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Thank you so much for considering to contribute to Amazon Q.&lt;/p&gt; 
&lt;p&gt;Before getting started, see our &lt;a href="https://raw.githubusercontent.com/aws/amazon-q-developer-cli/main/CONTRIBUTING.md#security-issue-notifications"&gt;contributing docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;MacOS 
  &lt;ul&gt; 
   &lt;li&gt;Xcode 13 or later&lt;/li&gt; 
   &lt;li&gt;Brew&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;1. Clone repo&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;git clone https://github.com/aws/amazon-q-developer-cli.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2. Install the Rust toolchain using &lt;a href="https://rustup.rs"&gt;Rustup&lt;/a&gt;:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
rustup default stable
rustup toolchain install nightly
cargo install typos-cli
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;3. Develop locally&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;To compile and run: &lt;code&gt;cargo run --bin chat_cli&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;To run tests: &lt;code&gt;cargo test&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;To run lints: &lt;code&gt;cargo clippy&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;To format rust files: &lt;code&gt;cargo +nightly fmt&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;To run subcommands: &lt;code&gt;cargo run --bin chat_cli -- {subcommand}&lt;/code&gt;. 
  &lt;ul&gt; 
   &lt;li&gt;Login would then be: &lt;code&gt;cargo run --bin chat_cli -- login&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Project Layout&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aws/amazon-q-developer-cli/main/crates/chat-cli/"&gt;&lt;code&gt;chat_cli&lt;/code&gt;&lt;/a&gt; - the &lt;code&gt;q&lt;/code&gt; CLI, allows users to interface with Amazon Q Developer from the command line&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aws/amazon-q-developer-cli/main/scripts/"&gt;&lt;code&gt;scripts/&lt;/code&gt;&lt;/a&gt; - Contains ops and build related scripts&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aws/amazon-q-developer-cli/main/crates/"&gt;&lt;code&gt;crates/&lt;/code&gt;&lt;/a&gt; - Contains all rust crates&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/aws/amazon-q-developer-cli/main/docs/"&gt;&lt;code&gt;docs/&lt;/code&gt;&lt;/a&gt; - Contains technical documentation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;p&gt;For security related concerns, see &lt;a href="https://raw.githubusercontent.com/aws/amazon-q-developer-cli/main/SECURITY.md"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Licensing&lt;/h2&gt; 
&lt;p&gt;This repo is dual licensed under MIT and Apache 2.0 licenses.&lt;/p&gt; 
&lt;p&gt;Those licenses can be found &lt;a href="https://raw.githubusercontent.com/aws/amazon-q-developer-cli/main/LICENSE.MIT"&gt;here&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/aws/amazon-q-developer-cli/main/LICENSE.APACHE"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;“Amazon Web Services” and all related marks, including logos, graphic designs, and service names, are trademarks or trade dress of AWS in the U.S. and other countries. AWS’s trademarks and trade dress may not be used in connection with any product or service that is not AWS’s, in any manner that is likely to cause confusion among customers, or in any manner that disparages or discredits AWS.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>rerun-io/rerun</title>
      <link>https://github.com/rerun-io/rerun</link>
      <description>&lt;p&gt;Visualize streams of multimodal data. Free, fast, easy to use, and simple to integrate. Built in Rust.&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; &lt;a href="https://www.rerun.io/"&gt; &lt;img alt="banner" src="https://user-images.githubusercontent.com/1148717/218142418-1d320929-6b7a-486e-8277-fbeef2432529.png" /&gt; &lt;/a&gt; &lt;/h1&gt; 
&lt;h1 align="center"&gt; &lt;a href="https://pypi.org/project/rerun-sdk/"&gt; &lt;img alt="PyPi" src="https://img.shields.io/pypi/v/rerun-sdk.svg?sanitize=true" /&gt; &lt;/a&gt; &lt;a href="https://crates.io/crates/rerun"&gt; &lt;img alt="crates.io" src="https://img.shields.io/crates/v/rerun.svg?sanitize=true" /&gt; &lt;/a&gt; &lt;a href="https://github.com/rerun-io/rerun/raw/main/LICENSE-MIT"&gt; &lt;img alt="MIT" src="https://img.shields.io/badge/license-MIT-blue.svg?sanitize=true" /&gt; &lt;/a&gt; &lt;a href="https://github.com/rerun-io/rerun/raw/main/LICENSE-APACHE"&gt; &lt;img alt="Apache" src="https://img.shields.io/badge/license-Apache-blue.svg?sanitize=true" /&gt; &lt;/a&gt; &lt;a href="https://discord.gg/Gcm8BbTaAj"&gt; &lt;img alt="Rerun Discord" src="https://img.shields.io/discord/1062300748202921994?label=Rerun%20Discord" /&gt; &lt;/a&gt; &lt;/h1&gt; 
&lt;h1&gt;Time-aware multimodal data stack and visualizations&lt;/h1&gt; 
&lt;p&gt;Rerun is building the multimodal data stack to model, ingest, store, query and view robotics-style data. It's used in areas like robotics, spatial and embodied AI, generative media, industrial processing, simulation, security, and health.&lt;/p&gt; 
&lt;p&gt;Rerun is easy to use! Use the Rerun SDK (available for C++, Python and Rust) to log data like images, tensors, point clouds, and text. Logs are streamed to the Rerun Viewer for live visualization or to file for later use. You can also query the logged data through &lt;a href="https://rerun.io/docs/howto/dataframe-api"&gt;our dataframe API&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/rerun-io/rerun/main/#getting-started"&gt;Get started&lt;/a&gt; in minutes – no account needed.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.rerun.io/viewer"&gt;Run the Rerun Viewer in your browser&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.rerun.io/docs/getting-started/what-is-rerun"&gt;Read about what Rerun is and who it is for&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;A short taste&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-py"&gt;import rerun as rr  # pip install rerun-sdk

rr.init("rerun_example_app")

rr.spawn()  # Spawn a child process with a viewer and connect
# rr.save("recording.rrd")  # Stream all logs to disk
# rr.connect_grpc()  # Connect to a remote viewer

# Associate subsequent data with 42 on the “frame” timeline
rr.set_time("frame", sequence=42)

# Log colored 3D points to the entity at `path/to/points`
rr.log("path/to/points", rr.Points3D(positions, colors=colors))
…
&lt;/code&gt;&lt;/pre&gt; 
&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;img src="https://static.rerun.io/opf_screenshot/bee51040cba93c0bae62ef6c57fa703704012a41/full.png" alt="" /&gt; 
  &lt;source media="(max-width: 480px)" srcset="https://static.rerun.io/opf_screenshot/bee51040cba93c0bae62ef6c57fa703704012a41/480w.png" /&gt; 
  &lt;source media="(max-width: 768px)" srcset="https://static.rerun.io/opf_screenshot/bee51040cba93c0bae62ef6c57fa703704012a41/768w.png" /&gt; 
  &lt;source media="(max-width: 1024px)" srcset="https://static.rerun.io/opf_screenshot/bee51040cba93c0bae62ef6c57fa703704012a41/1024w.png" /&gt; 
  &lt;source media="(max-width: 1200px)" srcset="https://static.rerun.io/opf_screenshot/bee51040cba93c0bae62ef6c57fa703704012a41/1200w.png" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.rerun.io/docs/getting-started/quick-start/cpp"&gt;&lt;strong&gt;C++&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.rerun.io/docs/getting-started/quick-start/python"&gt;&lt;strong&gt;Python&lt;/strong&gt;&lt;/a&gt;: &lt;code&gt;pip install rerun-sdk&lt;/code&gt; or on &lt;a href="https://github.com/conda-forge/rerun-sdk-feedstock"&gt;&lt;code&gt;conda&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.rerun.io/docs/getting-started/quick-start/rust"&gt;&lt;strong&gt;Rust&lt;/strong&gt;&lt;/a&gt;: &lt;code&gt;cargo add rerun&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Installing the Rerun Viewer binary&lt;/h3&gt; 
&lt;p&gt;To stream log data over the network or load our &lt;code&gt;.rrd&lt;/code&gt; data files you also need the &lt;code&gt;rerun&lt;/code&gt; binary. It can be installed with &lt;code&gt;pip install rerun-sdk&lt;/code&gt; or with &lt;code&gt;cargo install rerun-cli --locked --features nasm&lt;/code&gt; (see note below). Note that only the Python SDK comes bundled with the Viewer whereas C++ &amp;amp; Rust always rely on a separate install.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: the &lt;code&gt;nasm&lt;/code&gt; Cargo feature requires the &lt;a href="https://github.com/netwide-assembler/nasm"&gt;&lt;code&gt;nasm&lt;/code&gt;&lt;/a&gt; CLI to be installed and available in your path. Alternatively, you may skip enabling this feature, but this may result in inferior video decoding performance.&lt;/p&gt; 
&lt;p&gt;You should now be able to run &lt;code&gt;rerun --help&lt;/code&gt; in any terminal.&lt;/p&gt; 
&lt;h3&gt;Documentation&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;📚 &lt;a href="http://rerun.io/docs"&gt;High-level docs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;⏃ &lt;a href="https://www.rerun.io/docs/reference/types"&gt;Loggable Types&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;⚙️ &lt;a href="http://rerun.io/examples"&gt;Examples&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;📖 &lt;a href="https://raw.githubusercontent.com/rerun-io/rerun/main/docs/snippets/INDEX.md"&gt;Code snippets&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;🌊 &lt;a href="https://ref.rerun.io/docs/cpp"&gt;C++ API docs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;🐍 &lt;a href="https://ref.rerun.io/docs/python"&gt;Python API docs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;🦀 &lt;a href="https://docs.rs/rerun/"&gt;Rust API docs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;⁉️ &lt;a href="https://www.rerun.io/docs/getting-started/troubleshooting"&gt;Troubleshooting&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Status&lt;/h2&gt; 
&lt;p&gt;We are in active development. There are many features we want to add, and the API is still evolving. &lt;em&gt;Expect breaking changes!&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;Some shortcomings:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rerun-io/rerun/issues/7115"&gt;The viewer slows down when there are too many entities&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rerun-io/rerun/issues/1611"&gt;We don't support transparency yet&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;The data you want to visualize must fit in RAM 
  &lt;ul&gt; 
   &lt;li&gt;See &lt;a href="https://www.rerun.io/docs/howto/limit-ram"&gt;https://www.rerun.io/docs/howto/limit-ram&lt;/a&gt; for how to bound memory use.&lt;/li&gt; 
   &lt;li&gt;We plan on having a disk-based data store some time in the future.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rerun-io/rerun/issues/1136"&gt;Multi-million point clouds can be slow&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;What is Rerun for?&lt;/h2&gt; 
&lt;p&gt;Rerun is built to help you understand and improve complex processes that include rich multimodal data, like 2D, 3D, text, time series, tensors, etc. It is used in many industries, including robotics, simulation, computer vision, or anything that involves a lot of sensors or other signals that evolve over time.&lt;/p&gt; 
&lt;h3&gt;Example use case&lt;/h3&gt; 
&lt;p&gt;Say you're building a vacuum cleaning robot and it keeps running into walls. Why is it doing that? You need some tool to debug it, but a normal debugger isn't gonna be helpful. Similarly, just logging text won't be very helpful either. The robot may log "Going through doorway" but that won't explain why it thinks the wall is a door.&lt;/p&gt; 
&lt;p&gt;What you need is a visual and temporal debugger, that can log all the different representations of the world the robots holds in its little head, such as:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;RGB camera feed&lt;/li&gt; 
 &lt;li&gt;depth images&lt;/li&gt; 
 &lt;li&gt;lidar scan&lt;/li&gt; 
 &lt;li&gt;segmentation image (how the robot interprets what it sees)&lt;/li&gt; 
 &lt;li&gt;its 3D map of the apartment&lt;/li&gt; 
 &lt;li&gt;all the objects the robot has detected (or thinks it has detected), as 3D shapes in the 3D map&lt;/li&gt; 
 &lt;li&gt;its confidence in its prediction&lt;/li&gt; 
 &lt;li&gt;etc&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You also want to see how all these streams of data evolve over time so you can go back and pinpoint exactly what went wrong, when and why.&lt;/p&gt; 
&lt;p&gt;Maybe it turns out that a glare from the sun hit one of the sensors in the wrong way, confusing the segmentation network leading to bad object detection. Or maybe it was a bug in the lidar scanning code. Or maybe the robot thought it was somewhere else in the apartment, because its odometry was broken. Or it could be one of a thousand other things. Rerun will help you find out!&lt;/p&gt; 
&lt;p&gt;But seeing the world from the point of the view of the robot is not just for debugging - it will also give you ideas on how to improve the algorithms, new test cases to set up, or datasets to collect. It will also let you explain the brains of the robot to your colleagues, boss, and customers. And so on. Seeing is believing, and an image is worth a thousand words, and multimodal temporal logging is worth a thousand images :)&lt;/p&gt; 
&lt;p&gt;While seeing and understanding your data is core to making progress in robotics, there is one more thing: You can also use the data you collected for visualization to create new datasets for training and evaluating the models and algorithms that run on your robot. Rerun provides query APIs to make it easy to extract clean datasets from your recording for exactly that purpose.&lt;/p&gt; 
&lt;p&gt;Of course, Rerun is useful for much more than just robots. Any time you have any form of sensors, or 2D or 3D state evolving over time, Rerun is a great tool.&lt;/p&gt; 
&lt;h2&gt;Business model&lt;/h2&gt; 
&lt;p&gt;Rerun uses an open-core model. Everything in this repository will stay open source and free (both as in beer and as in freedom).&lt;/p&gt; 
&lt;p&gt;We are also building a commercial data platform. Right now that is only available for a few select design partners. &lt;a href="https://rerun.io/pricing"&gt;Click here if you're interested&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The Rerun open source project targets the needs of individual developers. The commercial product targets the needs specific to teams that build and run computer vision and robotics products.&lt;/p&gt; 
&lt;h2&gt;How to cite Rerun&lt;/h2&gt; 
&lt;p&gt;When using Rerun in your research, please cite it to acknowledge its contribution to your work. This can be done by including a reference to Rerun in the software or methods section of your paper.&lt;/p&gt; 
&lt;p&gt;Suggested citation format:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@software{RerunSDK,
  title = {Rerun: A Visualization SDK for Multimodal Data},
  author = {{Rerun Development Team}},
  url = {https://www.rerun.io},
  version = {insert version number},
  date = {insert date of usage},
  year = {2024},
  publisher = {{Rerun Technologies AB}},
  address = {Online},
  note = {Available from https://www.rerun.io/ and https://github.com/rerun-io/rerun}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Please replace "insert version number" with the version of Rerun you used and "insert date of usage" with the date(s) you used the tool in your research. This citation format helps ensure that Rerun's development team receives appropriate credit for their work and facilitates the tool's discovery by other researchers.&lt;/p&gt; 
&lt;h1&gt;Development&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rerun-io/rerun/main/ARCHITECTURE.md"&gt;&lt;code&gt;ARCHITECTURE.md&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rerun-io/rerun/main/CODE_OF_CONDUCT.md"&gt;&lt;code&gt;CODE_OF_CONDUCT.md&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rerun-io/rerun/main/CODE_STYLE.md"&gt;&lt;code&gt;CODE_STYLE.md&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rerun-io/rerun/main/CONTRIBUTING.md"&gt;&lt;code&gt;CONTRIBUTING.md&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rerun-io/rerun/main/BUILD.md"&gt;&lt;code&gt;BUILD.md&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rerun-io/rerun/main/rerun_py/README.md"&gt;&lt;code&gt;rerun_py/README.md&lt;/code&gt;&lt;/a&gt; - instructions for Python SDK&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rerun-io/rerun/main/rerun_cpp/README.md"&gt;&lt;code&gt;rerun_cpp/README.md&lt;/code&gt;&lt;/a&gt; - instructions for C++ SDK&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installing a pre-release Python SDK&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Download the correct &lt;code&gt;.whl&lt;/code&gt; from &lt;a href="https://github.com/rerun-io/rerun/releases"&gt;GitHub Releases&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;pip install rerun_sdk&amp;lt;…&amp;gt;.whl&lt;/code&gt; (replace &lt;code&gt;&amp;lt;…&amp;gt;&lt;/code&gt; with the actual filename)&lt;/li&gt; 
 &lt;li&gt;Test it: &lt;code&gt;rerun --version&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt;</description>
    </item>
    
    <item>
      <title>ironcalc/IronCalc</title>
      <link>https://github.com/ironcalc/IronCalc</link>
      <description>&lt;p&gt;Main engine of the IronCalc ecosystem&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;IronCalc&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/ironcalc/IronCalc/raw/main/LICENSE-MIT"&gt;&lt;img src="https://img.shields.io/badge/license-MIT-blue.svg?sanitize=true" alt="MIT licensed" /&gt;&lt;/a&gt; &lt;a href="https://github.com/ironcalc/IronCalc/raw/main/LICENSE-Apache-2.0"&gt;&lt;img src="https://img.shields.io/badge/License-Apache_2.0-blue.svg?sanitize=true" alt="Apache 2.0 licensed" /&gt;&lt;/a&gt; &lt;a href="https://github.com/ironcalc/IronCalc/actions/workflows/rust-build-test.yaml?query=workflow%3ARust+branch%3Amain"&gt;&lt;img src="https://github.com/ironcalc/ironcalc/actions/workflows/rust-build-test.yaml/badge.svg?sanitize=true" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/ironcalc/IronCalc"&gt;&lt;img src="https://codecov.io/gh/ironcalc/IronCalc/graph/badge.svg?token=ASJX12CHNR" alt="Code coverage" /&gt;&lt;/a&gt; &lt;a href="https://docs.rs/ironcalc"&gt;&lt;img src="https://img.shields.io/docsrs/ironcalc?logo=rust&amp;amp;style=flat-square" alt="docs-badge" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/zZYWfh3RHJ"&gt;&lt;img src="https://img.shields.io/discord/1206947691058171904.svg?logo=discord&amp;amp;style=flat-square" alt="Discord chat" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;IronCalc is a new, modern, work-in-progress spreadsheet engine and set of tools to work with spreadsheets in diverse settings.&lt;/p&gt; 
&lt;p&gt;This repository contains the main engine and the xlsx reader and writer.&lt;/p&gt; 
&lt;p&gt;Programmed in Rust, you will be able to use it from a variety of programming languages like Python, JavaScript (wasm), nodejs and possibly R, Julia or Go.&lt;/p&gt; 
&lt;p&gt;We will build different &lt;em&gt;skins&lt;/em&gt;: in the terminal, as a desktop application or use it in your own web application.&lt;/p&gt; 
&lt;h1&gt;Docker&lt;/h1&gt; 
&lt;p&gt;If you have docker installed just run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker compose up --build
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;head over to &lt;a href="http://localhost:2080"&gt;http://localhost:2080&lt;/a&gt; to test the application.&lt;/p&gt; 
&lt;h1&gt;Building&lt;/h1&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cargo build --release
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;Testing, linting and code coverage&lt;/h1&gt; 
&lt;p&gt;Test are run automatically and test coverage can always be found in &lt;a href="https://codecov.io/gh/ironcalc/IronCalc"&gt;codecov&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;If you want to run the tests yourself:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make tests
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that this runs unit tests, integration tests, linter tests and formatting tests.&lt;/p&gt; 
&lt;p&gt;If you want to run the code coverage yourself:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make coverage
cd target/coverage/html/
python -m http.server
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;API Documentation&lt;/h1&gt; 
&lt;p&gt;Documentation is published at: &lt;a href="https://docs.rs/ironcalc/latest/ironcalc/"&gt;https://docs.rs/ironcalc/latest/ironcalc/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;It might be generated locally&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ make docs
$ cd target/doc
$ python -m http.server
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;And visit &lt;a href="http://0.0.0.0:8000/ironcalc/"&gt;http://0.0.0.0:8000/ironcalc/&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Simple example&lt;/h1&gt; 
&lt;p&gt;Add the dependency to &lt;code&gt;Cargo.toml&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;[dependencies]
ironcalc = { git = "https://github.com/ironcalc/IronCalc", version = "0.5"}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;And then use this code in &lt;code&gt;main.rs&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;use ironcalc::{
    base::{expressions::utils::number_to_column, Model},
    export::save_to_xlsx,
};

fn main() -&amp;gt; Result&amp;lt;(), Box&amp;lt;dyn std::error::Error&amp;gt;&amp;gt; {
    let mut model = Model::new_empty("hello-calc.xlsx", "en", "UTC")?;
    // Adds a square of numbers in the first sheet
    for row in 1..100 {
        for column in 1..100 {
            let value = row * column;
            model.set_user_input(0, row, column, format!("{}", value));
        }
    }
    // Adds a new sheet
    model.add_sheet("Calculation")?;
    // column 100 is CV
    let last_column = number_to_column(100).unwrap();
    let formula = format!("=SUM(Sheet1!A1:{}100)", last_column);
    model.set_user_input(1, 1, 1, formula);

    // evaluates
    model.evaluate();

    // saves to disk
    save_to_xlsx(&amp;amp;model, "hello-calc.xlsx")?;
    Ok(())
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See more examples in the &lt;code&gt;examples&lt;/code&gt; folder of the xlsx crate.&lt;/p&gt; 
&lt;h1&gt;ROADMAP&lt;/h1&gt; 
&lt;p&gt;See &lt;a href="https://github.com/ironcalc"&gt;https://github.com/ironcalc&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Early testing&lt;/h1&gt; 
&lt;p&gt;An early preview of the technology running entirely in your browser:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://app.ironcalc.com"&gt;https://app.ironcalc.com&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Collaborators needed!. Call to action&lt;/h1&gt; 
&lt;p&gt;We don't have a vibrant community just yet. This is the very stages of the project. But if you are passionate about code with high standards and no compromises, if you are looking for a project with high impact, if you are interested in a better, more open infrastructure for spreadsheets, whether you are a developer (rust, python, TypeScript, electron/tauri/anything else native app, React, you name it), a designer, an Excel power user who wants features, a business looking to integrate a MIT/Apache licensed spreadsheet in your own SaaS application join us!&lt;/p&gt; 
&lt;p&gt;The best place to start will be to join or &lt;a href="https://discord.gg/zZYWfh3RHJ"&gt;discord channel&lt;/a&gt; or send us an email at &lt;a href="mailto:hello@ironcalc.com"&gt;hello@ironcalc.com&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Many have said it better before me:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Folks wanted for hazardous journey. Low wages, bitter cold, long hours of complete darkness. Safe return doubtful. Honour and recognition in event of success.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h1&gt;License&lt;/h1&gt; 
&lt;p&gt;Licensed under either of&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ironcalc/IronCalc/main/LICENSE-MIT"&gt;MIT license&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ironcalc/IronCalc/main/LICENSE-Apache-2.0"&gt;Apache license, version 2.0&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;at your option.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>fish-shell/fish-shell</title>
      <link>https://github.com/fish-shell/fish-shell</link>
      <description>&lt;p&gt;The user-friendly command line shell.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;.. |Cirrus CI| image:: &lt;a href="https://api.cirrus-ci.com/github/fish-shell/fish-shell.svg?branch=master"&gt;https://api.cirrus-ci.com/github/fish-shell/fish-shell.svg?branch=master&lt;/a&gt; :target: &lt;a href="https://cirrus-ci.com/github/fish-shell/fish-shell"&gt;https://cirrus-ci.com/github/fish-shell/fish-shell&lt;/a&gt; :alt: Cirrus CI Build Status&lt;/p&gt; 
&lt;h1&gt;&lt;code&gt;fish &amp;lt;https://fishshell.com/&amp;gt;&lt;/code&gt;__ - the friendly interactive shell |Build Status| |Cirrus CI|&lt;/h1&gt; 
&lt;p&gt;fish is a smart and user-friendly command line shell for macOS, Linux, and the rest of the family. fish includes features like syntax highlighting, autosuggest-as-you-type, and fancy tab completions that just work, with no configuration required.&lt;/p&gt; 
&lt;p&gt;For downloads, screenshots and more, go to &lt;a href="https://fishshell.com/"&gt;https://fishshell.com/&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;fish generally works like other shells, like bash or zsh. A few important differences can be found at &lt;a href="https://fishshell.com/docs/current/tutorial.html"&gt;https://fishshell.com/docs/current/tutorial.html&lt;/a&gt; by searching for the magic phrase “unlike other shells”.&lt;/p&gt; 
&lt;p&gt;Detailed user documentation is available by running &lt;code&gt;help&lt;/code&gt; within fish, and also at &lt;a href="https://fishshell.com/docs/current/index.html"&gt;https://fishshell.com/docs/current/index.html&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Getting fish&lt;/h2&gt; 
&lt;p&gt;macOS&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;
fish can be installed:

-  using `Homebrew &amp;lt;http://brew.sh/&amp;gt;`__: ``brew install fish``
-  using `MacPorts &amp;lt;https://www.macports.org/&amp;gt;`__:
   ``sudo port install fish``
-  using the `installer from fishshell.com &amp;lt;https://fishshell.com/&amp;gt;`__
-  as a `standalone app from fishshell.com &amp;lt;https://fishshell.com/&amp;gt;`__

Note: The minimum supported macOS version is 10.10 "Yosemite".

Packages for Linux
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Packages for Debian, Fedora, openSUSE, and Red Hat Enterprise Linux/CentOS are available from the &lt;code&gt;openSUSE Build Service &amp;lt;https://software.opensuse.org/download.html?project=shells%3Afish&amp;amp;package=fish&amp;gt;&lt;/code&gt;__.&lt;/p&gt; 
&lt;p&gt;Packages for Ubuntu are available from the &lt;code&gt;fish PPA &amp;lt;https://launchpad.net/~fish-shell/+archive/ubuntu/release-4&amp;gt;&lt;/code&gt;__, and can be installed using the following commands:&lt;/p&gt; 
&lt;p&gt;::&lt;/p&gt; 
&lt;p&gt;sudo apt-add-repository ppa:fish-shell/release-4 sudo apt update sudo apt install fish&lt;/p&gt; 
&lt;p&gt;Instructions for other distributions may be found at &lt;code&gt;fishshell.com &amp;lt;https://fishshell.com&amp;gt;&lt;/code&gt;__.&lt;/p&gt; 
&lt;p&gt;Windows&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;
-  On Windows 10/11, fish can be installed under the WSL Windows Subsystem
   for Linux with the instructions for the appropriate distribution
   listed above under “Packages for Linux”, or from source with the
   instructions below.
-  Fish can also be installed on all versions of Windows using
   `Cygwin &amp;lt;https://cygwin.com/&amp;gt;`__ or `MSYS2 &amp;lt;https://github.com/Berrysoft/fish-msys2&amp;gt;`__.

Building from source
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If packages are not available for your platform, GPG-signed tarballs are available from &lt;code&gt;fishshell.com &amp;lt;https://fishshell.com/&amp;gt;&lt;/code&gt;__ and &lt;code&gt;fish-shell on GitHub &amp;lt;https://github.com/fish-shell/fish-shell/releases&amp;gt;&lt;/code&gt;__. See the &lt;code&gt;Building &amp;lt;#building&amp;gt;&lt;/code&gt;_ section for instructions.&lt;/p&gt; 
&lt;h2&gt;Running fish&lt;/h2&gt; 
&lt;p&gt;Once installed, run &lt;code&gt;fish&lt;/code&gt; from your current shell to try fish out!&lt;/p&gt; 
&lt;p&gt;Dependencies&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;
Running fish requires:

-  some common \*nix system utilities (currently ``mktemp``), in
   addition to the basic POSIX utilities (``cat``, ``cut``, ``dirname``,
   ``ls``, ``mkdir``, ``mkfifo``, ``rm``, ``sh``, ``sort``, ``tee``, ``tr``,
   ``uname`` and ``sed`` at least, but the full coreutils plus ``find`` and
   ``awk`` is preferred)

The following optional features also have specific requirements:

-  builtin commands that have the ``--help`` option or print usage
   messages require ``man`` for display
-  automated completion generation from manual pages requires Python 3.5+
-  the ``fish_config`` web configuration tool requires Python 3.5+ and a web browser
-  the :ref:`alt-o &amp;lt;shared-binds-alt-o&amp;gt;` binding requires the ``file`` program.
-  system clipboard integration (with the default Ctrl-V and Ctrl-X
   bindings) require either the ``xsel``, ``xclip``,
   ``wl-copy``/``wl-paste`` or ``pbcopy``/``pbpaste`` utilities
-  full completions for ``yarn`` and ``npm`` require the
   ``all-the-package-names`` NPM module
-  ``colorls`` is used, if installed, to add color when running ``ls`` on platforms
   that do not have color support (such as OpenBSD)

Building
--------

Dependencies
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Compiling fish requires:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Rust (version 1.85 or later)&lt;/li&gt; 
 &lt;li&gt;CMake (version 3.15 or later)&lt;/li&gt; 
 &lt;li&gt;a C compiler (for system feature detection and the test helper binary)&lt;/li&gt; 
 &lt;li&gt;PCRE2 (headers and libraries) - optional, this will be downloaded if missing&lt;/li&gt; 
 &lt;li&gt;gettext (only the msgfmt tool) - optional, for translation support&lt;/li&gt; 
 &lt;li&gt;an Internet connection, as other dependencies will be downloaded automatically&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Sphinx is also optionally required to build the documentation from a cloned git repository.&lt;/p&gt; 
&lt;p&gt;Additionally, running the full test suite requires diff, git, Python 3.5+, pexpect, less, tmux and wget.&lt;/p&gt; 
&lt;p&gt;Building from source with CMake&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;
Rather than building from source, consider using a packaged build for your platform. Using the
steps below makes fish difficult to uninstall or upgrade. Release packages are available from the
links above, and up-to-date `development builds of fish are available for many platforms
&amp;lt;https://github.com/fish-shell/fish-shell/wiki/Development-builds&amp;gt;`__

To install into ``/usr/local``, run:

.. code:: shell

   mkdir build; cd build
   cmake ..
   cmake --build .
   sudo cmake --install .

The install directory can be changed using the
``-DCMAKE_INSTALL_PREFIX`` parameter for ``cmake``.

CMake Build options
~~~~~~~~~~~~~~~~~~~

In addition to the normal CMake build options (like ``CMAKE_INSTALL_PREFIX``), fish's CMake build has some other options available to customize it.

- Rust_COMPILER=path - the path to rustc. If not set, cmake will check $PATH and ~/.cargo/bin
- Rust_CARGO=path - the path to cargo. If not set, cmake will check $PATH and ~/.cargo/bin
- Rust_CARGO_TARGET=target - the target to pass to cargo. Set this for cross-compilation.
- BUILD_DOCS=ON|OFF - whether to build the documentation. This is automatically set to OFF when Sphinx isn't installed.
- INSTALL_DOCS=ON|OFF - whether to install the docs. This is automatically set to on when BUILD_DOCS is or prebuilt documentation is available (like when building in-tree from a tarball).
- FISH_USE_SYSTEM_PCRE2=ON|OFF - whether to use an installed pcre2. This is normally autodetected.
- MAC_CODESIGN_ID=String|OFF - the codesign ID to use on Mac, or "OFF" to disable codesigning.
- WITH_GETTEXT=ON|OFF - whether to include translations.
- extra_functionsdir, extra_completionsdir and extra_confdir - to compile in an additional directory to be searched for functions, completions and configuration snippets

Building fish with Cargo
~~~~~~~~~~~~~~~~~~~~~~~~

You can also build fish with Cargo.
This example uses `uv &amp;lt;https://github.com/astral-sh/uv&amp;gt;`__ to install Sphinx (which is used for man-pages and ``--help`` options).
You can also install Sphinx another way and drop the ``uv run --no-managed-python`` prefix.

.. code:: shell

    git clone https://github.com/fish-shell/fish-shell
    cd fish-shell

    # Optional: check out a specific version rather than building the latest
    # development version.
    git checkout "$(git for-each-ref refs/tags/ | awk '$2 == "tag" { print $3 }' | tail -1)"

    uv run --no-managed-python \
        cargo install --path .

This will place standalone binaries in ``~/.cargo/bin/``, but you can move them wherever you want.

To disable translations, disable the ``localize-messages`` feature by passing ``--no-default-features --features=embed-data`` to cargo.

You can also link this build statically (but not against glibc) and move it to other computers.

Here are the remaining advantages of a full installation, as currently done by CMake:

- Man pages like ``fish(1)`` installed in standard locations, easily accessible from outside fish.
- A local copy of the HTML documentation, typically accessed via the ``help`` fish function.
  In Cargo builds, ``help`` will redirect to `&amp;lt;https://fishshell.com/docs/current/&amp;gt;`__
- Ability to use our CMake options extra_functionsdir, extra_completionsdir and extra_confdir,
  (also recorded in ``$PREFIX/share/pkgconfig/fish.pc``)
  which are used by some package managers to house third-party completions.
  Regardless of build system, fish uses ``$XDG_DATA_DIRS/{vendor_completion.d,vendor_conf.d,vendor_functions.d}``.

Contributing Changes to the Code
--------------------------------

See the `Guide for Developers &amp;lt;CONTRIBUTING.rst&amp;gt;`__.

Contact Us
----------

Questions, comments, rants and raves can be posted to the official fish
mailing list at https://lists.sourceforge.net/lists/listinfo/fish-users
or join us on our `matrix
channel &amp;lt;https://matrix.to/#/#fish-shell:matrix.org&amp;gt;`__. Or use the `fish tag
on Unix &amp;amp; Linux Stackexchange &amp;lt;https://unix.stackexchange.com/questions/tagged/fish&amp;gt;`__.
There is also a fish tag on Stackoverflow, but it is typically a poor fit.

Found a bug? Have an awesome idea? Please `open an
issue &amp;lt;https://github.com/fish-shell/fish-shell/issues/new&amp;gt;`__.

.. |Build Status| image:: https://github.com/fish-shell/fish-shell/workflows/make%20test/badge.svg
   :target: https://github.com/fish-shell/fish-shell/actions
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>supabase/etl</title>
      <link>https://github.com/supabase/etl</link>
      <description>&lt;p&gt;Stream your Postgres data anywhere in real-time. Simple Rust building blocks for change data capture (CDC) pipelines.&lt;/p&gt;&lt;hr&gt;&lt;br /&gt; 
&lt;p align="center"&gt; &lt;a href="https://supabase.com"&gt; 
  &lt;picture&gt; 
   &lt;img alt="ETL by Supabase" width="100%" src="https://raw.githubusercontent.com/supabase/etl/main/docs/assets/etl-logo-extended.png" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;/p&gt;
&lt;h1 align="center"&gt;ETL&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/supabase/etl/actions/workflows/ci.yml"&gt; &lt;img alt="CI" src="https://github.com/supabase/etl/actions/workflows/ci.yml/badge.svg?branch=main" /&gt; &lt;/a&gt; &lt;a href="https://coveralls.io/github/supabase/etl?branch=main"&gt; &lt;img alt="Coverage Status" src="https://coveralls.io/repos/github/supabase/etl/badge.svg?branch=main" /&gt; &lt;/a&gt; &lt;a href="https://github.com/supabase/etl/actions/workflows/docs.yml"&gt; &lt;img alt="Docs" src="https://github.com/supabase/etl/actions/workflows/docs.yml/badge.svg?branch=main" /&gt; &lt;/a&gt; &lt;a href="https://github.com/supabase/etl/actions/workflows/docker-build.yml"&gt; &lt;img alt="Docker Build" src="https://github.com/supabase/etl/actions/workflows/docker-build.yml/badge.svg?branch=main" /&gt; &lt;/a&gt; &lt;a href="https://github.com/supabase/etl/actions/workflows/audit.yml"&gt; &lt;img alt="Security Audit" src="https://github.com/supabase/etl/actions/workflows/audit.yml/badge.svg?branch=main" /&gt; &lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/supabase/etl/main/LICENSE"&gt; &lt;img alt="License" src="https://img.shields.io/badge/License-Apache_2.0-blue.svg?sanitize=true" /&gt; &lt;/a&gt; &lt;br /&gt; Build real-time Postgres replication applications in Rust &lt;br /&gt; &lt;a href="https://supabase.github.io/etl"&gt;&lt;strong&gt;Documentation&lt;/strong&gt;&lt;/a&gt; · &lt;a href="https://github.com/supabase/etl/tree/main/etl-examples"&gt;&lt;strong&gt;Examples&lt;/strong&gt;&lt;/a&gt; · &lt;a href="https://github.com/supabase/etl/issues"&gt;&lt;strong&gt;Issues&lt;/strong&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;ETL is a Rust framework by &lt;a href="https://supabase.com"&gt;Supabase&lt;/a&gt; for building high‑performance, real‑time data replication apps on Postgres. It sits on top of Postgres &lt;a href="https://www.postgresql.org/docs/current/protocol-logical-replication.html"&gt;logical replication&lt;/a&gt; and gives you a clean, Rust‑native API for streaming changes to your own destinations.&lt;/p&gt; 
&lt;h2&gt;Highlights&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Real‑time replication&lt;/strong&gt;: stream changes in real time to your own destinations.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;High performance&lt;/strong&gt;: configurable batching and parallelism to maximize throughput.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Fault-tolerant&lt;/strong&gt;: robust error handling and retry logic built-in.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Extensible&lt;/strong&gt;: implement your own custom destinations and state/schema stores.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Rust native&lt;/strong&gt;: typed and ergonomic Rust API.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Requirements&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;PostgreSQL Version:&lt;/strong&gt; ETL officially supports and tests against &lt;strong&gt;PostgreSQL 14, 15, 16, and 17&lt;/strong&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;PostgreSQL 15+&lt;/strong&gt; is recommended for access to advanced publication features including: 
  &lt;ul&gt; 
   &lt;li&gt;Column-level filtering&lt;/li&gt; 
   &lt;li&gt;Row-level filtering with &lt;code&gt;WHERE&lt;/code&gt; clauses&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;FOR ALL TABLES IN SCHEMA&lt;/code&gt; syntax&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For detailed configuration instructions, see the &lt;a href="https://supabase.github.io/etl/how-to/configure-postgres/"&gt;Configure Postgres documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Get Started&lt;/h2&gt; 
&lt;p&gt;Install via Git while we prepare for a crates.io release:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;[dependencies]
etl = { git = "https://github.com/supabase/etl" }
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Quick example using the in‑memory destination:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;use etl::{
    config::{BatchConfig, PgConnectionConfig, PipelineConfig, TlsConfig},
    destination::memory::MemoryDestination,
    pipeline::Pipeline,
    store::both::memory::MemoryStore,
};

#[tokio::main]
async fn main() -&amp;gt; Result&amp;lt;(), Box&amp;lt;dyn std::error::Error&amp;gt;&amp;gt; {
    let pg = PgConnectionConfig {
        host: "localhost".into(),
        port: 5432,
        name: "mydb".into(),
        username: "postgres".into(),
        password: Some("password".into()),
        tls: TlsConfig { enabled: false, trusted_root_certs: String::new() },
    };

    let store = MemoryStore::new();
    let destination = MemoryDestination::new();

    let config = PipelineConfig {
        id: 1,
        publication_name: "my_publication".into(),
        pg_connection: pg,
        batch: BatchConfig { max_size: 1000, max_fill_ms: 5000 },
        table_error_retry_delay_ms: 10_000,
        table_error_retry_max_attempts: 5,
        max_table_sync_workers: 4,
    };

    let mut pipeline = Pipeline::new(config, store, destination);
    pipeline.start().await?;
    // pipeline.wait().await?; // Optional: block until completion

    Ok(())
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For tutorials and deeper guidance, see the &lt;a href="https://supabase.github.io/etl"&gt;Documentation&lt;/a&gt; or jump into the &lt;a href="https://raw.githubusercontent.com/supabase/etl/main/etl-examples/README.md"&gt;examples&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Destinations&lt;/h2&gt; 
&lt;p&gt;ETL is designed to be extensible. You can implement your own destinations to send data to any destination you like, however it comes with a few built in destinations:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;BigQuery&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Out-of-the-box destinations are available in the &lt;code&gt;etl-destinations&lt;/code&gt; crate:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;[dependencies]
etl = { git = "https://github.com/supabase/etl" }
etl-destinations = { git = "https://github.com/supabase/etl", features = ["bigquery"] }
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Apache‑2.0. See &lt;code&gt;LICENSE&lt;/code&gt; for details.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p align="center"&gt; Made with ❤️ by the &lt;a href="https://supabase.com"&gt;Supabase&lt;/a&gt; team &lt;/p&gt;</description>
    </item>
    
    <item>
      <title>YaLTeR/niri</title>
      <link>https://github.com/YaLTeR/niri</link>
      <description>&lt;p&gt;A scrollable-tiling Wayland compositor.&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt;&lt;img alt="niri" src="https://github.com/user-attachments/assets/07d05cd0-d5dc-4a28-9a35-51bae8f119a0" /&gt;&lt;/h1&gt; 
&lt;p align="center"&gt;A scrollable-tiling Wayland compositor.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://matrix.to/#/#niri:matrix.org"&gt;&lt;img alt="Matrix" src="https://img.shields.io/badge/matrix-%23niri-blue?logo=matrix" /&gt;&lt;/a&gt; &lt;a href="https://github.com/YaLTeR/niri/raw/main/LICENSE"&gt;&lt;img alt="GitHub License" src="https://img.shields.io/github/license/YaLTeR/niri" /&gt;&lt;/a&gt; &lt;a href="https://github.com/YaLTeR/niri/releases"&gt;&lt;img alt="GitHub Release" src="https://img.shields.io/github/v/release/YaLTeR/niri?logo=github" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://yalter.github.io/niri/Getting-Started.html"&gt;Getting Started&lt;/a&gt; | &lt;a href="https://yalter.github.io/niri/Configuration%3A-Introduction.html"&gt;Configuration&lt;/a&gt; | &lt;a href="https://github.com/YaLTeR/niri/discussions/325"&gt;Setup&amp;nbsp;Showcase&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/535e6530-2f44-4b84-a883-1240a3eee6e9" alt="niri with a few windows open" /&gt;&lt;/p&gt; 
&lt;h2&gt;About&lt;/h2&gt; 
&lt;p&gt;Windows are arranged in columns on an infinite strip going to the right. Opening a new window never causes existing windows to resize.&lt;/p&gt; 
&lt;p&gt;Every monitor has its own separate window strip. Windows can never "overflow" onto an adjacent monitor.&lt;/p&gt; 
&lt;p&gt;Workspaces are dynamic and arranged vertically. Every monitor has an independent set of workspaces, and there's always one empty workspace present all the way down.&lt;/p&gt; 
&lt;p&gt;The workspace arrangement is preserved across disconnecting and connecting monitors where it makes sense. When a monitor disconnects, its workspaces will move to another monitor, but upon reconnection they will move back to the original monitor.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Built from the ground up for scrollable tiling&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://yalter.github.io/niri/Workspaces.html"&gt;Dynamic workspaces&lt;/a&gt; like in GNOME&lt;/li&gt; 
 &lt;li&gt;An &lt;a href="https://github.com/user-attachments/assets/379a5d1f-acdb-4c11-b36c-e85fd91f0995"&gt;Overview&lt;/a&gt; that zooms out workspaces and windows&lt;/li&gt; 
 &lt;li&gt;Built-in screenshot UI&lt;/li&gt; 
 &lt;li&gt;Monitor and window screencasting through xdg-desktop-portal-gnome 
  &lt;ul&gt; 
   &lt;li&gt;You can &lt;a href="https://yalter.github.io/niri/Configuration%3A-Window-Rules.html#block-out-from"&gt;block out&lt;/a&gt; sensitive windows from screencasts&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://yalter.github.io/niri/Screencasting.html#dynamic-screencast-target"&gt;Dynamic cast target&lt;/a&gt; that can change what it shows on the go&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/YaLTeR/niri/assets/1794388/946a910e-9bec-4cd1-a923-4a9421707515"&gt;Touchpad&lt;/a&gt; and &lt;a href="https://github.com/YaLTeR/niri/assets/1794388/8464e65d-4bf2-44fa-8c8e-5883355bd000"&gt;mouse&lt;/a&gt; gestures&lt;/li&gt; 
 &lt;li&gt;Group windows into &lt;a href="https://yalter.github.io/niri/Tabs.html"&gt;tabs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Configurable layout: gaps, borders, struts, window sizes&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://yalter.github.io/niri/Configuration%3A-Layout.html#gradients"&gt;Gradient borders&lt;/a&gt; with Oklab and Oklch support&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/YaLTeR/niri/assets/1794388/ce178da2-af9e-4c51-876f-8709c241d95e"&gt;Animations&lt;/a&gt; with support for &lt;a href="https://github.com/YaLTeR/niri/assets/1794388/27a238d6-0a22-4692-b794-30dc7a626fad"&gt;custom shaders&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Live-reloading config&lt;/li&gt; 
 &lt;li&gt;Works with &lt;a href="https://yalter.github.io/niri/Accessibility.html"&gt;screen readers&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Video Demo&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/YaLTeR/niri/assets/1794388/bce834b0-f205-434e-a027-b373495f9729"&gt;https://github.com/YaLTeR/niri/assets/1794388/bce834b0-f205-434e-a027-b373495f9729&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Also check out this video from Brodie Robertson that showcases a lot of the niri functionality: &lt;a href="https://youtu.be/DeYx2exm04M"&gt;Niri Is My New Favorite Wayland Compositor&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Status&lt;/h2&gt; 
&lt;p&gt;Niri is stable for day-to-day use and does most things expected of a Wayland compositor. Many people are daily-driving niri, and are happy to help in our &lt;a href="https://matrix.to/#/#niri:matrix.org"&gt;Matrix channel&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Give it a try! Follow the instructions on the &lt;a href="https://yalter.github.io/niri/Getting-Started.html"&gt;Getting Started&lt;/a&gt; page. Have your &lt;a href="https://github.com/Alexays/Waybar"&gt;waybar&lt;/a&gt;s and &lt;a href="https://codeberg.org/dnkl/fuzzel"&gt;fuzzel&lt;/a&gt;s ready: niri is not a complete desktop environment. Also check out &lt;a href="https://github.com/Vortriz/awesome-niri"&gt;awesome-niri&lt;/a&gt;, a list of niri-related links and projects.&lt;/p&gt; 
&lt;p&gt;Here are some points you may have questions about:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-monitor&lt;/strong&gt;: yes, a core part of the design from the very start. Mixed DPI works.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Fractional scaling&lt;/strong&gt;: yes, plus all niri UI stays pixel-perfect.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;NVIDIA&lt;/strong&gt;: seems to work fine.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Floating windows&lt;/strong&gt;: yes, starting from niri 25.01.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Input devices&lt;/strong&gt;: niri supports tablets, touchpads, and touchscreens. You can map the tablet to a specific monitor, or use &lt;a href="https://opentabletdriver.net/"&gt;OpenTabletDriver&lt;/a&gt;. We have touchpad gestures, but no touchscreen gestures yet.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Wlr protocols&lt;/strong&gt;: yes, we have most of the important ones like layer-shell, gamma-control, screencopy. You can check on &lt;a href="https://wayland.app"&gt;wayland.app&lt;/a&gt; at the bottom of each protocol's page.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Performance&lt;/strong&gt;: while I run niri on beefy machines, I try to stay conscious of performance. I've seen someone use it fine on an Eee&amp;nbsp;PC&amp;nbsp;900 from&amp;nbsp;2008, of all things.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Xwayland&lt;/strong&gt;: &lt;a href="https://yalter.github.io/niri/Xwayland.html#using-xwayland-satellite"&gt;integrated&lt;/a&gt; via xwayland-satellite starting from niri 25.08.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Media&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://youtu.be/Kmz8ODolnDg?list=PLRdS-n5seLRqrmWDQY4KDqtRMfIwU0U3T"&gt;niri: Making a Wayland compositor in Rust&lt;/a&gt; · &lt;em&gt;December 2024&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;My talk from the 2024 Moscow RustCon about niri, and how I do randomized property testing and profiling, and measure input latency. The talk is in Russian, but I prepared full English subtitles that you can find in YouTube's subtitle language selector.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.trommelspeicher.de/podcast/special_the_developer_behind_niri"&gt;An interview with Ivan, the developer behind Niri&lt;/a&gt; · &lt;em&gt;June 2025&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;An interview by a German tech podcast Das Triumvirat (in English). We talk about niri development and history, and my experience building and maintaining niri.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://lwn.net/Articles/1025866/"&gt;A tour of the niri scrolling-tiling Wayland compositor&lt;/a&gt; · &lt;em&gt;July 2025&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;An LWN article with a nice overview and introduction to niri.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;If you'd like to help with niri, there are plenty of both coding- and non-coding-related ways to do so. See &lt;a href="https://github.com/YaLTeR/niri/raw/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for an overview.&lt;/p&gt; 
&lt;h2&gt;Inspiration&lt;/h2&gt; 
&lt;p&gt;Niri is heavily inspired by &lt;a href="https://github.com/paperwm/PaperWM"&gt;PaperWM&lt;/a&gt; which implements scrollable tiling on top of GNOME Shell.&lt;/p&gt; 
&lt;p&gt;One of the reasons that prompted me to try writing my own compositor is being able to properly separate the monitors. Being a GNOME Shell extension, PaperWM has to work against Shell's global window coordinate space to prevent windows from overflowing.&lt;/p&gt; 
&lt;h2&gt;Tile Scrollably Elsewhere&lt;/h2&gt; 
&lt;p&gt;Here are some other projects which implement a similar workflow:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/paperwm/PaperWM"&gt;PaperWM&lt;/a&gt;: scrollable tiling on top of GNOME Shell.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/peterfajdiga/karousel"&gt;karousel&lt;/a&gt;: scrollable tiling on top of KDE.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dawsers/scroll"&gt;scroll&lt;/a&gt; and &lt;a href="https://spwhitton.name/tech/code/papersway/"&gt;papersway&lt;/a&gt;: scrollable tiling on top of sway/i3.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hyprwm/hyprland-plugins/tree/main/hyprscrolling"&gt;hyprscrolling&lt;/a&gt; and &lt;a href="https://gitlab.com/magus/hyprslidr"&gt;hyprslidr&lt;/a&gt;: scrollable tiling on top of Hyprland.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mogenson/PaperWM.spoon"&gt;PaperWM.spoon&lt;/a&gt;: scrollable tiling on top of macOS.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contact&lt;/h2&gt; 
&lt;p&gt;Our main communication channel is a Matrix chat, feel free to join and ask a question: &lt;a href="https://matrix.to/#/#niri:matrix.org"&gt;https://matrix.to/#/#niri:matrix.org&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;We also have a community Discord server: &lt;a href="https://discord.gg/vT8Sfjy7sx"&gt;https://discord.gg/vT8Sfjy7sx&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>modelcontextprotocol/rust-sdk</title>
      <link>https://github.com/modelcontextprotocol/rust-sdk</link>
      <description>&lt;p&gt;The official Rust SDK for the Model Context Protocol&lt;/p&gt;&lt;hr&gt;&lt;div align="right"&gt; 
 &lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/rust-sdk/main/docs/readme/README.zh-cn.md"&gt;简体中文(待更新)&lt;/a&gt; 
&lt;/div&gt; 
&lt;h1&gt;RMCP&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://crates.io/crates/rmcp"&gt;&lt;img src="https://img.shields.io/crates/v/rmcp" alt="Crates.io Version" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- ![Release status](https://github.com/modelcontextprotocol/rust-sdk/actions/workflows/release.yml/badge.svg) --&gt; 
&lt;!-- [![docs.rs](todo)](todo) --&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/modelcontextprotocol/rust-sdk/main/docs/coverage.svg?sanitize=true" alt="Coverage" /&gt;&lt;/p&gt; 
&lt;p&gt;An official Rust Model Context Protocol SDK implementation with tokio async runtime.&lt;/p&gt; 
&lt;p&gt;This repository contains the following crates:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/rust-sdk/main/crates/rmcp"&gt;rmcp&lt;/a&gt;: The core crate providing the RMCP protocol implementation (If you want to get more information, please visit &lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/rust-sdk/main/crates/rmcp/README.md"&gt;rmcp&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/rust-sdk/main/crates/rmcp-macros"&gt;rmcp-macros&lt;/a&gt;: A procedural macro crate for generating RMCP tool implementations (If you want to get more information, please visit &lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/rust-sdk/main/crates/rmcp-macros/README.md"&gt;rmcp-macros&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;h3&gt;Import the crate&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;rmcp = { version = "0.8.0", features = ["server"] }
## or dev channel
rmcp = { git = "https://github.com/modelcontextprotocol/rust-sdk", branch = "main" }
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Third Dependencies&lt;/h3&gt; 
&lt;p&gt;Basic dependencies:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tokio-rs/tokio"&gt;tokio required&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/serde-rs/serde"&gt;serde required&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Build a Client&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;Start a client&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-rust,"&gt;use rmcp::{ServiceExt, transport::{TokioChildProcess, ConfigureCommandExt}};
use tokio::process::Command;

#[tokio::main]
async fn main() -&amp;gt; Result&amp;lt;(), Box&amp;lt;dyn std::error::Error&amp;gt;&amp;gt; {
    let client = ().serve(TokioChildProcess::new(Command::new("npx").configure(|cmd| {
        cmd.arg("-y").arg("@modelcontextprotocol/server-everything");
    }))?).await?;
    Ok(())
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;Build a Server&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;Build a transport&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-rust,"&gt;use tokio::io::{stdin, stdout};
let transport = (stdin(), stdout());
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Build a service&lt;/summary&gt; 
 &lt;p&gt;You can easily build a service by using &lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/rust-sdk/main/crates/rmcp/src/handler/server.rs"&gt;&lt;code&gt;ServerHandler&lt;/code&gt;&lt;/a&gt; or &lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/rust-sdk/main/crates/rmcp/src/handler/client.rs"&gt;&lt;code&gt;ClientHandler&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-rust,"&gt;let service = common::counter::Counter::new();
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Start the server&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-rust,"&gt;// this call will finish the initialization process
let server = service.serve(transport).await?;
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Interact with the server&lt;/summary&gt; 
 &lt;p&gt;Once the server is initialized, you can send requests or notifications:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-rust,"&gt;// request
let roots = server.list_roots().await?;

// or send notification
server.notify_cancelled(...).await?;
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Waiting for service shutdown&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-rust,"&gt;let quit_reason = server.waiting().await?;
// or cancel it
let quit_reason = server.cancel().await?;
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/rust-sdk/main/examples/README.md"&gt;examples&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;OAuth Support&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/rust-sdk/main/docs/OAUTH_SUPPORT.md"&gt;oauth_support&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;Related Resources&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://spec.modelcontextprotocol.io/specification/2024-11-05/"&gt;MCP Specification&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/modelcontextprotocol/specification/raw/main/schema/2024-11-05/schema.ts"&gt;Schema&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Related Projects&lt;/h2&gt; 
&lt;h3&gt;Extending &lt;code&gt;rmcp&lt;/code&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://gitlab.com/lx-industries/rmcp-actix-web"&gt;rmcp-actix-web&lt;/a&gt; - An &lt;code&gt;actix_web&lt;/code&gt; backend for &lt;code&gt;rmcp&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gitlab.com/lx-industries/rmcp-openapi"&gt;rmcp-openapi&lt;/a&gt; - Transform OpenAPI definition endpoints into MCP tools&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Built with &lt;code&gt;rmcp&lt;/code&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rustfs/rustfs/tree/main/crates/mcp"&gt;rustfs-mcp&lt;/a&gt; - High-performance MCP server providing S3-compatible object storage operations for AI/LLM integration&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jokemanfire/mcp-containerd"&gt;containerd-mcp-server&lt;/a&gt; - A containerd-based MCP server implementation&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gitlab.com/lx-industries/rmcp-openapi/-/tree/main/crates/rmcp-openapi-server"&gt;rmcp-openapi-server&lt;/a&gt; - High-performance MCP server that exposes OpenAPI definition endpoints as MCP tools&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/linw1995/nvim-mcp"&gt;nvim-mcp&lt;/a&gt; - A MCP server to interact with Neovim&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mediar-ai/terminator"&gt;terminator&lt;/a&gt; - AI-powered desktop automation MCP server with cross-platform support and &amp;gt;95% success rate&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/stakpak/agent"&gt;stakpak-agent&lt;/a&gt; - Security-hardened terminal agent for DevOps with MCP over mTLS, streaming, secret tokenization, and async task management&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;h3&gt;Tips for Contributors&lt;/h3&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/rust-sdk/main/docs/CONTRIBUTE.MD"&gt;docs/CONTRIBUTE.MD&lt;/a&gt; to get some tips for contributing.&lt;/p&gt; 
&lt;h3&gt;Using Dev Container&lt;/h3&gt; 
&lt;p&gt;If you want to use dev container, see &lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/rust-sdk/main/docs/DEVCONTAINER.md"&gt;docs/DEVCONTAINER.md&lt;/a&gt; for instructions on using Dev Container for development.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>idootop/open-xiaoai</title>
      <link>https://github.com/idootop/open-xiaoai</link>
      <description>&lt;p&gt;让小爱音箱「听见你的声音」，解锁无限可能。&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Open-XiaoAI&lt;/h1&gt; 
&lt;p&gt;让小爱音箱「听见你的声音」，解锁无限可能。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/idootop/open-xiaoai/main/docs/images/cover.jpg" alt="" /&gt;&lt;/p&gt; 
&lt;h2&gt;简介&lt;/h2&gt; 
&lt;p&gt;2017 年，当全球首款千万级销量的智能音箱诞生时，我们以为触摸到了未来。但很快发现，这些设备被困在「指令-响应」的牢笼里：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;它听得见分贝，却听不懂情感&lt;/li&gt; 
 &lt;li&gt;它能执行命令，却不会主动思考&lt;/li&gt; 
 &lt;li&gt;它有千万用户，却只有一套思维&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;我们曾幻想中的"贾维斯"级人工智能，在现实场景中沦为"天气预报+音乐播放器"。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;真正的智能不应被预设的代码逻辑所束缚，而应像生命体般在交互中进化。&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;在上一个 &lt;a href="https://github.com/idootop/mi-gpt"&gt;MiGPT&lt;/a&gt; 项目中，我们已经实现将 ChatGPT 接入到小爱音箱。&lt;/p&gt; 
&lt;p&gt;这一次 &lt;a href="https://github.com/idootop/open-xiaoai"&gt;Open-XiaoAI&lt;/a&gt; 再次进化，直接接管小爱音箱的“耳朵”和“嘴巴”，&lt;/p&gt; 
&lt;p&gt;通过多模态大模型和 AI Agent，将小爱音箱的潜力完全释放，解锁无限可能。&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;未来由你定义!&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;你的声音 + 小爱音箱 = 无限可能&lt;/h2&gt; 
&lt;p&gt;👉 &lt;a href="https://www.bilibili.com/video/BV1TxJhzvEhz"&gt;小爱音箱接入小智 AI 演示视频&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.bilibili.com/video/BV1TxJhzvEhz"&gt;&lt;img src="https://raw.githubusercontent.com/idootop/open-xiaoai/main/docs/images/xiaozhi.jpg" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;👉 &lt;a href="https://www.bilibili.com/video/BV1YfVUz5EMj"&gt;小爱音箱自定义唤醒词演示视频&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.bilibili.com/video/BV1YfVUz5EMj"&gt;&lt;img src="https://raw.githubusercontent.com/idootop/open-xiaoai/main/docs/images/kws.jpg" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;👉 &lt;a href="https://www.bilibili.com/video/BV1N1421y7qn"&gt;小爱音箱接入 MiGPT 演示视频&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.bilibili.com/video/BV1N1421y7qn"&gt;&lt;img src="https://raw.githubusercontent.com/idootop/open-xiaoai/main/docs/images/migpt.jpg" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;快速开始&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] 本教程仅适用于 &lt;strong&gt;小爱音箱 Pro（LX06）&lt;/strong&gt; 和 &lt;strong&gt;Xiaomi 智能音箱 Pro（OH2P）&lt;/strong&gt; 这两款机型，&lt;strong&gt;其他型号&lt;/strong&gt;的小爱音箱请勿直接使用！🚨&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;本项目由 Client 端 + Server 端两部分组成，你可以按照以下顺序运行该项目：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;刷机更新小爱音箱补丁固件，开启并 SSH 连接到小爱音箱 👉 &lt;a href="https://raw.githubusercontent.com/idootop/open-xiaoai/main/docs/flash.md"&gt;教程&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;在小爱音箱上安装运行 Client 端补丁程序 👉 &lt;a href="https://raw.githubusercontent.com/idootop/open-xiaoai/main/packages/client-rust/README.md"&gt;教程&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;运行以下演示程序，体验小爱音箱的全新能力 ✨ 
  &lt;ul&gt; 
   &lt;li&gt;👉 &lt;a href="https://raw.githubusercontent.com/idootop/open-xiaoai/main/examples/xiaozhi/README.md"&gt;小爱音箱接入小智 AI&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;👉 &lt;a href="https://raw.githubusercontent.com/idootop/open-xiaoai/main/examples/kws/README.md"&gt;小爱音箱自定义唤醒词&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;👉 &lt;a href="https://raw.githubusercontent.com/idootop/open-xiaoai/main/examples/migpt/README.md"&gt;小爱音箱接入 MiGPT（完美版）&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;👉 &lt;a href="https://raw.githubusercontent.com/idootop/open-xiaoai/main/examples/gemini/README.md"&gt;小爱音箱接入 Gemini Live API&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;以上皆为抛砖引玉，你也可以亲手编写自己想要的功能，一切由你定义！&lt;/p&gt; 
&lt;h2&gt;相关项目&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] 技术的意义在于分享与共创。如果你打算或正在使用本项目做些有趣的事情， 欢迎提交 PR 或 issue 分享你的项目和创意。✨&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;如果你不想刷机，或者不是小爱音箱 Pro，下面的项目或许对你有用：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/idootop/mi-gpt"&gt;https://github.com/idootop/mi-gpt&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/idootop/migpt-next"&gt;https://github.com/idootop/migpt-next&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/yihong0618/xiaogpt"&gt;https://github.com/yihong0618/xiaogpt&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hanxi/xiaomusic"&gt;https://github.com/hanxi/xiaomusic&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;参考链接&lt;/h2&gt; 
&lt;p&gt;如果你想要了解更多技术细节，下面的链接可能对你有用：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/yihong0618/gitblog/issues/258"&gt;https://github.com/yihong0618/gitblog/issues/258&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jialeicui/open-lx01"&gt;https://github.com/jialeicui/open-lx01&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/duhow/xiaoai-patch"&gt;https://github.com/duhow/xiaoai-patch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://javabin.cn/2021/xiaoai_fm.html"&gt;https://javabin.cn/2021/xiaoai_fm.html&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://xuanxuanblingbling.github.io/iot/2022/09/16/mi/"&gt;https://xuanxuanblingbling.github.io/iot/2022/09/16/mi/&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;免责声明&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;适用范围&lt;/strong&gt; 本项目为开源非营利项目，仅供学术研究或个人测试用途。严禁用于商业服务、网络攻击、数据窃取、系统破坏等违反《网络安全法》及使用者所在地司法管辖区的法律规定的场景。&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;非官方声明&lt;/strong&gt; 本项目由第三方开发者独立开发，与小米集团及其关联方（下称"权利方"）无任何隶属/合作关系，亦未获其官方授权/认可或技术支持。项目中涉及的商标、固件、云服务的所有权利归属小米集团。若权利方主张权益，使用者应立即主动停止使用并删除本项目。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;继续下载或运行本项目，即表示您已完整阅读并同意&lt;a href="https://raw.githubusercontent.com/idootop/open-xiaoai/main/agreement.md"&gt;用户协议&lt;/a&gt;，否则请立即终止使用并彻底删除本项目。&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/idootop/open-xiaoai/main/LICENSE"&gt;MIT&lt;/a&gt; License © 2024-PRESENT Del Wang&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>vosen/ZLUDA</title>
      <link>https://github.com/vosen/ZLUDA</link>
      <description>&lt;p&gt;CUDA on non-NVIDIA GPUs&lt;/p&gt;&lt;hr&gt;&lt;p&gt;ZLUDA is a drop-in replacement for CUDA on non-NVIDIA GPUs. ZLUDA allows running unmodified CUDA applications using non-NVIDIA GPUs with near-native performance&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;!-- 80x28 104.75x28  62x28--&gt; 
 &lt;p&gt;&lt;a href="https://zluda.readthedocs.io"&gt;&lt;img src="https://img.shields.io/badge/quick start-green?style=for-the-badge&amp;amp;logo=readthedocs&amp;amp;logoColor=white" width="267.5" height="56" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/sg6BNzXuc7"&gt;&lt;img src="https://img.shields.io/badge/Discord-%235865F2.svg?style=for-the-badge&amp;amp;logo=discord&amp;amp;logoColor=white" width="209.5" height="56" /&gt;&lt;/a&gt; &lt;a href="https://vosen.github.io/ZLUDA/"&gt;&lt;img src="https://img.shields.io/badge/news-red?style=for-the-badge&amp;amp;logo=book&amp;amp;logoColor=white" width="124" height="56" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;div&gt;&lt;/div&gt; 
&lt;/div&gt;</description>
    </item>
    
  </channel>
</rss>