<rss version="2.0">
  <channel>
    <title>GitHub All Languages Daily Trending</title>
    <description>Daily Trending of All Languages in GitHub</description>
    <pubDate>Tue, 12 Aug 2025 01:31:10 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>openai/codex</title>
      <link>https://github.com/openai/codex</link>
      <description>&lt;p&gt;Lightweight coding agent that runs in your terminal&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt;OpenAI Codex CLI&lt;/h1&gt; 
&lt;p align="center"&gt;&lt;code&gt;npm i -g @openai/codex&lt;/code&gt;&lt;br /&gt;or &lt;code&gt;brew install codex&lt;/code&gt;&lt;/p&gt; 
&lt;p align="center"&gt;&lt;strong&gt;Codex CLI&lt;/strong&gt; is a coding agent from OpenAI that runs locally on your computer.&lt;br /&gt;If you are looking for the &lt;em&gt;cloud-based agent&lt;/em&gt; from OpenAI, &lt;strong&gt;Codex Web&lt;/strong&gt;, see &lt;a href="https://chatgpt.com/codex"&gt;chatgpt.com/codex&lt;/a&gt;.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/openai/codex/main/.github/codex-cli-splash.png" alt="Codex CLI splash" width="50%" /&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Table of contents&lt;/strong&gt;&lt;/summary&gt; 
 &lt;!-- Begin ToC --&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#quickstart"&gt;Quickstart&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#installing-and-running-codex-cli"&gt;Installing and running Codex CLI&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#using-codex-with-your-chatgpt-plan"&gt;Using Codex with your ChatGPT plan&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#connecting-on-a-headless-machine"&gt;Connecting on a "Headless" Machine&lt;/a&gt; 
     &lt;ul&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#authenticate-locally-and-copy-your-credentials-to-the-headless-machine"&gt;Authenticate locally and copy your credentials to the "headless" machine&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#connecting-through-vps-or-remote"&gt;Connecting through VPS or remote&lt;/a&gt;&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#usage-based-billing-alternative-use-an-openai-api-key"&gt;Usage-based billing alternative: Use an OpenAI API key&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#choosing-codexs-level-of-autonomy"&gt;Choosing Codex's level of autonomy&lt;/a&gt; 
     &lt;ul&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#1-readwrite"&gt;&lt;strong&gt;1. Read/write&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#2-read-only"&gt;&lt;strong&gt;2. Read-only&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#3-advanced-configuration"&gt;&lt;strong&gt;3. Advanced configuration&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#can-i-run-without-any-approvals"&gt;Can I run without ANY approvals?&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#fine-tuning-in-configtoml"&gt;Fine-tuning in &lt;code&gt;config.toml&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#example-prompts"&gt;Example prompts&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#running-with-a-prompt-as-input"&gt;Running with a prompt as input&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#using-open-source-models"&gt;Using Open Source Models&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#platform-sandboxing-details"&gt;Platform sandboxing details&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#experimental-technology-disclaimer"&gt;Experimental technology disclaimer&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#system-requirements"&gt;System requirements&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#cli-reference"&gt;CLI reference&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#memory--project-docs"&gt;Memory &amp;amp; project docs&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#non-interactive--ci-mode"&gt;Non-interactive / CI mode&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#model-context-protocol-mcp"&gt;Model Context Protocol (MCP)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#tracing--verbose-logging"&gt;Tracing / verbose logging&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#dotslash"&gt;DotSlash&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#configuration"&gt;Configuration&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#faq"&gt;FAQ&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#zero-data-retention-zdr-usage"&gt;Zero data retention (ZDR) usage&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#codex-open-source-fund"&gt;Codex open source fund&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#contributing"&gt;Contributing&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#development-workflow"&gt;Development workflow&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#writing-high-impact-code-changes"&gt;Writing high-impact code changes&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#opening-a-pull-request"&gt;Opening a pull request&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#review-process"&gt;Review process&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#community-values"&gt;Community values&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#getting-help"&gt;Getting help&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#contributor-license-agreement-cla"&gt;Contributor license agreement (CLA)&lt;/a&gt; 
     &lt;ul&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#quick-fixes"&gt;Quick fixes&lt;/a&gt;&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#releasing-codex"&gt;Releasing &lt;code&gt;codex&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#security--responsible-ai"&gt;Security &amp;amp; responsible AI&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;!-- End ToC --&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;h3&gt;Installing and running Codex CLI&lt;/h3&gt; 
&lt;p&gt;Install globally with your preferred package manager:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;npm install -g @openai/codex  # Alternatively: `brew install codex`
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then simply run &lt;code&gt;codex&lt;/code&gt; to get started:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;codex
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;You can also go to the &lt;a href="https://github.com/openai/codex/releases/latest"&gt;latest GitHub Release&lt;/a&gt; and download the appropriate binary for your platform.&lt;/summary&gt; 
 &lt;p&gt;Each GitHub Release contains many executables, but in practice, you likely want one of these:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;macOS 
   &lt;ul&gt; 
    &lt;li&gt;Apple Silicon/arm64: &lt;code&gt;codex-aarch64-apple-darwin.tar.gz&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;x86_64 (older Mac hardware): &lt;code&gt;codex-x86_64-apple-darwin.tar.gz&lt;/code&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Linux 
   &lt;ul&gt; 
    &lt;li&gt;x86_64: &lt;code&gt;codex-x86_64-unknown-linux-musl.tar.gz&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;arm64: &lt;code&gt;codex-aarch64-unknown-linux-musl.tar.gz&lt;/code&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;Each archive contains a single entry with the platform baked into the name (e.g., &lt;code&gt;codex-x86_64-unknown-linux-musl&lt;/code&gt;), so you likely want to rename it to &lt;code&gt;codex&lt;/code&gt; after extracting it.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h3&gt;Using Codex with your ChatGPT plan&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/openai/codex/main/.github/codex-cli-login.png" alt="Codex CLI login" width="50%" /&gt; &lt;/p&gt; 
&lt;p&gt;Run &lt;code&gt;codex&lt;/code&gt; and select &lt;strong&gt;Sign in with ChatGPT&lt;/strong&gt;. You'll need a Plus, Pro, or Team ChatGPT account, and will get access to our latest models, including &lt;code&gt;gpt-5&lt;/code&gt;, at no extra cost to your plan. (Enterprise is coming soon.)&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Important: If you've used the Codex CLI before, follow these steps to migrate from usage-based billing with your API key:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Update the CLI and ensure &lt;code&gt;codex --version&lt;/code&gt; is &lt;code&gt;0.20.0&lt;/code&gt; or later&lt;/li&gt; 
  &lt;li&gt;Delete &lt;code&gt;~/.codex/auth.json&lt;/code&gt; (this should be &lt;code&gt;C:\Users\USERNAME\.codex\auth.json&lt;/code&gt; on Windows)&lt;/li&gt; 
  &lt;li&gt;Run &lt;code&gt;codex login&lt;/code&gt; again&lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;If you encounter problems with the login flow, please comment on &lt;a href="https://github.com/openai/codex/issues/1243"&gt;this issue&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Connecting on a "Headless" Machine&lt;/h3&gt; 
&lt;p&gt;Today, the login process entails running a server on &lt;code&gt;localhost:1455&lt;/code&gt;. If you are on a "headless" server, such as a Docker container or are &lt;code&gt;ssh&lt;/code&gt;'d into a remote machine, loading &lt;code&gt;localhost:1455&lt;/code&gt; in the browser on your local machine will not automatically connect to the webserver running on the &lt;em&gt;headless&lt;/em&gt; machine, so you must use one of the following workarounds:&lt;/p&gt; 
&lt;h4&gt;Authenticate locally and copy your credentials to the "headless" machine&lt;/h4&gt; 
&lt;p&gt;The easiest solution is likely to run through the &lt;code&gt;codex login&lt;/code&gt; process on your local machine such that &lt;code&gt;localhost:1455&lt;/code&gt; &lt;em&gt;is&lt;/em&gt; accessible in your web browser. When you complete the authentication process, an &lt;code&gt;auth.json&lt;/code&gt; file should be available at &lt;code&gt;$CODEX_HOME/auth.json&lt;/code&gt; (on Mac/Linux, &lt;code&gt;$CODEX_HOME&lt;/code&gt; defaults to &lt;code&gt;~/.codex&lt;/code&gt; whereas on Windows, it defaults to &lt;code&gt;%USERPROFILE%\.codex&lt;/code&gt;).&lt;/p&gt; 
&lt;p&gt;Because the &lt;code&gt;auth.json&lt;/code&gt; file is not tied to a specific host, once you complete the authentication flow locally, you can copy the &lt;code&gt;$CODEX_HOME/auth.json&lt;/code&gt; file to the headless machine and then &lt;code&gt;codex&lt;/code&gt; should "just work" on that machine. Note to copy a file to a Docker container, you can do:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# substitute MY_CONTAINER with the name or id of your Docker container:
CONTAINER_HOME=$(docker exec MY_CONTAINER printenv HOME)
docker exec MY_CONTAINER mkdir -p "$CONTAINER_HOME/.codex"
docker cp auth.json MY_CONTAINER:"$CONTAINER_HOME/.codex/auth.json"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;whereas if you are &lt;code&gt;ssh&lt;/code&gt;'d into a remote machine, you likely want to use &lt;a href="https://en.wikipedia.org/wiki/Secure_copy_protocol"&gt;&lt;code&gt;scp&lt;/code&gt;&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ssh user@remote 'mkdir -p ~/.codex'
scp ~/.codex/auth.json user@remote:~/.codex/auth.json
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or try this one-liner:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ssh user@remote 'mkdir -p ~/.codex &amp;amp;&amp;amp; cat &amp;gt; ~/.codex/auth.json' &amp;lt; ~/.codex/auth.json
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Connecting through VPS or remote&lt;/h4&gt; 
&lt;p&gt;If you run Codex on a remote machine (VPS/server) without a local browser, the login helper starts a server on &lt;code&gt;localhost:1455&lt;/code&gt; on the remote host. To complete login in your local browser, forward that port to your machine before starting the login flow:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# From your local machine
ssh -L 1455:localhost:1455 &amp;lt;user&amp;gt;@&amp;lt;remote-host&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then, in that SSH session, run &lt;code&gt;codex&lt;/code&gt; and select "Sign in with ChatGPT". When prompted, open the printed URL (it will be &lt;code&gt;http://localhost:1455/...&lt;/code&gt;) in your local browser. The traffic will be tunneled to the remote server.&lt;/p&gt; 
&lt;h3&gt;Usage-based billing alternative: Use an OpenAI API key&lt;/h3&gt; 
&lt;p&gt;If you prefer to pay-as-you-go, you can still authenticate with your OpenAI API key by setting it as an environment variable:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;export OPENAI_API_KEY="your-api-key-here"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Notes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;This command only sets the key for your current terminal session, which we recommend. To set it for all future sessions, you can also add the &lt;code&gt;export&lt;/code&gt; line to your shell's configuration file (e.g., &lt;code&gt;~/.zshrc&lt;/code&gt;).&lt;/li&gt; 
 &lt;li&gt;If you have signed in with ChatGPT, Codex will default to using your ChatGPT credits. If you wish to use your API key, use the &lt;code&gt;/logout&lt;/code&gt; command to clear your ChatGPT authentication.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Choosing Codex's level of autonomy&lt;/h3&gt; 
&lt;p&gt;We always recommend running Codex in its default sandbox that gives you strong guardrails around what the agent can do. The default sandbox prevents it from editing files outside its workspace, or from accessing the network.&lt;/p&gt; 
&lt;p&gt;When you launch Codex in a new folder, it detects whether the folder is version controlled and recommends one of two levels of autonomy:&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;1. Read/write&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Codex can run commands and write files in the workspace without approval.&lt;/li&gt; 
 &lt;li&gt;To write files in other folders, access network, update git or perform other actions protected by the sandbox, Codex will need your permission.&lt;/li&gt; 
 &lt;li&gt;By default, the workspace includes the current directory, as well as temporary directories like &lt;code&gt;/tmp&lt;/code&gt;. You can see what directories are in the workspace with the &lt;code&gt;/status&lt;/code&gt; command. See the docs for how to customize this behavior.&lt;/li&gt; 
 &lt;li&gt;Advanced: You can manually specify this configuration by running &lt;code&gt;codex --sandbox workspace-write --ask-for-approval on-request&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;This is the recommended default for version-controlled folders.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;strong&gt;2. Read-only&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Codex can run read-only commands without approval.&lt;/li&gt; 
 &lt;li&gt;To edit files, access network, or perform other actions protected by the sandbox, Codex will need your permission.&lt;/li&gt; 
 &lt;li&gt;Advanced: You can manually specify this configuration by running &lt;code&gt;codex --sandbox read-only --ask-for-approval on-request&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;This is the recommended default non-version-controlled folders.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;strong&gt;3. Advanced configuration&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;Codex gives you fine-grained control over the sandbox with the &lt;code&gt;--sandbox&lt;/code&gt; option, and over when it requests approval with the &lt;code&gt;--ask-for-approval&lt;/code&gt; option. Run &lt;code&gt;codex help&lt;/code&gt; for more on these options.&lt;/p&gt; 
&lt;h4&gt;Can I run without ANY approvals?&lt;/h4&gt; 
&lt;p&gt;Yes, run codex non-interactively with &lt;code&gt;--ask-for-approval never&lt;/code&gt;. This option works with all &lt;code&gt;--sandbox&lt;/code&gt; options, so you still have full control over Codex's level of autonomy. It will make its best attempt with whatever contrainsts you provide. For example:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Use &lt;code&gt;codex --ask-for-approval never --sandbox read-only&lt;/code&gt; when you are running many agents to answer questions in parallel in the same workspace.&lt;/li&gt; 
 &lt;li&gt;Use &lt;code&gt;codex --ask-for-approval never --sandbox workspace-write&lt;/code&gt; when you want the agent to non-interactively take time to produce the best outcome, with strong guardrails around its behavior.&lt;/li&gt; 
 &lt;li&gt;Use &lt;code&gt;codex --ask-for-approval never --sandbox danger-full-access&lt;/code&gt; to dangerously give the agent full autonomy. Because this disables important safety mechanisms, we recommend against using this unless running Codex in an isolated environment.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Fine-tuning in &lt;code&gt;config.toml&lt;/code&gt;&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# approval mode
approval_policy = "untrusted"
sandbox_mode    = "read-only"

# full-auto mode
approval_policy = "on-request"
sandbox_mode    = "workspace-write"

# Optional: allow network in workspace-write mode
[sandbox_workspace_write]
network_access = true
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also save presets as &lt;strong&gt;profiles&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;[profiles.full_auto]
approval_policy = "on-request"
sandbox_mode    = "workspace-write"

[profiles.readonly_quiet]
approval_policy = "never"
sandbox_mode    = "read-only"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Example prompts&lt;/h3&gt; 
&lt;p&gt;Below are a few bite-size examples you can copy-paste. Replace the text in quotes with your own task. See the &lt;a href="https://github.com/openai/codex/raw/main/codex-cli/examples/prompting_guide.md"&gt;prompting guide&lt;/a&gt; for more tips and usage patterns.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;✨&lt;/th&gt; 
   &lt;th&gt;What you type&lt;/th&gt; 
   &lt;th&gt;What happens&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;1&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;codex "Refactor the Dashboard component to React Hooks"&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Codex rewrites the class component, runs &lt;code&gt;npm test&lt;/code&gt;, and shows the diff.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;2&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;codex "Generate SQL migrations for adding a users table"&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Infers your ORM, creates migration files, and runs them in a sandboxed DB.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;codex "Write unit tests for utils/date.ts"&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Generates tests, executes them, and iterates until they pass.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;4&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;codex "Bulk-rename *.jpeg -&amp;gt; *.jpg with git mv"&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Safely renames files and updates imports/usages.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;codex "Explain what this regex does: ^(?=.*[A-Z]).{8,}$"&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Outputs a step-by-step human explanation.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;6&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;codex "Carefully review this repo, and propose 3 high impact well-scoped PRs"&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Suggests impactful PRs in the current codebase.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;7&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;codex "Look for vulnerabilities and create a security review report"&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Finds and explains security bugs.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Running with a prompt as input&lt;/h2&gt; 
&lt;p&gt;You can also run Codex CLI with a prompt as input:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;codex "explain this codebase to me"
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;codex --full-auto "create the fanciest todo-list app"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;That's it - Codex will scaffold a file, run it inside a sandbox, install any missing dependencies, and show you the live result. Approve the changes and they'll be committed to your working directory.&lt;/p&gt; 
&lt;h2&gt;Using Open Source Models&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Use &lt;code&gt;--profile&lt;/code&gt; to use other models&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;Codex also allows you to use other providers that support the OpenAI Chat Completions (or Responses) API.&lt;/p&gt; 
 &lt;p&gt;To do so, you must first define custom &lt;a href="https://raw.githubusercontent.com/openai/codex/main/config.md#model_providers"&gt;providers&lt;/a&gt; in &lt;code&gt;~/.codex/config.toml&lt;/code&gt;. For example, the provider for a standard Ollama setup would be defined as follows:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-toml"&gt;[model_providers.ollama]
name = "Ollama"
base_url = "http://localhost:11434/v1"
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;The &lt;code&gt;base_url&lt;/code&gt; will have &lt;code&gt;/chat/completions&lt;/code&gt; appended to it to build the full URL for the request.&lt;/p&gt; 
 &lt;p&gt;For providers that also require an &lt;code&gt;Authorization&lt;/code&gt; header of the form &lt;code&gt;Bearer: SECRET&lt;/code&gt;, an &lt;code&gt;env_key&lt;/code&gt; can be specified, which indicates the environment variable to read to use as the value of &lt;code&gt;SECRET&lt;/code&gt; when making a request:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-toml"&gt;[model_providers.openrouter]
name = "OpenRouter"
base_url = "https://openrouter.ai/api/v1"
env_key = "OPENROUTER_API_KEY"
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Providers that speak the Responses API are also supported by adding &lt;code&gt;wire_api = "responses"&lt;/code&gt; as part of the definition. Accessing OpenAI models via Azure is an example of such a provider, though it also requires specifying additional &lt;code&gt;query_params&lt;/code&gt; that need to be appended to the request URL:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-toml"&gt;[model_providers.azure]
name = "Azure"
# Make sure you set the appropriate subdomain for this URL.
base_url = "https://YOUR_PROJECT_NAME.openai.azure.com/openai"
env_key = "AZURE_OPENAI_API_KEY"  # Or "OPENAI_API_KEY", whichever you use.
# Newer versions appear to support the responses API, see https://github.com/openai/codex/pull/1321
query_params = { api-version = "2025-04-01-preview" }
wire_api = "responses"
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Once you have defined a provider you wish to use, you can configure it as your default provider as follows:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-toml"&gt;model_provider = "azure"
&lt;/code&gt;&lt;/pre&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;[!TIP] If you find yourself experimenting with a variety of models and providers, then you likely want to invest in defining a &lt;em&gt;profile&lt;/em&gt; for each configuration like so:&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;pre&gt;&lt;code class="language-toml"&gt;[profiles.o3]
model_provider = "azure"
model = "o3"

[profiles.mistral]
model_provider = "ollama"
model = "mistral"
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;This way, you can specify one command-line argument (.e.g., &lt;code&gt;--profile o3&lt;/code&gt;, &lt;code&gt;--profile mistral&lt;/code&gt;) to override multiple settings together.&lt;/p&gt; 
&lt;/details&gt; 
&lt;p&gt;Codex can run fully locally against an OpenAI-compatible OSS host (like Ollama) using the &lt;code&gt;--oss&lt;/code&gt; flag:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Interactive UI: 
  &lt;ul&gt; 
   &lt;li&gt;codex --oss&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Non-interactive (programmatic) mode: 
  &lt;ul&gt; 
   &lt;li&gt;echo "Refactor utils" | codex exec --oss&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Model selection when using &lt;code&gt;--oss&lt;/code&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;If you omit &lt;code&gt;-m/--model&lt;/code&gt;, Codex defaults to -m gpt-oss:20b and will verify it exists locally (downloading if needed).&lt;/li&gt; 
 &lt;li&gt;To pick a different size, pass one of: 
  &lt;ul&gt; 
   &lt;li&gt;-m "gpt-oss:20b"&lt;/li&gt; 
   &lt;li&gt;-m "gpt-oss:120b"&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Point Codex at your own OSS host:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;By default, &lt;code&gt;--oss&lt;/code&gt; talks to &lt;a href="http://localhost:11434/v1"&gt;http://localhost:11434/v1&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;To use a different host, set one of these environment variables before running Codex: 
  &lt;ul&gt; 
   &lt;li&gt;CODEX_OSS_BASE_URL, for example: 
    &lt;ul&gt; 
     &lt;li&gt;CODEX_OSS_BASE_URL="&lt;a href="http://my-ollama.example.com:11434/v1"&gt;http://my-ollama.example.com:11434/v1&lt;/a&gt;" codex --oss -m gpt-oss:20b&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;or CODEX_OSS_PORT (when the host is localhost): 
    &lt;ul&gt; 
     &lt;li&gt;CODEX_OSS_PORT=11434 codex --oss&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Advanced: you can persist this in your config instead of environment variables by overriding the built-in &lt;code&gt;oss&lt;/code&gt; provider in &lt;code&gt;~/.codex/config.toml&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;[model_providers.oss]
name = "Open Source"
base_url = "http://my-ollama.example.com:11434/v1"
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Platform sandboxing details&lt;/h3&gt; 
&lt;p&gt;The mechanism Codex uses to implement the sandbox policy depends on your OS:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;macOS 12+&lt;/strong&gt; uses &lt;strong&gt;Apple Seatbelt&lt;/strong&gt; and runs commands using &lt;code&gt;sandbox-exec&lt;/code&gt; with a profile (&lt;code&gt;-p&lt;/code&gt;) that corresponds to the &lt;code&gt;--sandbox&lt;/code&gt; that was specified.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Linux&lt;/strong&gt; uses a combination of Landlock/seccomp APIs to enforce the &lt;code&gt;sandbox&lt;/code&gt; configuration.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Note that when running Linux in a containerized environment such as Docker, sandboxing may not work if the host/container configuration does not support the necessary Landlock/seccomp APIs. In such cases, we recommend configuring your Docker container so that it provides the sandbox guarantees you are looking for and then running &lt;code&gt;codex&lt;/code&gt; with &lt;code&gt;--sandbox danger-full-access&lt;/code&gt; (or, more simply, the &lt;code&gt;--dangerously-bypass-approvals-and-sandbox&lt;/code&gt; flag) within your container.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Experimental technology disclaimer&lt;/h2&gt; 
&lt;p&gt;Codex CLI is an experimental project under active development. It is not yet stable, may contain bugs, incomplete features, or undergo breaking changes. We're building it in the open with the community and welcome:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Bug reports&lt;/li&gt; 
 &lt;li&gt;Feature requests&lt;/li&gt; 
 &lt;li&gt;Pull requests&lt;/li&gt; 
 &lt;li&gt;Good vibes&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Help us improve by filing issues or submitting PRs (see the section below for how to contribute)!&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;System requirements&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Requirement&lt;/th&gt; 
   &lt;th&gt;Details&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Operating systems&lt;/td&gt; 
   &lt;td&gt;macOS 12+, Ubuntu 20.04+/Debian 10+, or Windows 11 &lt;strong&gt;via WSL2&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Git (optional, recommended)&lt;/td&gt; 
   &lt;td&gt;2.23+ for built-in PR helpers&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;RAM&lt;/td&gt; 
   &lt;td&gt;4-GB minimum (8-GB recommended)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h2&gt;CLI reference&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Command&lt;/th&gt; 
   &lt;th&gt;Purpose&lt;/th&gt; 
   &lt;th&gt;Example&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;codex&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Interactive TUI&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;codex&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;codex "..."&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Initial prompt for interactive TUI&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;codex "fix lint errors"&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;codex exec "..."&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Non-interactive "automation mode"&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;codex exec "explain utils.ts"&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Key flags: &lt;code&gt;--model/-m&lt;/code&gt;, &lt;code&gt;--ask-for-approval/-a&lt;/code&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Memory &amp;amp; project docs&lt;/h2&gt; 
&lt;p&gt;You can give Codex extra instructions and guidance using &lt;code&gt;AGENTS.md&lt;/code&gt; files. Codex looks for &lt;code&gt;AGENTS.md&lt;/code&gt; files in the following places, and merges them top-down:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;code&gt;~/.codex/AGENTS.md&lt;/code&gt; - personal global guidance&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;AGENTS.md&lt;/code&gt; at repo root - shared project notes&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;AGENTS.md&lt;/code&gt; in the current working directory - sub-folder/feature specifics&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Non-interactive / CI mode&lt;/h2&gt; 
&lt;p&gt;Run Codex head-less in pipelines. Example GitHub Action step:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;- name: Update changelog via Codex
  run: |
    npm install -g @openai/codex
    export OPENAI_API_KEY="${{ secrets.OPENAI_KEY }}"
    codex exec --full-auto "update CHANGELOG for next release"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Model Context Protocol (MCP)&lt;/h2&gt; 
&lt;p&gt;The Codex CLI can be configured to leverage MCP servers by defining an &lt;a href="https://raw.githubusercontent.com/openai/codex/main/codex-rs/config.md#mcp_servers"&gt;&lt;code&gt;mcp_servers&lt;/code&gt;&lt;/a&gt; section in &lt;code&gt;~/.codex/config.toml&lt;/code&gt;. It is intended to mirror how tools such as Claude and Cursor define &lt;code&gt;mcpServers&lt;/code&gt; in their respective JSON config files, though the Codex format is slightly different since it uses TOML rather than JSON, e.g.:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# IMPORTANT: the top-level key is `mcp_servers` rather than `mcpServers`.
[mcp_servers.server-name]
command = "npx"
args = ["-y", "mcp-server"]
env = { "API_KEY" = "value" }
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] It is somewhat experimental, but the Codex CLI can also be run as an MCP &lt;em&gt;server&lt;/em&gt; via &lt;code&gt;codex mcp&lt;/code&gt;. If you launch it with an MCP client such as &lt;code&gt;npx @modelcontextprotocol/inspector codex mcp&lt;/code&gt; and send it a &lt;code&gt;tools/list&lt;/code&gt; request, you will see that there is only one tool, &lt;code&gt;codex&lt;/code&gt;, that accepts a grab-bag of inputs, including a catch-all &lt;code&gt;config&lt;/code&gt; map for anything you might want to override. Feel free to play around with it and provide feedback via GitHub issues.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Tracing / verbose logging&lt;/h2&gt; 
&lt;p&gt;Because Codex is written in Rust, it honors the &lt;code&gt;RUST_LOG&lt;/code&gt; environment variable to configure its logging behavior.&lt;/p&gt; 
&lt;p&gt;The TUI defaults to &lt;code&gt;RUST_LOG=codex_core=info,codex_tui=info&lt;/code&gt; and log messages are written to &lt;code&gt;~/.codex/log/codex-tui.log&lt;/code&gt;, so you can leave the following running in a separate terminal to monitor log messages as they are written:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;tail -F ~/.codex/log/codex-tui.log
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;By comparison, the non-interactive mode (&lt;code&gt;codex exec&lt;/code&gt;) defaults to &lt;code&gt;RUST_LOG=error&lt;/code&gt;, but messages are printed inline, so there is no need to monitor a separate file.&lt;/p&gt; 
&lt;p&gt;See the Rust documentation on &lt;a href="https://docs.rs/env_logger/latest/env_logger/#enabling-logging"&gt;&lt;code&gt;RUST_LOG&lt;/code&gt;&lt;/a&gt; for more information on the configuration options.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;DotSlash&lt;/h3&gt; 
&lt;p&gt;The GitHub Release also contains a &lt;a href="https://dotslash-cli.com/"&gt;DotSlash&lt;/a&gt; file for the Codex CLI named &lt;code&gt;codex&lt;/code&gt;. Using a DotSlash file makes it possible to make a lightweight commit to source control to ensure all contributors use the same version of an executable, regardless of what platform they use for development.&lt;/p&gt;  
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Build from source&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Clone the repository and navigate to the root of the Cargo workspace.
git clone https://github.com/openai/codex.git
cd codex/codex-rs

# Install the Rust toolchain, if necessary.
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y
source "$HOME/.cargo/env"
rustup component add rustfmt
rustup component add clippy

# Build Codex.
cargo build

# Launch the TUI with a sample prompt.
cargo run --bin codex -- "explain this codebase to me"

# After making changes, ensure the code is clean.
cargo fmt -- --config imports_granularity=Item
cargo clippy --tests

# Run the tests.
cargo test
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Configuration&lt;/h2&gt; 
&lt;p&gt;Codex supports a rich set of configuration options documented in &lt;a href="https://raw.githubusercontent.com/openai/codex/main/codex-rs/config.md"&gt;&lt;code&gt;codex-rs/config.md&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;By default, Codex loads its configuration from &lt;code&gt;~/.codex/config.toml&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Though &lt;code&gt;--config&lt;/code&gt; can be used to set/override ad-hoc config values for individual invocations of &lt;code&gt;codex&lt;/code&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;OpenAI released a model called Codex in 2021 - is this related?&lt;/summary&gt; 
 &lt;p&gt;In 2021, OpenAI released Codex, an AI system designed to generate code from natural language prompts. That original Codex model was deprecated as of March 2023 and is separate from the CLI tool.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Which models are supported?&lt;/summary&gt; 
 &lt;p&gt;Any model available with &lt;a href="https://platform.openai.com/docs/api-reference/responses"&gt;Responses API&lt;/a&gt;. The default is &lt;code&gt;o4-mini&lt;/code&gt;, but pass &lt;code&gt;--model gpt-4.1&lt;/code&gt; or set &lt;code&gt;model: gpt-4.1&lt;/code&gt; in your config file to override.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Why does &lt;code&gt;o3&lt;/code&gt; or &lt;code&gt;o4-mini&lt;/code&gt; not work for me?&lt;/summary&gt; 
 &lt;p&gt;It's possible that your &lt;a href="https://help.openai.com/en/articles/10910291-api-organization-verification"&gt;API account needs to be verified&lt;/a&gt; in order to start streaming responses and seeing chain of thought summaries from the API. If you're still running into issues, please let us know!&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;How do I stop Codex from editing my files?&lt;/summary&gt; 
 &lt;p&gt;Codex runs model-generated commands in a sandbox. If a proposed command or file change doesn't look right, you can simply type &lt;strong&gt;n&lt;/strong&gt; to deny the command or give the model feedback.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Does it work on Windows?&lt;/summary&gt; 
 &lt;p&gt;Not directly. It requires &lt;a href="https://learn.microsoft.com/en-us/windows/wsl/install"&gt;Windows Subsystem for Linux (WSL2)&lt;/a&gt; - Codex has been tested on macOS and Linux with Node 22.&lt;/p&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Zero data retention (ZDR) usage&lt;/h2&gt; 
&lt;p&gt;Codex CLI &lt;strong&gt;does&lt;/strong&gt; support OpenAI organizations with &lt;a href="https://platform.openai.com/docs/guides/your-data#zero-data-retention"&gt;Zero Data Retention (ZDR)&lt;/a&gt; enabled. If your OpenAI organization has Zero Data Retention enabled and you still encounter errors such as:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;OpenAI rejected the request. Error details: Status: 400, Code: unsupported_parameter, Type: invalid_request_error, Message: 400 Previous response cannot be used for this organization due to Zero Data Retention.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Ensure you are running &lt;code&gt;codex&lt;/code&gt; with &lt;code&gt;--config disable_response_storage=true&lt;/code&gt; or add this line to &lt;code&gt;~/.codex/config.toml&lt;/code&gt; to avoid specifying the command line option each time:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;disable_response_storage = true
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/openai/codex/main/codex-rs/config.md#disable_response_storage"&gt;the configuration documentation on &lt;code&gt;disable_response_storage&lt;/code&gt;&lt;/a&gt; for details.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Codex open source fund&lt;/h2&gt; 
&lt;p&gt;We're excited to launch a &lt;strong&gt;$1 million initiative&lt;/strong&gt; supporting open source projects that use Codex CLI and other OpenAI models.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Grants are awarded up to &lt;strong&gt;$25,000&lt;/strong&gt; API credits.&lt;/li&gt; 
 &lt;li&gt;Applications are reviewed &lt;strong&gt;on a rolling basis&lt;/strong&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Interested? &lt;a href="https://openai.com/form/codex-open-source-fund/"&gt;Apply here&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;This project is under active development and the code will likely change pretty significantly. We'll update this message once that's complete!&lt;/p&gt; 
&lt;p&gt;More broadly we welcome contributions - whether you are opening your very first pull request or you're a seasoned maintainer. At the same time we care about reliability and long-term maintainability, so the bar for merging code is intentionally &lt;strong&gt;high&lt;/strong&gt;. The guidelines below spell out what "high-quality" means in practice and should make the whole process transparent and friendly.&lt;/p&gt; 
&lt;h3&gt;Development workflow&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Create a &lt;em&gt;topic branch&lt;/em&gt; from &lt;code&gt;main&lt;/code&gt; - e.g. &lt;code&gt;feat/interactive-prompt&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Keep your changes focused. Multiple unrelated fixes should be opened as separate PRs.&lt;/li&gt; 
 &lt;li&gt;Following the &lt;a href="https://raw.githubusercontent.com/openai/codex/main/#development-workflow"&gt;development setup&lt;/a&gt; instructions above, ensure your change is free of lint warnings and test failures.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Writing high-impact code changes&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Start with an issue.&lt;/strong&gt; Open a new one or comment on an existing discussion so we can agree on the solution before code is written.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Add or update tests.&lt;/strong&gt; Every new feature or bug-fix should come with test coverage that fails before your change and passes afterwards. 100% coverage is not required, but aim for meaningful assertions.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Document behaviour.&lt;/strong&gt; If your change affects user-facing behaviour, update the README, inline help (&lt;code&gt;codex --help&lt;/code&gt;), or relevant example projects.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Keep commits atomic.&lt;/strong&gt; Each commit should compile and the tests should pass. This makes reviews and potential rollbacks easier.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Opening a pull request&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fill in the PR template (or include similar information) - &lt;strong&gt;What? Why? How?&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;Run &lt;strong&gt;all&lt;/strong&gt; checks locally (&lt;code&gt;cargo test &amp;amp;&amp;amp; cargo clippy --tests &amp;amp;&amp;amp; cargo fmt -- --config imports_granularity=Item&lt;/code&gt;). CI failures that could have been caught locally slow down the process.&lt;/li&gt; 
 &lt;li&gt;Make sure your branch is up-to-date with &lt;code&gt;main&lt;/code&gt; and that you have resolved merge conflicts.&lt;/li&gt; 
 &lt;li&gt;Mark the PR as &lt;strong&gt;Ready for review&lt;/strong&gt; only when you believe it is in a merge-able state.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Review process&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;One maintainer will be assigned as a primary reviewer.&lt;/li&gt; 
 &lt;li&gt;We may ask for changes - please do not take this personally. We value the work, we just also value consistency and long-term maintainability.&lt;/li&gt; 
 &lt;li&gt;When there is consensus that the PR meets the bar, a maintainer will squash-and-merge.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Community values&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Be kind and inclusive.&lt;/strong&gt; Treat others with respect; we follow the &lt;a href="https://www.contributor-covenant.org/"&gt;Contributor Covenant&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Assume good intent.&lt;/strong&gt; Written communication is hard - err on the side of generosity.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Teach &amp;amp; learn.&lt;/strong&gt; If you spot something confusing, open an issue or PR with improvements.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Getting help&lt;/h3&gt; 
&lt;p&gt;If you run into problems setting up the project, would like feedback on an idea, or just want to say &lt;em&gt;hi&lt;/em&gt; - please open a Discussion or jump into the relevant issue. We are happy to help.&lt;/p&gt; 
&lt;p&gt;Together we can make Codex CLI an incredible tool. &lt;strong&gt;Happy hacking!&lt;/strong&gt; &lt;span&gt;🚀&lt;/span&gt;&lt;/p&gt; 
&lt;h3&gt;Contributor license agreement (CLA)&lt;/h3&gt; 
&lt;p&gt;All contributors &lt;strong&gt;must&lt;/strong&gt; accept the CLA. The process is lightweight:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Open your pull request.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Paste the following comment (or reply &lt;code&gt;recheck&lt;/code&gt; if you've signed before):&lt;/p&gt; &lt;pre&gt;&lt;code class="language-text"&gt;I have read the CLA Document and I hereby sign the CLA
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;The CLA-Assistant bot records your signature in the repo and marks the status check as passed.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;No special Git commands, email attachments, or commit footers required.&lt;/p&gt; 
&lt;h4&gt;Quick fixes&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Scenario&lt;/th&gt; 
   &lt;th&gt;Command&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Amend last commit&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;git commit --amend -s --no-edit &amp;amp;&amp;amp; git push -f&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;The &lt;strong&gt;DCO check&lt;/strong&gt; blocks merges until every commit in the PR carries the footer (with squash this is just the one).&lt;/p&gt; 
&lt;h3&gt;Releasing &lt;code&gt;codex&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;em&gt;For admins only.&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;Make sure you are on &lt;code&gt;main&lt;/code&gt; and have no local changes. Then run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;VERSION=0.2.0  # Can also be 0.2.0-alpha.1 or any valid Rust version.
./codex-rs/scripts/create_github_release.sh "$VERSION"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will make a local commit on top of &lt;code&gt;main&lt;/code&gt; with &lt;code&gt;version&lt;/code&gt; set to &lt;code&gt;$VERSION&lt;/code&gt; in &lt;code&gt;codex-rs/Cargo.toml&lt;/code&gt; (note that on &lt;code&gt;main&lt;/code&gt;, we leave the version as &lt;code&gt;version = "0.0.0"&lt;/code&gt;).&lt;/p&gt; 
&lt;p&gt;This will push the commit using the tag &lt;code&gt;rust-v${VERSION}&lt;/code&gt;, which in turn kicks off &lt;a href="https://raw.githubusercontent.com/openai/codex/main/.github/workflows/rust-release.yml"&gt;the release workflow&lt;/a&gt;. This will create a new GitHub Release named &lt;code&gt;$VERSION&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;If everything looks good in the generated GitHub Release, uncheck the &lt;strong&gt;pre-release&lt;/strong&gt; box so it is the latest release.&lt;/p&gt; 
&lt;p&gt;Create a PR to update &lt;a href="https://github.com/Homebrew/homebrew-core/raw/main/Formula/c/codex.rb"&gt;&lt;code&gt;Formula/c/codex.rb&lt;/code&gt;&lt;/a&gt; on Homebrew.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Security &amp;amp; responsible AI&lt;/h2&gt; 
&lt;p&gt;Have you discovered a vulnerability or have concerns about model output? Please e-mail &lt;strong&gt;&lt;a href="mailto:security@openai.com"&gt;security@openai.com&lt;/a&gt;&lt;/strong&gt; and we will respond promptly.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This repository is licensed under the &lt;a href="https://raw.githubusercontent.com/openai/codex/main/LICENSE"&gt;Apache-2.0 License&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>nomic-ai/gpt4all</title>
      <link>https://github.com/nomic-ai/gpt4all</link>
      <description>&lt;p&gt;GPT4All: Run Local LLMs on Any Device. Open-source and available for commercial use.&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt;GPT4All&lt;/h1&gt; 
&lt;p align="center"&gt; Now with support for DeepSeek R1 Distillations &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.nomic.ai/gpt4all"&gt;Website&lt;/a&gt; • &lt;a href="https://docs.gpt4all.io"&gt;Documentation&lt;/a&gt; • &lt;a href="https://discord.gg/mGZE39AS3e"&gt;Discord&lt;/a&gt; • &lt;a href="https://www.youtube.com/watch?v=gQcZDXRVJok"&gt;YouTube Tutorial&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; GPT4All runs large language models (LLMs) privately on everyday desktops &amp;amp; laptops. &lt;/p&gt; 
&lt;p align="center"&gt; No API calls or GPUs required - you can just download the application and &lt;a href="https://docs.gpt4all.io/gpt4all_desktop/quickstart.html#quickstart"&gt;get started&lt;/a&gt;. &lt;/p&gt; 
&lt;p align="center"&gt; Read about what's new in &lt;a href="https://www.nomic.ai/blog/tag/gpt4all"&gt;our blog&lt;/a&gt;. &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://nomic.ai/gpt4all/#newsletter-form"&gt;Subscribe to the newsletter&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/nomic-ai/gpt4all/assets/70534565/513a0f15-4964-4109-89e4-4f9a9011f311"&gt;https://github.com/nomic-ai/gpt4all/assets/70534565/513a0f15-4964-4109-89e4-4f9a9011f311&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; GPT4All is made possible by our compute partner &lt;a href="https://www.paperspace.com/"&gt;Paperspace&lt;/a&gt;. &lt;/p&gt; 
&lt;h2&gt;Download Links&lt;/h2&gt; 
&lt;p&gt; — &lt;a href="https://gpt4all.io/installers/gpt4all-installer-win64.exe"&gt; &lt;img src="https://raw.githubusercontent.com/nomic-ai/gpt4all/main/gpt4all-bindings/python/docs/assets/windows.png" style="height: 1em; width: auto" /&gt; Windows Installer &lt;/a&gt; — &lt;/p&gt; 
&lt;p&gt; — &lt;a href="https://gpt4all.io/installers/gpt4all-installer-win64-arm.exe"&gt; &lt;img src="https://raw.githubusercontent.com/nomic-ai/gpt4all/main/gpt4all-bindings/python/docs/assets/windows.png" style="height: 1em; width: auto" /&gt; Windows ARM Installer &lt;/a&gt; — &lt;/p&gt; 
&lt;p&gt; — &lt;a href="https://gpt4all.io/installers/gpt4all-installer-darwin.dmg"&gt; &lt;img src="https://raw.githubusercontent.com/nomic-ai/gpt4all/main/gpt4all-bindings/python/docs/assets/mac.png" style="height: 1em; width: auto" /&gt; macOS Installer &lt;/a&gt; — &lt;/p&gt; 
&lt;p&gt; — &lt;a href="https://gpt4all.io/installers/gpt4all-installer-linux.run"&gt; &lt;img src="https://raw.githubusercontent.com/nomic-ai/gpt4all/main/gpt4all-bindings/python/docs/assets/ubuntu.svg?sanitize=true" style="height: 1em; width: auto" /&gt; Ubuntu Installer &lt;/a&gt; — &lt;/p&gt; 
&lt;p&gt; The Windows and Linux builds require Intel Core i3 2nd Gen / AMD Bulldozer, or better. &lt;/p&gt; 
&lt;p&gt; The Windows ARM build supports Qualcomm Snapdragon and Microsoft SQ1/SQ2 processors. &lt;/p&gt; 
&lt;p&gt; The Linux build is x86-64 only (no ARM). &lt;/p&gt; 
&lt;p&gt; The macOS build requires Monterey 12.6 or newer. Best results with Apple Silicon M-series processors. &lt;/p&gt; 
&lt;p&gt;See the full &lt;a href="https://raw.githubusercontent.com/nomic-ai/gpt4all/main/gpt4all-chat/system_requirements.md"&gt;System Requirements&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;br /&gt; 
&lt;br /&gt; 
&lt;p&gt; &lt;a href="https://flathub.org/apps/io.gpt4all.gpt4all"&gt; &lt;img style="height: 2em; width: auto" alt="Get it on Flathub" src="https://flathub.org/api/badge" /&gt;&lt;br /&gt; Flathub (community maintained) &lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;Install GPT4All Python&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;gpt4all&lt;/code&gt; gives you access to LLMs with our Python client around &lt;a href="https://github.com/ggerganov/llama.cpp"&gt;&lt;code&gt;llama.cpp&lt;/code&gt;&lt;/a&gt; implementations.&lt;/p&gt; 
&lt;p&gt;Nomic contributes to open source software like &lt;a href="https://github.com/ggerganov/llama.cpp"&gt;&lt;code&gt;llama.cpp&lt;/code&gt;&lt;/a&gt; to make LLMs accessible and efficient &lt;strong&gt;for all&lt;/strong&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install gpt4all
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from gpt4all import GPT4All
model = GPT4All("Meta-Llama-3-8B-Instruct.Q4_0.gguf") # downloads / loads a 4.66GB LLM
with model.chat_session():
    print(model.generate("How can I run LLMs efficiently on my laptop?", max_tokens=1024))
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Integrations&lt;/h2&gt; 
&lt;p&gt;&lt;span&gt;🦜&lt;/span&gt;&lt;span&gt;🔗&lt;/span&gt; &lt;a href="https://python.langchain.com/v0.2/docs/integrations/providers/gpt4all/"&gt;Langchain&lt;/a&gt; &lt;span&gt;🗃&lt;/span&gt; &lt;a href="https://github.com/weaviate/weaviate"&gt;Weaviate Vector Database&lt;/a&gt; - &lt;a href="https://weaviate.io/developers/weaviate/modules/retriever-vectorizer-modules/text2vec-gpt4all"&gt;module docs&lt;/a&gt; &lt;span&gt;🔭&lt;/span&gt; &lt;a href="https://github.com/openlit/openlit"&gt;OpenLIT (OTel-native Monitoring)&lt;/a&gt; - &lt;a href="https://docs.openlit.io/latest/integrations/gpt4all"&gt;Docs&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Release History&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;July 2nd, 2024&lt;/strong&gt;: V3.0.0 Release 
  &lt;ul&gt; 
   &lt;li&gt;Fresh redesign of the chat application UI&lt;/li&gt; 
   &lt;li&gt;Improved user workflow for LocalDocs&lt;/li&gt; 
   &lt;li&gt;Expanded access to more model architectures&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;October 19th, 2023&lt;/strong&gt;: GGUF Support Launches with Support for: 
  &lt;ul&gt; 
   &lt;li&gt;Mistral 7b base model, an updated model gallery on our website, several new local code models including Rift Coder v1.5&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://blog.nomic.ai/posts/gpt4all-gpu-inference-with-vulkan"&gt;Nomic Vulkan&lt;/a&gt; support for Q4_0 and Q4_1 quantizations in GGUF.&lt;/li&gt; 
   &lt;li&gt;Offline build support for running old versions of the GPT4All Local LLM Chat Client.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;September 18th, 2023&lt;/strong&gt;: &lt;a href="https://blog.nomic.ai/posts/gpt4all-gpu-inference-with-vulkan"&gt;Nomic Vulkan&lt;/a&gt; launches supporting local LLM inference on NVIDIA and AMD GPUs.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;July 2023&lt;/strong&gt;: Stable support for LocalDocs, a feature that allows you to privately and locally chat with your data.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;June 28th, 2023&lt;/strong&gt;: &lt;a href="https://github.com/nomic-ai/gpt4all/tree/cef74c2be20f5b697055d5b8b506861c7b997fab/gpt4all-api"&gt;Docker-based API server&lt;/a&gt; launches allowing inference of local LLMs from an OpenAI-compatible HTTP endpoint.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;GPT4All welcomes contributions, involvement, and discussion from the open source community! Please see CONTRIBUTING.md and follow the issues, bug reports, and PR markdown templates.&lt;/p&gt; 
&lt;p&gt;Check project discord, with project owners, or through existing issues/PRs to avoid duplicate work. Please make sure to tag all of the above with relevant project identifiers or your contribution could potentially get lost. Example tags: &lt;code&gt;backend&lt;/code&gt;, &lt;code&gt;bindings&lt;/code&gt;, &lt;code&gt;python-bindings&lt;/code&gt;, &lt;code&gt;documentation&lt;/code&gt;, etc.&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you utilize this repository, models or data in a downstream project, please consider citing it with:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@misc{gpt4all,
  author = {Yuvanesh Anand and Zach Nussbaum and Brandon Duderstadt and Benjamin Schmidt and Andriy Mulyar},
  title = {GPT4All: Training an Assistant-style Chatbot with Large Scale Data Distillation from GPT-3.5-Turbo},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/nomic-ai/gpt4all}},
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>umami-software/umami</title>
      <link>https://github.com/umami-software/umami</link>
      <description>&lt;p&gt;Umami is a modern, privacy-focused alternative to Google Analytics.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://content.umami.is/website/images/umami-logo.png" alt="Umami Logo" width="100" /&gt; &lt;/p&gt; 
&lt;h1 align="center"&gt;Umami&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;i&gt;Umami is a simple, fast, privacy-focused alternative to Google Analytics.&lt;/i&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/umami-software/umami/releases"&gt; &lt;img src="https://img.shields.io/github/release/umami-software/umami.svg?sanitize=true" alt="GitHub Release" /&gt; &lt;/a&gt; &lt;a href="https://github.com/umami-software/umami/raw/master/LICENSE"&gt; &lt;img src="https://img.shields.io/github/license/umami-software/umami.svg?sanitize=true" alt="MIT License" /&gt; &lt;/a&gt; &lt;a href="https://github.com/umami-software/umami/actions"&gt; &lt;img src="https://img.shields.io/github/actions/workflow/status/umami-software/umami/ci.yml" alt="Build Status" /&gt; &lt;/a&gt; &lt;a href="https://analytics.umami.is/share/LGazGOecbDtaIwDr/umami.is" style="text-decoration: none;"&gt; &lt;img src="https://img.shields.io/badge/Try%20Demo%20Now-Click%20Here-brightgreen" alt="Umami Demo" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🚀 Getting Started&lt;/h2&gt; 
&lt;p&gt;A detailed getting started guide can be found at &lt;a href="https://umami.is/docs/"&gt;umami.is/docs&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🛠 Installing from Source&lt;/h2&gt; 
&lt;h3&gt;Requirements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;A server with Node.js version 18.18 or newer&lt;/li&gt; 
 &lt;li&gt;A database. Umami supports &lt;a href="https://www.mariadb.org/"&gt;MariaDB&lt;/a&gt; (minimum v10.5), &lt;a href="https://www.mysql.com/"&gt;MySQL&lt;/a&gt; (minimum v8.0) and &lt;a href="https://www.postgresql.org/"&gt;PostgreSQL&lt;/a&gt; (minimum v12.14) databases.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Get the Source Code and Install Packages&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/umami-software/umami.git
cd umami
npm install
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Configure Umami&lt;/h3&gt; 
&lt;p&gt;Create an &lt;code&gt;.env&lt;/code&gt; file with the following:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;DATABASE_URL=connection-url
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The connection URL format:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;postgresql://username:mypassword@localhost:5432/mydb
mysql://username:mypassword@localhost:3306/mydb
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Build the Application&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npm run build
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;The build step will create tables in your database if you are installing for the first time. It will also create a login user with username &lt;strong&gt;admin&lt;/strong&gt; and password &lt;strong&gt;umami&lt;/strong&gt;.&lt;/em&gt;&lt;/p&gt; 
&lt;h3&gt;Start the Application&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npm run start
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;By default, this will launch the application on &lt;code&gt;http://localhost:3000&lt;/code&gt;. You will need to either &lt;a href="https://docs.nginx.com/nginx/admin-guide/web-server/reverse-proxy/"&gt;proxy&lt;/a&gt; requests from your web server or change the &lt;a href="https://nextjs.org/docs/api-reference/cli#production"&gt;port&lt;/a&gt; to serve the application directly.&lt;/em&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🐳 Installing with Docker&lt;/h2&gt; 
&lt;p&gt;To build the Umami container and start up a Postgres database, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively, to pull just the Umami Docker image with PostgreSQL support:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker pull docker.umami.is/umami-software/umami:postgresql-latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or with MySQL support:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker pull docker.umami.is/umami-software/umami:mysql-latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🔄 Getting Updates&lt;/h2&gt; 
&lt;p&gt;To get the latest features, simply do a pull, install any new dependencies, and rebuild:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git pull
npm install
npm run build
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To update the Docker image, simply pull the new images and rebuild:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker compose pull
docker compose up --force-recreate -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🛟 Support&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/umami-software/umami"&gt; &lt;img src="https://img.shields.io/badge/GitHub--blue?style=social&amp;amp;logo=github" alt="GitHub" /&gt; &lt;/a&gt; &lt;a href="https://twitter.com/umami_software"&gt; &lt;img src="https://img.shields.io/badge/Twitter--blue?style=social&amp;amp;logo=twitter" alt="Twitter" /&gt; &lt;/a&gt; &lt;a href="https://linkedin.com/company/umami-software"&gt; &lt;img src="https://img.shields.io/badge/LinkedIn--blue?style=social&amp;amp;logo=linkedin" alt="LinkedIn" /&gt; &lt;/a&gt; &lt;a href="https://umami.is/discord"&gt; &lt;img src="https://img.shields.io/badge/Discord--blue?style=social&amp;amp;logo=discord" alt="Discord" /&gt; &lt;/a&gt; &lt;/p&gt;</description>
    </item>
    
    <item>
      <title>tadata-org/fastapi_mcp</title>
      <link>https://github.com/tadata-org/fastapi_mcp</link>
      <description>&lt;p&gt;Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt;&lt;a href="https://github.com/tadata-org/fastapi_mcp"&gt;&lt;img src="https://github.com/user-attachments/assets/7e44e98b-a0ba-4aff-a68a-4ffee3a6189c" alt="fastapi-to-mcp" height="100/" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;span style="font-size: 0.85em; font-weight: normal;"&gt;Built by &lt;a href="https://tadata.com"&gt;Tadata&lt;/a&gt;&lt;/span&gt; 
&lt;/div&gt; 
&lt;h1 align="center"&gt; FastAPI-MCP &lt;/h1&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://trendshift.io/repositories/14064" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/14064" alt="tadata-org%2Ffastapi_mcp | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt;Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://pypi.org/project/fastapi-mcp/"&gt;&lt;img src="https://img.shields.io/pypi/v/fastapi-mcp?color=%2334D058&amp;amp;label=pypi%20package" alt="PyPI version" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/fastapi-mcp/"&gt;&lt;img src="https://img.shields.io/pypi/pyversions/fastapi-mcp.svg?sanitize=true" alt="Python Versions" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/tadata-org/fastapi_mcp/main/#"&gt;&lt;img src="https://img.shields.io/badge/FastAPI-009485.svg?logo=fastapi&amp;amp;logoColor=white" alt="FastAPI" /&gt;&lt;/a&gt; &lt;a href="https://github.com/tadata-org/fastapi_mcp/actions/workflows/ci.yml"&gt;&lt;img src="https://github.com/tadata-org/fastapi_mcp/actions/workflows/ci.yml/badge.svg?sanitize=true" alt="CI" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/tadata-org/fastapi_mcp"&gt;&lt;img src="https://codecov.io/gh/tadata-org/fastapi_mcp/branch/main/graph/badge.svg?sanitize=true" alt="Coverage" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt;&lt;a href="https://github.com/tadata-org/fastapi_mcp"&gt;&lt;img src="https://github.com/user-attachments/assets/b205adc6-28c0-4e3c-a68b-9c1a80eb7d0c" alt="fastapi-mcp-usage" height="400" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Authentication&lt;/strong&gt; built in, using your existing FastAPI dependencies!&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;FastAPI-native:&lt;/strong&gt; Not just another OpenAPI -&amp;gt; MCP converter&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Zero/Minimal configuration&lt;/strong&gt; required - just point it at your FastAPI app and it works&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Preserving schemas&lt;/strong&gt; of your request models and response models&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Preserve documentation&lt;/strong&gt; of all your endpoints, just as it is in Swagger&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Flexible deployment&lt;/strong&gt; - Mount your MCP server to the same app, or deploy separately&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ASGI transport&lt;/strong&gt; - Uses FastAPI's ASGI interface directly for efficient communication&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Hosted Solution&lt;/h2&gt; 
&lt;p&gt;If you prefer a managed hosted solution check out &lt;a href="https://tadata.com"&gt;tadata.com&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;We recommend using &lt;a href="https://docs.astral.sh/uv/"&gt;uv&lt;/a&gt;, a fast Python package installer:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv add fastapi-mcp
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively, you can install with pip:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install fastapi-mcp
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Basic Usage&lt;/h2&gt; 
&lt;p&gt;The simplest way to use FastAPI-MCP is to add an MCP server directly to your FastAPI application:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from fastapi import FastAPI
from fastapi_mcp import FastApiMCP

app = FastAPI()

mcp = FastApiMCP(app)

# Mount the MCP server directly to your FastAPI app
mcp.mount()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;That's it! Your auto-generated MCP server is now available at &lt;code&gt;https://app.base.url/mcp&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Documentation, Examples and Advanced Usage&lt;/h2&gt; 
&lt;p&gt;FastAPI-MCP provides &lt;a href="https://fastapi-mcp.tadata.com/"&gt;comprehensive documentation&lt;/a&gt;. Additionaly, check out the &lt;a href="https://raw.githubusercontent.com/tadata-org/fastapi_mcp/main/examples"&gt;examples directory&lt;/a&gt; for code samples demonstrating these features in action.&lt;/p&gt; 
&lt;h2&gt;FastAPI-first Approach&lt;/h2&gt; 
&lt;p&gt;FastAPI-MCP is designed as a native extension of FastAPI, not just a converter that generates MCP tools from your API. This approach offers several key advantages:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Native dependencies&lt;/strong&gt;: Secure your MCP endpoints using familiar FastAPI &lt;code&gt;Depends()&lt;/code&gt; for authentication and authorization&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ASGI transport&lt;/strong&gt;: Communicates directly with your FastAPI app using its ASGI interface, eliminating the need for HTTP calls from the MCP to your API&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Unified infrastructure&lt;/strong&gt;: Your FastAPI app doesn't need to run separately from the MCP server (though &lt;a href="https://fastapi-mcp.tadata.com/advanced/deploy#deploying-separately-from-original-fastapi-app"&gt;separate deployment&lt;/a&gt; is also supported)&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This design philosophy ensures minimum friction when adding MCP capabilities to your existing FastAPI services.&lt;/p&gt; 
&lt;h2&gt;Development and Contributing&lt;/h2&gt; 
&lt;p&gt;Thank you for considering contributing to FastAPI-MCP! We encourage the community to post Issues and create Pull Requests.&lt;/p&gt; 
&lt;p&gt;Before you get started, please see our &lt;a href="https://raw.githubusercontent.com/tadata-org/fastapi_mcp/main/CONTRIBUTING.md"&gt;Contribution Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;Join &lt;a href="https://join.slack.com/t/themcparty/shared_invite/zt-30yxr1zdi-2FG~XjBA0xIgYSYuKe7~Xg"&gt;MCParty Slack community&lt;/a&gt; to connect with other MCP enthusiasts, ask questions, and share your experiences with FastAPI-MCP.&lt;/p&gt; 
&lt;h2&gt;Requirements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Python 3.10+ (Recommended 3.12)&lt;/li&gt; 
 &lt;li&gt;uv&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;MIT License. Copyright (c) 2025 Tadata Inc.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>patchy631/ai-engineering-hub</title>
      <link>https://github.com/patchy631/ai-engineering-hub</link>
      <description>&lt;p&gt;In-depth tutorials on LLMs, RAGs and real-world AI agent applications.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/12800"&gt; &lt;img src="https://raw.githubusercontent.com/patchy631/ai-engineering-hub/main/assets/TRENDING-BADGE.png" alt="Trending Badge" style="width: 250px; height: 55px;" width="250" height="55" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/patchy631/ai-engineering-hub/main/assets/ai-eng-hub.gif" alt="AI Engineering Hub Banner" /&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;h1&gt;AI Engineering Hub 🚀&lt;/h1&gt; 
&lt;p&gt;Welcome to the &lt;strong&gt;AI Engineering Hub&lt;/strong&gt;!&lt;/p&gt; 
&lt;h2&gt;🌟 Why This Repo?&lt;/h2&gt; 
&lt;p&gt;AI Engineering is advancing rapidly, and staying at the forefront requires both deep understanding and hands-on experience. Here, you will find:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;In-depth tutorials on &lt;strong&gt;LLMs and RAGs&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;Real-world &lt;strong&gt;AI agent&lt;/strong&gt; applications&lt;/li&gt; 
 &lt;li&gt;Examples to implement, adapt, and scale in your projects&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Whether you’re a beginner, practitioner, or researcher, this repo provides resources for all skill levels to experiment and succeed in AI engineering.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;📬 Stay Updated with Our Newsletter!&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Get a FREE Data Science eBook&lt;/strong&gt; 📖 with 150+ essential lessons in Data Science when you subscribe to our newsletter! Stay in the loop with the latest tutorials, insights, and exclusive resources. &lt;a href="https://join.dailydoseofds.com"&gt;Subscribe now!&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://join.dailydoseofds.com"&gt;&lt;img src="https://github.com/patchy631/ai-engineering/raw/main/resources/join_ddods.png" alt="Daily Dose of Data Science Newsletter" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;📢 Contribute to the AI Engineering Hub!&lt;/h2&gt; 
&lt;p&gt;We welcome contributors! Whether you want to add new tutorials, improve existing code, or report issues, your contributions make this community thrive. Here’s how to get involved:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Fork&lt;/strong&gt; the repository.&lt;/li&gt; 
 &lt;li&gt;Create a new branch for your contribution.&lt;/li&gt; 
 &lt;li&gt;Submit a &lt;strong&gt;Pull Request&lt;/strong&gt; and describe the improvements.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr /&gt; 
&lt;h2&gt;📜 License&lt;/h2&gt; 
&lt;p&gt;This repository is licensed under the MIT License - see the &lt;a href="https://raw.githubusercontent.com/patchy631/ai-engineering-hub/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;h2&gt;💬 Connect&lt;/h2&gt; 
&lt;p&gt;For discussions, suggestions, and more, feel free to &lt;a href="https://github.com/patchy631/ai-engineering/issues"&gt;create an issue&lt;/a&gt; or reach out directly!&lt;/p&gt; 
&lt;p&gt;Happy Coding! 🎉&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>idosal/git-mcp</title>
      <link>https://github.com/idosal/git-mcp</link>
      <description>&lt;p&gt;Put an end to code hallucinations! GitMCP is a free, open-source, remote MCP server for any GitHub project&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;GitMCP&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;img width="884" alt="image" src="https://github.com/user-attachments/assets/2bf3e3df-556c-49c6-ab7b-36c279d53bba" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://raw.githubusercontent.com/idosal/git-mcp/main/#-what-is-gitmcp"&gt;What is GitMCP&lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/idosal/git-mcp/main/#-features"&gt;Features&lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/idosal/git-mcp/main/#-getting-started"&gt;Getting Started&lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/idosal/git-mcp/main/#-how-it-works"&gt;How It Works&lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/idosal/git-mcp/main/#-badge"&gt;Badge&lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/idosal/git-mcp/main/#-examples"&gt;Examples&lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/idosal/git-mcp/main/#-faq"&gt;FAQ&lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/idosal/git-mcp/main/#-privacy"&gt;Privacy&lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/idosal/git-mcp/main/#-contributing"&gt;Contributing&lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/idosal/git-mcp/main/#-license"&gt;License&lt;/a&gt; &lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://gitmcp.io/idosal/git-mcp"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://gitmcp.io/badge/idosal/git-mcp" alt="GitMCP" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/idosal1"&gt;&lt;img src="https://img.shields.io/twitter/follow/idosal1?style=social" alt="Twitter Follow" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/liadyosef"&gt;&lt;img src="https://img.shields.io/twitter/follow/liadyosef?style=social" alt="Twitter Follow" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://www.pulsemcp.com/servers/idosal-git-mcp"&gt;&lt;img src="https://www.pulsemcp.com/badge/top-pick/idosal-git-mcp" width="400" alt="Pulse MCP Badge" /&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;🤔 What is GitMCP?&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Stop vibe-hallucinating and start vibe-coding!&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://gitmcp.io"&gt;GitMCP&lt;/a&gt; is a free, open-source, remote &lt;a href="https://docs.anthropic.com/en/docs/agents-and-tools/mcp"&gt;Model Context Protocol (MCP)&lt;/a&gt; server that transforms &lt;strong&gt;any&lt;/strong&gt; GitHub project (repositories or GitHub pages) into a documentation hub. It enables AI tools like Cursor to access up-to-date documentation and code, even if the LLM has never encountered them, thereby eliminating code hallucinations seamlessly.&lt;/p&gt; 
&lt;p&gt;GitMCP supports &lt;strong&gt;two flavors&lt;/strong&gt; -&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Specific Repository (&lt;code&gt;gitmcp.io/{owner}/{repo}&lt;/code&gt; or &lt;code&gt;{owner}.gitmcp.io/{repo}&lt;/code&gt;):&lt;/strong&gt; Use these when you primarily work with a select number of libraries. This ensures your AI assistant always targets the correct project, enhancing security and relevance by preventing access to unintended repositories.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Generic Server (&lt;code&gt;gitmcp.io/docs&lt;/code&gt;):&lt;/strong&gt; Use this for maximum flexibility when you need to switch between different repositories frequently. The AI assistant will prompt you (or decide based on context) which repository to access for each request. Be mindful that this relies on correctly identifying the target repository each time.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;With GitMCP:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;AI assistants access the &lt;em&gt;latest&lt;/em&gt; documentation and code directly from the source.&lt;/li&gt; 
 &lt;li&gt;Get accurate API usage and reliable code examples.&lt;/li&gt; 
 &lt;li&gt;Work effectively even with niche, new, or rapidly changing libraries.&lt;/li&gt; 
 &lt;li&gt;Significantly reduced hallucinations and improved code correctness.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For example, this side-by-side comparison shows the result for the same one-shot prompt in Cursor when creating a &lt;a href="https://github.com/mrdoob/three.js"&gt;three.js&lt;/a&gt; scene -&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/fbf1b4a7-f9f0-4c0e-831c-4d64faae2c45"&gt;https://github.com/user-attachments/assets/fbf1b4a7-f9f0-4c0e-831c-4d64faae2c45&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;✨ Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;😎 &lt;strong&gt;Latest Documentation on ANY GitHub Project&lt;/strong&gt;: Grant your AI assistant seamless access to the GitHub project's documentation and code. The built-in smart search capabilities help find exactly what the AI needs without using too many tokens!&lt;/li&gt; 
 &lt;li&gt;🧠 &lt;strong&gt;No More Hallucinations&lt;/strong&gt;: With GitMCP, your AI assistant can provide accurate and relevant answers to your questions.&lt;/li&gt; 
 &lt;li&gt;☁️ &lt;strong&gt;Zero Setup&lt;/strong&gt;: GitMCP runs in the cloud. Simply add the chosen GitMCP URL as an MCP server in your IDE — no downloads, installations, signups, or changes are required.&lt;/li&gt; 
 &lt;li&gt;💬 &lt;strong&gt;Embedded Chat&lt;/strong&gt;: Start quickly by chatting directly with the repository's documentation through our in-browser chat!&lt;/li&gt; 
 &lt;li&gt;✅ &lt;strong&gt;Open, Free, and Private&lt;/strong&gt;: GitMCP is open-source and completely free to use. It doesn't collect personal information or store queries. You can even self-host it!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;
 &lt;video src="https://github.com/user-attachments/assets/2c3afaf9-6c08-436e-9efd-db8710554430"&gt;&lt;/video&gt;&lt;/p&gt; 
&lt;h2&gt;🚀 Getting Started&lt;/h2&gt; 
&lt;p&gt;Using GitMCP is easy! Simply follow these steps:&lt;/p&gt; 
&lt;h3&gt;Step 1: Choose the type of server you want&lt;/h3&gt; 
&lt;p&gt;Choose one of these URL formats depending on what you want to connect to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;For GitHub repositories: &lt;code&gt;gitmcp.io/{owner}/{repo}&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;For GitHub Pages sites: &lt;code&gt;{owner}.gitmcp.io/{repo}&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;For a generic tool that supports any repository (dynamic): &lt;code&gt;gitmcp.io/docs&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Replace &lt;code&gt;{owner}&lt;/code&gt; with the GitHub username or organization name, and &lt;code&gt;{repo}&lt;/code&gt; with the repository name.&lt;/p&gt; 
&lt;p&gt;For your convenience, you can also use the conversion tool on the landing page to format the GitHub URL into an MCP URL!&lt;/p&gt; 
&lt;h3&gt;Step 2: Connect your AI assistant&lt;/h3&gt; 
&lt;p&gt;Select your AI assistant from the options below and follow the configuration instructions:&lt;/p&gt; 
&lt;h4&gt;Connecting Cursor&lt;/h4&gt; 
&lt;p&gt;Update your Cursor configuration file at &lt;code&gt;~/.cursor/mcp.json&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "gitmcp": {
      "url": "https://gitmcp.io/{owner}/{repo}"
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Connecting Claude Desktop&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;In Claude Desktop, go to Settings &amp;gt; Developer &amp;gt; Edit Config&lt;/li&gt; 
 &lt;li&gt;Replace the configuration with: &lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "gitmcp": {
      "command": "npx",
      "args": [
        "mcp-remote",
        "https://gitmcp.io/{owner}/{repo}"
      ]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Connecting Windsurf&lt;/h4&gt; 
&lt;p&gt;Update your Windsurf configuration file at &lt;code&gt;~/.codeium/windsurf/mcp_config.json&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "gitmcp": {
      "serverUrl": "https://gitmcp.io/{owner}/{repo}"
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Connecting VSCode&lt;/h4&gt; 
&lt;p&gt;Update your VSCode configuration file at &lt;code&gt;.vscode/mcp.json&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "servers": {
    "gitmcp": {
      "type": "sse",
      "url": "https://gitmcp.io/{owner}/{repo}"
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Connecting Cline&lt;/h4&gt; 
&lt;p&gt;Update your Cline configuration file at &lt;code&gt;~/Library/Application Support/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_settings.json&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "gitmcp": {
      "url": "https://gitmcp.io/{owner}/{repo}",
      "disabled": false,
      "autoApprove": []
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Connecting Highlight AI&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;Open Highlight AI and click the plugins icon (@ symbol) in the sidebar&lt;/li&gt; 
 &lt;li&gt;Click &lt;strong&gt;Installed Plugins&lt;/strong&gt; at the top of the sidebar&lt;/li&gt; 
 &lt;li&gt;Select &lt;strong&gt;Custom Plugin&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;Click &lt;strong&gt;Add a plugin using a custom SSE URL&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Plugin name: &lt;code&gt;gitmcp&lt;/code&gt; SSE URL: &lt;code&gt;https://gitmcp.io/{owner}/{repo}&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;For more details on adding custom MCP servers to HighlightAI, refer to &lt;a href="https://docs.highlightai.com/learn/developers/plugins/custom-plugins-setup"&gt;the documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Connecting Augment Code&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;Open Augment Code settings&lt;/li&gt; 
 &lt;li&gt;Navigate to the MCP section&lt;/li&gt; 
 &lt;li&gt;Add a new MCP server with the following details:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Name the MCP server: &lt;code&gt;git-mcp Docs&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Use this command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npx mcp-remote https://gitmcp.io/{owner}/{repo}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or use the following configuration:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "git-mcp Docs": {
      "command": "npx",
      "args": [
        "mcp-remote",
        "https://gitmcp.io/{owner}/{repo}"
      ]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Connecting Msty AI&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;Open Msty Studio&lt;/li&gt; 
 &lt;li&gt;Go to Tools &amp;gt; Import Tools from JSON Clipboard&lt;/li&gt; 
 &lt;li&gt;Paste the following configuration:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "git-mcp Docs": {
      "command": "npx",
      "args": [
        "mcp-remote",
        "https://gitmcp.io/{owner}/{repo}"
      ]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more details on configuring MCP servers in Augment Code, visit &lt;a href="https://docs.augmentcode.com/setup-augment/mcp"&gt;the Augment Code documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Remember to replace &lt;code&gt;{owner}&lt;/code&gt; and &lt;code&gt;{repo}&lt;/code&gt; with the actual GitHub username/organization and repository name. You can also use the dynamic endpoint &lt;code&gt;https://gitmcp.io/docs&lt;/code&gt; to allow your AI to access any repository on demand.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;⚙ How It Works&lt;/h2&gt; 
&lt;p&gt;GitMCP connects your AI assistant to GitHub repositories using the Model Context Protocol (MCP), a standard that lets AI tools request additional information from external sources.&lt;/p&gt; 
&lt;p&gt;What happens when you use GitMCP:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;You provide the GitMCP URL&lt;/strong&gt; to your AI assistant (e.g., &lt;code&gt;gitmcp.io/microsoft/typescript&lt;/code&gt;). GitMCP exposes tools like documentation fetching, smart search, code search, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Prompt the AI assistant&lt;/strong&gt; on documentation/code-related questions.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Your AI sends requests&lt;/strong&gt; to GitMCP to use its tools (with your approval).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GitMCP executes the AI's request&lt;/strong&gt; and returns the requested data.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Your AI receives the information&lt;/strong&gt; and generates a more accurate, grounded response without hallucinations.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Supported Documentation&lt;/h3&gt; 
&lt;p&gt;GitMCP currently supports the following documents (in order of priority):&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://llmstxt.org"&gt;llms.txt&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;AI-optimized version of the project's documentation&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;README.md&lt;/code&gt;/root&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;💡 Examples&lt;/h2&gt; 
&lt;p&gt;Here are some examples of how to use GitMCP with different AI assistants and repositories:&lt;/p&gt; 
&lt;h3&gt;Example 1: Using Windsurf with a specific repository&lt;/h3&gt; 
&lt;p&gt;For the GitHub repository &lt;code&gt;https://github.com/microsoft/playwright-mcp&lt;/code&gt;, add &lt;code&gt;https://gitmcp.io/microsoft/playwright-mcp&lt;/code&gt; as an MCP server to Windsurf.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Prompt to Claude:&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;"How do I use the Playwright MCP"&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Windsurf will pull the relevant documentation from GitMCP to implement the memory feature correctly.&lt;/p&gt; 
&lt;h3&gt;Example 2: Using Cursor with a GitHub Pages site&lt;/h3&gt; 
&lt;p&gt;For the GitHub Pages site &lt;code&gt;langchain-ai.github.io/langgraph&lt;/code&gt;, add &lt;code&gt;https://langchain-ai.gitmcp.io/langgraph&lt;/code&gt; as an MCP server to Cursor.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Prompt to Cursor:&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;"Add memory to my LangGraph agent"&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Cursor will pull the relevant documentation and code from GitMCP to correctly implement the memory feature.&lt;/p&gt; 
&lt;h3&gt;Example 3: Using Claude Desktop with the dynamic endpoint&lt;/h3&gt; 
&lt;p&gt;You don't have to pick specific repositories. The generic &lt;code&gt;gitmcp.io/docs&lt;/code&gt; endpoint allows AI to pick the GitHub project on the fly!&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Prompt to any AI assistant:&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;"I want to learn about the OpenAI Whisper speech recognition model. Explain how it works.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Claude will pull the data from GitMCP and answer the question.&lt;/p&gt; 
&lt;h2&gt;🛠️ Tools&lt;/h2&gt; 
&lt;p&gt;GitMCP provides AI assistants with several valuable tools to help them access, understand, and query GitHub repositories.&lt;/p&gt; 
&lt;h3&gt;&lt;code&gt;fetch_&amp;lt;repo-name&amp;gt;_documentation&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;This tool gets the primary documentation from a GitHub repository. It works by retrieving relevant documentation (e.g., &lt;code&gt;llms.txt&lt;/code&gt;). This gives the AI a good overview of what the project is about&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;When it's useful:&lt;/strong&gt; For general questions about a project's purpose, features, or how to get started&lt;/p&gt; 
&lt;h3&gt;&lt;code&gt;search_&amp;lt;repo-name&amp;gt;_documentation&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;This tool lets the AI search through a repository's documentation by providing a specific search query. Instead of loading all the documentation (which could be very large), it uses intelligent search to find just the relevant parts.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;When it's useful:&lt;/strong&gt; For specific questions about particular features, functions, or concepts within a project&lt;/p&gt; 
&lt;h3&gt;&lt;code&gt;fetch_url_content&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;This tool helps the AI get information from links mentioned in the documentation. It retrieves the content from those links and converts it to a format the AI can easily read.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;When it's useful:&lt;/strong&gt; When documentation references external information that would help answer your question&lt;/p&gt; 
&lt;h3&gt;&lt;code&gt;search_&amp;lt;repo-name&amp;gt;_code&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;This tool searches through the actual code in the repository using GitHub's code search. It helps AI find specific code examples or implementation details.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;When it's useful:&lt;/strong&gt; When you want examples of how something is implemented or need technical details not covered in documentation&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; When using the dynamic endpoint (&lt;code&gt;gitmcp.io/docs&lt;/code&gt;), these tools are named slightly differently (&lt;code&gt;fetch_generic_documentation&lt;/code&gt;, &lt;code&gt;search_generic_code&lt;/code&gt;, and &lt;code&gt;search_generic_documentation&lt;/code&gt;) and need additional information about which repository to access.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;📊 Badge&lt;/h2&gt; 
&lt;p&gt;GitMCP has a badge to your repository's README. It allows users to quickly access your documentation through their IDE or browser (using the embedded chat). It also showcases how many times your documentation has been accessed through GitMCP.&lt;/p&gt; 
&lt;p&gt;Example (&lt;code&gt;idosal/git-mcp&lt;/code&gt;): &lt;a href="https://gitmcp.io/idosal/git-mcp"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://gitmcp.io/badge/idosal/git-mcp" alt="GitMCP" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Adding the Badge to Your Repository&lt;/h3&gt; 
&lt;p&gt;Add the following to your &lt;code&gt;README.md&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-markdown"&gt;[![GitMCP](https://img.shields.io/endpoint?url=https://gitmcp.io/badge/OWNER/REPO)](https://gitmcp.io/OWNER/REPO)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Replace &lt;code&gt;OWNER&lt;/code&gt; with your GitHub username or organization, and &lt;code&gt;REPO&lt;/code&gt; with your repository name.&lt;/p&gt; 
&lt;h3&gt;How We Count Views&lt;/h3&gt; 
&lt;p&gt;Increment for each tool call on the specific repository.&lt;/p&gt; 
&lt;h3&gt;Customizing the Badge&lt;/h3&gt; 
&lt;p&gt;You can customize the badge's appearance with parameters:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Parameter&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Default&lt;/th&gt; 
   &lt;th&gt;Example&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;color&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Color for the badge value&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;aquamarine&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;?color=green&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;label&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Badge label&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;GitMCP&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;Documentation&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Please reach out!&lt;/p&gt; 
&lt;h2&gt;❓ FAQ&lt;/h2&gt; 
&lt;h3&gt;What is the Model Context Protocol?&lt;/h3&gt; 
&lt;p&gt;The &lt;a href="https://modelcontextprotocol.io/introduction"&gt;Model Context Protocol&lt;/a&gt; is a standard that allows AI assistants to request and receive additional context from external sources in a structured manner, enhancing their understanding and performance.&lt;/p&gt; 
&lt;h3&gt;Does GitMCP work with any AI assistant?&lt;/h3&gt; 
&lt;p&gt;Yes, GitMCP is compatible with any AI assistant supporting the Model Context Protocol, including tools like Cursor, VSCode, Claude, etc.&lt;/p&gt; 
&lt;h3&gt;Is GitMCP compatible with all GitHub projects?&lt;/h3&gt; 
&lt;p&gt;Absolutely! GitMCP works with any public GitHub repository without requiring any modifications. It prioritizes the &lt;code&gt;llms.txt&lt;/code&gt; file and falls back to &lt;code&gt;README.md&lt;/code&gt; or other pages if the former is unavailable. Future updates aim to support additional documentation methods and even generate content dynamically.&lt;/p&gt; 
&lt;h3&gt;Does GitMCP cost money?&lt;/h3&gt; 
&lt;p&gt;No, GitMCP is a free service to the community with no associated costs.&lt;/p&gt; 
&lt;h2&gt;🔒 Privacy&lt;/h2&gt; 
&lt;p&gt;GitMCP is deeply committed to its users' privacy. The service doesn't have access to or store any personally identifiable information as it doesn't require authentication. In addition, it doesn't store any queries sent by the agents. Moreover, as GitMCP is an open-source project, it can be deployed independently in your environment.&lt;/p&gt; 
&lt;p&gt;GitMCP only accesses content that is already publicly available and only when queried by a user. GitMCP does not automatically scrape repositories. Before accessing any GitHub Pages site, the code checks for &lt;code&gt;robots.txt&lt;/code&gt; rules and follows the directives set by site owners, allowing them to opt out. Please note that GitMCP doesn't permanently store data regarding the GitHub projects or their content.&lt;/p&gt; 
&lt;h2&gt;👥 Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions, feedback, and ideas! Please review our &lt;a href="https://github.com/idosal/git-mcp/raw/main/.github/CONTRIBUTING.md"&gt;contribution&lt;/a&gt; guidelines.&lt;/p&gt; 
&lt;h3&gt;Local Development Setup&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Clone the repository&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/idosal/git-mcp.git
cd git-mcp
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Install dependencies&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pnpm install
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Run locally for development&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;npm run dev
# or
pnpm dev
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Using MCP Inspector for Testing&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Install the MCP Inspector tool:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;npx @modelcontextprotocol/inspector
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;In the inspector interface:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Set Transport Type to &lt;code&gt;SSE&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Enter your GitMCP URL (e.g., &lt;code&gt;http://localhost:5173/docs&lt;/code&gt;)&lt;/li&gt; 
   &lt;li&gt;Click "Connect"&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;📄 License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the &lt;a href="https://raw.githubusercontent.com/idosal/git-mcp/main/LICENSE"&gt;Apache License 2.0&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Disclaimer&lt;/h2&gt; 
&lt;p&gt;GitMCP is provided "as is" without warranty of any kind. While we strive to ensure the reliability and security of our service, we are not responsible for any damages or issues that may arise from its use. GitHub projects accessed through GitMCP are subject to their respective owners' terms and conditions. GitMCP is not affiliated with GitHub or any of the mentioned AI tools.&lt;/p&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#idosal/git-mcp&amp;amp;Timeline"&gt;&lt;img src="https://api.star-history.com/svg?repos=idosal/git-mcp&amp;amp;type=Timeline" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>mendableai/firecrawl</title>
      <link>https://github.com/mendableai/firecrawl</link>
      <description>&lt;p&gt;🔥 Turn entire websites into LLM-ready markdown or structured data. Scrape, crawl and extract with a single API.&lt;/p&gt;&lt;hr&gt;&lt;h3 align="center"&gt; &lt;a name="readme-top"&gt;&lt;/a&gt; &lt;img src="https://raw.githubusercontent.com/mendableai/firecrawl/main/img/firecrawl_logo.png" height="200" /&gt; &lt;/h3&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/mendableai/firecrawl/raw/main/LICENSE"&gt; &lt;img src="https://img.shields.io/github/license/mendableai/firecrawl" alt="License" /&gt; &lt;/a&gt; 
 &lt;a href="https://pepy.tech/project/firecrawl-py"&gt; &lt;img src="https://static.pepy.tech/badge/firecrawl-py" alt="Downloads" /&gt; &lt;/a&gt; 
 &lt;a href="https://GitHub.com/mendableai/firecrawl/graphs/contributors"&gt; &lt;img src="https://img.shields.io/github/contributors/mendableai/firecrawl.svg?sanitize=true" alt="GitHub Contributors" /&gt; &lt;/a&gt; 
 &lt;a href="https://firecrawl.dev"&gt; &lt;img src="https://img.shields.io/badge/Visit-firecrawl.dev-orange" alt="Visit firecrawl.dev" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;div&gt; 
 &lt;p align="center"&gt; &lt;a href="https://twitter.com/firecrawl_dev"&gt; &lt;img src="https://img.shields.io/badge/Follow%20on%20X-000000?style=for-the-badge&amp;amp;logo=x&amp;amp;logoColor=white" alt="Follow on X" /&gt; &lt;/a&gt; &lt;a href="https://www.linkedin.com/company/104100957"&gt; &lt;img src="https://img.shields.io/badge/Follow%20on%20LinkedIn-0077B5?style=for-the-badge&amp;amp;logo=linkedin&amp;amp;logoColor=white" alt="Follow on LinkedIn" /&gt; &lt;/a&gt; &lt;a href="https://discord.com/invite/gSmWdAkdwd"&gt; &lt;img src="https://img.shields.io/badge/Join%20our%20Discord-5865F2?style=for-the-badge&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Join our Discord" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;h1&gt;🔥 Firecrawl&lt;/h1&gt; 
&lt;p&gt;Empower your AI apps with clean data from any website. Featuring advanced scraping, crawling, and data extraction capabilities.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;This repository is in development, and we’re still integrating custom modules into the mono repo. It's not fully ready for self-hosted deployment yet, but you can run it locally.&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;What is Firecrawl?&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://firecrawl.dev?ref=github"&gt;Firecrawl&lt;/a&gt; is an API service that takes a URL, crawls it, and converts it into clean markdown or structured data. We crawl all accessible subpages and give you clean data for each. No sitemap required. Check out our &lt;a href="https://docs.firecrawl.dev"&gt;documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Pst. hey, you, join our stargazers :)&lt;/em&gt;&lt;/p&gt; 
&lt;a href="https://github.com/mendableai/firecrawl"&gt; &lt;img src="https://img.shields.io/github/stars/mendableai/firecrawl.svg?style=social&amp;amp;label=Star&amp;amp;maxAge=2592000" alt="GitHub stars" /&gt; &lt;/a&gt; 
&lt;h2&gt;How to use it?&lt;/h2&gt; 
&lt;p&gt;We provide an easy to use API with our hosted version. You can find the playground and documentation &lt;a href="https://firecrawl.dev/playground"&gt;here&lt;/a&gt;. You can also self host the backend if you'd like.&lt;/p&gt; 
&lt;p&gt;Check out the following resources to get started:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;API&lt;/strong&gt;: &lt;a href="https://docs.firecrawl.dev/api-reference/introduction"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;SDKs&lt;/strong&gt;: &lt;a href="https://docs.firecrawl.dev/sdks/python"&gt;Python&lt;/a&gt;, &lt;a href="https://docs.firecrawl.dev/sdks/node"&gt;Node&lt;/a&gt;, &lt;a href="https://docs.firecrawl.dev/sdks/go"&gt;Go&lt;/a&gt;, &lt;a href="https://docs.firecrawl.dev/sdks/rust"&gt;Rust&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;LLM Frameworks&lt;/strong&gt;: &lt;a href="https://python.langchain.com/docs/integrations/document_loaders/firecrawl/"&gt;Langchain (python)&lt;/a&gt;, &lt;a href="https://js.langchain.com/docs/integrations/document_loaders/web_loaders/firecrawl"&gt;Langchain (js)&lt;/a&gt;, &lt;a href="https://docs.llamaindex.ai/en/latest/examples/data_connectors/WebPageDemo/#using-firecrawl-reader"&gt;Llama Index&lt;/a&gt;, &lt;a href="https://docs.crewai.com/"&gt;Crew.ai&lt;/a&gt;, &lt;a href="https://composio.dev/tools/firecrawl/all"&gt;Composio&lt;/a&gt;, &lt;a href="https://docs.praison.ai/firecrawl/"&gt;PraisonAI&lt;/a&gt;, &lt;a href="https://superinterface.ai/docs/assistants/functions/firecrawl"&gt;Superinterface&lt;/a&gt;, &lt;a href="https://docs.vectorize.io/integrations/source-connectors/firecrawl"&gt;Vectorize&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Low-code Frameworks&lt;/strong&gt;: &lt;a href="https://dify.ai/blog/dify-ai-blog-integrated-with-firecrawl"&gt;Dify&lt;/a&gt;, &lt;a href="https://docs.langflow.org/"&gt;Langflow&lt;/a&gt;, &lt;a href="https://docs.flowiseai.com/integrations/langchain/document-loaders/firecrawl"&gt;Flowise AI&lt;/a&gt;, &lt;a href="https://docs.getcargo.io/integration/firecrawl"&gt;Cargo&lt;/a&gt;, &lt;a href="https://pipedream.com/apps/firecrawl/"&gt;Pipedream&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Others&lt;/strong&gt;: &lt;a href="https://zapier.com/apps/firecrawl/integrations"&gt;Zapier&lt;/a&gt;, &lt;a href="https://www.pabbly.com/connect/integrations/firecrawl/"&gt;Pabbly Connect&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Want an SDK or Integration? Let us know by opening an issue.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To run locally, refer to guide &lt;a href="https://github.com/mendableai/firecrawl/raw/main/CONTRIBUTING.md"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;API Key&lt;/h3&gt; 
&lt;p&gt;To use the API, you need to sign up on &lt;a href="https://firecrawl.dev"&gt;Firecrawl&lt;/a&gt; and get an API key.&lt;/p&gt; 
&lt;h3&gt;Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/mendableai/firecrawl/main/#scraping"&gt;&lt;strong&gt;Scrape&lt;/strong&gt;&lt;/a&gt;: scrapes a URL and get its content in LLM-ready format (markdown, structured data via &lt;a href="https://raw.githubusercontent.com/mendableai/firecrawl/main/#llm-extraction-beta"&gt;LLM Extract&lt;/a&gt;, screenshot, html)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/mendableai/firecrawl/main/#crawling"&gt;&lt;strong&gt;Crawl&lt;/strong&gt;&lt;/a&gt;: scrapes all the URLs of a web page and return content in LLM-ready format&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/mendableai/firecrawl/main/#map"&gt;&lt;strong&gt;Map&lt;/strong&gt;&lt;/a&gt;: input a website and get all the website urls - extremely fast&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/mendableai/firecrawl/main/#search"&gt;&lt;strong&gt;Search&lt;/strong&gt;&lt;/a&gt;: search the web and get full content from results&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/mendableai/firecrawl/main/#extract"&gt;&lt;strong&gt;Extract&lt;/strong&gt;&lt;/a&gt;: get structured data from single page, multiple pages or entire websites with AI.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Powerful Capabilities&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;LLM-ready formats&lt;/strong&gt;: markdown, structured data, screenshot, HTML, links, metadata&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;The hard stuff&lt;/strong&gt;: proxies, anti-bot mechanisms, dynamic content (js-rendered), output parsing, orchestration&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Customizability&lt;/strong&gt;: exclude tags, crawl behind auth walls with custom headers, max crawl depth, etc...&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Media parsing&lt;/strong&gt;: pdfs, docx, images&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Reliability first&lt;/strong&gt;: designed to get the data you need - no matter how hard it is&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Actions&lt;/strong&gt;: click, scroll, input, wait and more before extracting data&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Batching (New)&lt;/strong&gt;: scrape thousands of URLs at the same time with a new async endpoint.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You can find all of Firecrawl's capabilities and how to use them in our &lt;a href="https://docs.firecrawl.dev"&gt;documentation&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Crawling&lt;/h3&gt; 
&lt;p&gt;Used to crawl a URL and all accessible subpages. This submits a crawl job and returns a job ID to check the status of the crawl.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -X POST https://api.firecrawl.dev/v1/crawl \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer fc-YOUR_API_KEY' \
    -d '{
      "url": "https://docs.firecrawl.dev",
      "limit": 10,
      "scrapeOptions": {
        "formats": ["markdown", "html"]
      }
    }'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Returns a crawl job id and the url to check the status of the crawl.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "success": true,
  "id": "123-456-789",
  "url": "https://api.firecrawl.dev/v1/crawl/123-456-789"
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Check Crawl Job&lt;/h3&gt; 
&lt;p&gt;Used to check the status of a crawl job and get its result.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -X GET https://api.firecrawl.dev/v1/crawl/123-456-789 \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer YOUR_API_KEY'
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "status": "completed",
  "total": 36,
  "creditsUsed": 36,
  "expiresAt": "2024-00-00T00:00:00.000Z",
  "data": [
    {
      "markdown": "[Firecrawl Docs home page![light logo](https://mintlify.s3-us-west-1.amazonaws.com/firecrawl/logo/light.svg)!...",
      "html": "&amp;lt;!DOCTYPE html&amp;gt;&amp;lt;html lang=\"en\" class=\"js-focus-visible lg:[--scroll-mt:9.5rem]\" data-js-focus-visible=\"\"&amp;gt;...",
      "metadata": {
        "title": "Build a 'Chat with website' using Groq Llama 3 | Firecrawl",
        "language": "en",
        "sourceURL": "https://docs.firecrawl.dev/learn/rag-llama3",
        "description": "Learn how to use Firecrawl, Groq Llama 3, and Langchain to build a 'Chat with your website' bot.",
        "ogLocaleAlternate": [],
        "statusCode": 200
      }
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Scraping&lt;/h3&gt; 
&lt;p&gt;Used to scrape a URL and get its content in the specified formats.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -X POST https://api.firecrawl.dev/v1/scrape \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer YOUR_API_KEY' \
    -d '{
      "url": "https://docs.firecrawl.dev",
      "formats" : ["markdown", "html"]
    }'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Response:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "success": true,
  "data": {
    "markdown": "Launch Week I is here! [See our Day 2 Release 🚀](https://www.firecrawl.dev/blog/launch-week-i-day-2-doubled-rate-limits)[💥 Get 2 months free...",
    "html": "&amp;lt;!DOCTYPE html&amp;gt;&amp;lt;html lang=\"en\" class=\"light\" style=\"color-scheme: light;\"&amp;gt;&amp;lt;body class=\"__variable_36bd41 __variable_d7dc5d font-inter ...",
    "metadata": {
      "title": "Home - Firecrawl",
      "description": "Firecrawl crawls and converts any website into clean markdown.",
      "language": "en",
      "keywords": "Firecrawl,Markdown,Data,Mendable,Langchain",
      "robots": "follow, index",
      "ogTitle": "Firecrawl",
      "ogDescription": "Turn any website into LLM-ready data.",
      "ogUrl": "https://www.firecrawl.dev/",
      "ogImage": "https://www.firecrawl.dev/og.png?123",
      "ogLocaleAlternate": [],
      "ogSiteName": "Firecrawl",
      "sourceURL": "https://firecrawl.dev",
      "statusCode": 200
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Map&lt;/h3&gt; 
&lt;p&gt;Used to map a URL and get urls of the website. This returns most links present on the website.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -X POST https://api.firecrawl.dev/v1/map \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer YOUR_API_KEY' \
    -d '{
      "url": "https://firecrawl.dev"
    }'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Response:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "status": "success",
  "links": [
    "https://firecrawl.dev",
    "https://www.firecrawl.dev/pricing",
    "https://www.firecrawl.dev/blog",
    "https://www.firecrawl.dev/playground",
    "https://www.firecrawl.dev/smart-crawl",
  ]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Map with search&lt;/h4&gt; 
&lt;p&gt;Map with &lt;code&gt;search&lt;/code&gt; param allows you to search for specific urls inside a website.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -X POST https://api.firecrawl.dev/v1/map \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer YOUR_API_KEY' \
    -d '{
      "url": "https://firecrawl.dev",
      "search": "docs"
    }'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Response will be an ordered list from the most relevant to the least relevant.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "status": "success",
  "links": [
    "https://docs.firecrawl.dev",
    "https://docs.firecrawl.dev/sdks/python",
    "https://docs.firecrawl.dev/learn/rag-llama3",
  ]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Search&lt;/h3&gt; 
&lt;p&gt;Search the web and get full content from results&lt;/p&gt; 
&lt;p&gt;Firecrawl’s search API allows you to perform web searches and optionally scrape the search results in one operation.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Choose specific output formats (markdown, HTML, links, screenshots)&lt;/li&gt; 
 &lt;li&gt;Search the web with customizable parameters (language, country, etc.)&lt;/li&gt; 
 &lt;li&gt;Optionally retrieve content from search results in various formats&lt;/li&gt; 
 &lt;li&gt;Control the number of results and set timeouts&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -X POST https://api.firecrawl.dev/v1/search \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer fc-YOUR_API_KEY" \
  -d '{
    "query": "what is firecrawl?",
    "limit": 5
  }'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Response&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "success": true,
  "data": [
    {
      "url": "https://firecrawl.dev",
      "title": "Firecrawl | Home Page",
      "description": "Turn websites into LLM-ready data with Firecrawl"
    },
    {
      "url": "https://docs.firecrawl.dev",
      "title": "Documentation | Firecrawl",
      "description": "Learn how to use Firecrawl in your own applications"
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;With content scraping&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -X POST https://api.firecrawl.dev/v1/search \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer fc-YOUR_API_KEY" \
  -d '{
    "query": "what is firecrawl?",
    "limit": 5,
    "scrapeOptions": {
      "formats": ["markdown", "links"]
    }
  }'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Extract (Beta)&lt;/h3&gt; 
&lt;p&gt;Get structured data from entire websites with a prompt and/or a schema.&lt;/p&gt; 
&lt;p&gt;You can extract structured data from one or multiple URLs, including wildcards:&lt;/p&gt; 
&lt;p&gt;Single Page: Example: &lt;a href="https://firecrawl.dev/some-page"&gt;https://firecrawl.dev/some-page&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Multiple Pages / Full Domain Example: &lt;a href="https://firecrawl.dev/"&gt;https://firecrawl.dev/&lt;/a&gt;*&lt;/p&gt; 
&lt;p&gt;When you use /*, Firecrawl will automatically crawl and parse all URLs it can discover in that domain, then extract the requested data.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -X POST https://api.firecrawl.dev/v1/extract \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer YOUR_API_KEY' \
    -d '{
      "urls": [
        "https://firecrawl.dev/*", 
        "https://docs.firecrawl.dev/", 
        "https://www.ycombinator.com/companies"
      ],
      "prompt": "Extract the company mission, whether it is open source, and whether it is in Y Combinator from the page.",
      "schema": {
        "type": "object",
        "properties": {
          "company_mission": {
            "type": "string"
          },
          "is_open_source": {
            "type": "boolean"
          },
          "is_in_yc": {
            "type": "boolean"
          }
        },
        "required": [
          "company_mission",
          "is_open_source",
          "is_in_yc"
        ]
      }
    }'
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "success": true,
  "id": "44aa536d-f1cb-4706-ab87-ed0386685740",
  "urlTrace": []
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you are using the sdks, it will auto pull the response for you:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "success": true,
  "data": {
    "company_mission": "Firecrawl is the easiest way to extract data from the web. Developers use us to reliably convert URLs into LLM-ready markdown or structured data with a single API call.",
    "supports_sso": false,
    "is_open_source": true,
    "is_in_yc": true
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;LLM Extraction (Beta)&lt;/h3&gt; 
&lt;p&gt;Used to extract structured data from scraped pages.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -X POST https://api.firecrawl.dev/v1/scrape \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer YOUR_API_KEY' \
    -d '{
      "url": "https://www.mendable.ai/",
      "formats": ["json"],
      "jsonOptions": {
        "schema": {
          "type": "object",
          "properties": {
            "company_mission": {
                      "type": "string"
            },
            "supports_sso": {
                      "type": "boolean"
            },
            "is_open_source": {
                      "type": "boolean"
            },
            "is_in_yc": {
                      "type": "boolean"
            }
          },
          "required": [
            "company_mission",
            "supports_sso",
            "is_open_source",
            "is_in_yc"
          ]
        }
      }
    }'
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "success": true,
  "data": {
    "content": "Raw Content",
    "metadata": {
      "title": "Mendable",
      "description": "Mendable allows you to easily build AI chat applications. Ingest, customize, then deploy with one line of code anywhere you want. Brought to you by SideGuide",
      "robots": "follow, index",
      "ogTitle": "Mendable",
      "ogDescription": "Mendable allows you to easily build AI chat applications. Ingest, customize, then deploy with one line of code anywhere you want. Brought to you by SideGuide",
      "ogUrl": "https://mendable.ai/",
      "ogImage": "https://mendable.ai/mendable_new_og1.png",
      "ogLocaleAlternate": [],
      "ogSiteName": "Mendable",
      "sourceURL": "https://mendable.ai/"
    },
    "json": {
      "company_mission": "Train a secure AI on your technical resources that answers customer and employee questions so your team doesn't have to",
      "supports_sso": true,
      "is_open_source": false,
      "is_in_yc": true
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Extracting without a schema (New)&lt;/h3&gt; 
&lt;p&gt;You can now extract without a schema by just passing a &lt;code&gt;prompt&lt;/code&gt; to the endpoint. The llm chooses the structure of the data.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -X POST https://api.firecrawl.dev/v1/scrape \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer YOUR_API_KEY' \
    -d '{
      "url": "https://docs.firecrawl.dev/",
      "formats": ["json"],
      "jsonOptions": {
        "prompt": "Extract the company mission from the page."
      }
    }'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Interacting with the page with Actions (Cloud-only)&lt;/h3&gt; 
&lt;p&gt;Firecrawl allows you to perform various actions on a web page before scraping its content. This is particularly useful for interacting with dynamic content, navigating through pages, or accessing content that requires user interaction.&lt;/p&gt; 
&lt;p&gt;Here is an example of how to use actions to navigate to google.com, search for Firecrawl, click on the first result, and take a screenshot.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -X POST https://api.firecrawl.dev/v1/scrape \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer YOUR_API_KEY' \
    -d '{
        "url": "google.com",
        "formats": ["markdown"],
        "actions": [
            {"type": "wait", "milliseconds": 2000},
            {"type": "click", "selector": "textarea[title=\"Search\"]"},
            {"type": "wait", "milliseconds": 2000},
            {"type": "write", "text": "firecrawl"},
            {"type": "wait", "milliseconds": 2000},
            {"type": "press", "key": "ENTER"},
            {"type": "wait", "milliseconds": 3000},
            {"type": "click", "selector": "h3"},
            {"type": "wait", "milliseconds": 3000},
            {"type": "screenshot"}
        ]
    }'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Batch Scraping Multiple URLs (New)&lt;/h3&gt; 
&lt;p&gt;You can now batch scrape multiple URLs at the same time. It is very similar to how the /crawl endpoint works. It submits a batch scrape job and returns a job ID to check the status of the batch scrape.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -X POST https://api.firecrawl.dev/v1/batch/scrape \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer YOUR_API_KEY' \
    -d '{
      "urls": ["https://docs.firecrawl.dev", "https://docs.firecrawl.dev/sdks/overview"],
      "formats" : ["markdown", "html"]
    }'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Using Python SDK&lt;/h2&gt; 
&lt;h3&gt;Installing Python SDK&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install firecrawl-py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Crawl a website&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from firecrawl.firecrawl import FirecrawlApp
from firecrawl.firecrawl import ScrapeOptions

app = FirecrawlApp(api_key="fc-YOUR_API_KEY")

# Scrape a website:
scrape_status = app.scrape_url(
  'https://firecrawl.dev', 
  formats=["markdown", "html"]
)
print(scrape_status)

# Crawl a website:
crawl_status = app.crawl_url(
  'https://firecrawl.dev',
  limit=100,
  scrape_options=ScrapeOptions(
    formats=["markdown", "html"],),
  poll_interval=30
)
print(crawl_status)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Extracting structured data from a URL&lt;/h3&gt; 
&lt;p&gt;With LLM extraction, you can easily extract structured data from any URL. We support pydantic schemas to make it easier for you too. Here is how you to use it:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;class ArticleSchema(BaseModel):
    title: str
    points: int 
    by: str
    commentsURL: str

class TopArticlesSchema(BaseModel):
    top: List[ArticleSchema] = Field(..., description="Top 5 stories")

json_config = JsonConfig(schema=TopArticlesSchema.model_json_schema())

llm_extraction_result = app.scrape_url('https://news.ycombinator.com', formats=["json"], json=json_config)

print(llm_extraction_result.json)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Using the Node SDK&lt;/h2&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;p&gt;To install the Firecrawl Node SDK, you can use npm:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npm install @mendable/firecrawl-js
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Usage&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Get an API key from &lt;a href="https://firecrawl.dev"&gt;firecrawl.dev&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Set the API key as an environment variable named &lt;code&gt;FIRECRAWL_API_KEY&lt;/code&gt; or pass it as a parameter to the &lt;code&gt;FirecrawlApp&lt;/code&gt; class.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-js"&gt;import FirecrawlApp, { CrawlParams, CrawlStatusResponse } from '@mendable/firecrawl-js';

const app = new FirecrawlApp({apiKey: "fc-YOUR_API_KEY"});

// Scrape a website
const scrapeResponse = await app.scrapeUrl('https://firecrawl.dev', {
  formats: ['markdown', 'html'],
});

if (scrapeResponse) {
  console.log(scrapeResponse)
}

// Crawl a website
const crawlResponse = await app.crawlUrl('https://firecrawl.dev', {
  limit: 100,
  scrapeOptions: {
    formats: ['markdown', 'html'],
  }
} satisfies CrawlParams, true, 30) satisfies CrawlStatusResponse;

if (crawlResponse) {
  console.log(crawlResponse)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Extracting structured data from a URL&lt;/h3&gt; 
&lt;p&gt;With LLM extraction, you can easily extract structured data from any URL. We support zod schema to make it easier for you too. Here is how to use it:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-js"&gt;import FirecrawlApp from "@mendable/firecrawl-js";
import { z } from "zod";

const app = new FirecrawlApp({
  apiKey: "fc-YOUR_API_KEY"
});

// Define schema to extract contents into
const schema = z.object({
  top: z
    .array(
      z.object({
        title: z.string(),
        points: z.number(),
        by: z.string(),
        commentsURL: z.string(),
      })
    )
    .length(5)
    .describe("Top 5 stories on Hacker News"),
});

const scrapeResult = await app.scrapeUrl("https://news.ycombinator.com", {
  jsonOptions: { extractionSchema: schema },
});

console.log(scrapeResult.data["json"]);
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Open Source vs Cloud Offering&lt;/h2&gt; 
&lt;p&gt;Firecrawl is open source available under the AGPL-3.0 license.&lt;/p&gt; 
&lt;p&gt;To deliver the best possible product, we offer a hosted version of Firecrawl alongside our open-source offering. The cloud solution allows us to continuously innovate and maintain a high-quality, sustainable service for all users.&lt;/p&gt; 
&lt;p&gt;Firecrawl Cloud is available at &lt;a href="https://firecrawl.dev"&gt;firecrawl.dev&lt;/a&gt; and offers a range of features that are not available in the open source version:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/mendableai/firecrawl/main/img/open-source-cloud.png" alt="Open Source vs Cloud Offering" /&gt;&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We love contributions! Please read our &lt;a href="https://raw.githubusercontent.com/mendableai/firecrawl/main/CONTRIBUTING.md"&gt;contributing guide&lt;/a&gt; before submitting a pull request. If you'd like to self-host, refer to the &lt;a href="https://raw.githubusercontent.com/mendableai/firecrawl/main/SELF_HOST.md"&gt;self-hosting guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;It is the sole responsibility of the end users to respect websites' policies when scraping, searching and crawling with Firecrawl. Users are advised to adhere to the applicable privacy policies and terms of use of the websites prior to initiating any scraping activities. By default, Firecrawl respects the directives specified in the websites' robots.txt files when crawling. By utilizing Firecrawl, you expressly agree to comply with these conditions.&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;a href="https://github.com/mendableai/firecrawl/graphs/contributors"&gt; &lt;img alt="contributors" src="https://contrib.rocks/image?repo=mendableai/firecrawl" /&gt; &lt;/a&gt; 
&lt;h2&gt;License Disclaimer&lt;/h2&gt; 
&lt;p&gt;This project is primarily licensed under the GNU Affero General Public License v3.0 (AGPL-3.0), as specified in the LICENSE file in the root directory of this repository. However, certain components of this project are licensed under the MIT License. Refer to the LICENSE files in these specific directories for details.&lt;/p&gt; 
&lt;p&gt;Please note:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The AGPL-3.0 license applies to all parts of the project unless otherwise specified.&lt;/li&gt; 
 &lt;li&gt;The SDKs and some UI components are licensed under the MIT License. Refer to the LICENSE files in these specific directories for details.&lt;/li&gt; 
 &lt;li&gt;When using or contributing to this project, ensure you comply with the appropriate license terms for the specific component you are working with.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more details on the licensing of specific components, please refer to the LICENSE files in the respective directories or contact the project maintainers.&lt;/p&gt; 
&lt;p align="right" style="font-size: 14px; color: #555; margin-top: 20px;"&gt; &lt;a href="https://raw.githubusercontent.com/mendableai/firecrawl/main/#readme-top" style="text-decoration: none; color: #007bff; font-weight: bold;"&gt; ↑ Back to Top ↑ &lt;/a&gt; &lt;/p&gt;</description>
    </item>
    
    <item>
      <title>fastapi/full-stack-fastapi-template</title>
      <link>https://github.com/fastapi/full-stack-fastapi-template</link>
      <description>&lt;p&gt;Full stack, modern web application template. Using FastAPI, React, SQLModel, PostgreSQL, Docker, GitHub Actions, automatic HTTPS and more.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Full Stack FastAPI Template&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/fastapi/full-stack-fastapi-template/actions?query=workflow%3ATest" target="_blank"&gt;&lt;img src="https://github.com/fastapi/full-stack-fastapi-template/workflows/Test/badge.svg?sanitize=true" alt="Test" /&gt;&lt;/a&gt; &lt;a href="https://coverage-badge.samuelcolvin.workers.dev/redirect/fastapi/full-stack-fastapi-template" target="_blank"&gt;&lt;img src="https://coverage-badge.samuelcolvin.workers.dev/fastapi/full-stack-fastapi-template.svg?sanitize=true" alt="Coverage" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Technology Stack and Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;⚡ &lt;a href="https://fastapi.tiangolo.com"&gt;&lt;strong&gt;FastAPI&lt;/strong&gt;&lt;/a&gt; for the Python backend API. 
  &lt;ul&gt; 
   &lt;li&gt;🧰 &lt;a href="https://sqlmodel.tiangolo.com"&gt;SQLModel&lt;/a&gt; for the Python SQL database interactions (ORM).&lt;/li&gt; 
   &lt;li&gt;🔍 &lt;a href="https://docs.pydantic.dev"&gt;Pydantic&lt;/a&gt;, used by FastAPI, for the data validation and settings management.&lt;/li&gt; 
   &lt;li&gt;💾 &lt;a href="https://www.postgresql.org"&gt;PostgreSQL&lt;/a&gt; as the SQL database.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;🚀 &lt;a href="https://react.dev"&gt;React&lt;/a&gt; for the frontend. 
  &lt;ul&gt; 
   &lt;li&gt;💃 Using TypeScript, hooks, Vite, and other parts of a modern frontend stack.&lt;/li&gt; 
   &lt;li&gt;🎨 &lt;a href="https://chakra-ui.com"&gt;Chakra UI&lt;/a&gt; for the frontend components.&lt;/li&gt; 
   &lt;li&gt;🤖 An automatically generated frontend client.&lt;/li&gt; 
   &lt;li&gt;🧪 &lt;a href="https://playwright.dev"&gt;Playwright&lt;/a&gt; for End-to-End testing.&lt;/li&gt; 
   &lt;li&gt;🦇 Dark mode support.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;🐋 &lt;a href="https://www.docker.com"&gt;Docker Compose&lt;/a&gt; for development and production.&lt;/li&gt; 
 &lt;li&gt;🔒 Secure password hashing by default.&lt;/li&gt; 
 &lt;li&gt;🔑 JWT (JSON Web Token) authentication.&lt;/li&gt; 
 &lt;li&gt;📫 Email based password recovery.&lt;/li&gt; 
 &lt;li&gt;✅ Tests with &lt;a href="https://pytest.org"&gt;Pytest&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;📞 &lt;a href="https://traefik.io"&gt;Traefik&lt;/a&gt; as a reverse proxy / load balancer.&lt;/li&gt; 
 &lt;li&gt;🚢 Deployment instructions using Docker Compose, including how to set up a frontend Traefik proxy to handle automatic HTTPS certificates.&lt;/li&gt; 
 &lt;li&gt;🏭 CI (continuous integration) and CD (continuous deployment) based on GitHub Actions.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Dashboard Login&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/fastapi/full-stack-fastapi-template"&gt;&lt;img src="https://raw.githubusercontent.com/fastapi/full-stack-fastapi-template/master/img/login.png" alt="API docs" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Dashboard - Admin&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/fastapi/full-stack-fastapi-template"&gt;&lt;img src="https://raw.githubusercontent.com/fastapi/full-stack-fastapi-template/master/img/dashboard.png" alt="API docs" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Dashboard - Create User&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/fastapi/full-stack-fastapi-template"&gt;&lt;img src="https://raw.githubusercontent.com/fastapi/full-stack-fastapi-template/master/img/dashboard-create.png" alt="API docs" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Dashboard - Items&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/fastapi/full-stack-fastapi-template"&gt;&lt;img src="https://raw.githubusercontent.com/fastapi/full-stack-fastapi-template/master/img/dashboard-items.png" alt="API docs" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Dashboard - User Settings&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/fastapi/full-stack-fastapi-template"&gt;&lt;img src="https://raw.githubusercontent.com/fastapi/full-stack-fastapi-template/master/img/dashboard-user-settings.png" alt="API docs" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Dashboard - Dark Mode&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/fastapi/full-stack-fastapi-template"&gt;&lt;img src="https://raw.githubusercontent.com/fastapi/full-stack-fastapi-template/master/img/dashboard-dark.png" alt="API docs" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Interactive API Documentation&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/fastapi/full-stack-fastapi-template"&gt;&lt;img src="https://raw.githubusercontent.com/fastapi/full-stack-fastapi-template/master/img/docs.png" alt="API docs" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;How To Use It&lt;/h2&gt; 
&lt;p&gt;You can &lt;strong&gt;just fork or clone&lt;/strong&gt; this repository and use it as is.&lt;/p&gt; 
&lt;p&gt;✨ It just works. ✨&lt;/p&gt; 
&lt;h3&gt;How to Use a Private Repository&lt;/h3&gt; 
&lt;p&gt;If you want to have a private repository, GitHub won't allow you to simply fork it as it doesn't allow changing the visibility of forks.&lt;/p&gt; 
&lt;p&gt;But you can do the following:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Create a new GitHub repo, for example &lt;code&gt;my-full-stack&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Clone this repository manually, set the name with the name of the project you want to use, for example &lt;code&gt;my-full-stack&lt;/code&gt;:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone git@github.com:fastapi/full-stack-fastapi-template.git my-full-stack
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Enter into the new directory:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd my-full-stack
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Set the new origin to your new repository, copy it from the GitHub interface, for example:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git remote set-url origin git@github.com:octocat/my-full-stack.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Add this repo as another "remote" to allow you to get updates later:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git remote add upstream git@github.com:fastapi/full-stack-fastapi-template.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Push the code to your new repository:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git push -u origin master
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Update From the Original Template&lt;/h3&gt; 
&lt;p&gt;After cloning the repository, and after doing changes, you might want to get the latest changes from this original template.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Make sure you added the original repository as a remote, you can check it with:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git remote -v

origin    git@github.com:octocat/my-full-stack.git (fetch)
origin    git@github.com:octocat/my-full-stack.git (push)
upstream    git@github.com:fastapi/full-stack-fastapi-template.git (fetch)
upstream    git@github.com:fastapi/full-stack-fastapi-template.git (push)
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Pull the latest changes without merging:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git pull --no-commit upstream master
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will download the latest changes from this template without committing them, that way you can check everything is right before committing.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;If there are conflicts, solve them in your editor.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Once you are done, commit the changes:&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git merge --continue
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Configure&lt;/h3&gt; 
&lt;p&gt;You can then update configs in the &lt;code&gt;.env&lt;/code&gt; files to customize your configurations.&lt;/p&gt; 
&lt;p&gt;Before deploying it, make sure you change at least the values for:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;SECRET_KEY&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;FIRST_SUPERUSER_PASSWORD&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;POSTGRES_PASSWORD&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You can (and should) pass these as environment variables from secrets.&lt;/p&gt; 
&lt;p&gt;Read the &lt;a href="https://raw.githubusercontent.com/fastapi/full-stack-fastapi-template/master/deployment.md"&gt;deployment.md&lt;/a&gt; docs for more details.&lt;/p&gt; 
&lt;h3&gt;Generate Secret Keys&lt;/h3&gt; 
&lt;p&gt;Some environment variables in the &lt;code&gt;.env&lt;/code&gt; file have a default value of &lt;code&gt;changethis&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;You have to change them with a secret key, to generate secret keys you can run the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python -c "import secrets; print(secrets.token_urlsafe(32))"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Copy the content and use that as password / secret key. And run that again to generate another secure key.&lt;/p&gt; 
&lt;h2&gt;How To Use It - Alternative With Copier&lt;/h2&gt; 
&lt;p&gt;This repository also supports generating a new project using &lt;a href="https://copier.readthedocs.io"&gt;Copier&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;It will copy all the files, ask you configuration questions, and update the &lt;code&gt;.env&lt;/code&gt; files with your answers.&lt;/p&gt; 
&lt;h3&gt;Install Copier&lt;/h3&gt; 
&lt;p&gt;You can install Copier with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install copier
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or better, if you have &lt;a href="https://pipx.pypa.io/"&gt;&lt;code&gt;pipx&lt;/code&gt;&lt;/a&gt;, you can run it with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pipx install copier
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: If you have &lt;code&gt;pipx&lt;/code&gt;, installing copier is optional, you could run it directly.&lt;/p&gt; 
&lt;h3&gt;Generate a Project With Copier&lt;/h3&gt; 
&lt;p&gt;Decide a name for your new project's directory, you will use it below. For example, &lt;code&gt;my-awesome-project&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Go to the directory that will be the parent of your project, and run the command with your project's name:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;copier copy https://github.com/fastapi/full-stack-fastapi-template my-awesome-project --trust
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you have &lt;code&gt;pipx&lt;/code&gt; and you didn't install &lt;code&gt;copier&lt;/code&gt;, you can run it directly:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pipx run copier copy https://github.com/fastapi/full-stack-fastapi-template my-awesome-project --trust
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt; the &lt;code&gt;--trust&lt;/code&gt; option is necessary to be able to execute a &lt;a href="https://github.com/fastapi/full-stack-fastapi-template/raw/master/.copier/update_dotenv.py"&gt;post-creation script&lt;/a&gt; that updates your &lt;code&gt;.env&lt;/code&gt; files.&lt;/p&gt; 
&lt;h3&gt;Input Variables&lt;/h3&gt; 
&lt;p&gt;Copier will ask you for some data, you might want to have at hand before generating the project.&lt;/p&gt; 
&lt;p&gt;But don't worry, you can just update any of that in the &lt;code&gt;.env&lt;/code&gt; files afterwards.&lt;/p&gt; 
&lt;p&gt;The input variables, with their default values (some auto generated) are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;project_name&lt;/code&gt;: (default: &lt;code&gt;"FastAPI Project"&lt;/code&gt;) The name of the project, shown to API users (in .env).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;stack_name&lt;/code&gt;: (default: &lt;code&gt;"fastapi-project"&lt;/code&gt;) The name of the stack used for Docker Compose labels and project name (no spaces, no periods) (in .env).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;secret_key&lt;/code&gt;: (default: &lt;code&gt;"changethis"&lt;/code&gt;) The secret key for the project, used for security, stored in .env, you can generate one with the method above.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;first_superuser&lt;/code&gt;: (default: &lt;code&gt;"admin@example.com"&lt;/code&gt;) The email of the first superuser (in .env).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;first_superuser_password&lt;/code&gt;: (default: &lt;code&gt;"changethis"&lt;/code&gt;) The password of the first superuser (in .env).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;smtp_host&lt;/code&gt;: (default: "") The SMTP server host to send emails, you can set it later in .env.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;smtp_user&lt;/code&gt;: (default: "") The SMTP server user to send emails, you can set it later in .env.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;smtp_password&lt;/code&gt;: (default: "") The SMTP server password to send emails, you can set it later in .env.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;emails_from_email&lt;/code&gt;: (default: &lt;code&gt;"info@example.com"&lt;/code&gt;) The email account to send emails from, you can set it later in .env.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;postgres_password&lt;/code&gt;: (default: &lt;code&gt;"changethis"&lt;/code&gt;) The password for the PostgreSQL database, stored in .env, you can generate one with the method above.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;sentry_dsn&lt;/code&gt;: (default: "") The DSN for Sentry, if you are using it, you can set it later in .env.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Backend Development&lt;/h2&gt; 
&lt;p&gt;Backend docs: &lt;a href="https://raw.githubusercontent.com/fastapi/full-stack-fastapi-template/master/backend/README.md"&gt;backend/README.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Frontend Development&lt;/h2&gt; 
&lt;p&gt;Frontend docs: &lt;a href="https://raw.githubusercontent.com/fastapi/full-stack-fastapi-template/master/frontend/README.md"&gt;frontend/README.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Deployment&lt;/h2&gt; 
&lt;p&gt;Deployment docs: &lt;a href="https://raw.githubusercontent.com/fastapi/full-stack-fastapi-template/master/deployment.md"&gt;deployment.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;p&gt;General development docs: &lt;a href="https://raw.githubusercontent.com/fastapi/full-stack-fastapi-template/master/development.md"&gt;development.md&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;This includes using Docker Compose, custom local domains, &lt;code&gt;.env&lt;/code&gt; configurations, etc.&lt;/p&gt; 
&lt;h2&gt;Release Notes&lt;/h2&gt; 
&lt;p&gt;Check the file &lt;a href="https://raw.githubusercontent.com/fastapi/full-stack-fastapi-template/master/release-notes.md"&gt;release-notes.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;The Full Stack FastAPI Template is licensed under the terms of the MIT license.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>menloresearch/jan</title>
      <link>https://github.com/menloresearch/jan</link>
      <description>&lt;p&gt;Jan is an open source alternative to ChatGPT that runs 100% offline on your computer&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Jan - Local AI Assistant&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/menloresearch/jan/dev/docs/src/pages/docs/_assets/jan-app.png" alt="Jan AI" /&gt;&lt;/p&gt; 
&lt;p align="center"&gt; 
 &lt;!-- ALL-CONTRIBUTORS-BADGE:START - Do not remove or modify this section --&gt; &lt;img alt="GitHub commit activity" src="https://img.shields.io/github/commit-activity/m/menloresearch/jan" /&gt; &lt;img alt="Github Last Commit" src="https://img.shields.io/github/last-commit/menloresearch/jan" /&gt; &lt;img alt="Github Contributors" src="https://img.shields.io/github/contributors/menloresearch/jan" /&gt; &lt;img alt="GitHub closed issues" src="https://img.shields.io/github/issues-closed/menloresearch/jan" /&gt; &lt;img alt="Discord" src="https://img.shields.io/discord/1107178041848909847?label=discord" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://jan.ai/docs/quickstart"&gt;Getting Started&lt;/a&gt; - &lt;a href="https://jan.ai/docs"&gt;Docs&lt;/a&gt; - &lt;a href="https://jan.ai/changelog"&gt;Changelog&lt;/a&gt; - &lt;a href="https://github.com/menloresearch/jan/issues"&gt;Bug reports&lt;/a&gt; - &lt;a href="https://discord.gg/AsJ8krTT3N"&gt;Discord&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;Jan is an AI assistant that can run 100% offline on your device. Download and run LLMs with &lt;strong&gt;full control&lt;/strong&gt; and &lt;strong&gt;privacy&lt;/strong&gt;.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;The easiest way to get started is by downloading one of the following versions for your respective operating system:&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt;&lt;b&gt;Platform&lt;/b&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;b&gt;Stable&lt;/b&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;b&gt;Nightly&lt;/b&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;b&gt;Windows&lt;/b&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://app.jan.ai/download/latest/win-x64"&gt;jan.exe&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://app.jan.ai/download/nightly/win-x64"&gt;jan.exe&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;b&gt;macOS&lt;/b&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://app.jan.ai/download/latest/mac-universal"&gt;jan.dmg&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://app.jan.ai/download/nightly/mac-universal"&gt;jan.dmg&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;b&gt;Linux (deb)&lt;/b&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://app.jan.ai/download/latest/linux-amd64-deb"&gt;jan.deb&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://app.jan.ai/download/nightly/linux-amd64-deb"&gt;jan.deb&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;b&gt;Linux (AppImage)&lt;/b&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://app.jan.ai/download/latest/linux-amd64-appimage"&gt;jan.AppImage&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://app.jan.ai/download/nightly/linux-amd64-appimage"&gt;jan.AppImage&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p&gt;Download from &lt;a href="https://jan.ai/"&gt;jan.ai&lt;/a&gt; or &lt;a href="https://github.com/menloresearch/jan/releases"&gt;GitHub Releases&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Local AI Models&lt;/strong&gt;: Download and run LLMs (Llama, Gemma, Qwen, etc.) from HuggingFace&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cloud Integration&lt;/strong&gt;: Connect to OpenAI, Anthropic, Mistral, Groq, and others&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Custom Assistants&lt;/strong&gt;: Create specialized AI assistants for your tasks&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;OpenAI-Compatible API&lt;/strong&gt;: Local server at &lt;code&gt;localhost:1337&lt;/code&gt; for other applications&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Model Context Protocol&lt;/strong&gt;: MCP integration for enhanced capabilities&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Privacy First&lt;/strong&gt;: Everything runs locally when you want it to&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Build from Source&lt;/h2&gt; 
&lt;p&gt;For those who enjoy the scenic route:&lt;/p&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Node.js ≥ 20.0.0&lt;/li&gt; 
 &lt;li&gt;Yarn ≥ 1.22.0&lt;/li&gt; 
 &lt;li&gt;Make ≥ 3.81&lt;/li&gt; 
 &lt;li&gt;Rust (for Tauri)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Run with Make&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/menloresearch/jan
cd jan
make dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This handles everything: installs dependencies, builds core components, and launches the app.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Available make targets:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;make dev&lt;/code&gt; - Full development setup and launch&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make build&lt;/code&gt; - Production build&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make test&lt;/code&gt; - Run tests and linting&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make clean&lt;/code&gt; - Delete everything and start fresh&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Run with Mise (easier)&lt;/h3&gt; 
&lt;p&gt;You can also run with &lt;a href="https://mise.jdx.dev/"&gt;mise&lt;/a&gt;, which is a bit easier as it ensures Node.js, Rust, and other dependency versions are automatically managed:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/menloresearch/jan
cd jan

# Install mise (if not already installed)
curl https://mise.run | sh

# Install tools and start development
mise install    # installs Node.js, Rust, and other tools
mise dev        # runs the full development setup
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Available mise commands:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;mise dev&lt;/code&gt; - Full development setup and launch&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;mise build&lt;/code&gt; - Production build&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;mise test&lt;/code&gt; - Run tests and linting&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;mise clean&lt;/code&gt; - Delete everything and start fresh&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;mise tasks&lt;/code&gt; - List all available tasks&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Manual Commands&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;yarn install
yarn build:core
yarn build:extensions
yarn dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;System Requirements&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Minimum specs for a decent experience:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;macOS&lt;/strong&gt;: 13.6+ (8GB RAM for 3B models, 16GB for 7B, 32GB for 13B)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Windows&lt;/strong&gt;: 10+ with GPU support for NVIDIA/AMD/Intel Arc&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Linux&lt;/strong&gt;: Most distributions work, GPU acceleration available&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For detailed compatibility, check our &lt;a href="https://jan.ai/docs/desktop/mac"&gt;installation guides&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Troubleshooting&lt;/h2&gt; 
&lt;p&gt;If things go sideways:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Check our &lt;a href="https://jan.ai/docs/troubleshooting"&gt;troubleshooting docs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Copy your error logs and system specs&lt;/li&gt; 
 &lt;li&gt;Ask for help in our &lt;a href="https://discord.gg/FTk2MvZwJH"&gt;Discord&lt;/a&gt; &lt;code&gt;#🆘|jan-help&lt;/code&gt; channel&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Contributions welcome. See &lt;a href="https://raw.githubusercontent.com/menloresearch/jan/dev/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for the full spiel.&lt;/p&gt; 
&lt;h2&gt;Links&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://jan.ai/docs"&gt;Documentation&lt;/a&gt; - The manual you should read&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://jan.ai/api-reference"&gt;API Reference&lt;/a&gt; - For the technically inclined&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://jan.ai/changelog"&gt;Changelog&lt;/a&gt; - What we broke and fixed&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/FTk2MvZwJH"&gt;Discord&lt;/a&gt; - Where the community lives&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contact&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Bugs&lt;/strong&gt;: &lt;a href="https://github.com/menloresearch/jan/issues"&gt;GitHub Issues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Business&lt;/strong&gt;: &lt;a href="mailto:hello@jan.ai"&gt;hello@jan.ai&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Jobs&lt;/strong&gt;: &lt;a href="mailto:hr@jan.ai"&gt;hr@jan.ai&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;General Discussion&lt;/strong&gt;: &lt;a href="https://discord.gg/FTk2MvZwJH"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Apache 2.0 - Because sharing is caring.&lt;/p&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;p&gt;Built on the shoulders of giants:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ggerganov/llama.cpp"&gt;Llama.cpp&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://tauri.app/"&gt;Tauri&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/scalar/scalar"&gt;Scalar&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>midday-ai/midday</title>
      <link>https://github.com/midday-ai/midday</link>
      <description>&lt;p&gt;Invoicing, Time tracking, File reconciliation, Storage, Financial Overview &amp; your own Assistant made for Freelancers&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/midday-ai/midday/main/github.png" alt="hero" /&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;/p&gt;
&lt;h1 align="center"&gt;&lt;b&gt;Midday&lt;/b&gt;&lt;/h1&gt; 
&lt;p align="center"&gt; Run your business smarter &lt;br /&gt; &lt;br /&gt; &lt;a href="https://go.midday.ai/anPiuRx"&gt;Discord&lt;/a&gt; · &lt;a href="https://midday.ai"&gt;Website&lt;/a&gt; · &lt;a href="https://github.com/midday-ai/midday/issues"&gt;Issues&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://go.midday.ai/K7GwMoQ"&gt; &lt;img src="https://img.shields.io/badge/Supabase-3ECF8E?style=for-the-badge&amp;amp;logo=supabase&amp;amp;logoColor=white" alt="Supabase" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;About Midday&lt;/h2&gt; 
&lt;p&gt;Midday is an all-in-one tool designed to help freelancers, contractors, consultants, and solo entrepreneurs manage their business operations more efficiently. It integrates various functions typically scattered across multiple platforms into a single, cohesive system.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Time Tracking&lt;/strong&gt;: Allows for live time tracking of projects to boost productivity and collaboration, providing insightful project overviews.&lt;br /&gt; &lt;strong&gt;Invoicing&lt;/strong&gt;: An upcoming feature that will enable users to create web-based invoices, collaborate in real-time, and synchronize projects seamlessly.&lt;br /&gt; &lt;strong&gt;Magic Inbox&lt;/strong&gt;: Automatically matches incoming invoices or receipts to the correct transactions, simplifying financial tracking and organization.&lt;br /&gt; &lt;strong&gt;Vault&lt;/strong&gt;: Secure storage for important files like contracts and agreements, keeping everything in one place for easy access​.&lt;br /&gt; &lt;strong&gt;Seamless Export&lt;/strong&gt;: Facilitates easy export of financial data, packaged neatly in CSV files for accountants.&lt;br /&gt; &lt;strong&gt;Assistant&lt;/strong&gt;: Provides tailored insights into financial situations, helping users understand spending patterns, cut costs, and find documents.&lt;br /&gt;&lt;/p&gt; 
&lt;h2&gt;Get started&lt;/h2&gt; 
&lt;p&gt;We are working on the documentation to get started with Midday for local development: &lt;a href="https://docs.midday.ai"&gt;https://docs.midday.ai&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;App Architecture&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Monorepo&lt;/li&gt; 
 &lt;li&gt;Bun&lt;/li&gt; 
 &lt;li&gt;React&lt;/li&gt; 
 &lt;li&gt;TypeScript&lt;/li&gt; 
 &lt;li&gt;Nextjs&lt;/li&gt; 
 &lt;li&gt;Supabase&lt;/li&gt; 
 &lt;li&gt;Shadcn&lt;/li&gt; 
 &lt;li&gt;Tauri&lt;/li&gt; 
 &lt;li&gt;Expo&lt;/li&gt; 
 &lt;li&gt;TailwindCSS&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Hosting&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Supabase (database, storage, realtime, auth)&lt;/li&gt; 
 &lt;li&gt;Vercel (Website, Dashboard)&lt;/li&gt; 
 &lt;li&gt;Fly.io (API/tRPC)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Services&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Trigger.dev (background jobs)&lt;/li&gt; 
 &lt;li&gt;Resend (Transactional &amp;amp; Marketing)&lt;/li&gt; 
 &lt;li&gt;Novu (notifications)&lt;/li&gt; 
 &lt;li&gt;Github Actions (CI/CD)&lt;/li&gt; 
 &lt;li&gt;GoCardLess (Bank connection EU)&lt;/li&gt; 
 &lt;li&gt;Plaid (Bank connection in Canada and US)&lt;/li&gt; 
 &lt;li&gt;Teller (Bank connection in the US)&lt;/li&gt; 
 &lt;li&gt;OpenPanel (Events and Analytics)&lt;/li&gt; 
 &lt;li&gt;Polar (Payment processing)&lt;/li&gt; 
 &lt;li&gt;Typesense (Search)&lt;/li&gt; 
 &lt;li&gt;Mistral&lt;/li&gt; 
 &lt;li&gt;OpenAI&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Repo Activity&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://repobeats.axiom.co/api/embed/96aae855e5dd87c30d53c1d154b37cf7aa5a89b3.svg?sanitize=true" alt="Alt" title="Repobeats analytics image" /&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the &lt;strong&gt;&lt;a href="https://opensource.org/licenses/AGPL-3.0"&gt;AGPL-3.0&lt;/a&gt;&lt;/strong&gt; for non-commercial use.&lt;/p&gt; 
&lt;h3&gt;Commercial Use&lt;/h3&gt; 
&lt;p&gt;For commercial use or deployments requiring a setup fee, please contact us for a commercial license at &lt;a href="mailto:engineer@midday.ai"&gt;engineer@midday.ai&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;By using this software, you agree to the terms of the license.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>xiaoyaocz/dart_simple_live</title>
      <link>https://github.com/xiaoyaocz/dart_simple_live</link>
      <description>&lt;p&gt;简简单单的看直播&lt;/p&gt;&lt;hr&gt;&lt;blockquote&gt; 
 &lt;h3&gt;⚠ 本项目不提供Release安装包，请自行编译后运行测试。&lt;/h3&gt; 
&lt;/blockquote&gt; 
&lt;p align="center"&gt; &lt;img width="128" src="https://raw.githubusercontent.com/xiaoyaocz/dart_simple_live/master/assets/logo.png" alt="Simple Live logo" /&gt; &lt;/p&gt; 
&lt;h2 align="center"&gt;Simple Live&lt;/h2&gt; 
&lt;p align="center"&gt; 简简单单的看直播 &lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/xiaoyaocz/dart_simple_live/master/assets/screenshot_light.jpg" alt="浅色模式" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/xiaoyaocz/dart_simple_live/master/assets/screenshot_dark.jpg" alt="深色模式" /&gt;&lt;/p&gt; 
&lt;h2&gt;支持直播平台：&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;虎牙直播&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;斗鱼直播&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;哔哩哔哩直播&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;抖音直播&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;APP支持平台&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Android&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; iOS&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Windows &lt;code&gt;BETA&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; MacOS &lt;code&gt;BETA&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Linux &lt;code&gt;BETA&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Android TV &lt;code&gt;BETA&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;项目结构&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;simple_live_core&lt;/code&gt; 项目核心库，实现获取各个网站的信息及弹幕。&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;simple_live_console&lt;/code&gt; 基于simple_live_core的控制台程序。&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;simple_live_app&lt;/code&gt; 基于核心库实现的Flutter APP客户端。&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;simple_live_tv_app&lt;/code&gt; 基于核心库实现的Flutter Android TV客户端。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;环境&lt;/h2&gt; 
&lt;p&gt;Flutter : &lt;code&gt;3.22&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;参考及引用&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/xiaoyaocz/AllLive"&gt;AllLive&lt;/a&gt; &lt;code&gt;本项目的C#版，有兴趣可以看看&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/xiaoyaocz/dart_tars_protocol.git"&gt;dart_tars_protocol&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/wbt5/real-url"&gt;wbt5/real-url&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/lovelyyoshino/Bilibili-Live-API/raw/master/API.WebSocket.md"&gt;lovelyyoshino/Bilibili-Live-API&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/IsoaSFlus/danmaku"&gt;IsoaSFlus/danmaku&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/BacooTang/huya-danmu"&gt;BacooTang/huya-danmu&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/TarsCloud/Tars"&gt;TarsCloud/Tars&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/YunzhiYike/douyin-live"&gt;YunzhiYike/douyin-live&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/5ime/Tiktok_Signature"&gt;5ime/Tiktok_Signature&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;声明&lt;/h2&gt; 
&lt;p&gt;本项目的所有功能都是基于互联网上公开的资料开发，无任何破解、逆向工程等行为。&lt;/p&gt; 
&lt;p&gt;本项目仅用于学习交流编程技术，严禁将本项目用于商业目的。如有任何商业行为，均与本项目无关。&lt;/p&gt; 
&lt;p&gt;如果本项目存在侵犯您的合法权益的情况，请及时与开发者联系，开发者将会及时删除有关内容。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>microsoft/generative-ai-for-beginners</title>
      <link>https://github.com/microsoft/generative-ai-for-beginners</link>
      <description>&lt;p&gt;21 Lessons, Get Started Building with Generative AI 🔗 https://microsoft.github.io/generative-ai-for-beginners/&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/images/repo-thumbnailv4-fixed.png?WT.mc_id=academic-105485-koreyst" alt="Generative AI For Beginners" /&gt;&lt;/p&gt; 
&lt;h3&gt;21 Lessons teaching everything you need to know to start building Generative AI applications&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/microsoft/Generative-AI-For-Beginners/raw/master/LICENSE?WT.mc_id=academic-105485-koreyst"&gt;&lt;img src="https://img.shields.io/github/license/microsoft/Generative-AI-For-Beginners.svg?sanitize=true" alt="GitHub license" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/microsoft/Generative-AI-For-Beginners/graphs/contributors/?WT.mc_id=academic-105485-koreyst"&gt;&lt;img src="https://img.shields.io/github/contributors/microsoft/Generative-AI-For-Beginners.svg?sanitize=true" alt="GitHub contributors" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/microsoft/Generative-AI-For-Beginners/issues/?WT.mc_id=academic-105485-koreyst"&gt;&lt;img src="https://img.shields.io/github/issues/microsoft/Generative-AI-For-Beginners.svg?sanitize=true" alt="GitHub issues" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/microsoft/Generative-AI-For-Beginners/pulls/?WT.mc_id=academic-105485-koreyst"&gt;&lt;img src="https://img.shields.io/github/issues-pr/microsoft/Generative-AI-For-Beginners.svg?sanitize=true" alt="GitHub pull-requests" /&gt;&lt;/a&gt; &lt;a href="http://makeapullrequest.com?WT.mc_id=academic-105485-koreyst"&gt;&lt;img src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square" alt="PRs Welcome" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://GitHub.com/microsoft/Generative-AI-For-Beginners/watchers/?WT.mc_id=academic-105485-koreyst"&gt;&lt;img src="https://img.shields.io/github/watchers/microsoft/Generative-AI-For-Beginners.svg?style=social&amp;amp;label=Watch" alt="GitHub watchers" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/microsoft/Generative-AI-For-Beginners/network/?WT.mc_id=academic-105485-koreyst"&gt;&lt;img src="https://img.shields.io/github/forks/microsoft/Generative-AI-For-Beginners.svg?style=social&amp;amp;label=Fork" alt="GitHub forks" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/microsoft/Generative-AI-For-Beginners/stargazers/?WT.mc_id=academic-105485-koreyst"&gt;&lt;img src="https://img.shields.io/github/stars/microsoft/Generative-AI-For-Beginners.svg?style=social&amp;amp;label=Star" alt="GitHub stars" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://aka.ms/genai-discord?WT.mc_id=academic-105485-koreyst"&gt;&lt;img src="https://dcbadge.limes.pink/api/server/ByRwuEEgH4" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;🌐 Multi-Language Support&lt;/h3&gt; 
&lt;h4&gt;Supported via GitHub Action (Automated &amp;amp; Always Up-to-Date)&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/fr/README.md"&gt;French&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/es/README.md"&gt;Spanish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/de/README.md"&gt;German&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/ru/README.md"&gt;Russian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/ar/README.md"&gt;Arabic&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/fa/README.md"&gt;Persian (Farsi)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/ur/README.md"&gt;Urdu&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/zh/README.md"&gt;Chinese (Simplified)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/mo/README.md"&gt;Chinese (Traditional, Macau)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/hk/README.md"&gt;Chinese (Traditional, Hong Kong)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/tw/README.md"&gt;Chinese (Traditional, Taiwan)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/ja/README.md"&gt;Japanese&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/ko/README.md"&gt;Korean&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/hi/README.md"&gt;Hindi&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/bn/README.md"&gt;Bengali&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/mr/README.md"&gt;Marathi&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/ne/README.md"&gt;Nepali&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/pa/README.md"&gt;Punjabi (Gurmukhi)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/pt/README.md"&gt;Portuguese (Portugal)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/br/README.md"&gt;Portuguese (Brazil)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/it/README.md"&gt;Italian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/pl/README.md"&gt;Polish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/tr/README.md"&gt;Turkish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/el/README.md"&gt;Greek&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/th/README.md"&gt;Thai&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/sv/README.md"&gt;Swedish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/da/README.md"&gt;Danish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/no/README.md"&gt;Norwegian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/fi/README.md"&gt;Finnish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/nl/README.md"&gt;Dutch&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/he/README.md"&gt;Hebrew&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/vi/README.md"&gt;Vietnamese&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/id/README.md"&gt;Indonesian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/ms/README.md"&gt;Malay&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/tl/README.md"&gt;Tagalog (Filipino)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/sw/README.md"&gt;Swahili&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/hu/README.md"&gt;Hungarian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/cs/README.md"&gt;Czech&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/sk/README.md"&gt;Slovak&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/ro/README.md"&gt;Romanian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/bg/README.md"&gt;Bulgarian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/sr/README.md"&gt;Serbian (Cyrillic)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/hr/README.md"&gt;Croatian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/sl/README.md"&gt;Slovenian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/uk/README.md"&gt;Ukrainian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/translations/my/README.md"&gt;Burmese (Myanmar)&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Generative AI for Beginners (Version 3) - A Course&lt;/h1&gt; 
&lt;p&gt;Learn the fundamentals of building Generative AI applications with our 21-lesson comprehensive course by Microsoft Cloud Advocates.&lt;/p&gt; 
&lt;h2&gt;🌱 Getting Started&lt;/h2&gt; 
&lt;p&gt;This course has 21 lessons. Each lesson covers its own topic so start wherever you like!&lt;/p&gt; 
&lt;p&gt;Lessons are labeled either "Learn" lessons explaining a Generative AI concept or "Build" lessons that explain a concept and code examples in both &lt;strong&gt;Python&lt;/strong&gt; and &lt;strong&gt;TypeScript&lt;/strong&gt; when possible.&lt;/p&gt; 
&lt;p&gt;For .NET Developers checkout &lt;a href="https://github.com/microsoft/Generative-AI-for-beginners-dotnet?WT.mc_id=academic-105485-koreyst"&gt;Generative AI for Beginners (.NET Edition)&lt;/a&gt;!&lt;/p&gt; 
&lt;p&gt;Each lesson also includes a "Keep Learning" section with additional learning tools.&lt;/p&gt; 
&lt;h2&gt;What You Need&lt;/h2&gt; 
&lt;h3&gt;To run the code of this course, you can use either:&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://aka.ms/genai-beginners/azure-open-ai?WT.mc_id=academic-105485-koreyst"&gt;Azure OpenAI Service&lt;/a&gt; - &lt;strong&gt;Lessons:&lt;/strong&gt; "aoai-assignment"&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://aka.ms/genai-beginners/gh-models?WT.mc_id=academic-105485-koreyst"&gt;GitHub Marketplace Model Catalog&lt;/a&gt; - &lt;strong&gt;Lessons:&lt;/strong&gt; "githubmodels"&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://aka.ms/genai-beginners/open-ai?WT.mc_id=academic-105485-koreyst"&gt;OpenAI API&lt;/a&gt; - &lt;strong&gt;Lessons:&lt;/strong&gt; "oai-assignment"&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Basic knowledge of Python or TypeScript is helpful - *For absolute beginners check out these &lt;a href="https://aka.ms/genai-beginners/python?WT.mc_id=academic-105485-koreyst"&gt;Python&lt;/a&gt; and &lt;a href="https://aka.ms/genai-beginners/typescript?WT.mc_id=academic-105485-koreyst"&gt;TypeScript&lt;/a&gt; courses&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;A GitHub account to &lt;a href="https://aka.ms/genai-beginners/github?WT.mc_id=academic-105485-koreyst"&gt;fork this entire repo&lt;/a&gt; to your own GitHub account&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We have created a &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/00-course-setup/README.md?WT.mc_id=academic-105485-koreyst"&gt;Course Setup&lt;/a&gt;&lt;/strong&gt; lesson to help you with setting up your development environment.&lt;/p&gt; 
&lt;p&gt;Don't forget to &lt;a href="https://docs.github.com/en/get-started/exploring-projects-on-github/saving-repositories-with-stars?WT.mc_id=academic-105485-koreyst"&gt;star (🌟) this repo&lt;/a&gt; to find it easier later.&lt;/p&gt; 
&lt;h2&gt;🧠 Ready to Deploy?&lt;/h2&gt; 
&lt;p&gt;If you are looking for more advanced code samples, check out our &lt;a href="https://aka.ms/genai-beg-code?WT.mc_id=academic-105485-koreyst"&gt;collection of Generative AI Code Samples&lt;/a&gt; in both &lt;strong&gt;Python&lt;/strong&gt; and &lt;strong&gt;TypeScript&lt;/strong&gt;.&lt;/p&gt; 
&lt;h2&gt;🗣️ Meet Other Learners, Get Support&lt;/h2&gt; 
&lt;p&gt;Join our &lt;a href="https://aka.ms/genai-discord?WT.mc_id=academic-105485-koreyst"&gt;official Azure AI Foundry Discord server&lt;/a&gt; to meet and network with other learners taking this course and get support.&lt;/p&gt; 
&lt;p&gt;Ask questions or share product feedback in our &lt;a href="https://aka.ms/azureaifoundry/forum"&gt;Azure AI Foundry Developer Forum&lt;/a&gt; on Github.&lt;/p&gt; 
&lt;h2&gt;🚀 Building a Startup?&lt;/h2&gt; 
&lt;p&gt;Visit &lt;a href="https://www.microsoft.com/startups"&gt;Microsoft for Startups&lt;/a&gt; to find out how to get started building with Azure credits today.&lt;/p&gt; 
&lt;h2&gt;🙏 Want to help?&lt;/h2&gt; 
&lt;p&gt;Do you have suggestions or found spelling or code errors? &lt;a href="https://github.com/microsoft/generative-ai-for-beginners/issues?WT.mc_id=academic-105485-koreyst"&gt;Raise an issue&lt;/a&gt; or &lt;a href="https://github.com/microsoft/generative-ai-for-beginners/pulls?WT.mc_id=academic-105485-koreyst"&gt;Create a pull request&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;📂 Each lesson includes:&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;A short video introduction to the topic&lt;/li&gt; 
 &lt;li&gt;A written lesson located in the README&lt;/li&gt; 
 &lt;li&gt;Python and TypeScript code samples supporting Azure OpenAI and OpenAI API&lt;/li&gt; 
 &lt;li&gt;Links to extra resources to continue your learning&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🗃️ Lessons&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;#&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;Lesson Link&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;Description&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;Video&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;Extra Learning&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;00&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/00-course-setup/README.md?WT.mc_id=academic-105485-koreyst"&gt;Course Setup&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Learn:&lt;/strong&gt; How to Setup Your Development Environment&lt;/td&gt; 
   &lt;td&gt;Video Coming Soon&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst"&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;01&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/01-introduction-to-genai/README.md?WT.mc_id=academic-105485-koreyst"&gt;Introduction to Generative AI and LLMs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Learn:&lt;/strong&gt; Understanding what Generative AI is and how Large Language Models (LLMs) work.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/gen-ai-lesson-1-gh?WT.mc_id=academic-105485-koreyst"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst"&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;02&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/02-exploring-and-comparing-different-llms/README.md?WT.mc_id=academic-105485-koreyst"&gt;Exploring and comparing different LLMs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Learn:&lt;/strong&gt; How to select the right model for your use case&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/gen-ai-lesson2-gh?WT.mc_id=academic-105485-koreyst"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst"&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;03&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/03-using-generative-ai-responsibly/README.md?WT.mc_id=academic-105485-koreyst"&gt;Using Generative AI Responsibly&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Learn:&lt;/strong&gt; How to build Generative AI Applications responsibly&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/gen-ai-lesson3-gh?WT.mc_id=academic-105485-koreyst"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst"&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;04&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/04-prompt-engineering-fundamentals/README.md?WT.mc_id=academic-105485-koreyst"&gt;Understanding Prompt Engineering Fundamentals&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Learn:&lt;/strong&gt; Hands-on Prompt Engineering Best Practices&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/gen-ai-lesson4-gh?WT.mc_id=academic-105485-koreyst"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst"&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;05&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/05-advanced-prompts/README.md?WT.mc_id=academic-105485-koreyst"&gt;Creating Advanced Prompts&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Learn:&lt;/strong&gt; How to apply prompt engineering techniques that improve the outcome of your prompts.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/gen-ai-lesson5-gh?WT.mc_id=academic-105485-koreyst"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst"&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;06&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/06-text-generation-apps/README.md?WT.mc_id=academic-105485-koreyst"&gt;Building Text Generation Applications&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Build:&lt;/strong&gt; A text generation app using Azure OpenAI / OpenAI API&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/gen-ai-lesson6-gh?WT.mc_id=academic-105485-koreyst"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst"&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;07&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/07-building-chat-applications/README.md?WT.mc_id=academic-105485-koreyst"&gt;Building Chat Applications&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Build:&lt;/strong&gt; Techniques for efficiently building and integrating chat applications.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/gen-ai-lessons7-gh?WT.mc_id=academic-105485-koreyst"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst"&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;08&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/08-building-search-applications/README.md?WT.mc_id=academic-105485-koreyst"&gt;Building Search Apps Vector Databases&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Build:&lt;/strong&gt; A search application that uses Embeddings to search for data.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/gen-ai-lesson8-gh?WT.mc_id=academic-105485-koreyst"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst"&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;09&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/09-building-image-applications/README.md?WT.mc_id=academic-105485-koreyst"&gt;Building Image Generation Applications&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Build:&lt;/strong&gt; An image generation application&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/gen-ai-lesson9-gh?WT.mc_id=academic-105485-koreyst"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst"&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;10&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/10-building-low-code-ai-applications/README.md?WT.mc_id=academic-105485-koreyst"&gt;Building Low Code AI Applications&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Build:&lt;/strong&gt; A Generative AI application using Low Code tools&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/gen-ai-lesson10-gh?WT.mc_id=academic-105485-koreyst"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst"&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;11&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/11-integrating-with-function-calling/README.md?WT.mc_id=academic-105485-koreyst"&gt;Integrating External Applications with Function Calling&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Build:&lt;/strong&gt; What is function calling and its use cases for applications&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/gen-ai-lesson11-gh?WT.mc_id=academic-105485-koreyst"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst"&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;12&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/12-designing-ux-for-ai-applications/README.md?WT.mc_id=academic-105485-koreyst"&gt;Designing UX for AI Applications&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Learn:&lt;/strong&gt; How to apply UX design principles when developing Generative AI Applications&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/gen-ai-lesson12-gh?WT.mc_id=academic-105485-koreyst"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst"&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;13&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/13-securing-ai-applications/README.md?WT.mc_id=academic-105485-koreyst"&gt;Securing Your Generative AI Applications&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Learn:&lt;/strong&gt; The threats and risks to AI systems and methods to secure these systems.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/gen-ai-lesson13-gh?WT.mc_id=academic-105485-koreyst"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst"&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;14&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/14-the-generative-ai-application-lifecycle/README.md?WT.mc_id=academic-105485-koreyst"&gt;The Generative AI Application Lifecycle&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Learn:&lt;/strong&gt; The tools and metrics to manage the LLM Lifecycle and LLMOps&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/gen-ai-lesson14-gh?WT.mc_id=academic-105485-koreyst"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst"&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;15&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/15-rag-and-vector-databases/README.md?WT.mc_id=academic-105485-koreyst"&gt;Retrieval Augmented Generation (RAG) and Vector Databases&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Build:&lt;/strong&gt; An application using a RAG Framework to retrieve embeddings from a Vector Databases&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/gen-ai-lesson15-gh?WT.mc_id=academic-105485-koreyst"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst"&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/16-open-source-models/README.md?WT.mc_id=academic-105485-koreyst"&gt;Open Source Models and Hugging Face&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Build:&lt;/strong&gt; An application using open source models available on Hugging Face&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/gen-ai-lesson16-gh?WT.mc_id=academic-105485-koreyst"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst"&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;17&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/17-ai-agents/README.md?WT.mc_id=academic-105485-koreyst"&gt;AI Agents&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Build:&lt;/strong&gt; An application using an AI Agent Framework&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/gen-ai-lesson17-gh?WT.mc_id=academic-105485-koreyst"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst"&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;18&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/18-fine-tuning/README.md?WT.mc_id=academic-105485-koreyst"&gt;Fine-Tuning LLMs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Learn:&lt;/strong&gt; The what, why and how of fine-tuning LLMs&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/gen-ai-lesson18-gh?WT.mc_id=academic-105485-koreyst"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst"&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;19&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/19-slm/README.md?WT.mc_id=academic-105485-koreyst"&gt;Building with SLMs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Learn:&lt;/strong&gt; The benefits of building with Small Language Models&lt;/td&gt; 
   &lt;td&gt;Video Coming Soon&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst"&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;20&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/20-mistral/README.md?WT.mc_id=academic-105485-koreyst"&gt;Building with Mistral Models&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Learn:&lt;/strong&gt; The features and differences of the Mistral Family Models&lt;/td&gt; 
   &lt;td&gt;Video Coming Soon&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst"&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;21&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/generative-ai-for-beginners/main/21-meta/README.md?WT.mc_id=academic-105485-koreyst"&gt;Building with Meta Models&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Learn:&lt;/strong&gt; The features and differences of the Meta Family Models&lt;/td&gt; 
   &lt;td&gt;Video Coming Soon&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst"&gt;Learn More&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;🌟 Special thanks&lt;/h3&gt; 
&lt;p&gt;Special thanks to &lt;a href="https://www.linkedin.com/in/john0isaac/"&gt;&lt;strong&gt;John Aziz&lt;/strong&gt;&lt;/a&gt; for creating all of the GitHub Actions and workflows&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.linkedin.com/in/bernhard-merkle-738b73/"&gt;&lt;strong&gt;Bernhard Merkle&lt;/strong&gt;&lt;/a&gt; for making key contributions to each lesson to improve the learner and code experience.&lt;/p&gt; 
&lt;h2&gt;🎒 Other Courses&lt;/h2&gt; 
&lt;p&gt;Our team produces other courses! Check out:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/mcp-for-beginners?WT.mc_id=academic-105485-koreyst"&gt;&lt;strong&gt;NEW&lt;/strong&gt; Model Context Protocol for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/ai-agents-for-beginners?WT.mc_id=academic-105485-koreyst"&gt;AI Agents for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/Generative-AI-for-beginners-dotnet?WT.mc_id=academic-105485-koreyst"&gt;Generative AI for Beginners using .NET&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/genai-js-course?WT.mc_id=academic-105485-koreyst"&gt;Generative AI for Beginners using JavaScript&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/ml-beginners?WT.mc_id=academic-105485-koreyst"&gt;ML for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/datascience-beginners?WT.mc_id=academic-105485-koreyst"&gt;Data Science for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/ai-beginners?WT.mc_id=academic-105485-koreyst"&gt;AI for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/Security-101??WT.mc_id=academic-96948-sayoung"&gt;Cybersecurity for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/webdev-beginners?WT.mc_id=academic-105485-koreyst"&gt;Web Dev for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/iot-beginners?WT.mc_id=academic-105485-koreyst"&gt;IoT for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/xr-development-for-beginners?WT.mc_id=academic-105485-koreyst"&gt;XR Development for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/GitHubCopilotAI?WT.mc_id=academic-105485-koreyst"&gt;Mastering GitHub Copilot for AI Paired Programming&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/mastering-github-copilot-for-dotnet-csharp-developers?WT.mc_id=academic-105485-koreyst"&gt;Mastering GitHub Copilot for C#/.NET Developers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/CopilotAdventures?WT.mc_id=academic-105485-koreyst"&gt;Choose Your Own Copilot Adventure&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>libsdl-org/SDL</title>
      <link>https://github.com/libsdl-org/SDL</link>
      <description>&lt;p&gt;Simple Directmedia Layer&lt;/p&gt;&lt;hr&gt;&lt;p&gt;Simple DirectMedia Layer (SDL for short) is a cross-platform library designed to make it easy to write multi-media software, such as games and emulators.&lt;/p&gt; 
&lt;p&gt;You can find the latest release and additional information at: &lt;a href="https://www.libsdl.org/"&gt;https://www.libsdl.org/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Installation instructions and a quick introduction is available in &lt;a href="https://raw.githubusercontent.com/libsdl-org/SDL/main/INSTALL.md"&gt;INSTALL.md&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;This library is distributed under the terms of the zlib license, available in &lt;a href="https://raw.githubusercontent.com/libsdl-org/SDL/main/LICENSE.txt"&gt;LICENSE.txt&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Enjoy!&lt;/p&gt; 
&lt;p&gt;Sam Lantinga (&lt;a href="mailto:slouken@libsdl.org"&gt;slouken@libsdl.org&lt;/a&gt;)&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>trailofbits/buttercup</title>
      <link>https://github.com/trailofbits/buttercup</link>
      <description>&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Buttercup Cyber Reasoning System (CRS)&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/trailofbits/buttercup/actions/workflows/tests.yml"&gt;&lt;img src="https://github.com/trailofbits/buttercup/actions/workflows/tests.yml/badge.svg?sanitize=true" alt="Tests" /&gt;&lt;/a&gt; &lt;a href="https://github.com/trailofbits/buttercup/actions/workflows/tests.yml"&gt;&lt;img src="https://github.com/trailofbits/buttercup/actions/workflows/tests.yml/badge.svg?event=schedule" alt="Tests (Nightly)" /&gt;&lt;/a&gt; &lt;a href="https://github.com/trailofbits/buttercup/actions/workflows/integration.yml"&gt;&lt;img src="https://github.com/trailofbits/buttercup/actions/workflows/integration.yml/badge.svg?sanitize=true" alt="Integration" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Buttercup&lt;/strong&gt; is a Cyber Reasoning System (CRS) developed by &lt;strong&gt;Trail of Bits&lt;/strong&gt; for the &lt;strong&gt;DARPA AIxCC (AI Cyber Challenge)&lt;/strong&gt;. Buttercup finds and patches software vulnerabilities in open-source code repositories like &lt;a href="https://github.com/tob-challenges/example-libpng"&gt;example-libpng&lt;/a&gt;. It starts by running an AI/ML-assisted fuzzing campaign (built on oss-fuzz) for the program. When vulnerabilities are found, Buttercup analyzes them and uses a multi-agent AI-driven patcher to repair the vulnerability. &lt;strong&gt;Buttercup&lt;/strong&gt; system consists of several components:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Orchestrator&lt;/strong&gt;: Coordinates the overall task process and manages the workflow&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Seed Generator&lt;/strong&gt;: Creates inputs for vulnerability discovery&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Fuzzer&lt;/strong&gt;: Discovers vulnerabilities through intelligent fuzzing techniques&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Program Model&lt;/strong&gt;: Analyzes code structure and semantics for better understanding&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Patcher&lt;/strong&gt;: Generates and applies security patches to fix vulnerabilities&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;System Requirements&lt;/h2&gt; 
&lt;h3&gt;Minimum Requirements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;CPU:&lt;/strong&gt; 8 cores&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Memory:&lt;/strong&gt; 16 GB RAM&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Storage:&lt;/strong&gt; 100 GB available disk space&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Network:&lt;/strong&gt; Stable internet connection for downloading dependencies&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Buttercup uses third-party AI providers (LLMs from companies like OpenAI, Anthropic and Google), which cost money. Please ensure that you manage per-deployment costs by using the built-in LLM budget setting.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Buttercup works best with access to models from OpenAI &lt;strong&gt;and&lt;/strong&gt; Anthropic, but can be run with at least one API key from one third-party provider (support for Gemini coming soon).&lt;/p&gt; 
&lt;h3&gt;Supported Systems&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Linux x86_64&lt;/strong&gt; (fully supported)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ARM64&lt;/strong&gt; (partial support for upstream Google OSS-Fuzz projects)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Required System Packages&lt;/h3&gt; 
&lt;p&gt;Before setup, ensure you have these packages installed:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Ubuntu/Debian
sudo apt-get update
sudo apt-get install -y make curl git

# RHEL/CentOS/Fedora
sudo yum install -y make curl git
# or
sudo dnf install -y make curl git

# MacOS
brew install make curl git
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Supported Targets&lt;/h3&gt; 
&lt;p&gt;Buttercup works with:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;C source code repositories&lt;/strong&gt; that are OSS-Fuzz compatible&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Java source code repositories&lt;/strong&gt; that are OSS-Fuzz compatible&lt;/li&gt; 
 &lt;li&gt;Projects that build successfully and have existing fuzzing harnesses&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone the repository with submodules:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone --recurse-submodules https://github.com/trailofbits/buttercup.git
cd buttercup
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Run automated setup (Recommended)&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make setup-local
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This script will install all dependencies, configure the environment, and guide you through the setup process.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; If you prefer manual setup, see the &lt;a href="https://raw.githubusercontent.com/trailofbits/buttercup/main/MANUAL_SETUP.md"&gt;Manual Setup Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Start Buttercup locally&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make deploy-local
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;Verify local deployment:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make status
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When a deployment is successful, you should see all pods in "Running" or "Completed" status.&lt;/p&gt; 
&lt;ol start="5"&gt; 
 &lt;li&gt;Send Buttercup a simple task&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; When tasked, Buttercup will start consuming third-party AI resources.&lt;/p&gt; 
&lt;p&gt;This command will make Buttercup pull down an example repo &lt;a href="https://github.com/tob-challenges/example-libpng"&gt;example-libpng&lt;/a&gt; with a known vulnerability. Buttercup will start fuzzing it to find and patch vulnerabilities.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make send-libpng-task
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="6"&gt; 
 &lt;li&gt;Access Buttercup's web-based GUI&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make web-ui
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then navigate to &lt;code&gt;http://localhost:31323&lt;/code&gt; in your web browser.&lt;/p&gt; 
&lt;p&gt;In the GUI you can monitor active tasks and see when Buttercup finds bugs and generates patches for them.&lt;/p&gt; 
&lt;ol start="7"&gt; 
 &lt;li&gt;Stop Buttercup&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; This is an important step to ensure Buttercup shuts down and stops consuming third-party AI resources.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make undeploy
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Accessing Logs&lt;/h2&gt; 
&lt;p&gt;Buttercup includes local SigNoz deployment by default for comprehensive system observability. You can access logs, traces, and metrics through the SigNoz UI:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make signoz-ui
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then navigate to &lt;code&gt;http://localhost:33301&lt;/code&gt; in your web browser to view:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Distributed traces&lt;/li&gt; 
 &lt;li&gt;Application metrics&lt;/li&gt; 
 &lt;li&gt;Error monitoring&lt;/li&gt; 
 &lt;li&gt;Performance insights&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you configured LangFuse during setup, you can also monitor LLM usage and costs there.&lt;/p&gt; 
&lt;p&gt;For additional log access methods, see the &lt;a href="https://raw.githubusercontent.com/trailofbits/buttercup/main/QUICK_REFERENCE.md"&gt;Quick Reference Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Additional Resources&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/trailofbits/buttercup/main/QUICK_REFERENCE.md"&gt;Quick Reference Guide&lt;/a&gt; - Common commands and troubleshooting&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/trailofbits/buttercup/main/MANUAL_SETUP.md"&gt;Manual Setup Guide&lt;/a&gt; - Detailed manual installation steps&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/trailofbits/buttercup/main/AKS_DEPLOYMENT.md"&gt;AKS Deployment Guide&lt;/a&gt; - Production deployment on Azure&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/trailofbits/buttercup/main/CONTRIBUTING.md"&gt;Contributing Guidelines&lt;/a&gt; - Development workflow and standards&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/trailofbits/buttercup/main/deployment/README.md"&gt;Deployment Documentation&lt;/a&gt; - Advanced deployment configuration&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/trailofbits/buttercup/main/CUSTOM_CHALLENGES.md"&gt;Writing Custom Challenges&lt;/a&gt; - Custom project configuration and setup&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
  </channel>
</rss>